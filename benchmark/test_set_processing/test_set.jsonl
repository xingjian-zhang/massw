{"pid": "13b7ef9c-bdd6-4294-b9a2-32412308a40f", "context": "Large databases often contain a vast amount of data, with some of it being corrupted, leading to difficulties in finding representative data entries and refining the data for further use.", "key_idea": "The paper proposes a method for discovering informative patterns from data, which can reduce large databases to only a few representative data entries and clean databases containing corrupted data.", "method": "The method includes on-line and off-line algorithms, which are experimentally checked on databases of handwritten images.", "outcome": "The proposed method managed to discover informative patterns and clean corrupted data from handwritten image databases. However, the abstract doesn't provide specific metrics or results.", "future_impact": "The paper suggests that the general applicability of the proposed framework makes it a promising candidate for new applications in knowledge discovery, potentially improving efficiency in data management and analysis.", "venue": "SIGKDD", "year": 1996, "title": "Discovering informative patterns and data cleaning"}
{"pid": "104d6c92-1e04-467f-b362-fcc260b2ef0d", "context": "Time series motifs are approximately repeated patterns found within data and have been applied in areas such as medicine, motion capture, robotics, and meteorology. However, the existing definitions and algorithms are brittle to slight changes of uniform scaling or the speed at which patterns develop.", "key_idea": "This paper introduces a new algorithm for time series motifs discovery that offers invariance to uniform scaling, enabling it to detect patterns regardless of how fast they develop.", "method": "The authors stress test the new algorithm by applying it to several domains where time series motifs have been used before.", "outcome": "The proposed algorithm produces objectively superior results in several important domains as it can handle slight changes in the speed of pattern development.", "future_impact": "The proposed method simplifies the motif discovery process by significantly reducing the number of parameters that need to be specified, which may streamline future advancements in the field.", "venue": "SIGKDD", "year": 2007, "title": "Detecting time series motifs under uniform scaling"}
{"pid": "62b3da1f5aee126c0fb1b5e0", "context": "In team sports like soccer and basketball, understanding team tactics often involves analyzing team formations. Existing approaches, however, assume formations remain consistent throughout the match or assign formations frame-by-frame, contradicting real-world scenarios.", "key_idea": "The authors introduce SoccerCPD, a change-point detection framework that differentiates between deliberate tactical formation and role changes and temporary changes in soccer matches.", "method": "The authors first assign player roles frame-by-frame and conduct two-step change-point detections: (1) formation change-point detection based on the sequence of role-adjacency matrices and (2) role change-point detection based on the sequence of role permutations.", "outcome": "The evaluation of SoccerCPD using ground truth annotations from domain experts showcases that the method accurately identifies points of tactical changes and estimates the formation and role assignments per segment.", "future_impact": "Practical use-cases introduced in the study that can be easily interpreted and utilized by domain participants may lead to more informed tactical decision-making in soccer and similar sports.", "venue": "SIGKDD", "year": 2022, "title": "SoccerCPD: Formation and Role Change-Point Detection in Soccer Matches Using Spatiotemporal Tracking Data"}
{"pid": "5181795a-4ce6-40ca-b230-2cf42c546c42", "context": "The emergence of eTextbooks has brought about significant opportunities for improving educational practices, but there have been both positive and negative reports about their use in academic settings.", "key_idea": "This study explores the concept of eTextbooks, with a focus on stakeholders' opinions on the features and functions of eTextbooks that could be implemented in K-12 classes.", "method": "A three-round Delphi study was conducted with 56 respondents including administrators, teachers, students, parents, and researchers from 14 organizations in Beijing. They then tested eTextbooks in real classes at two primary schools.", "outcome": "The study identified 18 features and functions of eTextbooks that could be beneficial, covering a range of dimensions such as structure and layout, interactive media, note-taking tools, assignment tools and management tools. The results also showed that eTextbooks could keep the instructional process running as smoothly as before.", "future_impact": "This study might encourage more comprehensive implementation of eTextbooks in K-12 classes with specific attention paid to the identified beneficial features and functions.", "venue": "SIGKDD", "year": 2013, "title": "The Concept of eTextbooks in K-12 Classes from the Perspective of Its Stakeholders"}
{"pid": "cbfe80b5-d968-4a98-8900-52bffc2ada19", "context": "Network science has emerged as an interdisciplinary field due to the complexity in social, biological and economical systems arising from pairwise interactions, leading to a surge in interest in understanding networks.", "key_idea": "This tutorial focuses on the presentation of popular random-graph models used for modeling real-world networks and algorithmic techniques for mining large graphs, with emphasis on extracting graph sparsifiers, partitioning graphs into densely connected components, and finding dense subgraphs.", "method": "The tutorial is based on a review and presentation of the most popular random-graph models and efficient algorithmic techniques for mining large graphs, driven by real-world applications.", "outcome": "The tutorial uncovers the intuition behind key ideas in the areas of modeling and mining large graphs.", "future_impact": "The tutorial presents potential future research directions in modeling and mining of large graphs.", "venue": "SIGKDD", "year": 2013, "title": "Algorithmic techniques for modeling and mining large graphs (AMAzING)"}
{"pid": "6303540590e50fcafd7ccc23", "context": "New physical systems often have limited data for model training, necessitating effective knowledge transfer from other relevant grids. Domain adaptation (DA) seeks domain-invariant features to boost model performance in the target domain. However, existing DA techniques face significant challenges such as complex spatial-temporal correlations, diverse data sources, and large-scale data sizes.", "key_idea": "The authors propose a novel cross-graph DA based on two core designs: graph kernels and graph coarsening. They create a Graph kerNel-based distribution Adaptation (GNA) with a custom-designed graph kernel that integrates spatial structures, temporal trends, measurement similarity, and label information to determine the similarity of two graphs.", "method": "The authors prove that the proposed graph kernel is positive definite and universal. They also propose a coarsening process to reduce the computation cost of the kernel for large systems. The GNA is tested on diverse systems, including power systems, mass-damper systems, and human-activity sensing systems.", "outcome": "The authors successfully demonstrate the superiority of GNA in diversified systems, outperforming other methods.", "future_impact": "The authors suggest that their novel cross-graph DA can effectively handle the challenges posed by physical datasets, suggesting its potential for broad applications in physical systems.", "venue": "SIGKDD", "year": 2022, "title": "Domain Adaptation in Physical Systems via Graph Kernel"}
{"pid": "d72be03e-cd15-43e0-abb8-65f28164df1f", "context": "The evolving field of spatial pattern mining has a clear demand for a flexible spatial pattern mining language to allow easy pattern specification. However, an easy to use and understand visual pattern language has not been catered to yet.", "key_idea": "This paper defines a new pattern mining language, CSPML, designed specifically for specifying spatial patterns. Alongside, it proposes a visual interface that extends traditional visual languages and is intended to allow users to specify patterns visually.", "method": "The authors seemingly propose the language and interface without explicitly outlining a methods or validation approach.", "outcome": "The outcome is the proposed pattern mining language, CSPML, and a designed visual interface for pattern specification.", "future_impact": "The CSPML language and the improved visual interface, by enabling users to specify complex spatial patterns, could impact the field of spatial pattern mining and could be further implemented or extended in future work.", "venue": "SIGKDD", "year": 2007, "title": "A language and a visual interface to specify complex spatial patterns"}
{"pid": "6303503190e50fcafd7681fc", "context": "Empirical variance is a fundamental concept that is often used in data management and analytics. The calculation of empirical variance usually involves scanning the entire data table, which is computationally expensive and inefficient for large data sets. Existing solutions use block sampling, but they provide no theoretical guarantee, and estimations can be inaccurate due to potential block correlation.", "key_idea": "The authors explore how to provide approximation guarantees for empirical variance with block sampling from a theoretical perspective. If the records stored in a table are 4-wise independent to each other, a slightly modified block sampling method can provide the same approximation guarantee with the same asymptotic sampling cost as independent random sampling.", "method": "The authors present their approximate algorithm for empirical variance and an approximate top-k algorithm and conduct extensive experiments to evaluate the efficiency of their methods.", "outcome": "The approximate algorithm for empirical variance and an approximate top-k algorithm, based on the proposed sampling strategy, outperforms existing solutions by up to an order of magnitude.", "future_impact": "For data analysis on tables that are exported from hash-based storage in modern commercial database systems, the authors' strategy can be integrated to significantly improve sampling efficiency.", "venue": "SIGKDD", "year": 2022, "title": "Efficient Approximate Algorithms for Empirical Variance with Hashed Block Sampling"}
{"pid": "64af9a073fda6d7f065a6d31", "context": "Out-of-distribution (OOD) detection, which aims to identify OOD samples in test data, is an essential problem in machine learning. While much work has been done on Euclidean data, the problem remains under-explored in graph-structured data. Various studies have attempted graph OOD detection, but all require training a graph neural network from scratch, which comes with a high computational cost.", "key_idea": "This work is the first attempt to give a well-trained graph neural network (GNN) the ability to detect OODs without modifying its parameters. For this, an Adaptive Amplifier for Graph OOD Detection (AAGOD) framework is proposed, which emphasizes key patterns helpful for graph OOD detection, thereby increasing the gap between OOD and in-distribution graphs.", "method": "The AAGOD framework introduces a parameterized amplifier matrix to the adjacency matrix of the input graph. A Learnable Amplifier Generator (LAG) is designed to customize amplifiers for different graphs and a Regularized Learning Strategy (RLS) is used to train parameters without needing OOD data. Various existing GNN models are then used to encode the amplified graphs into vector representations and pre-defined scoring functions convert these representations into detection scores.", "outcome": "Experimental results show that the AAGOD can be applied to various GNNs to enable OOD detection. When compared to the state-of-the-art, AAGOD shows a 6.21% relative enhancement in AUC and trains 34 times faster.", "future_impact": "The proposed AAGOD framework provides a way to improve the OOD detection ability of various well-trained GNNs. Its efficiency and performance enhancement indicate its potential in addressing the OOD detection problem in graph-structured data.", "venue": "SIGKDD", "year": 2023, "title": "A Data-centric Framework to Endow Graph Neural Networks with Out-Of-Distribution Detection Ability."}
{"pid": "60d996c80abde95dc965f66f", "context": "Podcasts have been emerging as a new medium for sharing and broadcasting information over the Internet and the need for information access systems that allow efficient discovery from a heterogeneous collection of music and podcasts has been growing. However, research on information access in such domains remains limited.", "key_idea": "This study conducts a large-scale log analysis to study and compare podcast and music search behavior on Spotify, subsequently proposing a transformer-based neural instant search model that retrieves items from a heterogeneous collection of music and podcast content, utilizing multi-task learning to optimize both a ranking objective and a query intent type identification objective.", "method": "The authors perform a large-scale log analysis to study user behavior on Spotify. Following this data collection, they propose and implement a transformer-based neural instant search model.", "outcome": "Their analysis found fundamental differences in user behavior when searching for podcasts compared to music. The proposed neural instant search model significantly outperforms strong baselines for both podcast and music queries.", "future_impact": "The proposed approach could help improve podcast search performance, addressing the identified need for better search systems in this growing area of digital content.", "venue": "SIGKDD", "year": 2021, "title": "Neural Instant Search for Music and Podcast"}
{"pid": "b53b9c93-11d2-4d5b-8d44-1a5c9c09e6ae", "context": "Website traffic varies through time in consistent and predictable ways, and it is important to present repeat visitors with new content to keep them coming back. However, balancing the goal of keeping a website fresh and the need to present the best content to the most visitors at peak times remains a challenge.", "key_idea": "In this paper, an efficient algorithm is proposed to balance the needs of keeping a website updated with new content and presenting the best content to visitors at peak times by maximizing total clicks, taking into account the overall traffic pattern and time varying clickthrough rates of available media content.", "method": "The authors formulate the problem as the media scheduling problem and apply this algorithm to real data obtained from server logs.", "outcome": "The method shows evidence of significant improvements in traffic from the implemented algorithmic schedules according to the analysis of data collected from server logs.", "future_impact": "The applied methodology might provide insights into how the clickthrough rate for new content declines as it ages.", "venue": "SIGKDD", "year": 2009, "title": "Optimizing web traffic via the media scheduling problem"}
{"pid": "8990e41f-00b5-4ae9-923a-261e4a2d6e94", "context": "Recent research in privacy-preserving data mining (PPDM) has vastly increased due to the applications of data mining and the need for privacy protection. Most existing methods assume that all parties involved operate semi-honestly, without collusion.", "key_idea": "This paper considers the issue of collusion in PPDM, where some parties may share their records to deduce the private information of other parties. The authors propose a new method to ensure full privacy, where no sensitive information of a party will be revealed even if all other parties collude.", "method": "The proposed method is applied to a general problem in PPDM -- secure computations of functions of secure summations of data spread across multiple parties. The performance of the proposed method is evaluated in terms of running time and ability to solve PPDM problems.", "outcome": "The proposed method demonstrates full privacy preservation even in the case of collusion, with a scalable running time of O(m). It also exhibits enhanced security and tackles a large number of problems in Privacy-Preserving Data Mining.", "future_impact": "The method proposed in this paper could significantly enhance the security of privacy-preserving data mining by providing a solution that is resilient to collusion and scales efficiently.", "venue": "SIGKDD", "year": 2010, "title": "Collusion-resistant privacy-preserving data mining"}
{"pid": "33ea4dbb-6b6c-4ed4-b756-336e68b57421", "context": "The complexity of treatment decisions for patients with relapsed or resistant Hodgkin's Disease, including bone marrow transplants, has led to a need for determining influencing factors using data analysis techniques.", "key_idea": "The authors aim to implement the Knowledge Discovery in Databases (KDD) process, including techniques for data reduction, data cleansing, and data mining, on the EBMT database to uncover factors that influence the success of bone marrow transplants for Hodgkin's Disease.", "method": "The authors apply various techniques of the KDD process, including data cleansing, data reduction, and data mining to the EBMT database. Techniques include the use of induction rules, artificial neural networks, and association rules.", "outcome": "Using these methods, the authors discovered several nuggets of knowledge, including induction rules that potentially allow for outcome prediction based on patient characteristics, important attributes identified by the artificial neural networks, and association rules that indicate co-occurring patient characteristics for different outcomes.", "future_impact": "This knowledge could potentially be useful in predicting the outcome of bone marrow transplants for patients with Hodgkin's Disease based on their characteristics.", "venue": "SIGKDD", "year": 1998, "title": "Knowledge discovery in medical databases: what factors influence a successful bone marrow transplant for Hodgkin's disease"}
{"pid": "43c315ae-6a3e-45ae-bda0-9271a2751036", "context": "Typical approaches to learning retrieval functions for search engines require training data generated from expert relevance judgments, which is expensive and difficult to apply.", "key_idea": "This paper develops a method that utilizes clickthrough data for training, namely the query-log of the search engine in connection with the log of links the users clicked on in the presented ranking.", "method": "A method is proposed grounded on a Support Vector Machine (SVM) approach for learning retrieval functions, which is shown to be well-founded in a risk minimization framework. The effectiveness of this approach is validated in a controlled experiment.", "outcome": "The method is shown to be feasible for large sets of queries and features, and can effectively adapt the retrieval function of a meta-search engine to a particular group of users, outperforming Google in terms of retrieval quality after only a couple of hundred training examples.", "future_impact": "The utilization of abundant and low-cost clickthrough data to optimize the retrieval quality of search engines can reduce the dependency on expert relevance judgments, hence has the potential to simplify and improve the efficiency of search engines in the future.", "venue": "SIGKDD", "year": 2002, "title": "Optimizing search engines using clickthrough data"}
{"pid": "60d996c80abde95dc965f661", "context": "Point Of Interest Auto-Completion (POI-AC) is a featured function in the Baidu Maps search engine, but despite using a user's profile and input prefixes for personalized POI suggestions, the state-of-the-art approach, P^3AC, still falls short in generating personalized, time- and geography-aware suggestions.", "key_idea": "The researchers propose a meta-learned, end-to-end spatial-temporal POI-AC (ST-PAC) module, and an efficient MapReduce algorithm to overcome the challenge of the long-tail distribution of time- and location-specific data on POI-AC.", "method": "A benchmark was drawn from large-scale search logs at Baidu Maps to test the offline performance of the meta-learned ST-PAC model. The metrics used for assessment are Mean Reciprocal Rank (MRR), Success Rate (SR) and normalized Discounted Cumulative Gain (nDCG).", "outcome": "MST-PAC consistently improved these metrics, reducing the average number of keystrokes in a POI-AC session, increasing user satisfaction. It handles billions of POI-AC requests daily as it has been deployed in production at Baidu Maps.", "future_impact": "By proving to be a practical and robust solution for large-scale POI Search, MST-PAC's usage could increase significantly in the future as it has demonstrated that it can overcome the long-tailed problem and quickly adapt to cold-start POI-AC tasks with fewer examples.", "venue": "SIGKDD", "year": 2021, "title": "Meta-Learned Spatial-Temporal POI Auto-Completion for the Search Engine at Baidu Maps"}
{"pid": "5ee8986891e011e66831c381", "context": "Although quantum computing has advanced significantly, finding suitable applications remains a challenge. Quantum machine learning, especially the Quantum-assisted Variational Autoencoder (QVAE), holds promise but its real-world applicability still needs to be validated.", "key_idea": "The paper explores the real-world application of QVAE by proposing a method for similarity search in large-scale high-dimensional datasets, which is traditionally challenging.", "method": "The authors construct a space-efficient search index based on the latent space representation of a QVAE and conduct experiments on the Moderate Resolution Imaging Spectroradiometer (MODIS) dataset.", "outcome": "The authors observed a correlation between the Hamming distance in the embedded space and the Euclidean distance in the original space of the dataset. They found real-world speedups compared to linear search and demonstrated memory-efficient scaling to half a billion data points.", "future_impact": "This work could pioneer quantum computing applications in machine learning, thereby enhancing the efficiency of similarity searches in large, high-dimensional datasets.", "venue": "SIGKDD", "year": 2020, "title": "High-Dimensional Similarity Search with Quantum-Assisted Variational  Autoencoder"}
{"pid": "9972bf73-dc51-4756-912e-3709920b9733", "context": "The study of ideal point estimation, a method to understand the ideological positions and voting behavior of legislators, is common in political science and computer science. Typically, legislators are assigned a global ideal position based on their voting or other social behavior. The challenge is that people often have different positions on various policy dimensions.", "key_idea": "This paper introduces a new topic-factorized ideal point estimation model for a legislative voting network, which provides ideal points of legislators and bills for each policy topic rather than assigning them a global one. The generation of topics is guided by the voting matrix as well as the textual information contained in the bills.", "method": "An iterative learning algorithm is proposed to learn the topics of the bills as well as the topic-factorized ideal points of the legislators and bills. Comparisons are made with pre-existing ideal point estimation models to measure the performance of this new model.", "outcome": "The proposed topic-factorized ideal point estimation model demonstrates better explanation power in terms of held-out log-likelihood and other metrics in comparison to existing models. Case studies show that the topic-factorized ideal points align with human intuition.", "future_impact": "The paper illustrates how these topic-factorized ideal points may be used in the future to predict voting results for unseen bills.", "venue": "SIGKDD", "year": 2014, "title": "Topic-factorized ideal point estimation model for legislative voting network"}
{"pid": "888c57fb-395c-4fbd-b04e-7b538e6aadf0", "context": "Learning the information diffusion model is a fundamental problem in studying information diffusion in social networks. Existing approaches learn the diffusion models from events in social networks but do not distinguish between events caused by the social influence from those caused by external trends.", "key_idea": "The paper introduces an approach for extracting social events from data streams in social networks, and using these events to improve the learning of information diffusion models.", "method": "The authors propose a LADP (Latent Action Diffusion Path) model to incorporate the information diffusion model with the model of external trends and design an EM-based algorithm to infer the diffusion probabilities, the external trends and the sources of events efficiently.", "outcome": "The details about the performance or results of the proposed LADP model are absent from the abstract.", "future_impact": "The implication is that the authors' work might offer a more accurate model for learning and predicting information diffusion in social networks, though they do not explicitly state this.", "venue": "SIGKDD", "year": 2013, "title": "Extracting social events for learning better information diffusion models"}
{"pid": "60b6d5e891e011903fc2b86b", "context": "In e-commerce platforms, providing good advertising experiences for advertisers by reducing their trial-and-error costs in discovering the optimal advertising strategies is crucial. Traditionally, the advertising platform needs to identify the advertiser's optimization objectives and then recommend the corresponding strategies to fulfill the objectives.", "key_idea": "The paper proposes an enhanced strategy recommendation system that learns advertisers' preferences over various advertising performance indicators and their optimization objectives via their adoption of different recommended advertising strategies.", "method": "The authors first deploy a prototype of strategy recommender system on the Taobao display advertising platform. They then augment this system by learning the advertisers' preferences using contextual bandit algorithms. They conduct simulation experiments based on Taobao online bidding data to test this system.", "outcome": "The initial deployment of the prototype increased both the advertisers' performance and the platform's revenue. Further, the simulation experiments show that the augmented system can effectively optimize the strategy adoption rate of advertisers.", "future_impact": "The proposed system has the potential to significantly enhance the effectiveness of online advertising by personalizing strategy recommendations to advertisers' preferences and objectives, potentially boosting both advertiser satisfaction and platform revenue.", "venue": "SIGKDD", "year": 2021, "title": "We Know What You Want: An Advertising Strategy Recommender System for Online Advertising"}
{"pid": "5c0afaa7-5bf1-4de3-8f25-814606a79fc6", "context": "Traditional frequent episode mining (FEM) treats all events as equally important, assumes a single occurrence of an event type at any time point, and typically focuses on simple event sequences where different events don't occur simultaneously. This doesn't reflect real application scenarios leading to loss of valuable information such as profit utilities.", "key_idea": "The authors propose a new framework incorporating the concept of utility into episode mining, allowing different events to have varying importance and to occur simultaneously - a problem of mining high utility episodes from complex event sequences that has not been explored yet.", "method": "The authors devise a new algorithm called UP-Span (Utility ePisodes mining by Spanning prefixes) that incorporates several features and strategies to manage challenges such as the absence of anti-monotone property and the large set of candidate episodes.", "outcome": "Experimental results, performed using real and synthetic datasets, show that UP-Span performs excellently and effectively addresses the problem of mining high utility episodes from complex event sequences.", "future_impact": "The proposed framework and the UP-Span algorithm provide a new direction for data mining research and applications, potentially improving profitability and effectiveness in various fields.", "venue": "SIGKDD", "year": 2013, "title": "Mining high utility episodes in complex event sequences"}
{"pid": "baacec85-d0a6-4838-9e17-2f966d184ec8", "context": "Community detection is a crucial task for analysing social networks. Modularity-based methods for community detection have gained popularity, however, they suffer from a well-known issue of resolution limit.", "key_idea": "This paper proposes a connection between modularity-based methods and correlation analysis by subtly reformulating mathematical formulas and aims to tackle the resolution limit problem of modularity-based methods in community detection by making full use of correlation analysis.", "method": "The authors modify the objective function of modularity-based community detection methods through correlation analysis. They carry out a theoretical analysis on the upper boundary of different objective functions, followed by practical tests on real and simulated data.", "outcome": "The paper provides a theoretically analysed upper bound for various objective functions, enabling an understanding of their bias to different community sizes. The experiments further validate these findings.", "future_impact": "This paper opens up an effective way to tackle the resolution limit problem in modularity-based community detection methods, which could shape the future approaches in the field of community detection in social networks.", "venue": "SIGKDD", "year": 2014, "title": "Community detection in graphs through correlation"}
{"pid": "85fdb861-4e89-4cfd-a334-fe4e5fbb7009", "context": "Current state-of-the-art correlation clustering approaches are sensitive to the initial set of seeds chosen and do not yield the optimal result in the presence of noise, which is a challenge when finding correlation clusters in the arbitrary subspaces of high-dimensional data.", "key_idea": "The authors propose RObust SEedless Correlation Clustering (ROSECC), an algorithm which does not require the selection of the initial set of seeds, and incrementally partitions the data, applying PCA to each partition independently.", "method": "They validate their approach on both synthetic and real-world datasets, and test the robustness of their method in the presence of significant noise levels in the data.", "outcome": "Experimental results demonstrated that the proposed method was effective and showed robustness in the presence of significant noise levels in the data.", "future_impact": "ROSECC \u2014 having no need for initial seed selection, an incremental partitioning approach, and automatic determination of cluster dimensionality \u2014 could address limitations of current correlation clustering approaches in handling high-dimensional data and noise.", "venue": "SIGKDD", "year": 2010, "title": "A robust seedless algorithm for correlation clustering"}
{"pid": "62a6aabf5aee126c0ff3694a", "context": "Computer simulations are frequently used across scientific and engineering fields, often with varying levels of sophistication for a balance between accuracy and efficiency. Existing multi-fidelity surrogate modeling methods, which merge outputs of different simulation levels, use Gaussian processes that have limitations in dealing with high dimensional settings due to strong kernel function assumptions.", "key_idea": "This paper introduces a new model, Multi-fidelity Hierarchical Neural Processes (MF-HNP), a flexible and scalable neural latent variable model that is designed for multi-fidelity surrogate modeling.", "method": "The authors evaluate the performance of MF-HNP using epidemiology and climate modeling tasks. They compare these results with those of existing methods.", "outcome": "The proposed MF-HNP model demonstrated competitive accuracy and uncertainty estimation results. Moreover, it proved efficient for dealing with high-dimensional complex simulations, with numbers reaching over 7000 for epidemiology modeling and 45000 for climate modeling, showcasing an improvement over deep Gaussian Processes.", "future_impact": "The superior performance of MF-HNP in handling high-dimensional tasks indicates its potential for accelerating similar high-dimensional complex simulations in science and engineering, especially in the fields of epidemiology and climate modeling.", "venue": "SIGKDD", "year": 2022, "title": "Multi-fidelity Hierarchical Neural Processes"}
{"pid": "62a013775aee126c0ff68fda", "context": "Embedding models, which provide low-dimensional vector representations of objects, are fundamental for modern machine learning systems. However, when these models are regularly updated to improve performance on their intended tasks, the new embeddings are incompatible with models of consumer teams that use the embeddings for different, unintended tasks. The result is either the unfeasible retirement of historical embeddings or the costly retraining of all consumer models.", "key_idea": "To address the issue of backward compatibility in embedding version updates, the authors propose a method of learning backward compatible embeddings, where a lightweight transformation is learned in tandem with a new embedding model to align the new embedding to its previous version. This mechanism allows for frequent updates to the embedding model while enabling the latest version to be quickly transformed into any of its historical versions, obviating the need for retraining of consumer models.", "method": "Six different methods conforming to the authors' framework are explored and evaluated in a real-world recommender system application.", "outcome": "The authors found that the best method, BC-Aligner, maintains backward compatibility with existing unintended tasks even after multiple model version updates, while also achieving intended task performance similar to the embedding model that is solely optimized for the intended task.", "future_impact": "This approach to learning backward compatible embeddings has the potential to greatly reduce the costs associated with updating embedding models in industrial settings, as it enables continuous embedding model updates without necessitating costly retraining of consumer models.", "venue": "SIGKDD", "year": 2022, "title": "Learning Backward Compatible Embeddings"}
{"pid": "646d8642d68f896efa0a2b6e", "context": "Automated Machine Learning (AutoML) aims to automate deploying Machine Learning systems with minimal human expertise. It revolves around optimizing the Machine Learning systems pipelines, including preprocessing, augmentations, models, and optimizers. However, existing Pipeline Optimization techniques fail to explore the deep interactions between pipeline stages/components.", "key_idea": "This paper presents a novel neural architecture for capturing the deep interaction between Machine Learning pipeline components. It embeds pipelines into a latent representation through a unique per-component encoder mechanism, which is used with deep-kernel Gaussian Process surrogates inside a Bayesian Optimization setup for pipeline optimization.", "method": "The authors use diverse collections of related datasets (meta-datasets) to meta-learn the pipeline embedding network's parameters. They evaluate the approach through extensive experiments on three large-scale meta-datasets.", "outcome": "The paper shows that the proposed pipeline embeddings yield state-of-the-art results in Pipeline Optimization on three different large-scale meta-datasets.", "future_impact": "This novel approach to capture deep interactions in machine learning pipelines could significantly enhance the capabilities of Automated Machine Learning systems, thereby democratizing AI.", "venue": "SIGKDD", "year": 2023, "title": "Deep Pipeline Embeddings for AutoML"}
{"pid": "5a928758-8b25-4712-878e-536496c135b2", "context": "Neural Networks effectively acquire hidden knowledge in datasets, but represent knowledge in forms humans cannot easily understand; while several rule extraction methods exist, they typically require specialized types of Neural Networks, binary inputs, or are computationally expensive. Craven's technique for extracting MofN type Decision Trees is not deemed suitable for high dimensional real-world problems.", "key_idea": "A new method is introduced for extracting regular C4.5-like Decision Trees from trained Neural Networks (named DecText) considered suitable for handling high dimensional and real world problems.", "method": "The efficacy of the DecText was demonstrated through its application to trained neural networks. Continuous features were handled through a newly introduced discretization technique, while a new pruning technique was used to find the simplest tree with the highest fidelity.", "outcome": "The results show that DecText is effective in extracting high fidelity trees from trained networks.", "future_impact": "The introduced method (DecText) can enhance the human-understandability of knowledge represented in Neural Networks, thus making it easier to interpret, debug or improve the neural models.", "venue": "SIGKDD", "year": 2002, "title": "Extracting decision trees from trained neural networks"}
{"pid": "59f78c98-b4f1-4a01-8c51-c47348d0eb8a", "context": "Estimating local triangle counts accurately in a graph stream without storing the whole graph is a challenging problem and it has wide applications in various fields such as social network analysis, anomaly detection, web mining, etc.", "key_idea": "This paper proposes MASCOT, a memory-efficient and accurate method for local triangle estimation in a graph stream based on edge sampling. It integrates two naive local triangle counting algorithms in a graph stream: MASCOT-C and MASCOT-A.", "method": "The authors conduct extensive experiments to compare the accuracy of MASCOT with the existing algorithm and its own variants, MASCOT-C and MASCOT-A, based on the same number of edges sampled. Moreover, MASCOT was used to identify anomalous patterns in real graphs.", "outcome": "The experimental results show that MASCOT provides better accuracy compared to the existing algorithm as well as its two initial variants for the same number of edges sampled. MASCOT also successfully identified interesting anomalous patterns in real graphs.", "future_impact": "Thanks to MASCOT's ability to accurately estimate local triangle counts in graph streams without storing the whole graph, it can be used for various applications such as anomaly detection and web mining in the future.", "venue": "SIGKDD", "year": 2015, "title": "MASCOT: Memory-efficient and Accurate Sampling for Counting Local Triangles in Graph Streams"}
{"pid": "6303545e90e50fcafd7d3b71", "context": "Currently, Neural Architecture Search (NAS) for Graph Neural Networks (GNN) finds an optimal architecture for a given graph, but it applies this architecture to all nodes in the graph equally, which might be insufficient to handle diverse local patterns in the graph.", "key_idea": "The paper posits the need for a node-wise architecture search for GNN and proposes a framework with parametric controllers that decide the GNN architecture for each node based on its local patterns.", "method": "The authors instantiate the proposed framework with depth, aggregator, and resolution controllers, and elaborate on the learning of the backbone GNN model and the controllers to encourage their cooperation.", "outcome": "The node-wise architecture significantly outperforms state-of-the-art methods on half of the ten real-world datasets tested. The performance improvements were attributed to the impacts of the three controllers.", "future_impact": "The results suggest that node-wise architecture can help GNNs become versatile models, ensuring better performance across diverse datasets.", "venue": "SIGKDD", "year": 2022, "title": "Graph Neural Networks with Node-wise Architecture"}
{"pid": "62f5c4fe90e50fcafde9c808", "context": "Origin-Destination (O-D) travel demand prediction is a fundamental challenge in transportation. Despite recent advancements with spatial-temporal deep learning models, these models struggle with uncertainty and sparsity issues in fine-grained O-D matrices.", "key_idea": "To address the issues of uncertainty and sparsity in O-D travel demand prediction, the paper proposes a Spatial-Temporal Zero-Inflated Negative Binomial Graph Neural Network (STZINB-GNN) that quantifies the uncertainty of the sparse travel demand.", "method": "STZINB-GNN uses diffusion and temporal convolution networks to analyze spatial and temporal correlations, which are then fused to parameterize probabilistic distributions of travel demand. The model is examined using two real-world datasets with various spatial and temporal resolutions.", "outcome": "The results show that the STZINB-GNN performs better than benchmark models, particularly under high spatial-temporal resolutions. This is due to its high accuracy, tight confidence intervals, and interpretable parameters.", "future_impact": "The sparsity parameter of the STZINB-GNN, which can be interpreted physically, is suggested to be potentially beneficial for various transportation applications.", "venue": "SIGKDD", "year": 2022, "title": "Uncertainty Quantification of Sparse Travel Demand Prediction with Spatial-Temporal Graph Neural Networks"}
{"pid": "8b674e01-4120-45e3-bbb8-ee9dfe15038a", "context": "HTML documents have inherent structure and content that can be mined to extract valuable information. However, traditional methods do not take into account factors such as hyperlinking and unlablelling in mining HTML texts, nor do they consider the importance of slot and token weighting in filtering structured documents.", "key_idea": "The study proposes a method to mine HTML documents into structured documents and to filter those structured documents using both slot weighting (considering the relative importance of different information slots) and token weighting (considering the relative importance of different terms).", "method": "The authors used a mining algorithm to find slot-token patterns in HTML documents and a preference computation algorithm employing vector similarity and Bayesian probability to filter structured documents.", "outcome": "Experimental results show that considering hyperlinking and unlablelling is important in mining HTML texts and that slot and token weighting can enhance the performance of structured document filtering.", "future_impact": "The proposed method could improve the efficiency and effectiveness of processing HTML documents, benefiting fields that frequently work with web data.", "venue": "SIGKDD", "year": 2003, "title": "An integrated system of mining HTML texts and filtering structured documents"}
{"pid": "6e0ed6f0-31bb-4a7d-83eb-35d4eced6475", "context": "Online social networks have led to the accumulation of user data, raising issues of privacy and security. Specifically, a challenge arises when sharing or releasing anonymized data without accidentally leaking personally identifiable information (PII), which even sophisticated statistical techniques may not entirely prevent. Recent work showed that anonymizing node identities may not be sufficient to ensure the network's privacy.", "key_idea": "This paper explores the conditions under which de-anonymization of anonymized nodes in a network is possible by introducing a random graph model for a specified version of the de-anonymization problem.", "method": "Their model is parameterized by the expected node degree and a similarity parameter that controls the correlation between two graphs over the same vertex set.", "outcome": "The authors find simple conditions on these parameters delineating the boundary of privacy. They show that the mean node degree only needs to grow slightly faster than log n with network-size n for nodes to be identifiable.", "future_impact": "The insights and results of this study bear policy implications for the sharing of anonymized network information, thereby potentially guiding the creation of more effective data anonymization strategies.", "venue": "SIGKDD", "year": 2011, "title": "On the privacy of anonymized networks"}
{"pid": "2434c8d0-1d70-4745-b440-a001afbd0745", "context": "Current cost-sensitive learning approaches deal with classification problems with varying misclassification costs but face challenges in balancing computational efficiency and predictive performance.", "key_idea": "The authors propose a new method for solving multi-class cost-sensitive learning problems using any binary classification algorithm. The method incorporates the ideas of iterative weighting, data space expansion, and gradient boosting with stochastic ensembles.", "method": "The proposed method is theoretically analyzed for performance and the boosting property, under a weak learning assumption on the component binary classifier. The authors also used benchmark datasets for the empirical evaluation of their method.", "outcome": "Theoretical guarantees concerning the performance of the method are established. Empirical results show that this method outperforms other cost-sensitive learning methods in both predictive performance (cost minimization) and computational efficiency on benchmark data sets.", "future_impact": "The proposed approach potentially introduces a new, effective, and efficient way of solving multi-class cost-sensitive learning problems, which could influence the development of future models and algorithms in the field.", "venue": "SIGKDD", "year": 2004, "title": "An iterative method for multi-class cost-sensitive learning"}
{"pid": "849d46bd-244b-4d68-ab32-6ff3cfa622f4", "context": "Understanding changes in rainfall and temperature patterns over India is an essential aspect of climate research. Traditionally, these changes have been studied individually, without an integration of various methods.", "key_idea": "The paper introduces a comprehensive approach to detect changes in rainfall and temperature patterns over India by utilizing Mann-Kendall trend test, Bayesian change point analysis, and a hidden Markov model. It further introduces a regionalization method to identify areas experiencing similar weather states.", "method": "The authors investigate the data at different temporal and spatial resolutions. They also evaluate the robustness of the detected changes using recent reanalysis datasets.", "outcome": "The study found that all India summer monsoon is stable, whereas the winter or the north-east monsoon is gradually intensifying. An abrupt drop in the winter and spring temperature over north-central India and a gradual increase in the summer temperature over the peninsular India is also detected.", "future_impact": "The approach and findings of this study could be valuable for future climate modelling and research on how changing climatic patterns affect various regions in India.", "venue": "SIGKDD", "year": 2009, "title": "Change detection in rainfall and temperature patterns over India"}
{"pid": "60d996c80abde95dc965f62b", "context": "User information exists in multiple platforms or services, making cross-domain recommendation an important task in industry. However, it is known that users show different preferences in different domains, but existing studies seldom model how domain biases affect user preferences.", "key_idea": "This paper proposes a novel debiasing learning based cross-domain recommendation framework with causal embedding, concentrating on mitigating the domain biases when transferring the user information cross domains.", "method": "The authors design an Inverse-Propensity-Score (IPS) estimator for cross-domain scenario, and introduce three kinds of restrictions for propensity score learning. The authors conduct extensive experiments on both public and industry datasets to verify the effectiveness of the proposed framework.", "outcome": "The results from experiments on both public and industry datasets demonstrated the effectiveness of the proposed debiasing learning based cross-domain recommendation framework.", "future_impact": "The developed framework can be generally applied to various recommendation algorithms for cross-domain recommendation, indicating potential for wide applicability in the industry.", "venue": "SIGKDD", "year": 2021, "title": "Debiasing Learning based Cross-domain Recommendation"}
{"pid": "f96adc87-b1f7-4f88-90f3-7b31ea816e55", "context": "Clipping Web pages, or extracting informative areas, has many applications but most existing methods can either work only on certain types of Web pages, or require extra user efforts in adjusting the outputs. The problem of accurately clipping any type of Web page in a fully automatic way is still largely unaddressed.", "key_idea": "In this study, a novel approach is proposed that leverages the wisdom of crowds to provide accurate recommendations of informative clips on any given web pages. They use knowledge from how previous users clipped similar web pages to formulate a pattern mining problem, mining top-1 qualified pattern, on a transaction database for this recommendation.", "method": "The authors formulated a new pattern mining problem and explored properties on occupancy to further prune the search space for high-efficient pattern mining. The effectiveness of the proposed algorithm was tested on a human-labeled ground truth dataset consisting of 2000 web pages from 100 major Web sites and its efficiency on large synthetic datasets.", "outcome": "The study successfully demonstrates the effectiveness of the proposed algorithm on a human-labeled ground truth dataset and its efficiency on larger synthetic datasets.", "future_impact": "This study introduces a novel method of web page clipping that can handle multiple types of web pages automatically, which might stimulate further research in this domain and automate the process of web page clipping.", "venue": "SIGKDD", "year": 2012, "title": "Harnessing the wisdom of the crowds for accurate web page clipping"}
{"pid": "60d996c80abde95dc965f694", "context": "Molecular lead optimization focuses on generating novel molecules similar to a drug candidate but with enhanced properties. Prior works focused on supervised models requiring datasets of pairs of a molecule and an enhanced molecule, which can be limited by the bias of the specific examples and requirement of large amounts of data.", "key_idea": "In this work, an unsupervised generative approach is proposed with a molecule-embedding component that maps a discrete representation of a molecule to a continuous space and a unique training architecture leveraging molecule fingerprints and applying double cycle constraints.", "method": "The proposed method is evaluated on multiple common molecular optimization tasks, such as dopamine receptor (DRD2) and drug likeness (QED). Ablation experiments were conducted to show the necessity of various components of the model.", "outcome": "The proposed method outperforms previous state-of-the-art baselines and can generate FDA-approved drugs, like Perazine and Clozapine, that it has never encountered before. The system is currently being deployed in the Targeted Drug Delivery and Personalized Medicine laboratories.", "future_impact": "The proposed method is expected to have an impact on generating treatments using nanoparticle-based technology within the domains of Targeted Drug Delivery and Personalized Medicine.", "venue": "SIGKDD", "year": 2021, "title": "Unpaired Generative Molecule-to-Molecule Translation for Lead Optimization"}
{"pid": "e69854c9-a60e-458b-b116-3856c6e48656", "context": "The problem of class imbalance in datasets and the limitation of existing methods in handling this situation are the motivators of this study. Information fusion can be used to improve classification performance but has not been applied in this regard.", "key_idea": "The authors propose to improve the performance of a classifier using a method borrowed from information fusion, where new features are constructed by merging existing numeric features, aiding in classifying minority-class examples.", "method": "New features are created by mapping the numeric values for each feature to a rank and averaging these ranks. The approach is validated on ten datasets, using three learning methods.", "outcome": "The method proposed improves classifier performance and is particularly effective for datasets with class imbalance. The degree of performance improvement varies with the type of learning method employed.", "future_impact": "The method represented in this paper for fusing features to improve classifier performance offers new approaches for dealing with class imbalanced data, potentially affecting research within the areas of machine learning and data analysis.", "venue": "SIGKDD", "year": 2007, "title": "First International Workshop on Mining Multiple Information Sources"}
{"pid": "2f204e1a-dd08-4cc9-a05e-95fe8fe5fa9e", "context": "Prior literature lacks an extensive examination of graph eccentricity estimation algorithms in shared-memory parallel computing environments.", "key_idea": "This study introduces efficient, shared-memory parallel implementations of graph eccentricity estimation algorithms that utilize various techniques, including two-pass breadth-first searches, executing breadth-first searches from specially determined sets of vertices, algorithms based on probabilistic counters, and a well-known 2-approximation algorithm.", "method": "An experimental study was conducted on large undirected real-world graphs to evaluate the shared-memory parallel implementations of the graph eccentricity estimation algorithms.", "outcome": "The experiments demonstrated that the algorithm based on two-pass breadth-first searches performed the best in terms of running time and accuracy, outperforming the other algorithms by up to orders of magnitude.", "future_impact": "The high efficiency and accuracy of the best implementation enable the swift generation of eccentricity estimates for large graphs, which can benefit many applications in large-scale network analysis.", "venue": "SIGKDD", "year": 2015, "title": "An Evaluation of Parallel Eccentricity Estimation Algorithms on Undirected Real-World Graphs"}
{"pid": "ac6967b1-4206-4a16-871a-57583cecba84", "context": "UNICEF Uganda operates U-report, an open-source SMS platform designed to elevate community voices on issues impacting them. With over 200,000 participants sending up to 10,000 unsolicited text messages a week, manual inspection of all messages is no longer sustainable.", "key_idea": "The paper describes an automated message-understanding and routing system developed by IBM for UNICEF that employs recent advances in data mining to effectively process and interpret the high-volume data stream from the U-report platform.", "method": "The authors use recent advances in data mining to get the most out of labelled training data and incorporate domain knowledge from experts. They also discuss trade-offs, design choices and challenges in applying these techniques in a real-world deployment.", "outcome": "This paper doesn't provide specific outcomes or results regarding the efficiency or effectiveness of the proposed system.", "future_impact": "The system could improve the ability of relevant UNICEF departments to understand data in real-time and address issues in a timely manner.", "venue": "SIGKDD", "year": 2013, "title": "Amplifying the voice of youth in Africa via text analytics"}
{"pid": "00773b33-8b0e-4567-af20-0539cf8d644e", "context": "Effective diagnosis of Alzheimer's disease (AD) is of primary importance in biomedical research. Existing studies have shown that AD is closely related to the structure change of the brain network, i.e., the connectivity among different brain regions.", "key_idea": "This paper suggests using the sparse inverse covariance estimation technique for identifying the connectivity among different brain regions, with a novel algorithm based on the block coordinate descent approach that allows for direct estimation of the inverse covariance matrix and the inclusion of user feedback and prior domain knowledge into the estimation process.", "method": "The proposed algorithm is applied to a collection of FDG-PET images from 232 Normal Controls (NC), Mild Cognitive Impairment (MCI), and Alzheimer's disease (AD) subjects.", "outcome": "The experimental results reveal the brain region connectivity differences among the three groups: Normal Controls, Mild Cognitive Impairment, and Alzheimer's disease.", "future_impact": "The proposed algorithm is likely to provide useful imaging-based biomarkers for distinguishing Normal Controls, Mild Cognitive Impairment, and Alzheimer's disease patients.", "venue": "SIGKDD", "year": 2009, "title": "Mining brain region connectivity for alzheimer's disease study via sparse inverse covariance estimation"}
{"pid": "60d996c70abde95dc965f547", "context": "Existing methods for pattern set mining have limitations due to their combinatorial nature of searching the twice-exponential search space over all possible pattern sets - this makes them suitable for data only over hundreds of features and prone to getting stuck in local minima.", "key_idea": "The authors propose a gradient based optimization approach, specifically a novel type of neural autoencoder called BinaPs, which uses binary activations and binarizing weights in each forward pass, to efficiently discover high-quality pattern sets from much larger datasets.", "method": "BinaPs is trained by optimizing a data-sparsity aware reconstruction loss, with continuous versions of the weights learned in small, noisy steps - this formulation creates a link between the discrete search space and continuous optimization, enabling a gradient-based strategy for pattern discovery.", "outcome": "Through experiments on both synthetic and real-world data such as supermarket transactions or biological variant calls, it is demonstrated that BinaPs is capable of discovering high quality, noise-robust patterns and scales well to larger datasets when compared to existing methods.", "future_impact": "This work has potential to contribute towards applications in large-scale data mining tasks, given BinaPs' demonstrated scalability to large datasets and its ability to efficiently discover high-quality pattern sets.", "venue": "SIGKDD", "year": 2021, "title": "Differentiable Pattern Set Mining"}
{"pid": "2a6340e2-1ae8-47b4-917d-49bf889affed", "context": "Data uncertainty is a common issue in various applications due to outdated sources or imprecise measurements. Traditional data mining techniques often ignore this uncertainty, leading to less accurate results.", "key_idea": "The authors propose the UK-means clustering algorithm, which enhances the K-means algorithm to better handle data uncertainty, specifically targeting moving-object uncertainty.", "method": "The authors apply their proposed UK-means clustering algorithm to handle the uncertainty of moving objects, to demonstrate its efficacy.", "outcome": "Experimental results indicate that by considering uncertainty, the UK-means clustering algorithm can produce more accurate results than the standard K-means.", "future_impact": "Improved data mining results when dealing with uncertain data can potentially be achieved by using the proposed UK-means algorithm.", "venue": "SIGKDD", "year": 2006, "title": "Uncertain data mining: an example in clustering location data"}
{"pid": "5c090b94-04d6-41f6-a652-4075f550cab5", "context": "Association Rule Mining is a technique originally proposed for market basket data, and has potential applications in diverse fields, including Remote Sensed Imagery (RSI) data. However, the large size of the image data usually makes it challenging to be mined using existing algorithms in a reasonable amount of time.", "key_idea": "The authors propose an efficient association rule mining method for RSI data using Peano Count Tree (P-tree) structure, a lossless and compressed data representation structure that they had previously proposed.", "method": "The authors create an algorithm, P-ARM, based on P-trees for fast support calculation and provides significant pruning techniques. Experiments to test the efficiency of P-ARM are conducted by comparing its performance with FP-growth and Apriori algorithms.", "outcome": "The experiments reveal that the P-ARM algorithm is more superior for association rule mining on RSI spatial data compared to FP-growth and Apriori algorithms.", "future_impact": "The proposed approach has the potential to improve the mining of data in areas like precision agriculture, community planning, resource discovery and other areas where RSI is relevant.", "venue": "SIGKDD", "year": 2002, "title": "Association Rule Mining on Remotely Sensed Images Using P-trees"}
{"pid": "8e4652f0-3e39-4ad0-9ec6-24a536b0d0ef", "context": "Large enterprise IT infrastructure components generate large volumes of alerts and incident tickets. These are manually screened, but it is otherwise difficult to extract information automatically from them for insights to improve operational efficiency.", "key_idea": "The authors propose a framework to cluster alerts and incident tickets based on the text in them, using unsupervised machine learning. This could eliminate the labor-intensive and costly manual classification process.", "method": "The proposed framework processes the semi-structured text in alerts and the unstructured text in incident tickets. Post text pre-processing and applying appropriate distance metrics, graph-theoretic approaches are used to cluster the alerts and incident tickets. For visualisation, the authors propose a method for semi-structured text and define prototypes for unstructured text clusters.", "outcome": "The framework for clustering and visualization enables enterprises to prioritize the issues in their IT infrastructure and improve their services' reliability and availability.", "future_impact": "The proposed framework has the potential to significantly improve the operational efficiency of large-scale enterprise IT by enabling automatic identification and prioritization of issues.", "venue": "SIGKDD", "year": 2014, "title": "Unveiling clusters of events for alert and incident management in large-scale enterprise it"}
{"pid": "60d996c80abde95dc965f59c", "context": "Metric learning aims to project original data into a space where classification can be more accurate. Current approaches formulate metric learning as a constrained optimization problem to avoid trivial results, these approaches iterate to approximate the optimal solution.", "key_idea": "The authors propose a new formulation of metric learning as a penalized optimization problem with a goal to minimize intra-class distance and maximize inter-class distance simultaneously.", "method": "The authors provide design guidelines, paradigms with a general formula, and two specific instantiations for the penalty term. They also provide an analytical solution for the penalized optimization to avoid costly computation.", "outcome": "Extensive experiments on real-world data sets have been conducted, and the results verify the effectiveness and efficiency of the proposed approach.", "future_impact": "This new metric learning approach can bypass the limitation of costly computations, convergence rates, and approximation ratios present in current methods, making it a potential method for improving classification tasks in real-world datasets.", "venue": "SIGKDD", "year": 2021, "title": "Metric Learning via Penalized Optimization"}
{"pid": "6303512f90e50fcafd77fbb5", "context": "The ride-hailing service offered by mobility-on-demand platforms like Uber and Didi Chuxing focus on efficiency, but this approach tends to ignore the fairness of driver incomes, which impacts the sustainability of the ride-hailing system in the long run.", "key_idea": "This paper aims to use joint order dispatching and driver repositioning to optimize both long-term efficiency and fairness in ride-hailing systems. The authors propose a multi-agent reinforcement learning framework, JDRL, to make distributed order selection and repositioning decisions with a variable action space and adopts max-min fairness.", "method": "The authors test the proposed framework on three public real-world ride-hailing order datasets including over 2 million orders in Haikou, China; over 5 million orders in Chengdu, China; and over 6 million orders in New York City, USA.", "outcome": "Experimental results show that JDRL consistently outperforms state-of-the-art baselines in terms of both efficiency and fairness.", "future_impact": "This work might pave the way for future studies aiming at optimizing efficiency and fairness in ride-hailing systems, as it is the first to exploit joint order dispatching and driver repositioning for these purposes.", "venue": "SIGKDD", "year": 2022, "title": "Optimizing Long-Term Efficiency and Fairness in Ride-Hailing via Joint Order Dispatching and Driver Repositioning"}
{"pid": "aa91b2fe-9abd-4f79-963c-e30700d75cd8", "context": "Recent studies on social network evolution propose generative models which capture only the statistical properties related to node-to-node link formation, but they do not explain group formation.", "key_idea": "The authors propose a novel model capturing the co-evolution of social and affiliation networks, revealing insights into group formation that users often join groups for reasons other than their friends being there.", "method": "The model was applied to several real-world networks, in experiments that captured both newly observed and previously studied network properties.", "outcome": "The model successfully captured both the newly observed and previously studied network properties, providing insights into group formation in social and affiliation networks.", "future_impact": "The proposed model can facilitate controlled experiments to study the effect of actor's behavior on the evolution of affiliation networks and it allows the generation of realistic synthetic datasets.", "venue": "SIGKDD", "year": 2009, "title": "Co-evolution of social and affiliation networks"}
{"pid": "570e29fc-c55b-4cb4-8d25-4b85e3663010", "context": "People take actions to achieve their personal, high-order goals and make decisions based on their personal experience, knowledge, and instinct. However, many lack the necessary experience and knowledge to make good decisions.", "key_idea": "The paper proposes mining the relationship between actions and their outcomes from the aggregated timelines of individuals posting experiential microblog reports as a means of decision support.", "method": "The authors propose an architecture for extracting action-outcome relationships from social media data and techniques for identifying experiential social media messages. They convert them to event timelines and evaluate this in case studies.", "outcome": "The paper includes the analysis and evaluation of action-outcome extraction, although the specific success metrics or results are not mentioned.", "future_impact": "The capability to mine action-outcome relationships from social media data can allow individuals to make decisions based not only on personal experience but also on the experiences reported by a larger community.", "venue": "SIGKDD", "year": 2015, "title": "Towards Decision Support and Goal Achievement: Identifying Action-Outcome Relationships From Social Media"}
{"pid": "5f03f3b611dc830562231fd9", "context": "Existing time series decomposition methods such as RobustSTL struggle to handle multiple seasonal patterns and high computational time, which restricts their practical use.", "key_idea": "The authors extended RobustSTL to handle multiple seasonality and proposed a special generalized ADMM algorithm to reduce its computational complexity.", "method": "The authors provided rigorous proofs to demonstrate convergence and complexity reduction, and they compared their proposed algorithm with other state-of-the-art seasonal-trend decomposition methods including MSTL, STR, TBATS on both synthetic and real-world datasets with single and multiple seasonality.", "outcome": "The experimental results demonstrate that the proposed decomposition algorithm shows superior performance in terms of effectiveness and efficiency compared to other seasonal-trend decomposition methods.", "future_impact": "The improved decomposition algorithm could facilitate time series tasks including anomaly detection, forecasting, and classification.", "venue": "SIGKDD", "year": 2020, "title": "Fast RobustSTL: Efficient and Robust Seasonal-Trend Decomposition for Time Series with Complex Patterns"}
{"pid": "67011197-380b-4dc6-beb5-17b84b8c353b", "context": "Finding natural communities in large-scale linked networks and tracking their changes over time is a challenging problem. Current clustering algorithms can be unstable under small perturbations of the input data and struggle with data where the community structure is not strong.", "key_idea": "The authors have developed an efficient, scalable agglomerative clustering strategy that is aimed to be stable under small perturbations of the input data and can potentially identify natural communities in these networks.", "method": "The authors applied their new clustering strategy to the citation graph of the NEC CiteSeer database, which consists of 250,000 papers and 4.5 million citations.", "outcome": "Some communities were found to be essentially random and unstable, while others were identified as natural and showed stability in most clusterings, demonstrating the potential of this agglomerative clustering strategy.", "future_impact": "This strategy can enable the tracking of the evolution of natural communities over time in large-scale linked networks.", "venue": "SIGKDD", "year": 2003, "title": "Natural communities in large linked networks"}
{"pid": "7c6e79c1-b2e6-4b5a-960f-107ee2cc13e4", "context": "Most research on time series forecasting focuses on point predictions, i.e., estimating the expected value of the target variable for a particular point in time. However, for certain applications, forecasting a range of expected future values is more important.", "key_idea": "This paper studies the prediction of a range of expected values for a future time interval, as opposed to single point prediction. This is particularly relevant in fields where variation and an expected value range is substantial in managing and planning around the target variable.", "method": "The authors describe several possible approaches to this task and propose an alternative procedure which is then tested through extensive experiments on both artificial and real-world domains.", "outcome": "Results from extensive experiments on artificial and real-world domains show clear advantages of the proposed alternative procedure for predicting a range of expected values for a future time interval", "future_impact": "The authors anticipate that their alternative procedure for forecasting a range of expectations will have strong applicability to domains such as wind and electricity power production and customer wallet estimation. This method may improve key decision-making by ensuring more accurate forecasts.", "venue": "SIGKDD", "year": 2011, "title": "2D-interval predictions for time series"}
{"pid": "6303530990e50fcafd7ac1a5", "context": "Recommender systems are fundamental to modern web applications, relying on high-quality user and item representations for personalized recommendations. Recently, self-supervised graph embedding has been used to construct these representations by modeling relational data such as social graphs, membership graphs, and user-item engagements.", "key_idea": "The authors aim to elucidate different families of self-supervised graph embedding approaches, providing insights into various techniques, their merits and demerits, along with discussions on recent work in the field.", "method": "The authors undertake a tutorial-like investigation of different families of self-supervised graph embedding techniques, followed by a demonstration of embedding usage within the realm of industry-scale deep learning recommender systems, specifically in candidate retrieval and ranking tasks.", "outcome": "The authors provide a comprehensive guide on self-supervised graph embedding techniques and demonstrate how to effectively use large embedding tables in industry-scale recommender systems.", "future_impact": "This work can enlighten future practices and research in the recommender system field by offering a detailed understanding of various self-supervised graph embedding techniques and their application in real-world, large-scale recommendation settings.", "venue": "SIGKDD", "year": 2022, "title": "Graph-based Representation Learning for Web-scale Recommender Systems"}
{"pid": "60d996c70abde95dc965f590", "context": "Knowledge tracing (KT), a method of tracing students' changing knowledge state during their learning process, has been greatly impactful in improving students' learning efficiency in online learning systems. However, existing KT methods focus mainly on high accuracy of student performance prediction and neglect the consistency of students' changing knowledge state with their learning process.", "key_idea": "The authors propose a new paradigm, exploring a novel model called Learning Process-consistent Knowledge Tracing (LPKT). This model monitors students' knowledge state by directly modelling their learning process and formalizes the basic learning cell as an exercise---answer time---answer tuple, deeply measuring the learning gain and its diversity.", "method": "The authors model student's learning process through a Learning Process-consistent Knowledge Tracing (LPKT) model, which included a learning gate to distinguish students' absorptive capacity of knowledge and a forgetting gate to model the decline of students' knowledge over time. This was tested on three public datasets.", "outcome": "The model was able to obtain more reasonable knowledge states in line with the learning process and outperforms state-of-the-art KT methods on student performance prediction.", "future_impact": "The work introduces potential future research direction for Knowledge Tracing which offers both high interpretability and accuracy.", "venue": "SIGKDD", "year": 2021, "title": "Learning Process-consistent Knowledge Tracing"}
{"pid": "26426ca2-31ff-4fee-8b13-3ffca4490c3b", "context": "The problem stated is the detection of anomalies in large, weighted graphs, a task for which intuitive rules or guidelines have been unclear.", "key_idea": "The key idea is the proposal of the 'oddball' algorithm, which identifies anomalies in weighted graphs by applying several newly discovered power laws related to density, weights, ranks, and eigenvalues of neighborhood sub-graphs.", "method": "The authors conducted experiments on many real graphs with up to 1.6 million nodes to evaluate the performance of the oddball algorithm.", "outcome": "The algorithm successfully identified unusual nodes in the tested graphs, which were in agreement with intuition.", "future_impact": "The oddball algorithm provides a new and effective way to perform unsupervised anomaly detection in large, weighted graphs, thereby offering potential advancements in related fields.", "venue": "SIGKDD", "year": 2010, "title": "OddBall: spotting anomalies in weighted graphs"}
{"pid": "41dc5f1a-a42d-4ee4-943b-b48cc19ae709", "context": "Prediction markets, which exploit the wisdom of crowds to make forecasts, have been used in diverse contexts from predicting cultural outcomes to business forecasting. However, there's a lack of practical experience in setting up and running these markets, especially in corporate settings.", "key_idea": "The authors share insights and experiences from Ford Motor Company's deployment of one of the largest known corporate prediction markets, which asked questions concerning new vehicle features, sales volumes, pricing, and macroeconomic trends.", "method": "The paper reviews the experience of operating a prediction market at Ford Motor Company, highlighting both successes and failures. It discusses the correlation between predictions made in the market and real-world results.", "outcome": "The authors found both strong and weak correlations between market predictions and actual results. Yet, the benefits of a prediction market extended beyond mere prediction accuracy, including value from comments, trends in stock price changes, overcoming bureaucratic limitations, and aiding decision-making.", "future_impact": "The authors offer advice for establishing and operating prediction markets, which may guide future business entities in employing such markets and may contribute to improved methods for leveraging collective knowledge in businesses.", "venue": "SIGKDD", "year": 2013, "title": "Experience from hosting a corporate prediction market: benefits beyond the forecasts"}
{"pid": "652b52c7-ff3f-400a-864e-bd9167f59571", "context": "Traditional techniques for large-scale regression tasks and detecting anomalies in future sensor data include static red-line limits, variance-based error bars, and general probability density estimation.", "key_idea": "This study proposes a novel combination of greedy input selection and asymmetric cost for learning envelope functions that are suitable for automated detection of anomalies in future sensor data.", "method": "The authors tested the new approach on large-scale regression tasks for learning envelope functions.", "outcome": "The study argues that this new approach can be more effective than traditional techniques.", "future_impact": "The introduced approach could enhance automated detection of anomalies in future sensor data.", "venue": "SIGKDD", "year": 1997, "title": "Mining multivariate time-series sensor data to discover behavior envelopes"}
{"pid": "60d996c70abde95dc965f52d", "context": "The current methods for approximating Betweenness Centrality (BC) of all vertices in a graph lacks efficient bounds on the deviation of the estimates from the actual values.", "key_idea": "The authors introduce Bavarian, a collection of sampling-based algorithms utilizing Monte-Carlo Empirical Rademacher Averages (MCERAs) to approximate Betweenness Centrality (BC) with tight bounds on maximum deviation.", "method": "The authors evaluate Bavarian by comparing it with existing sampling-based estimators of BC, assessing the trade-offs between sample size and accuracy guarantee.", "outcome": "The authors show that their method provides a stronger approximation guarantee than the state of the art due to its use of variance-aware probabilistic tail bounds. They also prove novel sample-complexity results showing dependancy of sample size on vertex-diameter of the graph for achieving approximation guarantee.", "future_impact": "The authors introduce a framework that could facilitate a fair comparison between existing BC estimators, decoupled from the original sample-complexity results they were introduced with. They show potential for extensions to other centrality measures, such as percolation centrality.", "venue": "SIGKDD", "year": 2021, "title": "Bavarian: Betweenness Centrality Approximation with Variance-Aware Rademacher Averages"}
{"pid": "630352af90e50fcafd7a4344", "context": "Efficient vaccine allocation for COVID-19 is urgently needed, especially in large metropolises where health risks vary in nearby neighborhoods. Challenges exist in decision making due to large scale complexity, difficulty in utilizing heterogeneous information from all aspects of the metropolis' contact network, and limited explainability of reinforcement learning strategies.", "key_idea": "The authors propose a reinforcement learning enhanced experts method, which deals with complexity by a specially designed algorithm that aggregates city blocks into communities and hierarchically integrates reinforcement learning among these communities. A self-supervised contact network representation algorithm is designed to fuse the heterogeneous information for efficient vaccine allocation decision making.", "method": "The authors conduct extensive experiments in three metropolises with real-world data to test the proposed method.", "outcome": "Their method outperforms the best baseline by reducing infections by 9.01% and deaths by 12.27%. The authors successfully demonstrated the explainability of the reinforcement learning model.", "future_impact": "This work has potential in bringing credibility to reinforcement learning strategies through explainability, which can aid experts in vaccine allocation for future pandemics.", "venue": "SIGKDD", "year": 2022, "title": "Reinforcement Learning Enhances the Experts: Large-scale COVID-19 Vaccine Allocation with Multi-factor Contact Network"}
{"pid": "9998baec-07ae-4ff4-8187-a5965e6eacc5", "context": "In active learning, there's a scarcity of labeled data because labeling data is often a costly process. The current methods of active learning are primarily pool-based, where a learner can only select examples from a given pool of unlabeled examples for labeling queries. These pool-based methods have several weaknesses.", "key_idea": "The authors propose novel active learning algorithms that construct examples directly to query for labels, bypassing the need for a pool of existing unlabeled examples. They study a specific active learner based on the decision tree algorithm, and a general active learner that can work with any base learning algorithm.", "method": "Testing was conducted using both a specific active learner built on the decision tree algorithm, and a more general version that can be used with any underlying learning algorithm.", "outcome": "The proposed active learning methods have been shown to require fewer label queries to quickly reduce the predictive error, casting doubt on the usefulness of the traditional pool-based approach in active learning.", "future_impact": "Though these algorithms challenge the role of the pool in pool-based active learning, the authors' methods can be easily adapted to work with a given pool of unlabeled examples, promising adaptability in future applications.", "venue": "SIGKDD", "year": 2008, "title": "Active learning with direct query construction"}
{"pid": "34607be0-9938-409d-8176-3566ca3950e5", "context": "Many databases contain or can be enhanced with structural information, and finding repetitive and interesting substructures is a crucial step in extracting knowledge from such databases.", "key_idea": "The authors introduce the SUBDUE system, which employs the minimum description length (MDL) principle to identify substructures that compress the database and represent the data's structural concepts.", "method": "SUBDUE replaces previously-discovered substructures repeatedly to create a hierarchical representation of the data's structural regularities. It incorporates background knowledge to guide the system toward relevant substructures for a specific domain or discovery objective and it uses an inexact graph match to allow for controlled deviations in the instance of a substructure concept.", "outcome": "The authors applied SUBDUE to a variety of domains and discuss methods to combine SUBDUE with non-structural discovery systems.", "future_impact": "The introduction of SUBDUE could influence how future systems are designed to extract knowledge from structurally rich databases, potentially leading to more efficient and directed searching methods.", "venue": "SIGKDD", "year": 1994, "title": "Substructure discovery in the SUBDUE system"}
{"pid": "5f7fdd328de39f0828397f47", "context": "The profile maximum likelihood (PML) distribution is a crucial element in symmetric property estimation, but efficiently computing it has been a challenge.", "key_idea": "The authors propose a novel algorithm for efficiently approximating PML distributions. The algorithm takes advantage of new sparsity structure in approximate PML distributions and includes a novel matrix rounding technique.", "method": "The authors develop a new algorithm, PseudoPML, for estimating various symmetric properties. They also create a simplified and more practical PseudoPML version and evaluate it through empirical methods.", "outcome": "The proposed algorithm matches the efficiencies of existing algorithms for computing PML approximations and performs better when the number of distinct observed frequencies is small. Additionally, they provide an efficient estimator for distributions with small profile entropy.", "future_impact": "The efficient approximately estimation of PML distributions will allow for enhanced estimation of a broad class of symmetric properties and complement the theoretical guarantees of such estimators.", "venue": "NeurIPS", "year": 2020, "title": "Instance Based Approximations to Profile Maximum Likelihood"}
{"pid": "60c190a291e0112cf43c2094", "context": "Recent advances in deep generative models have been impressive, but there is growing concern that deep learning models might be memorizing part of the input data. Previous work has been focused on understanding the nature of this memorization.", "key_idea": "The authors extend a recently proposed measure of memorization for supervised learning to the unsupervised density estimation problem, making it computationally efficient. They also conduct a study on how memorization can occur in probabilistic deep generative models such as variational autoencoders.", "method": "The authors proposed a memorization score measure and used it to understand and demonstrate how memorization occurs in variational autoencoders, an example of probabilistic deep generative models. They also discuss several strategies to limit memorization in practice.", "outcome": "Their studies revealed that the form of memorization to which these models are susceptible differs fundamentally from mode collapse and overfitting, and that the proposed memorization score measures a phenomenon that is not captured by commonly-used nearest neighbor tests.", "future_impact": "The framework provided by this work would aid in better understanding and solving the problematic memorization in probabilistic generative models in future research.", "venue": "NeurIPS", "year": 2021, "title": "On Memorization in Probabilistic Deep Generative Models."}
{"pid": "6268a6795aee126c0f14322d", "context": "Customized vision transformers have been adapted for human pose estimation and have achieved superior performance with elaborate structures. However, the efficacy of plain vision transformers for facilitating pose estimation remains unclear.", "key_idea": "The authors propose ViTPose, a model that uses a plain and non-hierarchical vision transformer together with simple deconvolution decoders for human pose estimation.", "method": "The authors used MAE pretraining with their model and then finetuned it on human pose estimation datasets. The model's performance was evaluated on the MS COCO test-dev set.", "outcome": "ViTPose demonstrated high scalability with respect to models size, flexibility in input resolution and token number, and could be pretrained with unlabeled pose data. The largest model, ViTPose based on the ViTAE-G backbone with 1 billion parameters, achieved the highest mAP of 80.9 on the MS COCO test-dev set. Ensembled models achieved a new state-of-the-art mAP of 81.1.", "future_impact": "The ViTPose model, given its performance, has potential for further enhancements and usage in application domains requiring human pose estimation. Moreover, the open-source nature of their project indicates a platform for others to build upon.", "venue": "NeurIPS", "year": 2022, "title": "ViTPose: Simple Vision Transformer Baselines for Human Pose Estimation"}
{"pid": "5eede0b791e0116a23aafe85", "context": "Matrix sketching is widely used for effective dimensionality reduction in large datasets. Though there are many articles discussing its worst-case performance, guarantees provided typically differ significantly from real-life observations.", "key_idea": "The authors introduced novel techniques providing accurate expressions for the expected value of random projection matrices achieved via sketching, grounded on recent advances in spectral analysis of random matrices.", "method": "The introduced techniques were used to analyse the performance of dimensionality reduction in various standard machine learning tasks like low-rank approximation and iterative stochastic optimization. The study also included sketching methods such as Gaussian and Rademacher sketches in its scope.", "outcome": "The results indicate that the expressions derived are able to reflect the actual performance of these sketching methods even to the extent of lower-order effects and constant factors.", "future_impact": "The successful application of developed techniques could significantly improve understanding and performance prediction of several sketching methods in various machine learning tasks.", "venue": "NeurIPS", "year": 2022, "title": "Precise expressions for random projections: Low-rank approximation and   randomized Newton"}
{"pid": "654d9304939a5f408257eff3", "context": "Generalized Additive Models (GAMs) often use pairwise interactions to maintain accuracy, flexibility, and interpretability, but this creates a computational challenge as the number of terms increases quadratically. Previous approaches that consider sparse pairwise interactions don\u2019t scale well, particularly with added structural interpretability constraints.", "key_idea": "The authors propose the GRAND-SLAMIN framework for learning GAMs with interactions under sparsity and additional structural constraints. This tool offers flexibility, scalability, and accuracy across differentiable loss functions and is implemented using first-order gradient-based optimization and sparse backpropagation.", "method": "The proposed method is validated through numerical experiments on real-world datasets, comparing its performance, variable selection, and scalability with popular toolkits used to fit GAMs with interactions.", "outcome": "The experimental results show that the GRAND-SLAMIN framework performs favorably in terms of performance, variable selection, and scalability when compared with other popular GAM toolkits.", "future_impact": "This work may expand the landscape of interpretable modeling while maintaining prediction accuracy, presenting a competitive alternative to non-interpretable black-box models.", "venue": "NeurIPS", "year": 2023, "title": "GRAND-SLAMIN\u2019 Interpretable Additive Modeling with Structural Constraints"}
{"pid": "654d9d53939a5f40827362f7", "context": "Anomaly detection (AD) is the machine learning task of identifying abnormal samples solely relying on the consistency of normal training samples. When a distribution shift occurs, the assumption that training samples and test samples are drawn from the same distribution breaks down, undermining the effectiveness of AD.", "key_idea": "The authors propose using causal inference tools to increase the resilience of anomaly detection models to different kinds of distribution shifts, illustrated by the derivation of a regularization term conducive to partial distribution invariance across environments.", "method": "The authors evaluate their approach through extensive experiments on synthetic and real-world tasks, covering six different AD methods. They test the performance of models regularized with the proposed term under both covariate and domain shift.", "outcome": "The experimental results show that the use of the new regularization term leads to marked increased robustness of the models under various types of distribution shifts.", "future_impact": "This approach could improve the resilience of Anomaly Detection models in different kinds of distribution shifts, enhancing their performance in real-world applications, particularly ones facing fluctuating data distributions.", "venue": "NeurIPS", "year": 2023, "title": "Invariant Anomaly Detection under Distribution Shifts: A Causal   Perspective"}
{"pid": "507b29e9-046d-4f4b-b42e-c641efb5b7e8", "context": "Invariant feature learning is an ongoing topic in the field of machine learning, where the idea is to learn features that are invariant to specified transformations. Previously, a theory of invariance (I-theory) was introduced as a method for obtaining such features.", "key_idea": "The paper proposes an approach to invariant feature learning based on a novel random feature map derived from I-theory, creating a group invariant signal signature from cumulative distributions of group-transformed random projections.", "method": "The authors prove their proposal theoretically, showing that their feature map defines an expected Haar-integration kernel that is invariant to the specified group action, and that the map approximates this kernel uniformly on a set of N points.", "outcome": "The authors demonstrated that their function space is dense in the Invariant Reproducing Kernel Hilbert Space. They also quantified the error rates of the convergence of the empirical risk minimization and the reduction in sample complexity when using their invariant representation for signal classification.", "future_impact": "The anticipated impact is better signal classification in supervised learning by using this new invariant representation, due to reduced sample complexity and reduced error rates in empirical risk minimization.", "venue": "NeurIPS", "year": 2015, "title": "Learning with group invariant features: a kernel perspective"}
{"pid": "5ef3247a91e0110c353da8e4", "context": "Current Convolutional Neural Networks (CNNs) do not explicitly encode for objects, parts, and their physical properties, limiting their success in tasks requiring a structured understanding of visual scenes.", "key_idea": "The authors introduce Physical Scene Graphs (PSGs) which encode scenes as hierarchical graphs with nodes representing object parts at different scales and edges signifying physical connections between parts. They also propose PSGNet, a network architecture that learns to extract PSGs by reconstructing scenes through a PSG-structured bottleneck.", "method": "PSGNet includes recurrent feedback connections to mingle low and high-level image information, graph pooling, vectorization operations to change spatially-uniform feature maps into object-centric graph structures, and perceptual grouping principles. The architecture's efficiency is assessed against alternative self-supervised scene representation algorithms at scene segmentation tasks.", "outcome": "PSGNet outperformed other self-supervised scene representation algorithms, especially on complex real-world images, and generalized well to unseen object types and scene arrangements. Learned latent attributes captured intuitive scene properties, and the network could learn from physical motion, improving scene estimates for static images.", "future_impact": "The presented work and the use of PSGs have the potential to greatly enhance the understanding and inference of compositional scenes.", "venue": "NeurIPS", "year": 2020, "title": "Learning Physical Graph Representations from Visual Scenes"}
{"pid": "61a885456750f87bf870215d", "context": "Inter-experimental variability is a common issue when integrating data from multiple experiments in systems neuroscience. Modern machine learning approaches offer ways to remove this variability, but their use has been mostly confined to single-cell genomics.", "key_idea": "The authors developed a theoretical framework for domain adaptation in systems neuroscience, which is implemented as an adversarial optimization scheme. This scheme can remove inter-experimental variability while retaining the biological signal.", "method": "The method is compared to previous approaches using a large-scale dataset of two-photon imaging recordings of retinal bipolar cell responses to visual stimuli. They test this both in a supervised setting, where they compare the generalization performance of cell type classifiers across experiments, and in an unsupervised setting.", "outcome": "The method achieved the best trade-off between removing inter-experimental variability and preserving biological signal in both the supervised and unsupervised settings. The efficacy of the method was validated using anatomical cell type distributions from electron microscopy data.", "future_impact": "The adversarial optimization scheme has the potential to improve the integration of datasets in systems neuroscience by reducing inter-experimental variability, thus paving the way for more accurate and generalizable results.", "venue": "NeurIPS", "year": 2021, "title": "Removing Inter-Experimental Variability from Functional Data in Systems Neuroscience."}
{"pid": "6531e2ca939a5f4082f5d695", "context": "Existing agent-centric methods for real-time motion prediction in autonomous driving systems demonstrate impressive performance but suffer from high computational overhead and poor scalability as the number of agents to be predicted increases.", "key_idea": "This study introduces the K-nearest neighbor attention with relative pose encoding (KNARPE), a novel attention mechanism, and the Heterogeneous Polyline Transformer with Relative pose encoding (HPTR), a hierarchical framework enabling asynchronous token update during the online inference.", "method": "The authors test their approach on the Waymo and Argoverse-2 datasets and compare its performance to existing end-to-end methods that do not apply expensive post-processing or model ensembling.", "outcome": "The proposed HPTR model demonstrates superior performance among end-to-end methods that do not apply expensive post-processing or model ensembling, while maintaining the efficiency of scene-centric methods by sharing and reusing contexts among agents.", "future_impact": "The HPTR, with its ability to efficiently predict motions in real-time autonomous driving systems, could be significant in driving advancements in the performance and scalability of these systems.", "venue": "NeurIPS", "year": 2023, "title": "Real-Time Motion Prediction via Heterogeneous Polyline Transformer with   Relative Pose Encoding"}
{"pid": "4704edf5-18a5-4708-be0f-1af56869f9d7", "context": "Color correction is a challenging problem in visual systems, with existing solutions typically relying on standard digital methods.", "key_idea": "The authors have created a new system for color correction based on Land's Retinex theory of color constancy using subthreshold analog CMOS VLSI. The system incorporates custom chips and resistive grids implemented in analog VLSI for smoothing operations.", "method": "The authors designed, built, and tested a system with three custom chips implemented using subthreshold analog CMOS VLSI for color correction.", "outcome": "The Retinex-based color correction system was successfully built and tested, producing colors that closely resemble those produced by the human visual system.", "future_impact": "This study opens avenues for exploring the strengths and weaknesses of the proposed color correction algorithm, offering potential for improvements and application in various visual systems.", "venue": "NeurIPS", "year": 1990, "title": "A VLSI Neural Network for Color Constancy"}
{"pid": "5f05a52391e011c57e3e8ea1", "context": "A common formulation of curiosity-driven exploration in reinforcement learning uses the difference between the real future and the future predicted by a learned model. However, predicting the future can be an inherently difficult task, particularly in the context of stochasticity.", "key_idea": "An alternative form of curiosity is introduced that rewards novel associations between different senses. This method exploits multiple modalities to provide a stronger signal for more efficient exploration, mirroring the natural exploration behaviors in humans where sight and sound play a key role.", "method": "The authors test this approach in several Atari environments and Habitat, a photorealistic navigation simulator, using the audio-visual association model for intrinsically guiding learning agents in the absence of external rewards.", "outcome": "The results show the benefits of using an audio-visual association model for intrinsically guiding learning agents in the absence of external rewards.", "future_impact": "The study provides a new way of rewarding curiosity driven behavior, by rewarding novel associations between senses. This approach has the potential to significantly enhance the efficiency of exploration in reinforcement learning.", "venue": "NeurIPS", "year": 2020, "title": "See, Hear, Explore: Curiosity via Audio-Visual Association"}
{"pid": "651b7e593fda6d7f0631634c", "context": "Current diffusion models are successful in learning complex, high-dimensional data distributions thanks to their capability to construct diffusion processes with analytic transition kernels and score functions. However, there are limitations when the data is confined to a constrained set rather than being in standard Euclidean space.", "key_idea": "The authors propose a method called Mirror Diffusion Models (MDM), capable of generating data on convex constrained sets with the same tractability as existing models, thanks to learning diffusion processes in a dual space made from a mirror map, which is a standard Euclidean space.", "method": "The authors develop methods for efficient computation of mirror maps for popular constrained sets such as simplices and $\\ell_2$-balls, and compare the performance of MDMs with existing methods. They also explore the embedding of invisible but quantitative information (i.e., watermarks) in generated data.", "outcome": "The results show significantly improved performance of Mirror Diffusion Models over existing methods when generating data on constrained sets.", "future_impact": "This work may bring new algorithmic opportunities for learning tractable diffusion on complex domains, and it could potentially be a compelling approach for embedding quantitative information for safety and privacy purposes in generated data.", "venue": "NeurIPS", "year": 2023, "title": "Mirror Diffusion Models for Constrained and Watermarked Generation"}
{"pid": "6350bc6690e50fcafdeceb08", "context": "Optimizing expensive-to-evaluate black-box functions of discrete and potentially continuous design parameters is a common issue. Bayesian Optimization (BO) is a popular approach to address this. But maximizing the acquisition function (AF) over mixed or high-cardinality discrete search spaces using standard gradient-based methods is challenging due to computational constraints.", "key_idea": "The paper proposes using Probabilistic Reparameterization (PR) to solve the challenging issue of Bayesian optimization over discrete and mixed spaces. The core idea is to maximize the expectation of the AF over a probability distribution defined with continuous parameters, instead of directly optimizing the AF on the search space with discrete parameters.", "method": "The authors use mathematical proofs to demonstrate the validity of their approach. They also empirically validate the performance of their suggested approach on a wide range of applications.", "outcome": "The authors proved that their approach maximizes the probabilistic objective and converges to a stationary point of the probabilistic objective under gradient ascent using scalable, unbiased estimators. They also demonstrated state-of-the-art optimization performance in a variety of real-world applications.", "future_impact": "The researchers expect Probabilistic Reparameterization to be complementary to recent work, benefiting, and naturally generalizing to settings with multiple objectives and black-box constraints.", "venue": "NeurIPS", "year": 2022, "title": "Bayesian Optimization over Discrete and Mixed Spaces via Probabilistic   Reparameterization"}
{"pid": "63608e4f90e50fcafdee0fd8", "context": "Randomized controlled trials can be biased due to the problem of interference, where the outcome of one unit depends on the treatment status of other units. Previous methods often focused on a cluster-randomized design, a popular method to mitigate interference, but it has not been well-studied in the one-sided bipartite experiment setting.", "key_idea": "The authors formalize a model for interference in one-sided bipartite experiments using the exposure mapping framework, and propose a minimax optimal design that minimizes the bias of the difference-in-means estimator.", "method": "The framework is exhibited, initially identifying settings where current cluster-randomized designs fail to address interference correctly. Then, the authors showcase their design's optimality and robustness theoretically and experimentally on a variety of interference graphs and potential outcomes models.", "outcome": "The authors provided theoretical and experimental evidence that their design is robust to a variety of interference graphs and potential outcomes models.", "future_impact": "The authors anticipate that their framework and design may impact the field of controlled trials with one-sided bipartite experiments by reducing bias due to interference.", "venue": "NeurIPS", "year": 2022, "title": "Cluster Randomized Designs for One-Sided Bipartite Experiments"}
{"pid": "61a884e66750f87bf87020fa", "context": "Training deep neural networks (DNNs) on parallel hardware devices like GPUs can be difficult due to their limited high-bandwidth memory capacity, leading to increased runtime or decreased accuracy when reducing model or batch size. Current approaches to tackle this issue often resort to lossy compression, but these solutions rely on a hyperparameter search for balancing convergence and compression, which negates time-saving benefits.", "key_idea": "The authors propose an approach, AC-GC, that builds on updated perceptions of Stochastic Gradient Descent convergence. This methodology establishes an upper bound on the expected loss increase during training with compressed activation storage and lets the compression rate automatically adjust to training stages.", "method": "AC-GC\u2019s advantage is explored by comparing it with existing lossy compression techniques. When paired with error-bounded methods, Its performance is evaluated using text and image datasets.", "outcome": "AC-GC, when paired with error-bounded methods, achieves a 15.1x compression rate with an average accuracy change of 0.1% on text and image datasets. By avoiding the necessity for compression rate search, training time is cut down by 4.6x over Successive Halving.", "future_impact": "AC-GC presents a promising future in efficiently training deep neural networks by overcoming memory limitations, implying potential for further improvement and application in the broader realm of machine learning.", "venue": "NeurIPS", "year": 2021, "title": "AC-GC: Lossy Activation Compression with Guaranteed Convergence."}
{"pid": "646edca5d68f896efaddb0ef", "context": "Automatic code generation tools, such as Copilot, are becoming popular. These tools present potential hazards tied to social biases, particularly at the stage of code generation models validation.", "key_idea": "This study unveils and addresses the social bias problem within pretrained code generation models. An innovative framework is proposed for constructing code prompts that reveal social biases in these models.", "method": "The authors devise a new dataset along with three metrics to quantify the severity of social biases in the code generated by the models, and this method is then applied to evaluate three pretrained code generation models (Codex, InCoder, and CodeGen).", "outcome": "The experimentation reveals severe social biases within the three pretrained code generation models. Further analysis also provides consequential insights for selecting code generation models with low social bias.", "future_impact": "This study could influence the development of future code generation models, pushing for the choice of models with lower social bias, thus fostering a more ethical and inclusive approach in automatic code generation.", "venue": "NeurIPS", "year": 2023, "title": "Uncovering and Quantifying Social Biases in Code Generation"}
{"pid": "5f75b31391e0111c1eb4d45f", "context": "Solving generic inverse problems, where one wishes to determine the hidden parameters of a natural system that will give rise to a particular set of measurements, has been approached recently by many deep learning based methods showing impressive results.", "key_idea": "The authors propose evaluating the accuracy of deep learning approaches for solving inverse problems as a function of time instead of a single estimated solution and conceptualize these models as different schemes for efficiently, but randomly, exploring the space of possible inverse solutions.", "method": "The authors compare several state-of-the-art inverse modeling approaches on four benchmark tasks, including two existing tasks, one simple task for visualization and one new task from metamaterial design. They also propose the neural-adjoint solution that uses a deep learning model to approximate the forward model, and then uses backpropagation to search for good inverse solutions.", "outcome": "The neural-adjoint approach achieves the best performance in many scenarios compared to other methods.", "future_impact": "The conception of using time as an evaluation metric and the exploration of the inverse problem might inspire the design of more efficient deep learning models to solve inverse problems.", "venue": "NeurIPS", "year": 2020, "title": "Benchmarking deep inverse models over time, and the neural-adjoint  method"}
{"pid": "63a413f690e50fcafd6d1d3f", "context": "Structured multi-label prediction problems where labels are organized under implication and mutual exclusion constraints have a key requirement - the predictions must be logically consistent with these constraints.", "key_idea": "The authors propose a method to treat structured multi-label prediction as an embedding inference problem, where the constraints are implemented on the embeddings of labels by using geometric construction, specifically employing the hyperbolic Poincar\u00e9 ball model and interpreting labels as Poincar\u00e9 hyperplane.", "method": "The proposed method is evaluated through extensive experiments on 12 datasets evaluating mean average precision, number of constraint violations, and dimensions compared with existing baselines.", "outcome": "The proposed method showed significant improvements in mean average precision, lower number of constraint violations and required an order of magnitude fewer dimensions than baselines.", "future_impact": "While not explicitly stated in the abstract, the approach of treating structured multi-label prediction as an embedding problem could potentially influence the way such problems are tackled in the future, likely extending the proposed method to other similar problems.", "venue": "NeurIPS", "year": 2022, "title": "Hyperbolic Embedding Inference for Structured Multi-Label Prediction"}
{"pid": "634e194190e50fcafd24e7af", "context": "Evaluations of Deep Reinforcement Learning (DRL) methods often use a few instances of Markov Decision Processes (MDPs) to represent the task, but real-world applications often involve large families of MDPs due to variations in the underlying environment.", "key_idea": "This paper suggests augmenting DRL evaluations to consider parameterized families of MDPs rather than select instances, as it could uncover overfitting and provide a more accurate representation of a method's performance across a larger range of scenarios.", "method": "The authors compare the evaluation of DRL methods on select MDP instances and the evaluation on parameterized families of MDPs. This comparison is validated in standard control benchmarks and the real-world application of traffic signal control.", "outcome": "The results demonstrate that evaluating the MDP family often yields a substantially different relative ranking of methods than evaluating select MDP instances, casting doubt on the determination of state-of-the-art methods.", "future_impact": "The findings pose new challenges for empirical rigor in reinforcement learning and importantly, they influence the outcomes of DRL that trickle into downstream decision-making in real-world tasks.", "venue": "NeurIPS", "year": 2022, "title": "The Impact of Task Underspecification in Evaluating Deep Reinforcement   Learning"}
{"pid": "e8473ad5-e433-4fc4-b114-cb1d0439f695", "context": "Neural feature selectivity is commonly characterized using the linear-nonlinear model wherein the neural firing rate is a nonlinear function of relevant stimulus components. Identifying these relevant dimensions is crucial and often involves using a family of objective functions known as Renyi divergences.", "key_idea": "The paper establishes that maximizing Renyi divergence of order 2 is equivalent to least-square fitting of the linear-nonlinear model to neural data. Meanwhile, the smallest reconstruction errors are obtained with Renyi divergence of order 1, which is Kullback-Leibler divergence, equivalent to maximizing mutual information.", "method": "Using Renyi divergences of arbitrary order, the authors perform an asymptotic analysis to calculate the reconstruction errors in the relevant stimuli dimensions. Furthermore, they perform a numerical test on model visual neurons in low signal-to-noise ratio regimes (small number of spikes and increasing neural noise).", "outcome": "Results indicate that both least-square fitting and information maximization optimization schemes perform well even in low signal-to-noise ratio scenarios. However, information maximization provides slightly but significantly better reconstructions than least-square fitting.", "future_impact": "This work bolsters the case for using information-theoretic measures in scenarios where they are not more data limited than methods based on least squares, highlighting its potential usefulness in determining relevant stimulus dimensions and lossy compression.", "venue": "NeurIPS", "year": 2007, "title": "Comparison of objective functions for estimating linear-nonlinear models"}
{"pid": "1be7893e-c4ee-4c73-9fe8-664e7fc6bd94", "context": "Previous work on time series predictions with feed-forward networks has not comprehensively addressed whether the asymptotic behavior of such models is governed by the architecture, regardless the details of the weights.", "key_idea": "The authors analyze hierarchies among classes of architectures with respect to the attractor dimension of the long-term sequences they can generate, ultimately asserting that long-term prediction with such models is governed by attractor dynamics related to the architecture.", "method": "The authors study model feed-forward networks as time series predictors in the stationary limit, focusing on complex but non-chaotic behavior. Analytical solutions are developed for the perceptron with general weights, and multilayer networks are also examined.", "outcome": "The authors find that larger numbers of hidden units can generate higher dimensional attractors. They also establish that the flow is typically one-dimensional for a perceptron and that the relaxation time to the stationary solution scales linearly with the size of the network. In multilayer networks, the number of hidden units provide bounds on the number and dimension of possible attractors.", "future_impact": "This study illuminates the inherent interplay between the architecture and predictability of feed-forward networks, which can improve future model design and understanding of their long-term prediction capabilities.", "venue": "NeurIPS", "year": 1997, "title": "Analytical Study of the Interplay between Architecture and Predictability"}
{"pid": "623d88916750f864fe4c6d0d", "context": "In high-dimensional statistics, the challenge lies in achieving outlier-robust estimation under sparsity constraints, specifically for tasks such as robust sparse mean estimation and robust sparse PCA, which has previously been carried out under more restrictive distributional assumptions.", "key_idea": "A connection is made between outlier-robust high-dimensional statistics and non-convex optimization, and novel optimization formulations for robust sparse mean estimation and robust sparse PCA are developed, which guarantees any approximate stationary point of the optimization problem to yield near-optimal solutions.", "method": "The authors uncover this connection and develop the novel formulations by investigating the robustness of sparse mean estimation and sparse PCA, leveraging the concept of approximate stationary points of the associated optimization problems.", "outcome": "The resulting algorithms were found to be practical and simple, improving upon previous methods by succeeding under broader distributional assumptions.", "future_impact": "Given its success under broader distributional assumptions and simplicity, these newly developed algorithms can become an important tool in practical, high-dimensional statistics and may pave the way for further work in these core tasks.", "venue": "NeurIPS", "year": 2021, "title": "Outlier-Robust Sparse Estimation via Non-Convex Optimization"}
{"pid": "61a8808c6750f82b1762e0bd", "context": "The majority of medial entorhinal cortex (MEC) neurons do not exhibit stereotypical firing patterns associated with specialized cell types like grid, border, and head-direction cells enigmatic about their role in supporting MEC functionality. Existing models fail to encompass these neurons' response profiles, keeping them on the sidelines despite their reliability in response patterns.", "key_idea": "The authors propose a computational approach where they statistically analyze the reliability of heterogeneous MEC cells and use task-optimized neural network models to encapsulate the response profiles of both stereotypical and heterogeneous cells, including grid cells. The authors also introduce a novel MEC model for reward-modulated path integration.", "method": "The authors conducted a statistical analysis of the response patterns of heterogeneous MEC cells, evaluated various models to describe these response profiles, and conducted in silico experiments on these models. A new MEC model that performs reward-modulated path integration was also developed.", "outcome": "The study proved that heterogeneous MEC cells are as reliable as stereotypical cells and that task-optimized neural network models are much better at matching most MEC neuronal response profiles than traditional models and even perform well in novel scenarios. A new MEC model was also effectively developed for reward-modulated path integration which matches neural recordings across variable-reward conditions.", "future_impact": "The findings of the study suggest a conceptually principled, goal-driven modeling approach for encompassing various cell types in future experimental and computational efforts, potentially leading to more holistic and effective models.", "venue": "NeurIPS", "year": 2021, "title": "Explaining heterogeneity in medial entorhinal cortex with task-driven neural networks."}
{"pid": "60c2b89691e0117e30ca26c6", "context": "In deep reinforcement learning (RL), learning good feature representations is crucial. However, with limited experience, she often suffers from data inefficiency for training. For un-experienced or less-experienced trajectories (i.e., state-action sequences), the lack of data limits the use of them for better feature learning.", "key_idea": "The authors propose a method called PlayVirtual, which augments cycle-consistent virtual trajectories to enhance the data efficiency for RL feature representation learning. PlayVirtual predicts future states in a latent space based on the current state and action by a dynamics model and predicts the previous states by a backward dynamics model, forming a trajectory cycle.", "method": "The authors enforce a trajectory to meet the cycle consistency constraint and validate the effectiveness of the method on the Atari and DeepMind Control Suite benchmarks.", "outcome": "PlayVirtual enhances data efficiency and achieves state-of-the-art performance on both Atari and DeepMind Control Suite benchmarks, demonstrating the effectiveness of their designs.", "future_impact": "The PlayVirtual method can be leveraged for better feature learning in environments with limited data experience, potentially fostering advances in deep reinforcement learning applications.", "venue": "NeurIPS", "year": 2021, "title": "PlayVirtual: Augmenting Cycle-Consistent Virtual Trajectories for Reinforcement Learning."}
{"pid": "5f76efa391e011f31b980538", "context": "Stage-wise conservative linear stochastic bandits focus on bandit optimization, which encompasses unknown safety constraints that are crucial in areas like online advertising and medical trials. There is a requirement for the learner to choose actions that not only boost cumulative reward over time but also adhere to a linear baseline constraint that acts as a lower bound on instant reward.", "key_idea": "The paper introduces two new algorithms, stage-wise conservative linear Thompson Sampling (SCLTS) and stage-wise conservative linear UCB (SCLUCB), that uphold the baseline constraints and have probabilistic regret bounds of order O(sqrt{T} * log^{3/2}T) and O(sqrt{T} * log T) respectively.", "method": "The authors present two novel algorithms (SCLTS and SCLUCB) for the problem of stage-wise conservative linear stochastic bandits. They also explore variations of the problem such as constraints with bandit-feedback, or an unknown sequence of baseline actions.", "outcome": "The study establishes that SCLTS can lower the frequency of playing the non-optimal baseline action down to at most O(log T) times as opposed to earlier observed O(sqrt T) times. Also, the paper proves that the SCLUCB stays effective in the scenario of an upper limit on the instant reward after a simple modification.", "future_impact": "The algorithms proposed potentially provide improvements over the current state-of-the-art, enabling better handling of different problem variations and offering crucial insights into safety constraints in online advertising and medical trials.", "venue": "NeurIPS", "year": 2020, "title": "Stage-wise Conservative Linear Bandits"}
{"pid": "f2a3b1ef-02cd-4efb-a3b9-221020b9ef2b", "context": "Kernel classifiers, such as support vector machines (SVM), are the subject of ongoing research, however, issues such as the existence of a regularization parameter in SVMs may influence performance. In addition, statistical performance guarantees for the kernel classifiers are currently insufficient.", "key_idea": "A new kernel classifier is introduced that optimizes the $L_2$ or integrated squared error (ISE) of a difference of densities. This classifier shares features with SVMs but does not involve a regularization parameter, highlighting its distinctiveness.", "method": "The authors provided a statistical performance guarantee for this classifier through the use of a distribution-free concentration inequality for a cross-validation based estimate of the ISE.", "outcome": "The authors proved that the classifier was consistent in the sense of both ISE and probability of error and backed this claim with an oracle inequality.", "future_impact": "These findings could be applied to enhance performance guarantees for an existing method of $L_2$ kernel density estimation.", "venue": "NeurIPS", "year": 2008, "title": "Performance analysis for L_2 kernel classification."}
{"pid": "5ef5c78e91e011b29a6985b7", "context": "Modern neural networks are often seen as complex and difficult to understand because of their nonlinear dependence on data and the nonconvexity in their loss landscapes.", "key_idea": "The authors propose that the early-time learning dynamics of a two-layer fully-connected neural network can be simulated by training a simple linear model on the inputs, challenging the common perception of neural networks as complex entities.", "method": "The authors formally demonstrate this concept for a class of well-behaved input distributions, and extend these arguments to networks with more layers and convolutional architecture, which they validate empirically.", "outcome": "The authors show that simple linear models can mimic the early learning dynamics of larger, more complex neural networks, reducing the complexity of understanding such networks.", "future_impact": "This discovery may lead to better understanding of neural networks, potentially enabling optimized training and improved network architectures, particularly in the early phases of network training.", "venue": "NeurIPS", "year": 2020, "title": "The Surprising Simplicity of the Early-Time Learning Dynamics of Neural Networks"}
{"pid": "633cf5d490e50fcafd7733be", "context": "Most recent self-supervised methods for learning image representations either focus on producing a global feature with invariance properties, or on producing a set of local features. The former works best for classification tasks while the latter is more suitable for detection and segmentation tasks.", "key_idea": "The paper presents a new method called VICRegL that simultaneously learns good global and local features, aiming to provide excellent performance on detection and segmentation tasks while still maintaining good performance on classification tasks.", "method": "Two identical branches of a standard convolutional net architecture are fed two differently distorted versions of the same image. Applying VICReg criterion on pairs of global feature vectors and pairs of local feature vectors occurring before the last pooling layer.", "outcome": "The new method VICRegL demonstrates strong performance on linear classification and segmentation transfer tasks.", "future_impact": "The work expands the feasibility of simultaneously learning global and local features in self-supervised image representation, which could stimulate research to improve performance on various computer vision tasks.", "venue": "NeurIPS", "year": 2022, "title": "VICRegL: Self-Supervised Learning of Local Visual Features"}
{"pid": "5f7fdd328de39f0828397ba0", "context": "In online convex optimization (OCO), the functions are typically assumed to have Lipschitz continuity to obtain sublinear regret. If these functions are also strongly convex, many algorithms give logarithmic regret. There has been recent work on 'relative Lipschitz continuity' and 'relative strong convexity' as generalizations of their classical counterparts.", "key_idea": "This paper explores OCO for relative Lipschitz and relative strongly convex functions, aiming to extend the known regret bounds for classical OCO algorithms to the relative setting.", "method": "The authors assess the regret bounds of classical OCO algorithms, specifically follow the regularized leader algorithms and a variant of online mirror descent, under conditions of relative Lipschitz continuity and relative strong convexity.", "outcome": "The researchers are able to show regret bounds for the function classes under study, extending these results to further include algorithms with extra regularization such as regularized dual averaging.", "future_impact": "With these results, they establish regret bounds for a broad array of OCO algorithms under generalized conditions, potentially informing more flexibly adaptable designs in future online learning models.", "venue": "NeurIPS", "year": 2020, "title": "Regret Bounds without Lipschitz Continuity: Online Learning with Relative-Lipschitz Losses"}
{"pid": "62d620f65aee126c0fad4850", "context": "Video Super-Resolution (VSR) traditionally relies heavily on the alignment of adjacent frames for performance, with most advanced VSR models, including VSR Transformers, featuring well-designed alignment modules.", "key_idea": "The paper challenges the traditional notion of relying on alignment in VSR Transformers and put forth counter-intuitive observations: VSR Transformers can use information from unaligned videos effectively and existing alignment methods can sometimes be detrimental.", "method": "The authors conducted experiments to understand the alignment role in VSR transformers, observing results after removing alignment modules and adopting a larger attention window. They also propose a new alignment method called patch alignment that aligns image patches instead of pixels.", "outcome": "The experiments reveal that VSR Transformers can utilize multi-frame information directly from unaligned videos and existing alignment methods can sometimes be harmful. Further, a VSR Transformer equipped with the proposed patch alignment method exhibited state-of-the-art performance across multiple benchmarks.", "future_impact": "The study provides valuable insights for future work on multi-frame information usage in VSR and selection of alignment methods suitable for different networks/datasets.", "venue": "NeurIPS", "year": 2022, "title": "Rethinking Alignment in Video Super-Resolution Transformers"}
{"pid": "63a413f790e50fcafd6d21b7", "context": "Online convex optimization with hard constraints is a topic that has previously been studied under two different settings, fixed and adversarial constraints. Existing algorithms haven't been able to achieve low regret and violation under both constraints settings simultaneously.", "key_idea": "This paper introduces a new RECtified Online Optimization (RECOO) algorithm that can provide strong performance under both fixed and adversarial constraint settings, representing a versatile and effective approach to online convex optimization with hard constraints.", "method": "The authors validate RECOO by theoretically analyzing its performance in terms of regret and violation in both fixed and adversarial constraints settings, and by comparing its performance with existing algorithms through experiments.", "outcome": "The RECtified Online Optimization algorithm demonstrated superior performance, achieving an order-wise better bounds in both constraint settings. Specifically, in the case of strongly convex loss functions, it achieved $O(\\log T)$ regret and $O(1)$ violation for fixed constraints, and $O(\\log T)$ regret and $O(\\sqrt{T\\log T})$ violation for adversarial constraints.", "future_impact": "The overwhelming success of RECOO, as evidenced by its superior performance under both constraints settings, can potentially impact future research by setting a high benchmark for online convex optimization algorithms with hard constraints.", "venue": "NeurIPS", "year": 2022, "title": "Online Convex Optimization with Hard Constraints: Towards the Best of Two Worlds and Beyond"}
{"pid": "62aa9fb55aee126c0fa5c80b", "context": "While Stochastic gradient descent (SGD) is a widely used optimization algorithm in modern machine learning, the understanding of its computational efficiency and generalization behavior remains unclear. In the specific context of high-dimensional convex quadratics, SGD's convergence rate is similar to full-batch gradient descent and the concept of implicit regularization through SGD lacks clear explanation.", "key_idea": "The authors propose the study of multi-pass SGD dynamics in high-dimensional convex quadratics, where they present the new concept of homogenized SGD (HSGD), a stochastic differential equation which can offer precise elucidation of the learning and risk trajectories.", "method": "The researchers establish an asymptotic equivalence to a stochastic differential equation (HSGD) for studying dynamics of multi-pass SGD. They characterize the solutions in terms of a Volterra integral equation, yielding precise formulas for learning and risk trajectories.", "outcome": "The study reveals a mechanism of implicit conditioning, explaining the efficiency of SGD over Gradient Descent. It is also proven that the noise from SGD negatively impacts generalization performance, denying any potential for implicit regularization in this context. An exact prediction for the excess risk of multi-pass SGD relative to that of streaming SGD (bootstrap risk) is produced.", "future_impact": "The introduction of homogenized SGD and the findings about SGD's efficiency and implicit regularization could guide future optimization strategies in machine learning algorithms and further research in understanding SGD's behavior.", "venue": "NeurIPS", "year": 2022, "title": "Implicit Regularization or Implicit Conditioning? Exact Risk   Trajectories of SGD in High Dimensions"}
{"pid": "5f0d860891e011047aff988b", "context": "Prioritized Experience Replay (PER) is a deep reinforcement learning technique where agents learn from transitions sampled with non-uniform probability proportionate to their temporal-difference error.", "key_idea": "The authors demonstrate that any loss function evaluated with non-uniformly sampled data can be transformed into another uniformly sampled loss function with the same expected gradient.", "method": "The key idea is empirically tested with several MuJoCo and Atari environments, and the modified equivalents of PER using this new loss function.", "outcome": "In some environments, PER can be replaced entirely by the transformed loss function without impacting empirical performance. The proposed modifications to PER and the equivalent loss function showed effectiveness in several test environments.", "future_impact": "These findings suggest a new branch of improvements to Prioritized Experience Replay by correcting its uniformly sampled loss function equivalent.", "venue": "NeurIPS", "year": 2020, "title": "An Equivalence between Loss Functions and Non-Uniform Sampling in  Experience Replay"}
{"pid": "629ec1f85aee126c0fb6f4f5", "context": "While deep learning has greatly advanced monocular human reconstruction, existing methods such as parametric models, voxel grids, meshes, and implicit neural representations, struggle to achieve high-quality results and real-time speed simultaneously.", "key_idea": "The authors propose Fourier Occupancy Field (FOF), a novel 3D representation for monocular human reconstruction that retains the topology and neighborhood relation in the 2D domain, bridges the gap between 3D geometries and 2D images, and is compatible with 2D convolutional neural networks.", "method": "Based on the FOF, the first 30+FPS high-fidelity real-time monocular human reconstruction framework is designed and it is demonstrated on a public dataset and real captured data.", "outcome": "The FOF representation allowed high fidelity, real-time human reconstruction frame rates above 30 FPS, demonstrating its effectiveness with both public datasets and real recorded data.", "future_impact": "The authors plan to release the code for research purposes. The FOF is flexible and extensible, indicating that parametric models can be integrated into it as a prior to generate more robust results in the future.", "venue": "NeurIPS", "year": 2022, "title": "FOF: Learning Fourier Occupancy Field for Monocular Real-time Human   Reconstruction"}
{"pid": "34eeb712-a6f2-4ffc-975a-d1528253f758", "context": "Current models struggle to identify the dynamics of new task instances, limiting their ability to adapt to variations in tasks.", "key_idea": "The authors propose a framework that discovers latent factors, enabling the rapid identification of the dynamics of a new task, thus aiding an agent to adapt to task variations more flexibly.", "method": "The method used to investigate and validate the key idea is not mentioned in the abstract.", "outcome": "The outcome of the study is not specifically stated in the abstract.", "future_impact": "The anticipated impact of this work is that it could allow an agent to adapt more flexibly to variations in tasks.", "venue": "NeurIPS", "year": 2012, "title": "Transfer Learning by Discovering Latent Task Parametrizations"}
{"pid": "6125b6a95244ab9dcb41d8b6", "context": "Large-scale, two-sided matching platforms need to find market outcomes that align with user preferences while simultaneously learning these preferences from data. Classical notions of stability are of limited value in the learning setting, as preferences are inherently uncertain and destabilizing while they are being learned.", "key_idea": "The authors propose a framework and algorithms for learning stable market outcomes under uncertainty. The primary setting is matching with transferable utilities where the platform matches agents and sets monetary transfers between them.", "method": "The authors design an incentive-aware learning objective that captures the distance from a market outcome to equilibrium. They analyze the complexity of learning as a function of preference structure, casting learning as a stochastic multi-armed bandit problem.", "outcome": "Algorithmically, they show that 'optimism in the face of uncertainty', the principle underlying many bandit algorithms, applies to a primal-dual formulation of matching with transfers and leads to near-optimal regret bounds.", "future_impact": "This work is a first step toward elucidating when and how stable matchings arise in large, data-driven marketplaces.", "venue": "NeurIPS", "year": 2023, "title": "Learning Equilibria in Matching Markets with Bandit Feedback."}
{"pid": "61a887f16750f87bf8702243", "context": "The problem of learning the representations of a whole graph without human supervision has been a long-standing issue. Current self-supervised learning methods necessitate the design of 'views' for model training, which requires the expertise of human experts.", "key_idea": "Inspired by adversarial training, the authors propose an adversarial self-supervised learning (GASSL) framework that learns unsupervised representations of graph data without requiring any handcrafted views.", "method": "GASSL generates challenging views by adding perturbations to the input and is adversarially trained with respect to the encoder. It optimizes a min-max problem and employs a gradient accumulation strategy to expedite the training process.", "outcome": "Experimental results on ten graph classification datasets demonstrate that the GASSL approach surpasses state-of-the-art self-supervised learning baselines.", "future_impact": "The GASSL has the potential to transform how self-supervised learning is implemented, eliminating the need for expert-designed views and improving performance across diverse graph classification datasets.", "venue": "NeurIPS", "year": 2021, "title": "Graph Adversarial Self-Supervised Learning."}
{"pid": "5f7fdd328de39f0828397e47", "context": "Priority dispatching rule (PDR) is commonly used to solve real-world Job-shop scheduling problems (JSSP), but designing effective PDRs requires specialized knowledge and often results in limited performance.", "key_idea": "The authors propose using an end-to-end deep reinforcement learning agent to automatically learn PDRs for JSSP, using a Graph Neural Network-based scheme for embedding the problem states encountered while solving the JSSP.", "method": "The authors apply a deep reinforcement learning method to solve real-world Job-shop scheduling problems, using a Graph Neural Network based scheme to represent problem states.", "outcome": "The experiments indicate that the proposed system can learn high-quality PDRs from scratch, and its performance compared favorably against the best existing PDRs. The learned policies also performed well on larger unseen instances.", "future_impact": "The approach proposed could benefit real-world Job-shop scheduling problems by improving performance and allowing for generalization to larger-scale instances.", "venue": "NeurIPS", "year": 2020, "title": "Learning to Dispatch for Job Shop Scheduling via Deep Reinforcement Learning"}
{"pid": "6348d36990e50fcafd5462ae", "context": "Sampling from a log-concave distribution is a common problem that has applications in various fields such as machine learning, physics, and statistics. Classical algorithms have typically addressed this problem using gradient (first order) queries, and pale in performance in terms of the condition number and dimension.", "key_idea": "This study proposes quantum algorithms for sampling log-concave distributions and for estimating their normalizing constants, with improved query complexity. These new algorithms leverage underdamped Langevin diffusion, and use only evaluation queries, not gradient ones.", "method": "The researchers first develop quantum algorithms using underdamped Langevin diffusion. Subsequently, they create quantum Metropolis-adjusted Langevin algorithms, while simultaneously exploiting quantum analogs of the Monte Carlo method and quantum walks.", "outcome": "The proposed quantum algorithms match the query complexity (in terms of the condition number and dimension) of analogous classical algorithms, despite using only evaluation queries. The algorithms also achieve a quadratic speedup in the multiplicative error for estimating normalizing constants. Quantum Metropolis-adjusted Langevin algorithms show polynomial speedups over classical counterparts.", "future_impact": "The study also leans into the theoretical sphere by proving a quantum lower bound for estimating normalizing constants, implying that the proposed quantum algorithms approach optimality in terms of epsilon, which suggests potential avenues for future optimization research.", "venue": "NeurIPS", "year": 2022, "title": "Quantum Algorithms for Sampling Log-Concave Distributions and Estimating   Normalizing Constants"}
{"pid": "654d928e939a5f4082574ccc", "context": "Graph Neural Networks (GNNs), crucial for graph-structured machine learning applications, depend on sufficient labeled data, which is often hard to come by.", "key_idea": "The authors propose a novel active learning (AL) method for GNNs by extending the Expected Model Change Maximization (EMCM) principle to improve prediction performance on unlabeled data. Furthermore, they provide a Bayesian interpretation for the node embeddings generated by GNNs under a semi-supervised setting.", "method": "To demonstrate the method's efficiency and accuracy, they compute the closed-form EMCM acquisition function as the selection criterion for AL without re-training and carry out experiments comparing it to existing approaches.", "outcome": "Experimental results show the effectiveness of the proposed method in comparison to existing approaches, in terms of both accuracy and efficiency.", "future_impact": "The proposed method establishes a direct connection with expected prediction error minimization, theoretically promising improvements in AL performance.", "venue": "NeurIPS", "year": 2023, "title": "No Change, No Gain: Empowering Graph Neural Networks with Expected Model Change Maximization for Active Learning"}
{"pid": "5e54f1813a55acae32a25fa9", "context": "Training deep learning models robustly with potentially corrupted data, due to either label noise or out-of-distribution samples, is a key issue in machine learning. The standard empirical risk minimization (ERM) used for training these models tends to overfit to noise in the data, leading to sub-optimal performance.", "key_idea": "The proposed self-adaptive training is a new training algorithm that dynamically corrects problematic training labels with the model's predictions, improving the generalization capability of deep learning models for potentially corrupted training data.", "method": "The authors test the self-adaptive training method under various levels of noise and two types of adversarial training. They evaluate the error-capacity curve of this method and perform experiments on CIFAR and ImageNet datasets.", "outcome": "They demonstrate that self-adaptive training significantly improves generalization over ERM under various levels of noises and mitigates the overfitting issue. Test error is shown to decrease monotonously in relation to model capacity, contrasting to the double-descent phenomenon observed in ERM.", "future_impact": "The paper's proposed self-adaptive training method could significantly improve the training of deep learning models, particularly with corrupted data, in two applications tested (classification with label noise and selective classification).", "venue": "NeurIPS", "year": 2020, "title": "Self-Adaptive Training: beyond Empirical Risk Minimization"}
{"pid": "628707335aee126c0f78c4ee", "context": "Feature learning in infinite-width neural networks trained with gradient flow currently lacks a comprehensive understanding.", "key_idea": "The authors present a self-consistent dynamical field theory for understanding feature learning in wide neural networks. They construct deterministic dynamical order parameters, representing the inner-product kernels for hidden unit activations and gradients in each layer, to describe the network activity through training.", "method": "The authors devise an alternating sampling procedure to solve for the kernel order parameters self-consistently, and validate the theory with several comparisons to various approximation schemes. Additionally, they conduct experiments in more realistic settings on an image classification task with convolutional neural networks.", "outcome": "The study reveals that the proposed dynamical field theory recovers the recursive stochastic process of infinite-width feature learning networks. Comparisons to various approximation schemes show that general self-consistent solutions provide an accurate description even in regimes where these approximations fail. Experiments further demonstrate that the loss and kernel dynamics of convolutional neural networks at fixed feature learning strength are preserved across different network widths.", "future_impact": "This new understanding of feature learning through the dynamical field theory could potentially enhance the performance and training of wide neural networks in future studies.", "venue": "NeurIPS", "year": 2023, "title": "Self-consistent dynamical field theory of kernel evolution in wide neural networks"}
{"pid": "61a880f16750f82b1762e0d8", "context": "In binary classification tasks within the streaming setting, standard methods such as the Margin Algorithm or Uncertainty Sampling have been used for active learning, but without the efficient use of weak labels.", "key_idea": "The paper proposes a novel active learning algorithm that leverages weak labels to reduce the number of label requests and trains a model to optimize a surrogate loss on a set of labeled and weak-labeled points.", "method": "The authors carry out a theoretical analysis that examines the generalization and label complexity bounds of the proposed algorithm. An empirical study on 18 real-world datasets is conducted to compare the new algorithm against standard baselines such as the Margin Algorithm and Uncertainty Sampling.", "outcome": "Theoretical analysis showed that the proposed algorithm achieves favorable generalization and label complexity bounds. Empirical findings showed that the algorithm outperforms standard baselines on 18 real-world datasets.", "future_impact": "The proposed approach may change the way binary classification tasks are approached in the streaming setting by proving the value of leveraging weak labels, which could possibly lead to further exploration and improvements in this area.", "venue": "NeurIPS", "year": 2021, "title": "Online Active Learning with Surrogate Loss Functions."}
{"pid": "e1f49a85-3fe1-486a-a8de-6040b52db164", "context": "Previous approaches to invariant learning either augmented the training data with transformed examples under a group of desired invariances, or regularized the cost function to penalize changes in output when the input transforms under the said group.", "key_idea": "This paper introduces the concept of a probability distribution over group transformations and equates regularization in the learning process to the addition of transformed samples to the training data.", "method": "The authors remodel the cost function for the enhanced training data using the proposed notion of a probability distribution over group transformations.", "outcome": "Under certain conditions, the newly reformed cost function is equivalent to the sum of the original cost function plus a regularizer, therefore showing the simultaneous impact of data augmentation and regularization in creating model invariance.", "future_impact": "This equivalence and the introduction of a probability distribution over group transformations offers a new approach for achieving invariance in pattern recognition and other learning tasks.", "venue": "NeurIPS", "year": 1994, "title": "From Data Distributions to Regularization in Invariant Learning"}
{"pid": "628afb515aee126c0f04ea32", "context": "Deep learning is moving towards transfer learning, where large models are fine-tuned on downstream tasks based on an initialization learned from the source task. However, these initializations provide scant information about the source task.", "key_idea": "The authors propose learning highly informative posteriors from the source task, which are then used as the basis for priors that alter the entire loss surface on the downstream task, enhancing performance and data efficiency.", "method": "The authors apply their method in various downstream classification and segmentation tasks, demonstrating its compatibility as a drop-in alternative to standard pre-training strategies.", "outcome": "The implementation of these highly informative priors resulted in significant performance improvements and more effective learning on a variety of downstream classification and segmentation tasks.", "future_impact": "The highly informative priors can be stored for future use, similar to pre-trained weights, offering a distinctive approach compared to the zero-mean isotropic uninformative priors usually used in Bayesian deep learning.", "venue": "NeurIPS", "year": 2022, "title": "Pre-Train Your Loss: Easy Bayesian Transfer Learning with Informative   Priors"}
{"pid": "61a88c0a6750f8304711e993", "context": "Existing methods for computing prediction intervals in non-parametric regression have challenges in adapting to skewed data.", "key_idea": "The authors introduce a conformal method that uses black-box machine learning algorithms to estimate the conditional distribution of the outcome using histograms, then translates their output into the shortest prediction intervals with approximate conditional coverage.", "method": "A series of numerical experiments have been done using simulated and real data. The proposed method was compared with state-of-the-art alternatives including conformalized quantile regression and other distributional conformal prediction approaches.", "outcome": "The results from the conducted numerical experiments indicate that the proposed conformal method shows improved performance when compared with state-of-the-art alternatives.", "future_impact": "The new method could improve adaptability to skewed data for prediction intervals in non-parametric regression, offering potential for broader application and research.", "venue": "NeurIPS", "year": 2021, "title": "Conformal Prediction using Conditional Histograms."}
{"pid": "61a887636750f87bf8702224", "context": "In two-player zero-sum extensive-form games, Nash equilibrium prescribes optimal strategies against perfectly rational opponents, but fails to ensure rational play when mistakes are made by players. Though trembling-hand refinements can address this issue, their use in real world settings with imperfect players is challenging.", "key_idea": "The authors propose the study of equilibrium refinements for settings where one of the players is perfectly rational (the 'machine') and the other may make mistakes, introducing a modified version of the quasi-perfect equilibrium refinement called the one-sided quasi-perfect equilibrium.", "method": "The authors carry out experiments on standard benchmark games and an endgame from a match where the AI Libratus was used against top human professionals in heads-up no-limit Texas hold'em poker, to test the computation and performance of one-sided QPE versus traditional refinements.", "outcome": "The experiment results show that one-sided QPE can be computed more efficiently than all known prior refinements and also tends to play better than a Nash equilibrium strategy against imperfect opponents.", "future_impact": "These findings may lead to wider adoption of Nash equilibrium refinements in settings where perfectly rational machines interact with players prone to mistakes, potentially improving the performance of AI in two-player zero-sum extensive-form games.", "venue": "NeurIPS", "year": 2021, "title": "Equilibrium Refinement for the Age of Machines: The One-Sided Quasi-Perfect Equilibrium."}
{"pid": "6331182b90e50fcafdcbbb4f", "context": "Most existing video-language modeling methods assume that the video frames and text description are semantically correlated and focus on the modeling at video level. However, this is often incorrect due to the presence of noisy or meaningless video information and inability to cover all frames with a single description.", "key_idea": "The authors propose an efficient model, termed Language-Guided Denoising Network (LGDN), for video-language modeling, which dynamically filters out the misaligned or redundant frames under the language supervision and obtains only the salient frames per video for cross-modal token-level alignment.", "method": "Five different public datasets were used in extensive experiments to validate the effectiveness of the LGDN in video-language modelling.", "outcome": "The proposed LGDN outperforms the state-of-the-art in video-language modeling by large margins as shown in the experimental results.", "future_impact": "The authors hope that revealing the critical importance of solving the noise issue in video-language modeling will inspire future works in this area.", "venue": "NeurIPS", "year": 2022, "title": "LGDN: Language-Guided Denoising Network for Video-Language Modeling"}
{"pid": "61a882e46750f82b17638ae5", "context": "Neural module networks (NMN) are widely used for multi-modal tasks like visual question answering (VQA) and visual referring expression recognition (REF). However, previous NMN models don't effectively capture the relation between the visual input and the relevant neighborhood context of the textual input, limiting their generalizability.", "key_idea": "This paper introduces a language-guided adaptive convolution layer (LG-Conv) into NMN. The filter weights of convolutions are explicitly multiplied with a spatially varying language-guided kernel, allowing the neural module to co-attend over potential objects of interest from visual and textual inputs.", "method": "Testing is performed on VQA and REF tasks, and a new test split for the REF task, C3-Ref+, is introduced for evaluating the NMN\u2019s ability to generalize to adversarial perturbations and unseen combinations of known concepts.", "outcome": "Extensive experiments show the effectiveness of this approach, with additional tests on C3-Ref+ further demonstrating its generalization capabilities.", "future_impact": "This novel implementation of NMNs could improve their ability to generalize and therefore, their effectiveness in multi-modal tasks. It offers potential advancements in how neural networks handle visual and textual inputs.", "venue": "NeurIPS", "year": 2021, "title": "Robust Visual Reasoning via Language Guided Neural Module Networks."}
{"pid": "6180ac445244ab9dcb793f14", "context": "Although person re-identification (ReID) models are being used in safety-critical applications, current evaluations overlook the robustness of the models against various image corruptions, considering only their performance on clean datasets.", "key_idea": "The authors establish five ReID benchmarks for learning corruption invariant representation, aiming to conduct an exhaustive study on corruption invariant learning in single- and cross-modality datasets.", "method": "The authors reproduce and examine the robustness performance of 21 recent ReID methods on various datasets, including Market-1501, CUHK03, MSMT17, RegDB, SYSU-MM01. They analyze their observations and propose a strong baseline on both single- and cross-modality ReID datasets.", "outcome": "The study found that transformer-based models are more robust towards corrupted images compared to CNN-based models, and that increasing the probability of random erasing, a commonly used augmentation method, hurts model corruption robustness.", "future_impact": "Through their proposed benchmarks, this study will enable improved evaluation of ReID models against image corruptions and has potential to lead to models with improved robustness against diverse corruptions.", "venue": "NeurIPS", "year": 2021, "title": "Benchmarks for Corruption Invariant Person Re-identification."}
{"pid": "e8107305-396b-4c08-96eb-0d5bc8d71fc4", "context": "Previous methods for statistical analysis of neural responses to natural stimuli, which are non-Gaussian and exhibit strong correlations, fall short because they require simplified stimulus statistics for rigorous use.", "key_idea": "The authors propose a new method that maximizes the mutual information between the sequence of elicited neural responses and an ensemble of stimuli that has been projected on trial directions in the stimulus space. This is different from the existing methods because it allows for a more comprehensive statistical analysis even when the stimuli are non-Gaussian and highly correlated.", "method": "The proposed method is implemented iteratively by increasing the number of directions with respect to which information is maximized. These directions are studied for their potential to recover all the information between spikes and the full unprojected stimuli.", "outcome": "The paper argues for the effectiveness of the proposed new method but doesn't provide specific outcome or results.", "future_impact": "If the relevant subspace's dimensionality is much smaller than the overall stimulus space, it could be experimentally feasible to map out the neuron's input-output function even under fully natural stimulus conditions, providing a potentially significant advancement in the field.", "venue": "NeurIPS", "year": 2002, "title": "Maximally Informative Dimensions: Analyzing Neural Responses to Natural Signals"}
{"pid": "617b66765244ab9dcbb6a89e", "context": "Reinforcement learning (RL) has the potential for building general-purpose robotic systems, but training RL agents to solve robotics tasks is challenging due to the difficulty of exploration in purely continuous action spaces.", "key_idea": "Instead of focusing on improvement in RL algorithms through efficient exploration or better optimization, the authors propose manually specifying a library of robot action primitives (RAPS) that are parameterized with arguments to be learned by an RL policy.", "method": "An empirical study is performed across tasks in three distinct domains with image input and a sparse terminal reward to evaluate the efficiency and task performance of the proposed RAPS approach.", "outcome": "The change to the action interface in the form of RAPS improves both the learning efficiency and task performance, substantially outperforming prior methods that learn skills from offline expert data.", "future_impact": "The specified RAPS can potentially be expressed simply, enable efficient exploration, and be transferred across robots, tasks, and environments, contributing to the field of robotics and RL.", "venue": "NeurIPS", "year": 2021, "title": "Accelerating Robotic Reinforcement Learning via Parameterized Action Primitives."}
{"pid": "65406320939a5f4082649326", "context": "Unsupervised monocular depth estimation techniques have demonstrated encouraging results but typically assume that the scene is static, which leads to erroneous depth prediction for moving objects in dynamical scenes.", "key_idea": "Dynamo-Depth is introduced as an approach that disambiguates dynamical motion in a scene by jointly learning monocular depth, 3D independent flow field, and motion segmentation from unlabeled monocular videos.", "method": "The Dynamo-Depth technique jointly learns depth and independent motion using a good initial estimation of motion segmentation from unlabeled monocular videos. The model's performance is tested on Waymo Open and nuScenes Dataset.", "outcome": "The proposed method achieves state-of-the-art performance on monocular depth estimation on Waymo Open and nuScenes Dataset, with a significant improvement in the depth of moving objects.", "future_impact": "The introduction of Dynamo-Depth could potentially improve depth estimation in dynamic environments across various applications and datasets.", "venue": "NeurIPS", "year": 2023, "title": "Dynamo-Depth: Fixing Unsupervised Depth Estimation for Dynamical Scenes"}
{"pid": "654ce87b939a5f40826e49b9", "context": "Diffusion models, a new class of generative models, have advanced image generation, yet existing models often try to reconstruct the input image from a corrupted one via point-based reconstruction, possibly failing to fully preserve the neighborhood context of each predicted pixel or feature.", "key_idea": "The authors propose ConPreDiff, a method to reinforce diffusion-based image synthesis via context prediction, explicitly requiring each point to predict its neighborhood context during the training stage, which helps better reconstruct the point by preserving semantic connections with its neighborhood context.", "method": "ConPreDiff is tested in training stage with a context decoder at the end of diffusion denoising blocks. Experiments are conducted on unconditional image generation, text-to-image generation and image inpainting tasks.", "outcome": "The proposed ConPreDiff consistently outperforms previous methods and achieves a new state-of-the-art text-to-image generation result on MS-COCO with a zero-shot FID score of 6.21.", "future_impact": "The ConPreDiff methodology can be generalized to any discrete and continuous diffusion backbones without adding extra parameters in the sampling procedure, suggesting potential wider applicability for this approach.", "venue": "NeurIPS", "year": 2024, "title": "Improving Diffusion-Based Image Synthesis with Context Prediction"}
{"pid": "634f6ae490e50fcafdcb66a1", "context": "The recently-developed Associating Objects with Transformers (AOT) approach introduces hierarchical propagation into Video Object Segmentation (VOS) and has shown promising results. However, the increase of object-specific information leads to the loss of object-agnostic visual information in deep propagation layers.", "key_idea": "The authors propose the Decoupling Features in Hierarchical Propagation (DeAOT) method that decouples the hierarchical propagation of object-agnostic and object-specific embeddings by processing them in two independent branches. They also propose an efficient module for constructing hierarchical propagation, the Gated Propagation Module, specially designed with single-head attention.", "method": "The method is applied and validated by extensive experiments to compare the performance of AOT and DeAOT on benchmarks such as YouTube-VOS, DAVIS 2017, DAVIS 2016, and VOT 2020.", "outcome": "DeAOT significantly outperforms AOT in both accuracy and efficiency, achieving new state-of-the-art performance on four benchmarks (YouTube-VOS (86.2%), DAVIS 2017 (86.2%), DAVIS 2016 (92.9%), and VOT 2020 (0.622)).", "future_impact": "This new method of decoupling hierarchy features could potentially offer higher accuracy and efficiency in video object segmentation tasks and transform related research trends.", "venue": "NeurIPS", "year": 2022, "title": "Decoupling Features in Hierarchical Propagation for Video Object   Segmentation"}
{"pid": "629587475aee126c0fe14cf1", "context": "Despite their widespread use, the approximation properties of group convolutional neural networks (GCNNs) remain poorly explored. While their universality has been demonstrated from the late 2010s onwards, current understanding is incomplete due to a previous case-by-case approach, manually assigning network parameters and modifying GCNNs into other universal approximators.", "key_idea": "This study presents a versatile, depth-2 continuous GCNN S[\u03b3] formulated as a nonlinear mapping between group representations, using a newly introduced ridgelet transform analysis operator to map a function f to its network parameters such that S[\u03b3]=f.", "method": "We created a closed-form expression of the ridgelet transform to understand how network parameters would represent a function. The closed-form expression was further discretized to systematically generate a constructive proof of the cc-universality of finite GCNNs.", "outcome": "Using the ridgelet transform, we can understand for the first time how the parameters of GCNNs are organized to represent a function. By discretizing the closed-form expression of the ridgelet transform, we successfully provided a unified and highly constructive proof of the cc-universality of finite GCNNs.", "future_impact": "This new method of understanding the organisation of GCNN parameters through the ridgelet transform, and the unified and more constructive proofs of GCNN universality achieved, could further understanding and utilization of GCNNs in various applications.", "venue": "NeurIPS", "year": 2022, "title": "Universality of Group Convolutional Neural Networks Based on Ridgelet   Analysis on Groups"}
{"pid": "6114b0775244ab9dcbc924c4", "context": "The fairness community in machine learning often relies on the UCI Adult dataset, derived from a 1994 US Census survey, for the development of fair algorithmic interventions. However, this dataset has some limitations that can affect its external validity.", "key_idea": "The authors propose a suite of new datasets derived from US Census surveys to supplement the UCI Adult dataset. The datasets concern various prediction tasks including income, employment, health, transportation, and housing, enabling the study of geographical and temporal shifts.", "method": "The authors reconstructed a superset of the UCI Adult data from available US Census data, and derived the new datasets. They then conducted an initial empirical study of fairness criteria, algorithmic intervention performance, and the role of distribution shift within their datasets.", "outcome": "Through their datasets, the authors were able to highlight new empirical insights that challenge certain existing ideas in fairness research and offer valuable information in ongoing debates.", "future_impact": "These new datasets can enhance the quality of research in fair machine learning by allowing researchers to explore different perspectives and methods. They may also open up new research directions.", "venue": "NeurIPS", "year": 2021, "title": "Retiring Adult: New Datasets for Fair Machine Learning."}
{"pid": "6327dda690e50fcafd67dfcb", "context": "Model-Based Reinforcement Learning (MBRL) based on optimism or posterior sampling (PSRL) ensures global optimality asymptotically. However, for simplest nonlinear models, the complexity can grow exponentially, making global convergence impossible within finite iterations. Large generalization error can lead to large uncertainty, resulting in aggressive policy updates and over-exploration.", "key_idea": "The authors propose Conservative Dual Policy Optimization (CDPO), which consists of a Referential Update and a Conservative Update. The policy is first optimized under a reference model to provide stability and a conservative range of randomness is ensured.", "method": "The authors test CDPO for its ability to handle an MBRL problem and compare it against the performance of the PSRL model.", "outcome": "CDPO is able to achieve the same regret as PSRL. Empirical results demonstrate that CDPO enjoys monotonic policy improvement and global optimality simultaneously.", "future_impact": "This work offers a promising approach for efficiently handling model complexity and uncertainty issues in Model-Based Reinforcement learning scenarios, potentially leading to improved methods for dealing with complex reinforcement learning problems.", "venue": "NeurIPS", "year": 2022, "title": "Conservative Dual Policy Optimization for Efficient Model-Based   Reinforcement Learning"}
{"pid": "62fe164c90e50fcafd9fa08d", "context": "The search for low-cost catalysts to convert renewable energy into storable forms has been a pivotal challenge in the field of renewable energy. One of the key tasks in this search is to predict the energy of a system's relaxed state given atomic positions for an adsorbate-catalyst system, which requires machine learning approaches to approximate quantum mechanical computations in Density Functional Theory (DFT).", "key_idea": "The Open Catalyst Challenge at NeurIPS 2021 encouraged community-wide progress on developing machine learning approaches that can accurately predict the energy of a system's relaxed state, which is crucial in filtering potential electrocatalyst materials.", "method": "The challenge required participants to develop machine learning approaches that can predict the energy of an adsorbate-catalyst system's relaxed state from given atomic positions, essentially approximating DFT computations.", "outcome": "The winning approach improved direct relaxed energy prediction by 15% over the previous state-of-the-art.", "future_impact": "The developments from this challenge can spur further advances in machine learning methods for catalyst prediction, thus hastening the discovery of low-cost catalysts to drive reactions for renewable energy conversion.", "venue": "NeurIPS", "year": 2021, "title": "The Open Catalyst Challenge 2021: Competition Report."}
{"pid": "64ae66fc3fda6d7f0684b482", "context": "In-context learning (ICL) has shown promising few-shot performance, but the common practice is still to randomly sample examples to serve as context.", "key_idea": "The authors propose self-adaptive in-context learning, a new principle for ICL. They introduce a self-adaption mechanism that helps each sample find an in-context example organization (selection and permutation), thereby maximizing performance.", "method": "To validate the effectiveness of their self-adaptive ICL, they propose a general select-then-rank framework and instantiate it with new selection and ranking algorithms. The method is evaluated on eight different NLP datasets.", "outcome": "Their self-adaptive ICL method achieves a 40% relative improvement over the common practice, revealing its significant potential.", "future_impact": "The authors indicate that with more advanced algorithms, self-adaptive ICL might be able to close the gap between ICL and finetuning, implying potential for further research in this direction. The code for their methodology will also be released to facilitate future research.", "venue": "ACL", "year": 2023, "title": "Self-Adaptive In-Context Learning: An Information Compression Perspective for In-Context Example Selection and Ordering"}
{"pid": "6373035b90e50fcafd09ff0b", "context": "The task of dialogue summarization has seen significant progress, but results from existing methods remain unsatisfactory due to the problem of omission. However, few works explored this omission problem and related summarization datasets with omission labels are not available in current literature.", "key_idea": "The study proposes the OLDS dataset, which provides high-quality Omission Labels for Dialogue Summarization. The authors also formulate an omission detection task as a step towards reducing omission and improving summarization quality.", "method": "The authors analyze the proposed OLDS dataset to understand how providing ground-truth omission labels to the summarization model can help in recovering the omitted information and improve the quality of summarization.", "outcome": "The analysis of the OLDS dataset showed that providing ground-truth omission labels to the summarization model helps significantly in recovering omitted information and subsequently improving the quality of summarization.", "future_impact": "The authors foresee the importance of research in the field of omission detection for improving dialogue summarization and encourage further research using the OLDS dataset they proposed. They made, and will continue to make, their dataset and codes publicly available for this purpose.", "venue": "ACL", "year": 2022, "title": "Towards Understanding Omission in Dialogue Summarization"}
{"pid": "64ae66803fda6d7f06843fe1", "context": "The SemEval23 shared task of generating spoilers for clickbait headlines was the impetus for this research.", "key_idea": "The authors propose a Zero-Shot approach using two different Transformer architectures, BLOOM and RoBERTa, to generate three different types of spoilers: phrase, passage and multi.", "method": "The authors use two different Transformer architectures, BLOOM and RoBERTa, to generate three different types of spoilers, and they evaluated the performance of the architectures for these tasks.", "outcome": "It was discovered that RoBERTa, which was pretrained for Question-Answering tasks, performed better than BLOOM for causal language modelling.", "future_impact": "The promising results with both Transformer architectures indicate potential for future attempts at similar tasks.", "venue": "ACL", "year": 2023, "title": "Diane Simmons at SemEval-2023 Task 5: Is it possible to make good clickbait spoilers using a Zero-Shot approach? Check it out!"}
{"pid": "6095176d91e011e1dbbca9b5", "context": "For many (minority) languages, the resources needed to train large models are not available. Also, multilingual BERT-based models, even when they include the target language, do not provide the best performance for downstream tasks. ", "key_idea": "The authors propose to enhance BERT-based models for low-resource language varieties through zero-shot transfer learning. They retrain the lexical layers of these models using data from two target languages and independently fine-tune the Transformer layers on a POS-tagging task in the model's source language.", "method": "Four BERT-based models are retrained and fine-tuned with target language data and a POS-tagging task in the source language. The new lexical layers and fine-tuned Transformer layers are combined to test the task performance.", "outcome": "The proposed method achieves high task performance for both target languages. In cases of high language similarity, only 10MB of data is needed for substantial monolingual transfer performance. Retraining the lexical layer of monolingual BERT-based models achieves higher downstream task performance than multilingual BERT.", "future_impact": "The method can potentially improve machine learning tasks in minority and low-resource languages through its efficient use of limited training data.", "venue": "ACL", "year": 2021, "title": "Adapting Monolingual Models - Data can be Scarce when Language Similarity is High."}
{"pid": "e4fdb43f-1ce1-4352-8789-2e6ca88de6af", "context": "Processing natural language messages requires understanding implicit linguistic information, a challenge that existing systems struggle to deal with effectively.", "key_idea": "The authors propose a Prolog system PUNDIT, which consists of distinct syntactic, semantic and pragmatic modules. The novelty is to let syntax and semantics recognize missing linguistic entities as implicit entities, so they can be labelled, and a reference resolution task can find specific referents for these entities.", "method": "The method involves interplay between the syntactic, semantic, and pragmatic modules of PUNDIT to recognize implicit entities and then label and find referents for these entities.", "outcome": "The paper describes an approach for making implicit linguistic information explicit becomes a subset of the tasks performed by reference resolution. It doesn't present measurable outcomes.", "future_impact": "The success of this approach in understanding natural language can have potential implications in the field of natural language processing as it can help in improving models' performance that relies on implicit information.", "venue": "ACL", "year": 1986, "title": "RECOVERING IMPLICIT INFORMATION"}
{"pid": "6258e26b5aee126c0fbc7c08", "context": "Existing visual dialogue models lack a mechanism to keep a mental scoreboard of shared established facts in the dialogue context.", "key_idea": "The authors propose a theory-based evaluation method to investigate how well models pretrained on the VisDial dataset incrementally build representations that do scorekeeping.", "method": "The authors apply their theory-based evaluation method on models pretrained on the VisDial dataset to determine how effectively these models incrementally build representations for scorekeeping in a dialogue context.", "outcome": "It was identified that the analyzed models have a moderate ability to distinguish between shared and privately known statements in a dialogue. However, the consistency in maintaining this distinction throughout the dialogue was found to be lacking.", "future_impact": "The findings from the study reveal limitations of grounding interactions in current models, pointing towards a need for future research in improving the models' ability to incrementally maintain the distinction between shared and privately known statements in dialogues.", "venue": "ACL", "year": 2022, "title": "Can Visual Dialogue Models Do Scorekeeping? Exploring How Dialogue Representations Incrementally Encode Shared Knowledge"}
{"pid": "60796fb091e011f8093d8bb6", "context": "Current methods for learning cross-lingual sentence representations often depend on either paired or unpaired bilingual texts.", "key_idea": "The authors propose a new theory under which a model trained to align only two languages can encode more aligned representations multilingually. They introduce a concept called 'dual-pivot transfer', where they train on one language pair and evaluate on other pairs.", "method": "The authors develop unsupervised models trained on unpaired sentences and single-pair supervised models trained on bitexts, both based on the unsupervised language model XLM-R with its parameters frozen. The models are evaluated as universal sentence encoders on the task of unsupervised bitext mining on two datasets.", "outcome": "The results of the experiments showed that the unsupervised model reaches the state of the art of unsupervised retrieval, and the alternative single-pair supervised model approaches the performance of multilingually supervised models.", "future_impact": "The authors suggest that their proposed bilingual training techniques could be applied to attain sentence representations with multilingual alignment.", "venue": "ACL", "year": 2022, "title": "Bilingual alignment transfers to multilingual alignment for unsupervised parallel text mining"}
{"pid": "64ae668a3fda6d7f0684484e", "context": "While methods for summarizing medical notes, particularly hospital discharge summaries, have been extensively researched, there has been little work to understand the feasibility of this task, given the length, complexity, redundancy, and poor structure of these notes.", "key_idea": "This study proposes an investigation into the feasibility of summarizing hospital discharge summaries by determining the origin, or data provenance, of the discharge summary's source text.", "method": "The authors present DSProv, a new dataset of 51 hospital admissions annotated by clinical informatics physicians. They also propose an unsupervised method of matching notes used in discharge summaries.", "outcome": "The dataset is analyzed for semantics and the extent of copied text from human-authored electronic health record (EHR) notes; an unsupervised method of matching notes has been developed, and the associated dataset and source code have been released.", "future_impact": "The authors anticipate that their dataset, the annotation work, and the unsupervised method will support understanding the data challenges inherent to the task of hospital discharge summary, and also facilitate further research in this field.", "venue": "ACL", "year": 2023, "title": "Hospital Discharge Summarization Data Provenance"}
{"pid": "645dad15d68f896efad9dd3b", "context": "The study of sentiment analysis has been widely explored in many popular languages. However, less attention has been given to the Bangla language due to a lack of relevant data and cross-domain adaptability.", "key_idea": "The authors present BanglaBook, a large-scale dataset of Bangla book reviews containing 158,065 samples classified into three broad categories: positive, negative, and neutral.", "method": "The authors provide a detailed statistical analysis of the dataset and use a range of machine learning models, including SVM, LSTM, and Bangla-BERT, to establish performance baselines. They also conduct an in-depth error analysis by examining sentiment unigrams.", "outcome": "Findings demonstrate a substantial performance advantage of pre-trained models over models that rely on manually crafted features in sentiment analysis.", "future_impact": "The published dataset and findings can be used to improve sentiment analysis in under-resourced languages like Bangla. The error analysis can also provide insight into common classification errors in such languages.", "venue": "ACL", "year": 2023, "title": "BanglaBook: A Large-scale Bangla Dataset for Sentiment Analysis from   Book Reviews"}
{"pid": "64ae66813fda6d7f068440f9", "context": "The study was motivated by the task of identification of persuasion techniques in text, which is a subtask of the SemEval-2023 Task 3 on the multilingual detection of genre, framing, and persuasion techniques in online news involving multiple languages. This subtask is complex due to it being multi-label at the paragraph level with the inventory of persuasion techniques consisting of 23 options.", "key_idea": "The authors propose an ensemble solution based on various pre-trained language models (PLMs) that are fine-tuned on a propaganda dataset for detecting persuasion techniques in text across multiple languages.", "method": "The authors describe different experimental setups and provide results on the dev and test sets released by the organizers of SemEval-2023 Task 3. They also perform an extensive analysis of the data and annotations to understand their influence on the quality of their systems.", "outcome": "In the official evaluation, their ensemble approach ranked first in English and attained high scores in all other languages: French, German, Italian, Polish, and Russian.", "future_impact": "Although the future impact is not explicitly stated, the high performance of their system across multiple languages suggests potential for advancing the field of multilingual persuasion technique detection and multilingual NLP.", "venue": "ACL", "year": 2023, "title": "APatt at SemEval-2023 Task 3: The Sapienza NLP System for Ensemble-based Multilingual Propaganda Detection"}
{"pid": "6327dda690e50fcafd67e0fb", "context": "Generated responses from real-world dialogue systems should adhere to multiple constraints like being informative, truthful, and controllable. However, both predominant paradigms in language generation -- neural language modeling and rule-based generation, struggle to meet all these constraints due to issues like information hallucination, omission, and difficulty in creating flexible and fluent grammars respectively.", "key_idea": "The authors propose a hybrid architecture combining the strengths of both paradigms for dialogue response generation. This architecture consists of two components: a rule-based content selection model using a new formalism known as dataflow transduction, and a constrained decoding procedure that leverages these grammars to constraint a neural language model's output.", "method": "The authors test their hybrid architecture in a dialogue system to generate responses. Evaluation metrics of fluency, relevance, and truthfulness are used to measure the performance of the system.", "outcome": "The proposed hybrid architecture outperforms both rule-based and learned approaches in human evaluations of fluency, relevance, and truthfulness.", "future_impact": "The innovative hybrid architecture can serve as a new approach in dialogue response generation that satisfies the constraints of being informative, truthful, and easy to control.", "venue": "ACL", "year": 2022, "title": "The Whole Truth and Nothing But the Truth: Faithful and Controllable   Dialogue Response Generation with Dataflow Transduction and Constrained   Decoding"}
{"pid": "64ae66883fda6d7f06844762", "context": "Implicit discourse relation classification, which aids multiple NLP fields, has not undergone a broad search for suitable language models. This situation restricts researchers from fully leveraging publicly available models in discourse analysis.", "key_idea": "The study introduces a direct, fine-tuned performance comparison of seven pre-trained language models for discourse parsing using the PDTB-3 dataset.", "method": "This work conducts a comparison study using the PDTB-3, a popular discourse relation annotated dataset and tests seven different pre-trained language models.", "outcome": "From the model search, a new SOTA is raised to 0.671 ACC and new observations are obtained. Some of these observations challenge previous findings (Shi and Demberg, 2019b), suggesting that sentence-level pre-training objectives (NSP, SBO, SOP) generally do not yield the best-performing model for implicit discourse relation classification. Instead, similar-sized PLMs with MLM and full attention led to better performance.", "future_impact": "The findings from this work may inform future research strategies in implicit discourse relation classification, particularly regarding the selection and utilization of language models.", "venue": "ACL", "year": 2023, "title": "A Side-by-side Comparison of Transformers for Implicit Discourse Relation Classification"}
{"pid": "628748e75aee126c0ffd3b93", "context": "Existing approaches to commonsense inference rely on commonsense transformers which learn from commonsense knowledge graphs but usually suffer from lack of coverage and expressive diversity, resulting in poor representation quality.", "key_idea": "This paper presents SOLAR, a novel contrastive learning framework built to address the missing relations in commonsense knowledge graphs, contrasting sets of semantically similar and dissimilar events to learn richer inferential knowledge.", "method": "The authors evaluate SOLAR through performance comparison on commonsense inference with ConceptNet against the state-of-the-art commonsense transformer.", "outcome": "SOLAR outperforms the existing state-of-the-art transformers on commonsense inference with ConceptNet by an average of 1.84% across 8 automatic evaluation metrics.", "future_impact": "The in-depth analysis of SOLAR may provide insights into leveraging missing relations in learning commonsense knowledge graphs for improved results in future research.", "venue": "ACL", "year": 2022, "title": "Learning from Missing Relations: Contrastive Learning with Commonsense Knowledge Graphs for Commonsense Inference"}
{"pid": "13dc1f5b-7e5f-4ce1-90ab-291a5a61ebca", "context": "Previous work by Low, Ng, and Guo (2005) on Chinese word segmentation did not optimize results for multiple corpora.", "key_idea": "The authors extend the work of Low, Ng, and Guo (2005) by creating a Chinese word segmentation system based on a maximum entropy statistical model.", "method": "The authors entered this new system into the Third International Chinese Language Processing Bakeoff and it was evaluated on four separate corpora in their respective open tracks.", "outcome": "The system achieved the highest F-score for the UPUC corpus, and the second, third, and seventh highest for CKIP, CITYU, and MSRA respectively. However, additions made to Low et al.\u2019s system hurt the scores for the year's corpora.", "future_impact": "The work highlights the need for caution when adapting models to new data and suggests further testing and development to improve robustness across multiple datasets.", "venue": "ACL", "year": 2006, "title": "Maximum Entropy Word Segmentation of Chinese Text"}
{"pid": "6361dfe090e50fcafd898cb9", "context": "Pre-trained language models (PLMs) achieve remarkable performance on many downstream tasks, but may fail in giving reliable estimates of their predictive uncertainty. There's a lack of comprehensive understanding of PLMs' calibration, a topic that has not been thoroughly explored.", "key_idea": "The authors aim to examine whether PLMs learn to become calibrated in the training process and the effectiveness of existing calibration methods, providing a novel in-depth look at the calibration of PLMs.", "method": "The authors conduct fine-grained control experiments considering six factors, such as dataset difficulty and training steps. They study the effectiveness of existing calibration methods in both in-distribution and various out-of-distribution settings, and propose extended learnable methods based on existing ones.", "outcome": "It is found that PLMs do not learn to become calibrated throughout training, contradicting some existing beliefs. The experiments demonstrate that learnable methods significantly reduce PLMs' confidence in wrong predictions, and the methods proposed by the authors demonstrate superior performance.", "future_impact": "The findings and methods proposed in this study could pave the way for improving the calibration and predictive uncertainty estimation of pre-trained language models in future research.", "venue": "ACL", "year": 2022, "title": "A Close Look into the Calibration of Pre-trained Language Models"}
{"pid": "5f608d8591e0113805870059", "context": "Machine readers often need commonsense knowledge that is not explicitly mentioned in given documents to perform well on machine reading comprehension (MRC) tasks. Existing methods may not effectively handle this requirement.", "key_idea": "The paper proposes extracting a new type of structured knowledge from scripts, termed as 'contextualized knowledge', and using this knowledge to improve MRC. It also presents a teacher-student paradigm with multiple teachers to facilitate the transfer of knowledge in weakly-labeled MRC data.", "method": "The authors compare several fine-tuning strategies for using the weakly-labeled MRC data based on contextualized knowledge. Experiments are conducted on a Chinese multiple-choice MRC dataset C3 and a relation extraction dataset DialogRE.", "outcome": "The proposed paradigm outperforms other methods that use weakly-labeled data, improving a state-of-the-art baseline by 4.3% in accuracy on a Chinese multiple-choice MRC dataset C3. It also improves F1 by 2.9% on a relation extraction dataset DialogRE by simply adapting the resulting student reader.", "future_impact": "The findings demonstrate the potential usefulness of the extracted 'contextualized knowledge' for improving not just MRC tasks, but also other tasks requiring document comprehension, hinting towards broader applications of this approach.", "venue": "ACL", "year": 2022, "title": "Improving Machine Reading Comprehension with Contextualized Commonsense Knowledge"}
{"pid": "646465fdd68f896efa1951fa", "context": "Product Question Answering (PQA) systems are important for e-commerce applications. While research on PQA is primarily focused on English, there is a need to support multiple customer languages by leveraging product information available in English.", "key_idea": "The researchers present xPQA, a large-scale annotated cross-lingual PQA dataset in 12 languages intended to study the industrial task of producing accurate answers to customer questions across languages.", "method": "The researchers conduct experiments in which they evaluate various approaches involving machine translation at runtime versus offline, with and without xPQA training data, and using multilingual pre-trained language models.", "outcome": "The researchers find that in-domain data is essential as cross-lingual rankers trained on other domains perform poorly. They also find that candidate ranking often prefers runtime translation approaches while answer generation prefers multilingual approaches. Furthermore, translating offline improves candidate ranking mainly on languages with non-Latin scripts and helps answer generation mainly on languages with Latin scripts. However, there is a significant performance gap between the English and the cross-lingual test sets.", "future_impact": "This research could stimulate further exploration into multilingual, particularly non-English, PQA systems in the e-commerce industry, and may guide future work on how to handle translation in this context more effectively.", "venue": "ACL", "year": 2023, "title": "xPQA: Cross-Lingual Product Question Answering across 12 Languages"}
{"pid": "45cd70ee-f0c2-4857-a8f1-91de4084d4cd", "context": "Traditional text sentiment analysis typically involves binary classification, often categorizing texts as either positive or negative in sentiment.", "key_idea": "This study explores the validation of a two-dimensional typology of affective states (positive/negative; active/passive) as a basis for a more fine-grained classification of text affects.", "method": "Using a corpus of English weblog posts, annotated for mood by their authors, the authors trained support vector machine binary classifiers and four-class classifiers for each dimension of the typology.", "outcome": "The results indicate that it is possible to extend the standard binary sentiment analysis approach to a two-dimensional model, supporting a more fine-grained classification along these two axes.", "future_impact": "This new approach to sentiment analysis may enable more nuanced understanding of text sentiment, beyond the standard binary classification.", "venue": "ACL", "year": 2006, "title": "Towards a validated model for affective classification of texts"}
{"pid": "60bae06991e01102e59b6b16", "context": "While texts convey useful sophisticated knowledge, they can also convey sensitive information. Current text sanitization mechanisms offer low utility due to the curse of high-dimensional text representation, and the issue of using sanitized texts for downstream analytics is under-explored.", "key_idea": "This paper proposes a direct approach to text sanitization considering both sensitivity and similarity via a new local Differential Privacy (DP) notion. It utilizes the sanitized texts for sanitization-aware pretraining and fine-tuning, implementing privacy-preserving natural language processing over the BERT language model.", "method": "The study applies the idea of sanitization-aware pretraining and fine-tuning to the BERT language model to test its utility in privacy-preserving natural language processing.", "outcome": "The sanitized texts exhibited promising utility without noticeably boosting the success rate of inference attacks.", "future_impact": "The proposed method can be potentially utilized in various natural language processing applications that require preservation of privacy such as anonymizing sensitive text data.", "venue": "ACL", "year": 2021, "title": "Differential Privacy for Text Analytics via Natural Text Sanitization."}
{"pid": "64741a3ad68f896efaa6226c", "context": "Social biases and stereotypes are embedded in our culture through stories. Previous analyses of these biases in children's stories have been conducted manually and at a small scale, suggesting the need for automated large-scale investigations using natural language processing methods.", "key_idea": "The authors propose a unique computational pipeline that automatically extracts a story's temporal narrative verb-based event chain for each character, along with character attributes such as gender, and an annotation scheme that facilitates bias analysis by aligning with traditional stereotypes.", "method": "The proposed computational pipeline and annotation scheme were applied to analyze gender bias in fairy tales.", "outcome": "Through a case study, the authors demonstrate that their framework can reveal bias in not just the unigram verb-based events in which female and male characters participate, but also in the temporal narrative order of such event participation.", "future_impact": "The proposed computational pipeline and annotation scheme can help to automate and scale up the analysis of social biases in story narratives, leading to more in-depth and comprehensive investigations.", "venue": "ACL", "year": 2023, "title": "Are Fairy Tales Fair? Analyzing Gender Bias in Temporal Narrative Event   Chains of Children's Fairy Tales"}
{"pid": "6462f13cd68f896efa911dc4", "context": "Recent research suggests noticeable differences in language use between the Dark Web and the Surface Web. Studies on the Dark Web often require textual analysis, and this distinct language use could be detrimental to building an accurate representation of the domain.", "key_idea": "The authors propose DarkBERT, a language model specifically pre-trained on Dark Web language data with steps taken to filter and compile the text to minimize the impact of extreme lexical and structural diversity of the Dark Web.", "method": "The authors compare the performance of DarkBERT with its vanilla counterpart and other popular language models in various use cases to validate the benefits of a Dark Web-specific language model.", "outcome": "The evaluations show that DarkBERT outperforms the current language models, demonstrating its effectiveness for the Dark Web.", "future_impact": "The study indicates that DarkBERT could be a useful tool for future research on the Dark Web.", "venue": "ACL", "year": 2023, "title": "DarkBERT: A Language Model for the Dark Side of the Internet"}
{"pid": "48f7bc05-9cb3-4107-b59d-b1825f1c7c51", "context": "Colour is a significant part of information dissemination, often associated with real-world concepts in visualization and product marketing. However, there is a lack of a comprehensive source to capture these concept-colour associations.", "key_idea": "The authors propose creating a large lexicon of word-colour associations using crowdsourcing with a particular focus on abstract concepts and emotions that have strong colour associations.", "method": "A word-choice question was used to acquire sense-level annotations to verify the quality of the data gathered.", "outcome": "They found that even abstract concepts and emotions have strong colour associations.", "future_impact": "Creating a lexicon of word-colour associations will not only improve semantic coherence in information visualization and marketing but can also elicit the desired emotional response.", "venue": "ACL", "year": 2011, "title": "Even the Abstract have Color: Consensus in Word-Colour Associations"}
{"pid": "64ae66733fda6d7f06843481", "context": "Online Gender-Based Violence (GBV), such as misogynistic abuse, is an increasing problem that current technological approaches have found challenging to address. Furthermore, available resources for automated identification of GBV are limited in several ways.", "key_idea": "The main idea is to identify limitations in 63 available resources for automated identification of GBV, such as lack of theoretical grounding and stakeholder input, static nature, and focus on certain media platforms, by reviewing them through the lens of the GBV framework.", "method": "The authors systematically review 63 available resources for automated identification of language related to GBV using the GBV framework.", "outcome": "The authors find that the datasets used for automated identification of GBV language are flawed due to their lack of theoretical grounding and stakeholder input, static nature, and focus on specific media platforms.", "future_impact": "The authors recommend the development of future resources that are grounded in sociological expertise and that center the voices of stakeholders, namely GBV experts and people with lived experience of GBV. This may lead to improved identification and address of online GBV.", "venue": "ACL", "year": 2023, "title": "Resources for Automated Identification of Online Gender-Based Violence: A Systematic Review"}
{"pid": "63a2794d90e50fcafd2945b2", "context": "Temporal reasoning has been addressed by models that perform well on in-domain benchmarks. However, there is a lack of understanding of their generalizability due to limitations in the existing datasets.", "key_idea": "The authors introduce a new task named TODAY that includes temporal differential analysis, designed to evaluate if systems can understand the effect of incremental changes. It accomplishes this by modifying the context of given event pairs and requires systems to determine how this slight change in context impacts temporal relation distributions.", "method": "The authors use the TODAY task to assess existing models, including GPT-3, for their ability to understand the effect of subtle contextual changes on temporal relation distributions.", "outcome": "It was found that, when tested with TODAY, existing models including GPT-3, performed no better than random guessing. This suggests the models heavily rely on spurious information rather than proper reasoning for temporal predictions. But with the superivision style and explanation annotations of TODAY, models tend to use more appropriate signals during training, and show better performance across several benchmarks.", "future_impact": "The task TODAY can also be used to train models to draw incidental supervision from noisy sources such as GPT-3, potentially aiding the development of more effective generic temporal reasoning systems.", "venue": "ACL", "year": 2022, "title": "Generic Temporal Reasoning with Differential Analysis and Explanation"}
{"pid": "60d3da1991e0112ca5d185d3", "context": "There is a need for a consolidated platform that organizes and visualizes Twitter's natural language processing (NLP) data from various conferences and general NLP discussions.", "key_idea": "The paper presents TweenLP, a one-stop portal that curates tweets and provides an exploration platform with features like TweetExplorer, visualization of Twitter activity, discovery of popular research papers and researchers, and a timeline of conference submission deadlines.", "method": "TWEENLP curates 19,395 tweets from various NLP conferences and general discussions, and integrates the tweets with the NLPExplorer scientific literature search engine.", "outcome": "TWEENLP was developed and it supports multiple features such as visualizing insights from Twitter activity, discovering popular research papers and researchers, and building a timeline of conference and workshop submission deadlines.", "future_impact": "The authors envision TWEENLP to function as a collective memory unit for the NLP community, which could further enhance the search and discovery of NLP research.", "venue": "ACL", "year": 2021, "title": "Tweenlp: A Twitter Exploration Portal For Natural Language Processing"}
{"pid": "64ae66b33fda6d7f06846806", "context": "Prompting has gained much attention as a method for the adaptation of large-scale language models, yet prompts often act against human intuition and report unstable performances. This has prompted methods that automatically find effective prompts, with gradient-based search being one popular approach.", "key_idea": "The study proposes a new regularization method, CoRe, for gradient-based prompt tuning techniques, aiming to guide a prompt to produce a task context appropriately. It brings two regularization effects, context attuning and context filtering, to improve prediction performance in a zero-shot in-context learning setting without any demonstration examples.", "method": "The authors evaluate the proposed CoRe method on natural language understanding datasets and two large language models, GPT2-XL and GPT-J, in zero-shot learning settings.", "outcome": "The proposed CoRe training scheme shows performance improvements up to 11.9% on GPT2-XL, and up to 6.3% on GPT-J in zero-shot settings.", "future_impact": "The method may influence how future gradient-based prompt tuning techniques are developed, potentially leading to more stable and improved performances in the application of large language models.", "venue": "ACL", "year": 2023, "title": "Two Examples are Better than One: Context Regularization for Gradient-based Prompt Tuning"}
{"pid": "628748e15aee126c0ffd1b32", "context": "The biaffine parser has been extended to semantic dependency parsing (SDP), performing well on graphs. However, all arcs for a given sentence are predicted independently from each other, which does not account for potential interdependencies among arcs.", "key_idea": "The paper proposes introducing interdependence between arcs through simple auxiliary tasks, while retaining the architecture's O(n^2) complexity and high parallelizability.", "method": "Experiments were conducted on three English acyclic datasets (SemEval 2015 task 18) and on French deep syntactic cyclic graphs to test the proposed method.", "outcome": "The proposed method led to modest but consistent performance improvements on a near state-of-the-art baseline using transformer-based contextualized representations.", "future_impact": "The proposed method provides a simple and robust approach to boost performance in semantic dependency parsing (SDP).", "venue": "ACL", "year": 2022, "title": "Auxiliary Tasks to Boost Biaffine Semantic Dependency Parsing"}
{"pid": "6462f133d68f896efa911841", "context": "Interactive semantic parsing based on natural language (NL) feedback has emerged as a practical scenario, but prior work has relied heavily on human-annotated feedback data which is expensive and not scalable.", "key_idea": "The authors propose a new task of simulating NL feedback for interactive semantic parsing, along with a novel feedback evaluator to assess the quality of the simulated feedback.", "method": "The authors evaluate the proposed feedback simulator and its variants based on their ability to improve the error correction ability of a specific parser. A text-to-SQL dataset is used for this purpose.", "outcome": "The feedback simulator was able to generate high-quality NL feedback that improved the error correction ability of a parser. In low-data settings, the feedback simulator could achieve comparable error correction performance to models trained using a costly, full set of human annotations.", "future_impact": "The proposed feedback simulator and the novel task could enable scalable solutions for interactive semantic parsing and error correction, reducing the reliance on expensive human-annotated feedback data.", "venue": "ACL", "year": 2023, "title": "Learning to Simulate Natural Language Feedback for Interactive Semantic   Parsing"}
{"pid": "62833fe3a1f978000cc47378", "context": "Currently, the development of speech synthesis systems with state-of-the-art neural models requires large amounts of training data, which is a challenge for low-resource languages and those undergoing language revitalization, such as Indigenous languages in Canada.", "key_idea": "The authors propose developing speech synthesis systems for low-resource languages by re-evaluating the amount of data required. A specific example includes using a FastSpeech2 model trained with 1 hour of training data.", "method": "The authors build and evaluate speech synthesis systems for three low-resource Indigenous languages in Canada\u2014Kanien'keha, Gitksan, and SENCOTEN. They compare the performance of a FastSpeech2 model trained with 1 hour of English training data to a Tacotron2 model trained with 10 times the data.", "outcome": "The preliminary findings suggest that a FastSpeech2 model trained with 1 hour of training data can generate speech with naturalness comparable to a Tacotron2 model trained with 10 hours of data.", "future_impact": "The paper motivates future research in the evaluation of these low-resource speech synthesis systems and their integration in classroom settings for language revitalization.", "venue": "ACL", "year": 2022, "title": "Requirements and Motivations of Low-Resource Speech Synthesis for Language Revitalization"}
{"pid": "5eda6302-5c9a-4222-8c6a-399ed58388b4", "context": "In Chinese, zero anaphors occur frequently. Their identification and recovery in discourse processing present challenges due to their ambiguity and complex syntactic structures. There is a widely accepted belief that extra-linguistic knowledge is needed for resolving zero anaphors.", "key_idea": "The author proposes the use of syntactic tagging for detection of anaphora and introduces two principles based on linguistic information for recovering zero anaphors. The first principle is to return to the opening statement for recovery (topic continuity principle) and the second is to look for anaphors in the most recent element (recency principle), which can be modified by certain adverbial expressions.", "method": "The proposal is a theoretical framework, so there's no specified method for validation mentioned in the abstract.", "outcome": "No outcomes or results are provided in the abstract.", "future_impact": "The anticipated impact is not explicitly stated in the abstract, so it is marked as 'N/A'.", "venue": "ACL", "year": 2000, "title": "Zero Anaphors in Chinese Discourse Processing"}
{"pid": "615e65735244ab9dcbf2169c", "context": "Current methods of unsupervised parsing involve complex models and training procedures.", "key_idea": "This paper introduces a new method for unsupervised parsing that bootstraps two classifiers -- an inside classifier that acts on a span, and an outside classifier that acts on everything outside of a given span -- for sentence dominance identification.", "method": "The authors train these classifiers through self-training and co-training and prepare the data to train these classifiers using a seed bootstrapping technique. The approach is validated further with weak supervision using prior branching knowledge of a known language and minimal heuristics.", "outcome": "The application of the proposed method in conjunction with weak supervision and minimal heuristics achieves a 63.1 F-1 on the English (PTB) test set, showcasing improvement in accuracy of the classifiers and parser. Moreover, when evaluated on treebanks for Chinese (CTB) and Japanese (KTB), it achieved new state-of-the-art results.", "future_impact": "The effectiveness of this co-training architecture in improving parsing could lead to potential enhancements in natural language processing tasks across multiple languages.", "venue": "ACL", "year": 2022, "title": "Co-training an Unsupervised Constituency Parser withWeak Supervision"}
{"pid": "64ae66ca3fda6d7f06847be3", "context": "Demonstration-based learning has shown impressive performance in exploiting pretrained language models under few-shot learning settings. It has been observed that demonstrations, even those composed of random tokens, can still improve performance.", "key_idea": "The authors propose using a Structural Causal Model (SCM) to understand demonstration-based learning from causal perspectives and interpret random demonstrations as interventions on the demonstration variable within the causal model.", "method": "The authors investigate the causal effects in the Structural Causal Model and examine the impact of the concurrence of specific words and randomly sampled tokens in the demonstration.", "outcome": "The study found that the concurrence of specific words in the demonstration induces bias, while randomly sampled tokens do not. They also discover that their method of constructing random demonstrations outperforms hand-crafted, meaningful demonstrations on public sequence labeling benchmarks.", "future_impact": "The findings suggest potential ways to improve the performance of demonstration-based learning, which may have an impact on future studies in this area.", "venue": "ACL", "year": 2023, "title": "Understanding Demonstration-based Learning from a Causal Perspective"}
{"pid": "64ae667d3fda6d7f06843c5e", "context": "SemEval-2023 Task 4 aims to identify human values behind arguments by classifying whether or not an argument draws on a specific category. Previous attempts have utilized baseline techniques without utilizing a second-phase pre-training method or a sophisticated ensemble approach.", "key_idea": "The authors propose a two-fold strategy: a second-phase pre-training method to adapt a RoBERTa Language Model (LM), and a One-Versus-All approach to classification. Predictions are determined by majority voting from an ensemble of three sets of per-label models.", "method": "The authors conducted experiments to evaluate the impacts of different pre-trained language models on the task and compared their performance in both pre-trained and task-adapted settings.", "outcome": "The authors found that fine-tuning the RoBERTa LM on the task-specific dataset improves its performance, outperforming the best-performing baseline BERT approach. The approach achieved a Macro-F1 score of 0.47 on the official test set.", "future_impact": "The successful identification of human values behind arguments using this approach demonstrates potential for its application and improvement in future tasks of the same nature.", "venue": "ACL", "year": 2023, "title": "Aristoxenus at SemEval-2023 Task 4: A Domain-Adapted Ensemble Approach to the Identification of Human Values behind Arguments"}
{"pid": "63a1750e90e50fcafd1f3d33", "context": "Existing unified table-to-text tasks use a single encoder-decoder model trained via multi-task learning, typically encoding task information with a simple dataset name as a prefix to the encoder. This approach hampers effective multi-task learning and the model's ability to generalize to new domains or tasks not seen during training.", "key_idea": "This paper proposes compositional task configurations, which are a set of prompts prepended to the encoder to improve cross-task generalization of unified models. The task configurations specify the task type, and its input and output types.", "method": "The authors designed the task configurations and used them to better learn shared knowledge across different tasks at training and also control the model in a zero-shot manner by composing novel input-output combinations. Their method was tested over ten table-to-text tasks using a T5-large backbone.", "outcome": "Experiments show that the proposed method outperforms the UnifiedSKG baseline in both in-domain and zero-shot settings, with average improvements of +0.5 and +12.6 respectively.", "future_impact": "The method's improved ability to learn shared task knowledge and control models for unseen tasks could enhance the generalization and application of table-to-text models in new domains.", "venue": "ACL", "year": 2022, "title": "Improving Cross-task Generalization of Unified Table-to-text Models with   Compositional Task Configurations"}
{"pid": "5ec49a639fced0a24b4de7bb", "context": "Existing text generation methods often ignore the context that is not explicitly provided, resulting in a context-independent semantic representation that struggles to support the generation. The reasoning process for a given event in different perspectives requires considering various contexts in which the event occurs.", "key_idea": "The authors propose a text-generation approach that automatically identifies evidence for an event from a large text corpus and leverages this evidence to guide the generation of inferential texts. This approach employs an encoder-decoder structure with a Vector Quantised-Variational Autoencoder to yield representations from a distribution over discrete variables.", "method": "The authors utilize the Vector Quantised-Variational Autoencoder within their encoder-decoder design which allows for automatic selection of relevant evidence. This model was evaluated using the Event2Mind and ATOMIC datasets.", "outcome": "The proposed approach provides state-of-the-art performance on both the Event2Mind and ATOMIC datasets. The model selectively uses evidence to generate different inferential texts when utilising discrete representations.", "future_impact": "In allowing for the automatic selection of relevant evidence, the proposed method not only facilitates evidence-aware generation, but also provides a path to uncover the rationales behind the generation from large text corpora.", "venue": "ACL", "year": 2020, "title": "Evidence-Aware Inferential Text Generation with Vector Quantised Variational AutoEncoder"}
{"pid": "5ec49a639fced0a24b4de76f", "context": "Grounded Language Learning approaches typically focus on a single-task-based final performance measure, limiting the evaluation of desirable properties such as the ability to predict salient attributes or generalise to unseen situations.", "key_idea": "The paper introduces GROLLA, an evaluation framework for Grounded Language Learning with Attributes, and CompGuessWhat?!, an extended version of the GuessWhat?! dataset that incorporates a semantic layer on top of the perceptual one.", "method": "The authors test the evaluation framework on three tasks: Goal-oriented evaluation, object attribute prediction evaluation, and zero-shot evaluation. The effectiveness and comprehensiveness of the new framework are assessed by means of diagnostic classifiers.", "outcome": "The study found that current models do not learn expressive enough representations to encode object attributes, scoring an average F1 of 44.27. They also don't learn strategies or representations that are robust enough for unseen scenes or objects, achieving a best accuracy of 50.06% in zero-shot scenarios.", "future_impact": "GROLLA and the CompGuessWhat?! dataset could promote the development of more robust and expressive Grounded Language Learning models that not only perform single tasks but also effectively predict salient attributes and generalise to new situations.", "venue": "ACL", "year": 2020, "title": "CompGuessWhat?!: A Multi-task Evaluation Framework for Grounded Language Learning"}
{"pid": "638d612a90e50fcafd14b430", "context": "Existing language models (LMs) predict tokens with a softmax over a finite vocabulary, which can make it difficult to predict rare tokens or phrases.", "key_idea": "The authors introduce NPM, the first nonparametric masked language model that replaces the softmax with a nonparametric distribution over every phrase in a reference corpus.", "method": "The new model, NPM, is trained using a contrastive objective and an in-batch approximation to full corpus retrieval. Its performance is tested in a zero-shot evaluation on 9 closed-set tasks and 7 open-set tasks.", "outcome": "NPM significantly outperforms larger parametric models, with or without a retrieve-and-generate approach. It particularly excels at handling rare patterns and predicting rare or nearly unseen words.", "future_impact": "The authors have released the NPM model and code, potentially making it easier for others in the field to adopt or build upon this work.", "venue": "ACL", "year": 2022, "title": "Nonparametric Masked Language Modeling"}
{"pid": "04cbf6aa-142d-4060-b735-4224d90bd64f", "context": "Constructing a large-scale Chinese electronic dictionary is expensive and time-consuming which necessitates manual input or tagged text corpus.", "key_idea": "The paper proposes an unsupervised approach that leverages a small tagged seed corpus and a large untagged text corpus for inexpensive and rapid construction of a large-scale Chinese electronic dictionary. This approach uses a Viterbi reestimation technique for optimizing the automatic segmentation and tagging process and a two-class classifier for distinguishing words and non-words.", "method": "The study uses two system configurations to construct the dictionary: a Viterbi word identification module later followed by a Viterbi POS tagging module, and a two-class classification module as a postfilter for the Viterbi word identification module. The performance is examined using a seed of 1,000 sentences and an untagged corpus of 311,591 sentences.", "outcome": "When the two class classifier is applied to the word list suggested by Viterbi word identification module, precision of 56.88% and recall rate of 77.37% were achieved for bigram word identification. The Viterbi part of speech tag reestimation stage provided 71.16% and 71.81% weighted precision rates, and 73.42% and 73.83% weighted recall rates for the two different configurations when using a seed corpus of 9,676 sentences.", "future_impact": "The proposed techniques can make the process of constructing electronic dictionaries cost-effective and efficient, particularly for languages with untagged text corpora.", "venue": "ACL", "year": 1995, "title": "Automatic Construction of a Chinese Electronic Dictionary."}
{"pid": "62451c2b5aee126c0f47ab40", "context": "Language model pretraining helps downstream NLP tasks by extracting knowledge from text corpora. However, existing methods such as BERT model a single document and fail to capture document dependencies and knowledge that spans across documents.", "key_idea": "This study proposes LinkBERT, a novel language model pretraining method that incorporates document links such as hyperlinks into the pretraining process. It views the pretraining corpus as a graph of documents, using linked documents as contextual information.", "method": "LinkBERT is trained using two self-supervised tasks: masked language modeling task and a newly proposed task, document relation prediction. The evaluation of LinkBERT includes testing on general domain data using Wikipedia with hyperlinks and biomedical domain data using PubMed with citation links.", "outcome": "LinkBERT outperforms BERT on various downstream tasks in both general and biomedical domains. It attains notable improvements in multi-hop reasoning and few-shot QA tasks, creating new state-of-the-art performances on various BioNLP tasks.", "future_impact": "LinkBERT and BioLinkBERT, along with the code and data used, have been made available for further research. This could potentially change the way document relation processing is performed in language model pretraining, impacting future research directions.", "venue": "ACL", "year": 2022, "title": "LinkBERT: Pretraining Language Models with Document Links"}
{"pid": "5fd55e928cdecd4daa1361ce", "context": "Text emotion recognition has been a popular research topic, particularly in the context of narrative text understanding. The work by Kim et al. (2010), displaying high emotion detection performance on a corpus of fairy tales, sets a precedent. However, reproducibility issues are noticeable with Kim's approach and implementation issues arose when trying to reimplement the same.", "key_idea": "The authors propose a new framework for emotion recognition inspired by Kim's approach, aiming to overcome the reproducibility problems in the prior work. The approach therein involves identifying the most effective design choices and recognizing and filling in gaps in the emotion lexicon (Word-NetAffect) used to detect emotions.", "method": "They evaluated various design choices within the proposed framework for text emotion recognition and identified the highest-performing combination. For lexicon augmentation, they closely inspected the annotated data, revealing missing and incorrect emotion terms in Word-NetAffect.", "outcome": "The implemented framework, after identifying the most effective combination of design choices, outperformed Kim's reported performance by 7.6 F-1 points on average. Noteworthy gaps were found and filled in the emotion lexicon, improving recognition.", "future_impact": "The identified gaps in Word-NetAffect suggest that more effort in augmenting or refining emotion ontologies could improve the performance of emotion recognition systems in the future. Additionally, by releasing their code and data, the authors enable reproducibility and further improvements for future work.", "venue": "ACL", "year": 2020, "title": "Systematic Evaluation of a Framework for Unsupervised Emotion Recognition for Narrative Text"}
{"pid": "60b72b0e91e011903fc2bc4a", "context": "Transfer learning from pre-trained neural language models towards downstream tasks has been a predominant theme in Natural Language Processing (NLP). Studies have shown that deep NLP models learn a non-trivial amount of linguistic knowledge at different layers.", "key_idea": "This research explores how fine-tuning towards downstream NLP tasks impacts the learned linguistic knowledge. It uses layer and neuron-level diagnostic classifiers to assess impacts across popular pre-trained models (BERT, RoBERTa, XLNet).", "method": "A study was carried out across the pre-trained models BERT, RoBERTa, and XLNet using layer and neuron-level diagnostic classifiers.", "outcome": "Findings showed that linguistic information, originally distributed in pre-trained language models, gets localized to lower layers after fine-tuning. The pattern varies across architectures with BERT retaining linguistic information deeper in the network than RoBERTa and XLNet.", "future_impact": "This study illuminates how transfer learning impacts linguistic knowledge in deep NLP models, which can potentially influence the optimal application and fine-tuning of pre-trained NLP models for specific linguistic tasks in the future.", "venue": "ACL", "year": 2021, "title": "How transfer learning impacts linguistic knowledge in deep NLP models?"}
{"pid": "8f858484-22ea-48dd-9857-abcd79ecc987", "context": "Reduplication is a common phenomenon in Vietnamese language where words are formed through combinations of similar sounding syllables, but a computational model for this phenomenon has not been developed so far.", "key_idea": "The paper presents the first-ever computational model for the reduplication of the Vietnamese language, and systematizes the study of Vietnamese reduplicative words.", "method": "The author uses optimal finite-state devices, specifically minimal sequential string-to-string transducers, to build the computational model for efficient recognition and creation of reduplicative words.", "outcome": "The study successfully built a computational model for the reduplication of the Vietnamese language, capable of efficient recognition and production of reduplicative words.", "future_impact": "Several potential applications of the developed computational model are discussed, indicating its future use in understanding and processing the Vietnamese language.", "venue": "ACL", "year": 2009, "title": "Finite-State Description of Vietnamese Reduplication"}
{"pid": "1102f8ee-dd03-4453-b8c1-a0f99334ac80", "context": "Existing work has focused on extracting phosphorylation events from biomedical literature, but other post-translational modification events have not been extensively studied.", "key_idea": "The authors extend the event annotation approach to four major new post-transitional modification event types using a new corpus of 157 PubMed abstracts annotated for proteins and post-translational modification events.", "method": "Experiments were conducted using a state-of-the-art event extraction system to evaluate the task of extracting post-translational modification events from the newly compiled corpus.", "outcome": "The system was able to efficiently extract the events with 52% precision and 36% recall (42% F-score), which underlines the complexity of the task and suggests that it still poses considerable challenges.", "future_impact": "The corpus is made freely available to further the development of advanced event extraction technologies in the realm of post-translational modifications.", "venue": "ACL", "year": 2010, "title": "Event Extraction for Post-Translational Modifications"}
{"pid": "e0a864ef-74ad-4221-82f6-c21c8bcfc261", "context": "Pathway construction in biology involves representations of associations between various entities as reactions involving several reactants, outputs, and modifiers. However, until recently, few information extraction methods could resolve the detail required in text to support annotation of such pathway representations.", "key_idea": "The authors argue that event representations, popularized by the BioNLP Shared Task, could potentially be applied for pathway annotation support. They propose a novel event class and representation for protein association and dissociation reactions.", "method": "The authors study the mapping from a formal pathway representation to the event representation. They present a detailed study of protein association and dissociation reactions, and introduce a manually annotated resource incorporating the type among a total of nearly 1300 annotated event instances.", "outcome": "The authors develop the first pathway-to-event conversion software for SBML/CellDesigner pathways.", "future_impact": "This research provides opportunities to convert substantial existing pathway resources to events, which could support more effective pathway annotation.", "venue": "ACL", "year": 2011, "title": "From Pathways to Biomolecular Events: Opportunities and Challenges"}
{"pid": "5efdb17791e011a13faee544", "context": "The dominant methodology for inducing cross-lingual word embedding spaces (CLWEs) is mainly concentrated on enhancing the projection (i.e., mapping) mechanisms, rather than focusing on post-processing techniques.", "key_idea": "This paper presents a novel approach focused on the post-processing of monolingual embedding spaces to facilitate the learning of the cross-lingual alignment and significantly improve bilingual lexicon induction (BLI).", "method": "The proposed post-processing method specializes in the generalization of first- and second-order monolingual similarities to the nth-order similarity, and is tested on a set of 15 typologically diverse languages, in combination with two different projection methods.", "outcome": "The authors show that the post-processing of monolingual spaces before the cross-lingual alignment can substantially enhance the bilingual lexicon induction, which can work in synchrony with any projection-based method for inducing CLWE spaces.", "future_impact": "The proposed method creates a new focus on the post-processing techniques of monolingual embedding spaces to improve the performance of bilingual lexicon induction, potentially influencing future research in the field.", "venue": "ACL", "year": 2020, "title": "Improving Bilingual Lexicon Induction With Unsupervised Post-Processing Of Monolingual Word Vector Spaces"}
{"pid": "628d9e805aee126c0f979938", "context": "The ability for drones to converse with humans and follow commands in natural language is important as it can relieve people's burden of holding a controller all the time, allow multitasking, and make drone control more accessible for people with disabilities or with their hands occupied.", "key_idea": "The study introduces the Aerial Vision-and-Dialog Navigation (AVDN), a concept to navigate a drone via natural language conversation, and the Human Attention Aided (HAA) baseline model that predicts both navigation waypoints and human attention.", "method": "The authors developed a drone simulator with a continuous photorealistic environment and collected a dataset (AVDN) of over 3000 recorded navigation trajectories with asynchronous human-human dialogs between commanders and followers, wherein the follower's attention on the drone's visual observation was also recorded.", "outcome": "The authors presented an effective HAA baseline model based on the AVDN dataset, which can predict navigation waypoints and human attention.", "future_impact": "The study suggests avenues for further research in the field of natural language processing for drone navigation. Improving the HAA baseline model can enable more efficient human-drone interaction and navigation.", "venue": "ACL", "year": 2022, "title": "Aerial Vision-and-Dialog Navigation"}
{"pid": "648697e6d68f896efaa8782e", "context": "Most existing word alignment methods depend heavily on manual alignment datasets or parallel corpora, which limits their usefulness.", "key_idea": "The authors propose WSPAlign, an approach to word alignment that relies on a large-scale, weakly-supervised dataset made up of noisy, partially aligned and non-parallel paragraphs, which is then used for pre-training via span prediction.", "method": "The authors conduct extensive experiments with various settings to show that WSPAlign can be used for pre-training word aligners without manual data. The approach is fine-tuned on standard benchmarks.", "outcome": "WSPAlign sets a new state-of-the-art by improving upon the best supervised baseline by 3.3~6.1 points in F1 and 1.5~6.1 points in AER, achieving competitive performance in few-shot, zero-shot, and cross-lingual tests.", "future_impact": "WSPAlign has potential to be more practically usable for low-resource languages, extending its utility beyond existing methods.", "venue": "ACL", "year": 2023, "title": "WSPAlign: Word Alignment Pre-training via Large-Scale Weakly Supervised   Span Prediction"}
{"pid": "e5c96812-8fd5-4240-a2db-9ea980f8a1b1", "context": "The annotation of discourse connectives for the Chinese Discourse Treebank Project is being done, based on the principles of the Penn Discourse Treebank (PDTB) that annotates English discourse connectives in the Penn Treebank.", "key_idea": "The paper outlines and examines the range of discourse connectives under consideration, their explicit distribution, and the types of syntactic units they correspond to, while dealing with the challenges involving arguments' textual spans due to hierarchical nature of discourse relations.", "method": "The paper methodically explores the distribution of explicit discourse connectives and examines types of syntactic units that can be arguments to discourse connectives. It also delves into the challenges of determining textual spans of arguments.", "outcome": "The study uncovers the complexity of annotating Chinese discourse connectives, outlining the hierarchical nature of discourse relations and the challenges involved in determining the textual spans of arguments.", "future_impact": "The investigation into sense discrimination of discourse connectives and discourse connective variation may influence future discourse relation representation and facilitate structural and semantic annotation projects in other languages.", "venue": "ACL", "year": 2005, "title": "Annotating Discourse Connectives in the Chinese Treebank"}
{"pid": "746aaacc-403e-4987-9451-38f9ffb61167", "context": "In Information Retrieval, sense clustering criteria are a subject of research. Current methods are based on wordnet structure, co-occurrence of senses, and equivalent translations of senses in other languages via the EuroWordNet InterLingual Index (ILI).", "key_idea": "The authors argue that different Natural Language Processing applications require not only different sense granularities, but also different sense clusterings, which can be overlapped.", "method": "The authors examined three types of sense clustering criteria: methods based on wordnet structure, co-occurrence of senses obtained from Semcor, and equivalent translations of senses in other languages via the EuroWordNet InterLingual Index (ILI).", "outcome": "The study concludes that co-occurrence of senses in Semcor provides strong evidence for Information Retrieval clusters, unlike methods based on Wordnet structure and systematic polysemy. And, parallel polysemy in three or more languages via the ILI is strongly correlated with co-occurring senses in Semcor.", "future_impact": "The observations made in this study can potentially influence the development of sense cluster mechanisms for different NLP applications, such as machine translation and cross-language information retrieval.", "venue": "ACL", "year": 2000, "title": "Sense clusters for Information Retrieval: Evidence from Semcor and the EuroWordNet InterLingual Index"}
{"pid": "6462f133d68f896efa91188f", "context": "Previously, evaluating the performance of natural language processing (NLP) models on materials science text has been problematic due to the scarcity of high-quality annotated data in the materials science domain.", "key_idea": "This paper introduces MatSci-NLP, a natural language benchmark built from publicly available materials science text data for seven different NLP tasks, and MatBERT, a model trained specifically on materials science journals. Additionally, the authors propose a unified text-to-schema method for multitask learning in this domain.", "method": "Various BERT-based models pretrained on different scientific text corpora are evaluated using the MatSci-NLP benchmark. The models are fine-tuned with limited training data. The proposed text-to-schema method for multitask learning is compared with traditional fine-tuning methods.", "outcome": "In low-resource training settings, language models pretrained on scientific text outperformed BERT trained on general text. In particular, MatBERT generally performed best for most tasks. The proposed text-to-schema methods inspired by question-answering consistently outperformed single and multitask NLP fine-tuning methods.", "future_impact": "The study provides a basis for evaluating and further improving NLP models in the materials science domain. Additionally, the proposed text-to-schema method could enhance low-resource training in other specialized fields.", "venue": "ACL", "year": 2023, "title": "MatSci-NLP: Evaluating Scientific Language Models on Materials Science   Language Tasks Using Text-to-Schema Modeling"}
{"pid": "64a63bbad68f896efaec47ba", "context": "Pretrained language models like GPT2 tend to generate repetitive texts with maximization-based decoding algorithms for open-ended generation. This is believed to be due to a learning bias, where the models learn simple repetitive patterns faster with the MLE loss.", "key_idea": "The authors propose self-contrastive training as a solution to repetition problems in pretrained language models. The new method penalizes the output of a premature checkpoint of the same model when it incorrectly predicts repetition.", "method": "The authors test the proposed approach on two different datasets and investigate language models' use of longer-range dependencies to predict repetitive tokens in comparison to non-repetitive ones.", "outcome": "The proposed training method was shown to effectively mitigate repetition during generation tasks while maintaining textual fluency.", "future_impact": "This work could potentially address one of the key challenges - repetitiveness in responses of open-ended generation models, which will be significant for the future of AI-based text generation and machine learning.", "venue": "ACL", "year": 2023, "title": "Mitigating the Learning Bias towards Repetition by Self-Contrastive   Training for Open-Ended Generation"}
{"pid": "628748db5aee126c0ffcf418", "context": "Cross-lingual Entity Typing (CLET) aims at improving the quality of entity type prediction by transferring semantic knowledge learned from rich-resourced languages to low-resourced languages. Its performance and relationship to language similarity are underexplored.", "key_idea": "The authors propose a novel method leveraging multilingual transfer learning via the mixture-of-experts approach to dynamically capture the relationship between target language and each source language, effectively predicting types of unseen entities in new languages.", "method": "The model is evaluated through extensive experiments on multilingual datasets, comparing performance to multiple baselines, as well as an additional series of experiments to examine the relationship between language similarity and CLET performance.", "outcome": "The proposed method significantly outperforms multiple baselines and robustly handles negative transfer. The experiments also refute the commonly held belief that sourcing from more languages improves CLET performance.", "future_impact": "The work contributes the 'Similarity Hypothesis for CLET', which may guide future research on language selection strategies in Cross-lingual Entity Typing.", "venue": "ACL", "year": 2022, "title": "How Can Cross-lingual Knowledge Contribute Better to Fine-Grained Entity Typing?"}
{"pid": "628748d35aee126c0ffcbcf0", "context": "Recent work in task-independent graph semantic parsing has moved from symbolic approaches to neural models, demonstrating superior performance on various meaning representations. It, however, remains unclear about the limitations of these neural parsers and whether these can be compensated by embedding symbolic knowledge into model inference.", "key_idea": "By using English Resource Grammar (ERG) parsing as a case study, the authors developed a neural ERG parser based on T5 and proposed a simple yet principled collaborative framework for neural-symbolic semantic parsing, incorporating the prior knowledge from a symbolic parser and model uncertainty into the decision criterion for beam search.", "method": "The authors conduct detailed analyses of parser performance within fine-grained linguistic categories using the developed T5-based neural ERG parser. They then tested a collaborative neural-symbolic semantic parsing framework on long-tail categories.", "outcome": "The neural ERG parser performs superiorly on in-distribution test set but degrades significantly on long-tail situations, while the symbolic parser performs more robustly. The proposed collaborative framework yields comprehensive improvement over the neural baseline across long-tail categories and achieves the best known SMATCH score (97.01) on the DeepBank benchmark.", "future_impact": "The discovery of neural parser limitations and the development of a successful neural-symbolic collaborative parsing framework could inspire more research into combining neural and symbolic approaches in semantic parsing.", "venue": "ACL", "year": 2022, "title": "Towards Collaborative Neural-Symbolic Graph Semantic Parsing via Uncertainty"}
{"pid": "60e3a80791e0114c7cb9e2e0", "context": "Pretrained language models, despite their excellent performance on natural language understanding benchmarks, rely heavily on spurious correlations and struggle to generalize to out-of-distribution (OOD) data. Counterfactually-augmented data (CAD) has been explored to identify robust features that remain invariant under distribution shifts, however, the results have been inconsistent.", "key_idea": "This paper investigates the potential reasons for the mixed performance results associated with using CAD for OOD generalization. It suggests that even though features perturbed in CAD are indeed robust, it might prevent the model from learning other robust features, and CAD could reinforce existing spurious correlations in the data.", "method": "The authors conduct an empirical analysis on two crowdsourced CAD datasets along with a toy theoretical example.", "outcome": "The study finds that CAD's effectiveness in OOD generalization is limited due to a lack of perturbation diversity and its tendency to reinforce existing spurious correlations in the data.", "future_impact": "The findings suggest the need for innovative crowdsourcing procedures to foster diverse perturbation of examples to overcome the limitations of CAD's effectiveness in OOD generalization.", "venue": "ACL", "year": 2022, "title": "An Investigation of the (In)effectiveness of Counterfactually Augmented Data"}
{"pid": "628464625aee126c0faca772", "context": "While a great deal of work has been done on NLP approaches to lexical semantic change detection, other aspects of language change have received less attention from the NLP community, such as the detection of sound change through historical spelling.", "key_idea": "The authors propose a hypothesis that a sound change can be captured by comparing the relative distance through time between the distributions of the characters involved before and after the change has taken place, and model these distributions using PPMI character embeddings.", "method": "The authors verify their hypothesis in synthetic data and then test the method's ability to trace the well-known historical change of lenition of plosives in Danish historical sources.", "outcome": "The models were able to identify several of the changes under consideration and uncover meaningful contexts in which they appeared.", "future_impact": "The proposed methodology has potential to contribute to the study of open questions, such as the relative chronological order of sound shifts and their geographical distribution.", "venue": "ACL", "year": 2022, "title": "Letters From the Past: Modeling Historical Sound Change Through Diachronic Character Embeddings"}
{"pid": "5ea9504391e0118eb1e1a0d3", "context": "Pairwise annotation is widely used for active learning in coreference resolution, but its efficiency in terms of performance per annotation budget is not high.", "key_idea": "This paper proposes a method for active learning in coreference resolution by asking annotators to identify mention antecedents if a presented mention pair is deemed not coreferent.", "method": "The proposed method is combined with a novel mention clustering algorithm for selecting examples to label. It is tested through experiments with existing benchmark coreference datasets.", "outcome": "The experiments show that the signal from this additional question leads to significant performance gains per human-annotation hour.", "future_impact": "Future work can use this annotation protocol to effectively develop coreference models for new domains.", "venue": "ACL", "year": 2020, "title": "Active Learning for Coreference Resolution using Discrete Annotation"}
{"pid": "9200958a-7694-447e-bbff-4b330f74283c", "context": "Epistemic evaluation and knowledge attribution play a central role in scientific discourse; however, a robust model that captures how these evaluations are performed in scientific papers is missing.", "key_idea": "The authors propose a three dimensional model for knowledge attribution and epistemic evaluation in scientific discourse, consisting of source, value and basis.", "method": "The model was proposed based on a literature review and validated it with a corpus study on two biology papers, focusing on four linguistic features (modal auxiliary verbs, adverbs/adjectives, reporting verbs, and references).", "outcome": "The corpus study confirmed the usefulness of the proposed model and revealed some patterns in knowledge attribution, most notably the predominance of the reporting verb phrase 'These results suggest' in matrix clauses.", "future_impact": "Although the authors did not explicitly state the future impact, this model could be of utility in future studies understanding and analyzing knowledge attribution in scientific literature.", "venue": "ACL", "year": 2012, "title": "Epistemic Modality and Knowledge Attribution in Scientific Discourse: A Taxonomy of Types and Overview of Features"}
{"pid": "64ae66873fda6d7f06844651", "context": "The abstract talks about the work done on the Marathi to Hindi low-resource speech translation task and the issues faced in low-resource scenarios.", "key_idea": "The authors describe their two systems for this task: an end-to-end direct speech translation system and a cascaded system. Both systems have a backbone of a Hindi-Marathi bilingual ASR system.", "method": "The end-to-end speech translation system was initialized from the ASR and then fine-tuned for direct speech translation with an auxiliary CTC loss for translation. The MT model for the cascaded system was initialized from a cross-lingual language model and then fine-tuned using 1.6 M parallel sentences. They were trained from scratch on publicly available datasets, with a language model used to re-score the n-best hypotheses.", "outcome": "The primary submission achieved BLEU scores of 30.5 and 39.6, and the contrastive system obtained BLEU scores of 21.7 and 28.6 on official dev and test sets respectively.", "future_impact": "The paper's findings and experiments could inform strategies for improving speech translation in low-resource scenarios.", "venue": "ACL", "year": 2023, "title": "BUT Systems for IWSLT 2023 Marathi - Hindi Low Resource Speech Translation Task"}
{"pid": "52ea1282-bc16-4296-bebd-96df6695a1c1", "context": "Before this study, there was no established curriculum for teaching NLP that provided extensive hands-on experience with state-of-the-art technologies and practical application.", "key_idea": "The authors propose a curriculum for teaching NLP that includes two core classes focusing on theoretical background, hands-on experience with cutting-edge technologies, and practical application implemented via an intensive programming project.", "method": "The curriculum was implemented and the process of its establishment and implementation are discussed, along with how issues involving interdisciplinary coordination, curriculum design, and the challenges of teaching this discipline were managed.", "outcome": "The curriculum was successfully established and implemented, with the paper discussing practical issues like interdisciplinary coordination, curriculum design, and challenges in teaching this discipline.", "future_impact": "The proposed curriculum may guide and inform future efforts to teach NLP, and can provide a basis for further refinement and adaptation in various interdisciplinary settings.", "venue": "ACL", "year": 2002, "title": "A niche at the nexus: situating an NLP curriculum interdisciplinarily"}
{"pid": "dbeb207c-6566-43d4-a73e-232ddb0e5034", "context": "Studies of gender balance in academic computer science are typically based on statistics on enrollment and graduation which are coarse measures of gender participation.", "key_idea": "The study uses a fine-grained approach to examine gender in the field of Natural Language Processing, utilizing topic models (Latent Dirichlet Allocation) to explore the research topics of men and women in the ACL Anthology Network.", "method": "Gender was manually labeled for authors in the ACL Anthology and topic models were applied to explore the research topics among genders.", "outcome": "The study finds that women publish more on dialog, discourse, and sentiment, while men publish more in parsing, formal semantics, and finite state models. Historical patterns show that the proportion of women authors in computational linguistics has been increasing significantly since 1980.", "future_impact": "The manually labeled gender of authors in the ACL Anthology can be a useful resource for other gender studies in computer science.", "venue": "ACL", "year": 2012, "title": "He Said, She Said: Gender in the ACL Anthology"}
{"pid": "6356022390e50fcafd336abd", "context": "State-of-the-art methodologies for producing meaningful representations for clinical sentences and biomedical concepts operate by maximizing the similarity in representations of names referring to the same concept, and combatting collapse through contrastive learning. However, the challenge is that biomedical names are not always self-explanatory, which can lead to non-semantic representations.", "key_idea": "The authors propose BioLORD, a new pre-training strategy that overcomes the non-semantic representations issue by grounding its concept representations using definitions and short descriptions derived from a multi-relational knowledge graph consisting of biomedical ontologies.", "method": "The authors train BioLORD using definitions and short descriptions from a multi-relational graph of biomedical ontologies. They validate it on text similarity tasks for both clinical sentences (MedSTS) and biomedical concepts (MayoSRS).", "outcome": "The BioLORD model establishes a new standard for text similarity on both clinical sentences (MedSTS) and biomedical concepts (MayoSRS).", "future_impact": "The BioLORD model, thanks to its grounding, has the potential to produce more semantic concept representations that closely match the hierarchical structure of ontologies.", "venue": "EMNLP", "year": 2022, "title": "BioLORD: Learning Ontological Representations from Definitions (for   Biomedical Concepts and their Textual Descriptions)"}
{"pid": "5ff883d991e011c832674441", "context": "Top leaderboard submissions in popular Machine Reading Comprehension (MRC) benchmarks such as the Stanford Question Answering Dataset (SQuAD) and Natural Questions (NQ) commonly use model ensembles, but their ensembling strategies are rarely published.", "key_idea": "The authors propose ARES (A Reading Comprehension Ensembling Service), a novel MRC system that utilizes an ensemble of models to enhance performance, coupled with CFO and ReactJS distributed frameworks for an improved and scalable interactive Question Answering experience.", "method": "The authors evaluate various ensembling strategies utilizing the Natural Questions (NQ) dataset.", "outcome": "The authors managed to increase the F1 score by 2.3 points by implementing their ensembling strategies through ARES.", "future_impact": "ARES, by capitalizing on the agreement or lack thereof between models, improves the answer visualization experience which could have potential implications in the field of MRC.", "venue": "EMNLP", "year": 2020, "title": "ARES - A Reading Comprehension Ensembling Service."}
{"pid": "634e194790e50fcafd24f2b7", "context": "Current relation extraction methods aim to extract semantic relationships from unstructured text, mainly written language. However, essential data sources such as spoken language have been largely ignored mainly due to error propagation introduced in automatic speech recognition (ASR). Conversely, approaches exploring end-to-end speech-based relation extraction are rare.", "key_idea": "This paper introduces a new task of speech relation extraction\u2014extracting semantic relationships from spoken language. It proposes two approaches: a pipeline approach involving text-based extraction with a pretrained ASR module and an end-to-end approach via a new proposed encoder-decoder model, SpeechRE.", "method": "The authors construct training and testing datasets for speech relation extraction using text-to-speech systems and crowd-sourcing from native English speakers respectively. Comprehensive experiments were conducted to determine the challenges in speech relation extraction.", "outcome": "The results from the experiments help distinguish the challenges present in speech relation extraction. The code and data are publicly available on Github.", "future_impact": "The findings of the experiments may help guide future explorations in the speech relation extraction field.", "venue": "EMNLP", "year": 2022, "title": "Towards Relation Extraction From Speech"}
{"pid": "5feaffdb91e011f5d342075b", "context": "Pretrained transformers have become the state-of-the-art for tasks in natural language processing, prompting researchers to investigate their inner mechanisms and understand what features are important for prediction.", "key_idea": "The authors propose the use of information bottlenecks to analyze the attribution of each feature for prediction on a black-box model, with BERT used as the example.", "method": "The authors evaluate their approach both quantitatively and qualitatively, also conducting degradation tests on four datasets against other methods.", "outcome": "The method showed effectiveness in terms of attribution and provided insight into how information flows through layers. It also outperformed two competitive methods in degradation tests.", "future_impact": "This work can aid in further understanding of pretrained transformers and development of more efficient models.", "venue": "EMNLP", "year": 2020, "title": "Inserting Information Bottlenecks for Attribution in Transformers"}
{"pid": "619799f191e011c822373153", "context": "Adversarial attacks have been proven to effectively impact text classification systems' performance, however, their influence on named entity recognition (NER) models, a fundamental task in information extraction, is less understood.", "key_idea": "This paper explores how adversarial attacks initially designed for text classification systems affect NER models and tests the effectiveness of adversarial training against these attacks.", "method": "The authors examine the effectiveness and portability of adversarial attacks from text classification to named entity recognition, and the potential of adversarial training to counter these attacks.", "outcome": "The authors found character-level and word-level attacks to be the most effective. However, adversarial training was found to provide significant protection without significantly affecting standard performance.", "future_impact": "Broadcast of our algorithm SeqAttack, an infrastructure for executing adversarial attacks against token classification models, and a companion web application for adversarial examples investigation could allow for more discoveries on this topic.", "venue": "EMNLP", "year": 2021, "title": "SeqAttack: On Adversarial Attacks for Named Entity Recognition"}
{"pid": "63a1750d90e50fcafd1f3c42", "context": "There is a need for a versatile system that can support the annotation of diverse types of text and multimodal data, offer productivity-enhancing features for both the deployers and annotators, and provide extensive customizability.", "key_idea": "The authors introduce POTATO, a free, fully open-sourced portable text annotation tool designed with functionalities like active learning, keypress shortcuts, and configurable UI tailored for productivity and flexibility.", "method": "The productivity-enhancing features of POTATO and their impact on labeling speed were assessed with experiments over two annotation tasks, especially for long documents and complex tasks.", "outcome": "Experimental results suggest that the specialized productivity features of POTATO significantly improve labeling speed, particularly for long documents and complex tasks.", "future_impact": "POTATO, available for free on GitHub, will continue to be updated, suggesting potential extensions and continued impact on the field of text annotation.", "venue": "EMNLP", "year": 2022, "title": "POTATO: The Portable Text Annotation Tool"}
{"pid": "63881b9290e50fcafd3db31e", "context": "Machine learning models typically assume independent and identically distributed (i.i.d) data during training and testing, whilst in real-world scenarios, data and tasks often change over time. Furthermore, current modular approaches in Natural Language Processing (NLP) are not leveraging the progress in parameter efficient tuning of pretrained language models.", "key_idea": "The authors propose a new task of text classification in-the-wild, where it involves different non-stationary training/testing stages. To efficiently handle it, they introduce MODULARPROMPT, a label-modular prompt tuning framework that decomposes complex tasks into modular components for text classification.", "method": "In MODULARPROMPT, the input prompt consists of a sequence of soft label prompts, each encoding modular knowledge related to the corresponding class label. The framework is evaluated under challenging settings and its modular representation properties are analyzed.", "outcome": "MODULARPROMPT outperformed the relevant baselines in the most formidable settings, demonstrating strong generalization ability.", "future_impact": "The introduction of the in-the-wild text classification task and use of label-modular prompt tuning can encourage the development of more robust models that can handle the dynamic nature of real-world data.", "venue": "EMNLP", "year": 2022, "title": "Learning Label Modular Prompts for Text Classification in the Wild"}
{"pid": "5ff8839291e011c832673984", "context": "Multi-Domain Neural Machine Translation (NMT) is challenging due to the diversity of cross-domain wording and phrasing style, the imperfections of training data distribution, and the inherent defects of the current sequential learning process.", "key_idea": "The paper proposes the Factorized Transformer, a new NMT model that factorizes the parameters of the Transformer model into domain-shared ones that encode common cross-domain knowledge and domain-specific ones that are private for each constituent domain.", "method": "The authors experiment with various designs of their model and conduct tests on the English to French open multi-domain dataset.", "outcome": "The Factorized Transformer achieves state-of-the-art performance on the English to French multi-domain dataset.", "future_impact": "The proposed model opens up new perspectives for multi-domain and open-domain machine translation applications.", "venue": "EMNLP", "year": 2020, "title": "Factorized Transformer for Multi-Domain Neural Machine Translation."}
{"pid": "61b80b745244ab9dcbf49817", "context": "Keyphrase generation in scholarly domains has largely focused on generating keyphrases using only the title and abstract of the articles.", "key_idea": "The authors explore if incorporating additional information from the full text of an article or from semantically similar articles can enhance a neural keyphrase generation model. They propose incorporating sentences from the full text, particularly in the form of the extractive summary of the article, to significantly improve keyphrase generation.", "method": "The authors experiment with three widely used models for keyphrase generation plus one of the latest transformer models suitable for long documents, Longformer Encoder-Decoder (LED). They also present a new large-scale scholarly dataset FullTextKP for keyphrase generation.", "outcome": "Adding sentences from the full text, especially in the form of the extractive summary of the article, significantly improves the generation of keyphrases that are either present or absent from the text.", "future_impact": "The FullTextKP dataset, which includes full text of the articles along with the title and abstract, and source code will be released for future work in this field.", "venue": "EMNLP", "year": 2021, "title": "Keyphrase Generation Beyond the Boundaries of Title and Abstract"}
{"pid": "613ec1295244ab9dcb8168f3", "context": "Large pre-trained language models have achieved remarkable scores on a number of language understanding tasks. However, measurements based only on end task performance do not provide a clear picture of the machines' true capabilities in terms of language understanding and reasoning.", "key_idea": "The authors introduce a novel dataset known as Tiered Reasoning for Intuitive Physics (TRIP) which focuses on evaluating the underlying reasoning process of machines and not just the end performance.", "method": "The authors performed empirical evaluations using their TRIP dataset to assess the machine reasoning process.", "outcome": "While large LMs can achieve high end performance, the empirical results show that they struggle to support their predictions with valid supporting evidence.", "future_impact": "The TRIP dataset along with the associated baseline results can pave the way for verifiable evaluation of commonsense reasoning and facilitate future research toward developing better language understanding and reasoning models.", "venue": "EMNLP", "year": 2021, "title": "Tiered Reasoning for Intuitive Physics - Toward Verifiable Commonsense Language Understanding."}
{"pid": "618cfbab91e011333c93282c", "context": "Although the development of corpora in English has led to significant advances in training semantic parsers, data in other languages is limited, impacting the performance of parsers in these languages. While pretrained multilingual models have been proven useful for zero-shot cross-lingual transfer in many NLP tasks, the requirements for applying a parser trained in English to other languages for zero-shot cross-lingual semantic parsing are still unclear.", "key_idea": "The authors propose the use of simple language-independent features \u2014 Universal Dependency (UD) relations and Universal POS tags (UPOS) \u2014 in the generalization of English-trained Discourse Representation Structure (DRS) semantic parsers to Italian, German and Dutch.", "method": "The authors conducted experiments using six DRS semantic parsers in English and applied them to Italian, German and Dutch, where there are only a small number of manually annotated parses available.", "outcome": "The experiments show that despite its simplicity, adding UD relations and UPOS tags as model-agnostic features improves the performance of all parsers in the tested languages.", "future_impact": "The authors' approach could lead to further advances in zero-shot cross-lingual semantic parsing and open new opportunities for facilitating language processing in languages other than English.", "venue": "EMNLP", "year": 2021, "title": "Frustratingly Simple but Surprisingly Strong - Using Language-Independent Features for Zero-shot Cross-lingual Semantic Parsing."}
{"pid": "627dbeda5aee126c0ff67c70", "context": "Task transfer in the context of the conversational AI has not been thoroughly studied despite its potential to reduce the quantity of labeled data required to fine-tune dialogue understanding models.", "key_idea": "The authors introduce FETA, a benchmark for few-sample task transfer in open-domain dialogue. This includes 132 source-target task pairs enabling the study of intra-dataset task transfer without domain adaptation.", "method": "Three popular language models and three learning algorithms are utilised to analyse the transferability between various task pairs in both single- and multi-source settings, resulting in a baseline for future research.", "outcome": "Valuable findings were reported, including that performance trends are largely model-specific, and that span extraction and multiple-choice tasks benefit the most from task transfer.", "future_impact": "FETA can be a valuable resource for future research into efficiency and generalizability of pre-training datasets and model architectures, and for exploring learning settings such as continual and multitask learning.", "venue": "EMNLP", "year": 2022, "title": "FETA: A Benchmark for Few-Sample Task Transfer in Open-Domain Dialogue"}
{"pid": "67fde8dd-7364-4dc0-a1d2-8a66fba451da", "context": "String transformation, which reroutes a source string s into a desired form t*, is a key procedure in a number of applications like stemming, lemmatization, and spelling correction. Essential to the process of string transformation is the generation of candidates that the given string s is likely to transform into.", "key_idea": "A discriminative approach to candidate string generation is introduced in this paper. Substring substitution rules are used as features, and these are scored using an L1-regularized logistic regression model. A procedure is also proposed to generate negative instances that influence the decision boundary of the model.", "method": "The authors demonstrate the effectiveness of the proposed method through its application in the normalization of inflected words and spelling variations.", "outcome": "The implemention of the proposed method shows substantial performance in normalizing inflected words and spelling variations, however, the exact measures of its performance are not mentioned in the abstract.", "future_impact": "The paper suggests that the proposed method for candidate string generation can significantly improve the processes of string transformation in various applications such as stemming, lemmatization, and spelling correction, but specific impacts are not detailed in the abstract.", "venue": "EMNLP", "year": 2008, "title": "A Discriminative Candidate Generator for String Transformations"}
{"pid": "634e194790e50fcafd24f31c", "context": "Query-aware webpage snippet extraction is an important feature in search engines, but it is rarely studied, despite its usefulness in helping users better understand the content of returned webpages before clicking.", "key_idea": "The paper proposes an effective query-aware webpage snippet extraction method, DeepQSE, which first learns query-aware sentence representations, and then learns document-aware query-sentence relevance representations for snippet extraction, an idea which is further expanded upon with Efficient-DeepQSE.", "method": "DeepQSE's efficiency is improved via Efficient-DeepQSE, which decomposes the snippet extraction task into a coarse-grained candidate sentence selection stage, where sentence representations can be cached, and a fine-grained relevance modeling stage. Both methods are tested with experiments on two real-world datasets.", "outcome": "The authors report that their experiments validate the effectiveness and efficiency of their proposed methods, DeepQSE and Efficient-DeepQSE.", "future_impact": "The efficient query-aware webpage snippet extraction methods proposed in this paper might further assist in improving user experience during web searches, as users can better understand webpage content before clicking.", "venue": "EMNLP", "year": 2022, "title": "Effective and Efficient Query-aware Snippet Extraction for Web Search"}
{"pid": "614a9eca5244ab9dcbc38b7c", "context": "Adapting neural machine translation (NMT) models to emerging cases without retraining is a challenge. Existing non-parametric approaches that retrieve similar examples from a database to guide the translation process can overfit on these examples.", "key_idea": "The authors propose a new method called Kernel-Smoothed Translation with Example Retrieval (KSTER) to adapt neural machine translation models online without the need for retraining.", "method": "KSTER is evaluated on domain adaptation and multi-domain machine translation datasets.", "outcome": "The experiments show that KSTER can improve the result by 1.1 to 1.5 BLEU scores over other existing online adaptation methods without needing expensive retraining.", "future_impact": "Given the performance improvement achieved, the proposed KSTER method may shape future online adaptation strategies in Neural Machine Translation.", "venue": "EMNLP", "year": 2021, "title": "Learning Kernel-Smoothed Machine Translation with Retrieved Examples."}
{"pid": "6887c4af-61a4-4209-bd4b-c6e656f085d3", "context": "Models used for tasks such as Named Entity Recognition and Chunking typically require lexical features extracted from a training corpus, often with up to 100K distinct features.", "key_idea": "The authors propose the use of SVM anchoring to show that lexical features are not necessary for achieving state of the art results on naming entity recognition and chunking tasks. They argue that the impact of rare lexical features on classification in NLP is not fully understood.", "method": "The authors use SVM anchoring to create models with a reduced set of features. They perform a contrastive error analysis to measure the effect of lexical features on resolving semantic and complex syntactic ambiguities.", "outcome": "The authors were able to derive models with as few as 1K features that performed as well or better on different domains, indicating that lexical features may not generalize well outside the training corpus.", "future_impact": "They suggest a general strategy that lexical features should not be directly derived from a training corpus but carefully inferred and selected from other sources, which could change how NLP models are trained.", "venue": "EMNLP", "year": 2009, "title": "On the Role of Lexical Features in Sequence Labeling"}
{"pid": "6153e0335244ab9dcb39c30d", "context": "Improving the classification performance for challenging examples in machine learning models remains a challenge.", "key_idea": "The authors introduce a non-parametric post-processing step for classification called Classification with Alternating Normalization (CAN). It improves classification accuracy by re-adjusting the predicted class probability distribution using the predicted class distributions of high-confidence validation examples.", "method": "The properties of CAN are analyzed through simulated experiments, and its effectiveness is empirically demonstrated across a diverse set of classification tasks.", "outcome": "Empirical trials have shown CAN to be effective across a diverse set of classification tasks, although the abstract doesn't provide specific results.", "future_impact": "CAN can be easily applied to any probabilistic classifier, signaling potential wide applicability and impact in improving machine learning classification models.", "venue": "EMNLP", "year": 2021, "title": "When in Doubt - Improving Classification Performance with Alternating Normalization."}
{"pid": "6576dae5939a5f40821260ae", "context": "Sequence-to-sequence models struggle with compositional generalization (CG), the ability to systematically generalize to unseen compositions of seen components, due to entangled representations where syntactic and semantic representations of sequences are intertwined. Furthermore, it is suggested that the source keys and values representations passing into different decoder layers are also entangled.", "key_idea": "From the observation that lower layers of the Transformer encoder contain more syntactic information and the top ones contain more semantic information, the authors propose an extension to sequence-to-sequence models, CompoSition, that composes representations of different encoder layers dynamically for different tasks.", "method": "The authors introduce a composed layer between the encoder and decoder in seq2seq models to compose different encoder layer's representations and generate specific keys and values passing into different decoder layers. They empirically test this method on two comprehensive and realistic benchmarks.", "outcome": "CompoSition shows competitive results on two comprehensive and realistic benchmarks, confirming its effectiveness.", "future_impact": "The introduction of CompoSition opens an avenue for improving compositional generalization in seq2seq models by addressing representation entanglement issues, which will likely influence forthcoming research in this area.", "venue": "EMNLP", "year": 2023, "title": "Learning to Compose Representations of Different Encoder Layers towards Improving Compositional Generalization."}
{"pid": "5ff883d991e011c83267443b", "context": "Reproducibility is a common challenge in research and, in knowledge graph embedding models for link prediction, it's difficult to concurrently facilitate hyperparameter optimization, evaluation, and individual component analysis.", "key_idea": "LibKGE is an open-source PyTorch-based library designed for training, hyperparameter optimization, and evaluation of knowledge graph embedding models for link prediction, aiming to enable reproducible research, comprehensive experimental studies, and to facilitate component analysis.", "method": "LibKGE is created with high configurability and decoupling of individual components for flexibility. A comparative study (Ruffinelli et al., 2020) was conducted to evaluate the effectiveness of LibKGE.", "outcome": "LibKGE, characterized by its configurability and the decoupling of its components, allows for reproducibility of experiments from single configuration files. According to a study, LibKGE reached competitive to state-of-the-art performance for many models with a modest amount of automatic hyperparameter tuning.", "future_impact": "The library provides a framework for comprehensive experimental studies of knowledge graph embedding models for link prediction and the potential to analyze the contributions of individual components of the training method, model architecture, and evaluation methods.", "venue": "EMNLP", "year": 2020, "title": "LibKGE - A knowledge graph embedding library for reproducible research."}
{"pid": "4286f15d-417c-424c-9c9b-56654430eb6d", "context": "Determining the semantic roles of a verb's dependents is a crucial part of natural language understanding. Existing methods for learning verb argument patterns often require annotated text and don't provide statistics about the linkings used by each verb.", "key_idea": "The authors propose an unsupervised method for learning models of verb argument patterns directly from unannotified text.", "method": "The method is based on a structured probabilistic model of the domain, and the unsupervised learning is executed using the Expectation-Maximization (EM) algorithm.", "outcome": "The learned models are comparable to existing verb lexicons such as VerbNet and PropBank and also include statistics about the linkings used by each verb. The learned model reduces 28% of the error between an informed baseline and an oracle upper bound when evaluated relative to the PropBank annotation.", "future_impact": "The models learned from this method can be applied discriminatively as semantic role labelers, suggesting potential future applications in deeper natural language understanding tasks.", "venue": "EMNLP", "year": 2006, "title": "Unsupervised Discovery of a Statistical Verb Lexicon"}
{"pid": "63a2c50c90e50fcafdb9a194", "context": "Computer-aided translation (CAT) tools based on translation memories (TMs) are prominent in professional translators' workflow. However, their limited use for various translation tasks is due to the scarceness of in-domain TMs compared to in-domain monolingual corpora.", "key_idea": "A novel neural approach is introduced to overcome the limitations of TM-based CAT tools by exploiting in-domain target-language monolingual corpora. This approach uses cross-lingual sentence embeddings to retrieve translation proposals from the corpora and a neural model to estimate their post-editing effort.", "method": "The paper presents an automatic evaluation of the proposed approach on four language pairs and a human evaluation on a single language pair.", "outcome": "Results from both automatic and human evaluations show the success of the proposed approach in enhancing the functionality of TM-based CAT tools by leveraging monolingual corpora and effectively estimating the post-editing effort.", "future_impact": "The new approach could possibly boost the amount of useful translation proposals in CAT tools, hinting at the potential to improve productivity and efficiency in translation tasks.", "venue": "EMNLP", "year": 2024, "title": "Cross-lingual neural fuzzy matching for exploiting target-language   monolingual corpora in computer-aided translation"}
{"pid": "e08f89a8-148f-4d6a-9838-d5a32cc389aa", "context": "Microblog normalisation methods often use complex models and struggle to differentiate between correctly-spelled unknown words and lexical variants of known words.", "key_idea": "The authors propose a dictionary-based method for constructing a dictionary of lexical variants of known words that facilitates lexical normalisation via simple string substitution (e.g. tomorrow for tmrw).", "method": "The authors use context information to generate possible variant and normalisation pairs, then rank these pairs by string similarity. Highly-ranked pairs are selected to populate the dictionary.", "outcome": "The proposed dictionary-based method achieved state-of-the-art performance for both F-score and word error rate on a standard dataset.", "future_impact": "The proposed approach offers a fast, lightweight and easy-to-use solution and is suitable for high-volume microblog pre-processing.", "venue": "EMNLP", "year": 2012, "title": "Automatically Constructing a Normalisation Dictionary for Microblogs"}
{"pid": "8c34684f-fb99-470e-8810-d15b6db384a3", "context": "In the area of sentiment analysis and opinion mining, the automated extraction of subjective expressions is currently not robust due to the lack of linguistically rich patterns.", "key_idea": "This paper proposes a bootstrapping process that learns linguistically rich extraction patterns for subjective (opinionated) expressions. High-precision classifiers are used for annotation to automatically create a large training set for an extraction pattern learning algorithm.", "method": "The authors use a bootstrapping process where learned patterns are further used to identify more subjective sentences, thereby enriching the pool of extraction patterns in an iterative manner.", "outcome": "The bootstrapping process learns many subjective patterns and successfully increases recall while maintaining high precision.", "future_impact": "Given the importance of sentiment analysis in various applied domains like product reviews, customer feedback etc., this bootstrapping approach to learning subjective extraction patterns can lead to more efficient and automated sentiment analysis techniques.", "venue": "EMNLP", "year": 2003, "title": "Learning extraction patterns for subjective expressions"}
{"pid": "63d340e890e50fcafd9109d1", "context": "Using audience-tailored linguistic styles is important for user-centric language generation systems, but it is limiting to ground style on audience-independent external factors due to the challenges in collecting audience-specific stylistic data and defining stylistic objectives without audience feedback.", "key_idea": "The authors propose the new task of style infusion, which involves infusing the stylistic preferences of audiences in pretrained language generation models by leveraging limited pairwise human judgments to bootstrap a style analysis model and augment their seed set of judgments.", "method": "The adopted method is to infuse the learned textual style in a GPT-2 based text generator while balancing fluency and style adoption. Their approach is evaluated through quantitative and qualitative assessments.", "outcome": "The results show that their infusion approach can generate compelling stylized examples with generic text prompts.", "future_impact": "The method has the potential to greatly improve the quality and effectiveness of user-centric language generation systems by allowing them to more accurately reflect the stylistic preferences of their intended audience.", "venue": "EMNLP", "year": 2022, "title": "Audience-Centric Natural Language Generation via Style Infusion"}
{"pid": "635753cb90e50fcafdddd9bb", "context": "Adversarial Examples Detection (AED) is a crucial defense technique against adversarial attacks in Natural Language Processing (NLP). However, existing methods heavily rely on a shortcut by stopping once model predictions change, resulting in most adversarial examples being located near model decision boundaries.", "key_idea": "The authors suggest surpassing this shortcut by testing AED methods with Far Boundary (FB) adversarial examples, and propose a new technique called ADDMU (adversary detection with data and model uncertainty), which utilizes two types of uncertainty estimation for both regular and FB adversarial example detection.", "method": "The ADDMU is tested against previous AED methods using FB adversarial examples.", "outcome": "The ADDMU technique outperforms previous methods by 3.6 and 6.0 AUC points under each scenario.", "future_impact": "The two types of uncertainty provided by ADDMU can be utilized to characterize adversarial examples and identify the ones that contribute most to model's robustness, potentially improving adversarial training.", "venue": "EMNLP", "year": 2022, "title": "ADDMU: Detection of Far-Boundary Adversarial Examples with Data and Model Uncertainty Estimation"}
{"pid": "a94d8867-6b95-4ef1-a18c-6c0209d69a60", "context": "The common speech understanding architecture for spoken dialogue systems utilizes a combination of speech recognition based on a class N-gram language model, and robust parsing. However, training a good class N-gram language model requires a large amount of corpus data, and the grammar-based recognition often provides better results for users who are familiar with system coverage.", "key_idea": "The paper proposes the use of grammar-based methods for speech understanding, particularly for speech translation systems.", "method": "The paper compares the efficiency of class N-gram/robust and grammar-based systems and evaluates their performance through head-to-head comparisons.", "outcome": "The comparison results suggest that users who are familiar with system coverage get better results from grammar-based architectures.", "future_impact": "The findings from this study imply that real-world applications and emerging speech translation systems could benefit from employing grammar-based approaches.", "venue": "EMNLP", "year": 2005, "title": "Japanese Speech Understanding using Grammar Specialization"}
{"pid": "635753cc90e50fcafddddd48", "context": "Building open-domain chatbots that are able to use diverse communicative skills is an ongoing challenge and there's a need for datasets that could effectively train these chatbots.", "key_idea": "The authors propose the BotsTalk framework that allows multiple agents grounded to specific target skills to participate in a conversation, thereby automatically annotating multi-skill dialogues.", "method": "To validate BotsTalk, the authors generate the BSBT, a large-scale multi-skill dialogue dataset comprising 300K conversations and perform experiments with multi-skill dialogue systems.", "outcome": "The experiments demonstrate that the BSBT dataset can be effective for multi-skill dialogue systems, aiding the understanding of skill blending and skill grounding.", "future_impact": "The BotsTalk system and the BSBT dataset can be used for future development and improvement of open-domain chatbots requiring diverse communicative skills.", "venue": "EMNLP", "year": 2022, "title": "BotsTalk: Machine-sourced Framework for Automatic Curation of Large-scale Multi-skill Dialogue Datasets"}
{"pid": "5ff8839291e011c8326739f6", "context": "Early intervention using social media data to identify suicide risks has garnered attention. The use of a suicide dictionary created by mental health experts has proven effective in detecting suicidal ideation. However, validation of these dictionaries for languages other than English and Chinese, particularly for low-resource languages like Korean where a knowledge-based suicide dictionary has not been developed, has been lacking.", "key_idea": "The authors propose a cross-lingual suicidal ideation detection model that can identify whether a given social media post includes suicidal ideation. The model translates a post from a target low-resource language into English and Chinese, leveraging existing suicide dictionaries developed for these languages.", "method": "The proposed model uses suicidal-oriented word embeddings developed separately for English and Chinese. Posts written in Korean are translated into English and Chinese, utilizing the respective suicidal-oriented word embeddings. The model applies an ensemble approach for different languages.", "outcome": "The cross-lingual suicidal ideation model achieves high accuracy, over 87%, in identifying posts containing suicidal ideation.", "future_impact": "The authors anticipate that their model may be useful in accessing suicidal ideation from social media data, thus aiding in early-stage suicide risk prevention.", "venue": "EMNLP", "year": 2020, "title": "Cross-Lingual Suicidal-Oriented Word Embedding toward Suicide Prevention."}
{"pid": "cc331084-a6f3-495f-afb9-0756644c06d3", "context": "Boosting is a machine learning algorithm that is not well known in computational linguistics, particularly in part-of-speech tagging and prepositional phrase attachment tasks.", "key_idea": "The authors present the application of the boosting algorithm to part-of-speech tagging and prepositional phrase attachment tasks, and also propose its utilization to improve data quality by identifying annotation errors.", "method": "The method involves the application of the boosting algorithm to perform part-of-speech tagging and prepositional phrase attachment tasks and identify annotation errors.", "outcome": "The performance of the application of the boosting algorithm was found to be very encouraging.", "future_impact": "The use of boosting algorithm could potentially improve the quality of data by identifying annotation errors in computational linguistics.", "venue": "EMNLP", "year": 1999, "title": "Boosting Applied to Tagging and PP Attachment"}
{"pid": "952e8aa4-bf51-4a65-abc0-ef4f2ca3210c", "context": "Response generation to social media posts is a challenging task due to the wider range of possible responses, unaligned words/phrases, and the presence of large phrase pairs whose alignment cannot be further decomposed.", "key_idea": "The authors propose a novel data-driven approach for generating responses to Twitter status posts using phrase-based Statistical Machine Translation (SMT).", "method": "The authors addressed the challenges faced in mapping conversational stimuli onto responses and compared approaches based on SMT and Information Retrieval through human evaluation.", "outcome": "SMT was found to outperform Information Retrieval on the task of response generation. Even more, the SMT-generated responses were preferred over actual human responses in 15% of cases.", "future_impact": "This is the first work to use phrase-based SMT to directly translate a linguistic stimulus into an appropriate response, potentially having a significant impact on future research in automated response generation.", "venue": "EMNLP", "year": 2011, "title": "Data-Driven Response Generation in Social Media"}
{"pid": "628304435aee126c0f6ed01c", "context": "Verifying complex political claims is a challenging task, and current automatic fact-checking systems have limitations in determining the veracity of such claims. Their predictions like 'half-true' are not very informative by themselves since we have no clarity on which parts of the claim are true and which are not.", "key_idea": "The authors propose decomposing a complex claim into a comprehensive set of yes-no subquestions whose answers influence the veracity of the claim. They create 'ClaimDecomp', a dataset of decompositions for over 1000 claims, to address the detailed facets of a claim both explicitly and implicitly.", "method": "The authors use a verification paragraph written by fact-checkers for each claim in their dataset and have trained annotators write subquestions covering both explicit and implicit aspects of the claim. The authors then study whether state-of-the-art models can generate such subquestions from the dataset.", "outcome": "Their results show that while state-of-the-art models generate reasonable questions, they struggle in predicting the comprehensive set of subquestions derived from the original claim without evidence. However, these subquestions can assist in identifying relevant evidence to fact-check the full claim and help derive its veracity.", "future_impact": "The study suggests that these subquestions could be a useful component of a fact-checking pipeline, possibly enhancing the accuracy and effectiveness of automatic fact-checking systems.", "venue": "EMNLP", "year": 2022, "title": "Generating Literal and Implied Subquestions to Fact-check Complex Claims"}
{"pid": "6392a76d90e50fcafd8c3985", "context": "Transfer learning is used in low-resource neural machine translation (NMT) to boost model performance. However, existing transfer learning methods for NMT are static, transferring knowledge from a parent model to a child model only once through parameter initialization.", "key_idea": "The authors propose a novel transfer learning method for NMT called ConsistTL, which continuously transfers knowledge from the parent model during the child model's training. It creates semantically-equivalent instances for the parent model and encourages prediction consistency between models for every instance.", "method": "The authors conducted experiments on five low-resource NMT tasks to validate the proposed ConsistTL method.", "outcome": "Experimental results show that ConsistTL significantly improves over strong transfer learning baselines, achieving a gain of up to 1.7 BLEU over the existing back-translation model on the WMT17 Turkish-English benchmark.", "future_impact": "Further analysis indicates that ConsistTL could improve the inference calibration of the child model, hinting at potential for improving the efficiency and efficacy of transfer learning methods in the future.", "venue": "EMNLP", "year": 2022, "title": "ConsistTL: Modeling Consistency in Transfer Learning for Low-Resource Neural Machine Translation"}
{"pid": "635753d390e50fcafdddf22b", "context": "Construction Grammar (CxG) emphasises the connection between syntax and semantics in language. Pretrained language models are known for their state-of-the-art performance in several natural language processing tasks, and their compatibility with CxG is yet to be assessed.", "key_idea": "The authors aim to investigate the capability of pretrained language models (PLMs) like BERT, RoBERTa, and DeBERTa, to classify and understand the English comparative correlative (CC), which is a commonly studied construction in CxG.", "method": "The authors conduct experiments examining the classification accuracy of a syntactic probe, and the models' behaviour in a semantic application task, using BERT, RoBERTa, and DeBERTa.", "outcome": "The investigation results show that all the three PLMs can recognise the structure of CC but fail to use its meaning, suggesting challenges in central domains of linguistic knowledge.", "future_impact": "This study provides insights into the shortcomings of present language models, indicating the need for future research in improving the linguistic knowledge in a model to make it more human-like.", "venue": "EMNLP", "year": 2022, "title": "The Better Your Syntax, the Better Your Semantics? Probing Pretrained   Language Models for the English Comparative Correlative"}
{"pid": "635753cc90e50fcafddddc5e", "context": "There is a growing interest in developing evaluation metrics for estimating the quality of text generation without the need for a human-written reference text. These references can be costly and time-consuming to gather or may be unavailable in online settings.", "key_idea": "The authors argue that reference-free metrics, used for evaluating text generation, inherently carry certain biases and limitations, and thus, should not be used as a measure of progress, particularly in tasks like machine translation or summarization.", "method": "The authors assess the limitations of reference-free metrics, demonstrating their inherent biases and outlining how these metrics can be manipulated during test time, favor models similar to their own, and be biased against superior quality outputs, including human-written ones.", "outcome": "The study reveals that reference-free metrics are not reliable measures of model task performance due to their inherent biases and limitations.", "future_impact": "In light of these findings, the authors recommend that reference-free metrics be used as diagnostic tools for analyzing and understanding model behavior, rather than measures of task performance.", "venue": "EMNLP", "year": 2022, "title": "On the Limitations of Reference-Free Evaluations of Generated Text"}
{"pid": "647eaf51d68f896efad41de7", "context": "Large Language Models (LLMs) are generally trained to interpret static images, focusing primarily on image comprehension. However, these models face challenges in understanding videos, specifically in capturing temporal changes in visual scenes and integrating audio-visual signals.", "key_idea": "Video-LLaMA is a multi-modal framework that augments LLMs with the capability of understanding both visual and auditory content in videos. It extends pre-trained encoders and LLMs to a video encoder (Video Q-former) for capturing temporal changes and an audio encoder (Audio Q-former) for integrating audio-visual signals.", "method": "Video-LLaMA is trained on a large-scale vision caption dataset and a high-quantity vision-instruction-tuning dataset. It employs a video-to-text generation task to learn video-language correspondence and uses ImageBind as a pre-trained audio encoder.", "outcome": "Video-LLaMA demonstrates the ability to understand and interpret video content, generating meaningful responses that take into account the visual and auditory elements present in videos.", "future_impact": "The efficacy of Video-LLaMA in capturing and integrating visual and audio signals from videos suggests its potential to serve as a promising prototype for audio-visual AI assistants.", "venue": "EMNLP", "year": 2023, "title": "Video-LLaMA: An Instruction-tuned Audio-Visual Language Model for Video Understanding."}
{"pid": "613192785244ab9dcb9dffb9", "context": "Data-driven subword segmentation has become the default strategy for open-vocabulary machine translation and other NLP tasks. However, the effectiveness of such strategies for handling non-concatenative morphology (where morphemes are not always consecutive and linear) is still uncertain.", "key_idea": "This study designs a test suite to evaluate segmentation strategies on different types of morphological phenomena in a controlled, semi-synthetic setting.", "method": "The authors compare machine translation models trained on both subword- and character-level data, focusing on their ability to translate different morphological phenomena.", "outcome": "The experiments show that learning to analyse and generate morphologically complex surface representations, especially for non-concatenative morphological phenomena like reduplication or vowel harmony and for rare word stems, is still challenging.", "future_impact": "The authors recommend for future text representation strategies to be tested on a range of typologically diverse languages to minimize the risk of inadvertently disadvantaging certain languages, providing a direction for subsequent researches.", "venue": "EMNLP", "year": 2021, "title": "How Suitable Are Subword Segmentation Strategies for Translating Non-Concatenative Morphology?"}
{"pid": "634e194890e50fcafd24f61a", "context": "Instruction tuning (IT), which fine-tunes a pre-trained language model on a massive collection of human-crafted instructions, has shown effective results in instruction learning for unseen tasks, but it relies heavily on a large volume of human-annotated samples, limiting its generalization capacity.", "key_idea": "The study aims to improve IT with the usage of unlabeled data, specifically proposing a method called Unlabeled Data Augmented Instruction Tuning (UDIT), which constructs pseudo-labeled data from unlabeled plain texts for leveraging training instructions more efficiently.", "method": "The authors conduct investigations to shed light on IT performance trends in relation to the number of labeled data, instructions, and training tasks. They also test the effectiveness of UDIT through extensive experiments covering diverse scenarios of tasks and datasets.", "outcome": "The findings highlight the need to enhance the number of training instructions and suggest that instructions could be underutilized due to the dearth of labeled data. They also demonstrate that UDIT is effective across various scenarios of tasks and datasets.", "future_impact": "The detailed analysis of the key factors of UDIT could give further insight into how to improve Instruction Tuning with unlabeled data, potentially enhancing the ability to generalize across tasks in future work.", "venue": "EMNLP", "year": 2022, "title": "Learning Instructions with Unlabeled Data for Zero-Shot Cross-Task Generalization"}
{"pid": "618cfba991e011333c932744", "context": "Modeling material science synthesis procedures with Natural Language Processing (NLP) could facilitate insights into creating materials. However, information extraction models for these procedures need accurate labels for the materials, operations, and other entities.", "key_idea": "The authors present a new corpus of entity mention annotations over 595 Material Science synthesis procedural texts and introduce new label inventory and annotation approach intended to improve consistency and annotation speed of domain experts.", "method": "The authors use inter-annotator agreement studies and train baseline models on the data to validate the effectiveness of the corpus.", "outcome": "Inter-annotator agreement studies and baseline model performance suggest that the new corpus provides high-quality annotations.", "future_impact": "The presented corpus lays a foundation for future high-quality modeling of synthesis procedures, potentially advancing the field of materials science.", "venue": "EMNLP", "year": 2021, "title": "MS-Mentions - Consistently Annotating Entity Mentions in Materials Science Procedural Text."}
{"pid": "618cfbab91e011333c932875", "context": "In end-to-end speech translation, knowledge distillation from a machine translation (MT) task is often used to improve the speech translation (ST) task. However, this allows only one way transfer of knowledge, which is deemed sub-optimal.", "key_idea": "The authors propose a mutual-learning scenario where the MT and ST models are collaboratively trained as peers, moving away from the conventional teacher-student paradigm.", "method": "The authors conduct experiments to test the effectiveness of the mutual-learning scenario with both the MT and ST models on MuST-C datasets.", "outcome": "The experimental results show that in a mutual-learning scenario, models can effectively utilize auxiliary information from peer models and achieve compelling results.", "future_impact": "The mutual-learning scenario could provide an alternative, more effective method for improving end-to-end speech translation by allowing models to use auxiliary information from peer models.", "venue": "EMNLP", "year": 2021, "title": "Mutual-Learning Improves End-to-End Speech Translation."}
{"pid": "a3971588-a541-44ff-90b7-ba15a72b602d", "context": "Tagging proper names such as organization, person, and place names in multilingual texts is crucial for diverse tasks such as information extraction, information retrieval and machine translation. The most successful systems today rely on hand-coded patterns to identify desired names in texts.", "key_idea": "RoboTag, a machine learning-based multilingual information extraction system prototype, was developed to enable an end-user to build a tagging system by providing examples of what should be tagged, rather than requiring the user to understand a pattern language.", "method": "RoboTag comprises of a general client/server architecture employing a decision-tree tagging approach. RoboTag performance is evaluated for the proper noun tagging task in English and Japanese and compared against human-tagged keys and to the best hand-coded pattern performance.", "outcome": "Details comparing the performance of RoboTag with human-tagged keys and best hand-coded pattern performances were not provided in the abstract.", "future_impact": "The abstract mentions 'future directions' but does not provide specific information about the future impact.", "venue": "EMNLP", "year": 1997, "title": "Learning to Tag Multilingual Texts Through Observation"}
{"pid": "625e1a335aee126c0feca4ca", "context": "The generalizability of NLP models towards unseen tasks when given task instructions is a challenge in the field.", "key_idea": "The study introduces 'Super-NaturalInstructions', a benchmark comprising of 1,616 diverse NLP tasks and expert-written instructions for these tasks. In addition, the paper introduces a transformer model Tk-Instruct which is trained to follow a variety of in-context instructions.", "method": "The authors conduct experiments testing the performance of Tk-Instruct and compare it against existing instruction-following models such as InstructGPT on the Super-NaturalInstructions benchmark. They further analyse generalization as a function of various scaling parameters like the number of observed tasks, the number of instances per task, and model sizes.", "outcome": "Tk-Instruct outperforms existing instruction-following models such as InstructGPT by over 9% on their benchmark despite being an order of magnitude smaller.", "future_impact": "The authors expect that their dataset and model would facilitate future progress towards more general-purpose NLP models.", "venue": "EMNLP", "year": 2022, "title": "Super-NaturalInstructions: Generalization via Declarative Instructions   on 1600+ NLP Tasks"}
{"pid": "63d9d86990e50fcafd57b11b", "context": "Multilingual pretrained language models (mPLMs) have been effectively used in multilingual word alignment induction, but they usually start from mBERT or XLM-R. The task of alignment extraction requires word-level embeddings to be language-agnostic, which presents a challenge.", "key_idea": "The authors propose the use of the multilingual sentence Transformer LaBSE instead of mBERT or XLM-R and aim to finetune LaBSE on a parallel corpus for improved performance in the word alignment task.", "method": "The authors conduct experiments on seven language pairs to investigate the effectiveness of the LaBSE as a multilingual word aligner and the impacts of finetuning on the performance.", "outcome": "The vanilla LaBSE outperforms other mPLMs currently used in the alignment task. The finetuned LaBSE aligner outperforms previous state-of-the-art models and achieves new state-of-the-art results on zero-shot language pairs that were not present in the finetuning process.", "future_impact": "The development of an aligner that supports different language pairs in a single model opens up new possibilities for handling multilingual alignment tasks, especially for zero-shot language pairs.", "venue": "EMNLP", "year": 2022, "title": "Multilingual Sentence Transformer as A Multilingual Word Aligner"}
{"pid": "638d612490e50fcafd14ad4f", "context": "Past and present approaches for Semantic Role Labeling (SRL) rely upon discrete labels drawn from a predefined linguistic inventory to classify predicate senses and their arguments.", "key_idea": "Authors propose a new approach that uses Definition Modeling to reformulate SRL as a task of describing predicate-argument structures using natural language definitions instead of using discrete labels.", "method": "Authors conducted experiments and analyses on PropBank-style and FrameNet-style, dependency-based, and span-based SRL to test their new formulation.", "outcome": "The results demonstrate that a flexible model with an interpretable output does not necessarily come at the expense of performance.", "future_impact": "This new approach could enhance the interpretability and flexibility of semantic role labeling, which could potentially influence future research in this area. The authors also make their software public for research purposes.", "venue": "EMNLP", "year": 2022, "title": "Semantic Role Labeling Meets Definition Modeling: Using Natural Language   to Describe Predicate-Argument Structures"}
{"pid": "61e781645244ab9dcbf9a3e1", "context": "Structured knowledge grounding (SKG) leverages structured knowledge to complete user requests, but has been limited by the heterogeneous nature of its inputs and outputs, resulting in different SKG tasks being investigated by different communities in isolation.", "key_idea": "This study proposes UnifiedSKG, a framework that unifies 21 SKG tasks into a text-to-text format, aiming to promote systematic and compatible research across various SKG tasks, rather than being confined to a single task, domain, or dataset.", "method": "The authors benchmark the T5 model with varying sizes on the UnifiedSKG framework, implement multi-task prefix-tuning, and investigate zero-shot and few-shot learning capabilities of T0, GPT-3, and Codex. They also conduct controlled experiments on structured knowledge encoding variants across tasks.", "outcome": "T5, with simple modifications when necessary, achieves a state-of-the-art performance on nearly all of the 21 tasks, with multi-task prefix-tuning further boosting performance. Conversely, T0, GPT-3, and Codex struggle with zero-shot and few-shot learning for SKG.", "future_impact": "UnifiedSKG is easily extensible to more tasks, suggesting increased future research on systematic SKG that could potentially leverage this shared framework.", "venue": "EMNLP", "year": 2022, "title": "UnifiedSKG: Unifying and Multi-Tasking Structured Knowledge Grounding with Text-to-Text Language Models"}
{"pid": "613829e95244ab9dcb15f2e9", "context": "Differential privacy, which provides a formal approach to individual privacy, is increasingly applied in various scenarios such as protecting users' original utterances. ADePT, a differentially private auto-encoder for text rewriting, purportedly achieves positive results on downstream tasks while providing strong privacy guarantees.", "key_idea": "The authors conduct a formal analysis of ADePT, aiming to determine if it genuinely satisfies the stringent requirements of differential privacy.", "method": "The authors deconstruct and scrutinize the mathematical proof underpinning ADePT's claim of being differentially private, and quantify the impact of errors in its privacy mechanism.", "outcome": "Their analysis reveals that ADePT is not differentially private, rendering previous experimental outcomes moot. They find the model's true sensitivity is at least six times higher in an optimistic scenario, and the proportion of unprivatized utterances could potentially reach 100% of the dataset.", "future_impact": "The authors advocate for more detailed scrutiny and full disclosure when claiming formal guarantees for differential privacy applications in natural language processing.", "venue": "EMNLP", "year": 2021, "title": "When differential privacy meets NLP - The devil is in the detail."}
{"pid": "5ee3526a91e011cb3bff7284", "context": "Learning theory often assumes the availability of complete and correct supervision signals for large amounts of data. However, in practice, machine learning professionals often use incidental supervision signals, which only have statistical associations with the gold-standard supervision.", "key_idea": "The authors propose a unified PAC-Bayesian Informativeness measure (PABI) to quantify the benefits of various incidental supervision signals as an approach to characterizing the reduction in uncertainty provided by these signals.", "method": "To demonstrate the utility of PABI, the authors apply it to quantify several types of incidental signals such as partial labels, noisy labels, constraints, cross-domain signals, and some combinations of these. The performance of PABI is then evaluated through experiments on named entity recognition and question answering tasks.", "outcome": "Experiments show that the PABI measure correlates well with learning performance, demonstrating its effectiveness at ascertaining which supervision signals can be advantageous.", "future_impact": "This research may provide a promising direction for determining the beneficial supervision signals in machine learning, even before the learning process starts.", "venue": "EMNLP", "year": 2021, "title": "Foreseeing the Benefits of Incidental Supervision."}
{"pid": "618cfba991e011333c932561", "context": "Multiple sources of auxiliary information have been shown to be effective in zero-shot fine-grained entity typing (ZFET), but there isn't a comprehensive understanding of how to best use these information sources and how they affect ZFET performance.", "key_idea": "The authors propose a multi-source fusion model (MSF) that uses three types of auxiliary information: context consistency, type hierarchy, and background knowledge (e.g., prototypes and descriptions) of types.", "method": "The proposed MSF model is empirically studied and compared with state-of-the-art baselines on two datasets: BBN and Wiki.", "outcome": "The MSF model achieved up to 11.42% and 22.84% absolute gains over state-of-the-art baselines on BBN and Wiki respectively in terms of macro F1 scores.", "future_impact": "This study provides a better understanding of the characteristics, advantages, and disadvantages of each information source, thus paving the way for further studies on how best to incorporate these sources to improve ZFET.", "venue": "EMNLP", "year": 2021, "title": "An Empirical Study on Multiple Information Sources for Zero-Shot Fine-Grained Entity Typing."}
{"pid": "5f7d91a791e011346ad27ddb", "context": "Existing automatic evaluation metrics for generated text focus predominantly on assessing content selection, often neglecting the linguistic quality aspect.", "key_idea": "To fill this gap, the paper proposes GRUEN (Grammaticality, non-Redundancy, focUs, structure and coherENce), a new evaluation measure for generated text that examines system output from a linguistic quality standpoint using a BERT-based model and a suite of syntactic, semantic, and contextual features.", "method": "The authors conduct experiments on seven datasets over four language generation tasks to test the effectiveness and applicability of GRUEN.", "outcome": "The results of these experiments demonstrate that GRUEN correlates highly with human judgments, suggesting its effectiveness in assessing linguistic quality in generated text.", "future_impact": "With its reference-less, unsupervised, deterministic, and task-adaptable characteristics, GRUEN is likely to serve as a valuable tool in various text generation environments and tasks, offering more comprehensive assessments of generated texts.", "venue": "EMNLP", "year": 2020, "title": "GRUEN for Evaluating Linguistic Quality of Generated Text"}
{"pid": "6563fe62939a5f408220f27d", "context": "When training data are collected from human annotators, various elements such as design of the annotation instrument, instructions given to annotators, their characteristics, and their interactions can impact the training data. However, the influence of the annotation instrument on the models trained on the resulting annotations has been little studied in machine learning.", "key_idea": "The authors introduce the term 'annotation sensitivity' and argue that design choices made when creating an annotation instrument can impact not just the annotations but also downstream model performance and predictions.", "method": "The authors collected annotations of hate speech and offensive language in five experimental conditions of an annotation instrument, assigning annotators randomly to conditions. They fine-tuned BERT models on each of the five datasets and evaluated model performance on a holdout portion of each condition.", "outcome": "The study found considerable differences between the conditions in terms of annotation frequency, model performance, model predictions, and model learning curves.", "future_impact": "The authors call for more research into understanding how and why the annotation instrument design impacts the annotations, which will serve to inform the development of best practices in instrument design.", "venue": "EMNLP", "year": 2023, "title": "Annotation Sensitivity: Training Data Collection Methods Affect Model   Performance"}
{"pid": "6232a74d5aee126c0fe13dcb", "context": "Current multitasking approaches in NLP typically produce one decoder adaptation per task, but this limits flexibility and may not provide the best performance across diverse tasks.", "key_idea": "The authors suggest using input-conditioned hypernetworks to generate parameter-efficient adaptations for a decoder using a hypernetwork conditioned on the output of an encoder, creating a unique decoder adaptation per input instance and providing greater flexibility.", "method": "The method is applied to sequence classification tasks, extractive QA, and summarisation to validate its performance and efficiency.", "outcome": "The proposed method surpassed previous parameter efficient fine-tuning methods and often outperformed fully fine-tuning the underlying model. Additionally, analysis of embeddings used by the hypernetwork showed that they were sensitive to output label and type.", "future_impact": "The findings suggest that the proposed approach could better map from encoder representations to output labels, enhancing the efficacy and flexibility of NLP multitasking.", "venue": "EMNLP", "year": 2022, "title": "Hyperdecoders: Instance-specific decoders for multi-task NLP"}
{"pid": "a42d083c-a449-473e-93b4-9b0fa2eae4b7", "context": "Prior research in Chinese definitional question answering has yet to establish the effectiveness of using a combination of deep linguistic analysis with surface pattern learning.", "key_idea": "This study explores a hybrid approach for Chinese definitional question answering which involves combining deep linguistic analysis with surface pattern learning.", "method": "Extensive experiments are conducted on biographical questions and other definitional questions. The study addresses four questions regarding the effectiveness of linguistic analysis, pattern learning, required annotation, and the most useful linguistic features.", "outcome": "The major findings are that linguistic analysis and pattern learning are complementary and both are required for an effective definitional QA system. Pattern matching is particularly effective for biographical questions while a small amount of annotation enables good performance for pattern learning systems. The most useful linguistic features identified are copulas and appositives, and some propositions convey vital facts.", "future_impact": "Their findings may further optimize the development process, reducing resource usage and improving effectiveness of future Chinese QA systems.", "venue": "EMNLP", "year": 2005, "title": "Combining Deep Linguistics Analysis and Surface Pattern Learning: A Hybrid Approach to Chinese Definitional Question Answering"}
{"pid": "5f91588191e011126509bdb5", "context": "Machine learning models of turn-taking have used linguistic information such as syntactic and pragmatic completeness in a limited way, indicating room for improvement in turn-taking prediction in spoken dialog.", "key_idea": "The authors introduce TurnGPT, a transformer-based language model designed to predict turn-shifts in spoken dialog, with the ability to leverage dialog context and pragmatic completeness.", "method": "TurnGPT is trained and evaluated on a variety of written and spoken dialog datasets. The authors also perform an ablation study, as well as attention and gradient analyses to investigate how the model utilizes dialog context and pragmatic completeness.", "outcome": "TurnGPT outperforms two prior baselines in turn-taking prediction. The model's ability to utilize dialog context and pragmatic completeness for turn-taking prediction is also confirmed through various analyses.", "future_impact": "The authors envision that the model has potential in not only detecting but also projecting turn-completions, suggesting a possible new direction for research in spoken dialog systems.", "venue": "EMNLP", "year": 2020, "title": "TurnGPT: a Transformer-based Language Model for Predicting Turn-taking  in Spoken Dialog"}
{"pid": "5f858a3d91e011ff32809829", "context": "As machine translation (MT) systems improve rapidly, questions about their adequacy, especially in handling linguistic properties like negation, continue to be an issue.", "key_idea": "The authors focus on the effect of negation, a universal property of human language, on the performance of machine translation systems.", "method": "They investigate negation translation in contemporary machine translation systems, using 17 translation directions as a test bed.", "outcome": "The study reveals that negation can significantly impact the quality of translation, with some cases showing quality reductions of over 60%.", "future_impact": "The authors have released their annotations and code to replicate the analysis, which may foster further research and improvement in the field of machine translation.", "venue": "EMNLP", "year": 2020, "title": "It's not a Non-Issue: Negation as a Source of Error in Machine  Translation"}
{"pid": "618cfba991e011333c932592", "context": "While contextualized embeddings have driven increased interest in neural ranking approaches for information retrieval, two challenges persist: i) queries usually comprise a few keywords that increase ambiguity and complicate their contextualization, and ii) executing neural ranking on non-English documents is cumbersome due to the lack of labeled datasets.", "key_idea": "To navigate these issues, the paper introduces SIR (Sense-enhanced Information Retrieval), which leverages word sense information to enhance understanding. This includes a novel, multilingual query expansion mechanism grounded on Word Sense Disambiguation that proffers sense definitions as additional semantic data for the query.", "method": "The authors use senses as a bridge across languages, and compare the performance of their model against supervised and unsupervised alternatives across French, German, Italian, and Spanish languages on several CLEF benchmarks, all while training solely on English Robust04 data.", "outcome": "The SIR model performs significantly better than its supervised and unsupervised alternatives across several languages on various CLEF benchmarks, despite being trained solely on English data.", "future_impact": "The authors release SIR for public usage, suggesting potential broader applications and continuous developments in the field.", "venue": "EMNLP", "year": 2021, "title": "IR like a SIR - Sense-enhanced Information Retrieval for Multiple Languages."}
{"pid": "61722bd75244ab9dcb6eface", "context": "Generating texts in scientific papers often requires acquiring external information called 'context', yet its impact is not adequately exploited in text generation, especially in the scientific domain.", "key_idea": "The authors propose a new task, namely context-aware text generation in the scientific domain, emphasizing the importance of context in generating texts.", "method": "The authors present a novel large-scale Scientific Paper Dataset for Context-Aware Text Generation (SciXGen) consisting of well-annotated 205,304 papers with full references to paper's objects for benchmarking the performance of text generation methods.", "outcome": "The authors report benchmark results demonstrating the efficacy of their constructed SciXGen dataset in generating descriptions and paragraphs.", "future_impact": "The publicly available dataset and benchmarks are expected to facilitate future research in scientific text generation.", "venue": "EMNLP", "year": 2021, "title": "SciXGen - A Scientific Paper Dataset for Context-Aware Text Generation."}
{"pid": "6350bc6d90e50fcafdecf129", "context": "The Chinese Grammatical Error Correction (CGEC) field faces two major limitations: the lack of high-quality annotated training corpora and the disparity between the errors made in widely-used test sets and those made by native Chinese speakers, which prevents existing models from being significantly improved.", "key_idea": "The paper proposes a linguistic rules-based approach to construct large-scale CGEC training corpora with automatically generated grammatical errors, and presents a challenging CGEC benchmark derived from errors made by native Chinese speakers in real-world scenarios.", "method": "The authors utilize their proposed linguistic rules-based approach to build CGEC training data and derive a CGEC benchmark from errors made by native Chinese speakers. They then conduct extensive experiments and analyses to validate their approach and benchmark.", "outcome": "The approach proposed by the authors for constructing the training data effectively improves the performance of CGEC models and the benchmark proves to be an excellent resource for further development of the CGEC field.", "future_impact": "The improvements to the CGEC models resulting from this study, and the new CGEC benchmark, will serve as valuable resources for further development in the field of Chinese Grammatical Error Correction.", "venue": "EMNLP", "year": 2022, "title": "Linguistic Rules-Based Corpus Generation for Native Chinese Grammatical   Error Correction"}
{"pid": "634e194190e50fcafd24e762", "context": "Current methods for describing a text corpus may not imitate human behavior and may lack interpretability and reusability of existing knowledge.", "key_idea": "The authors introduce a new problem called coordinated topic modeling that uses well-defined topics as axes of a semantic space to model a corpus for easily understandable representation.", "method": "The authors propose ECTM, an embedding-based coordinated topic model, which leverages reference representation to capture corpus-specific aspects while preserving each topic's global semantics, and validates it using extensive experiments on multiple domains.", "outcome": "The experiment results show that the new model, ECTM, performs better than other baseline models.", "future_impact": "The coordinated topic modeling could benefit the task of comparing corpora by providing a more interpretable representation of the corpus.", "venue": "EMNLP", "year": 2022, "title": "Coordinated Topic Modeling"}
{"pid": "5f9bd80091e011dcf482d7e7", "context": "Opinion-framing, a strategy in argumentation where individuals frame their stance as an opinion endorsed by a reputable source, is powerful yet understudied, particularly in areas like the global warming debate which has become increasingly partisan and received little attention in natural language processing.", "key_idea": "The authors focus on studying opinion-framing in the global warming debate, introducing a dataset of stance-labeled global warming sentences, DeSMOG. They train a BERT classifier to analyse how different sides of a debate represent their own and each other's opinions.", "method": "The researchers constructed the DeSMOG dataset from 56K news articles, and used it to train a BERT classifier. Through the model, they analysed different sides in the global warming debate and how they represent their own and each other's opinions.", "outcome": "Findings reveal similar linguistic devices are used across global warming-accepting and skeptic media for self-affirming and opponent-doubting discourse, but more opponent-doubt is exhibited in global warming-skeptical media. Authors often characterize sources as hypocritical by attributing opinions that express their own view to source entities known to publicly endorse the opposing view.", "future_impact": "The released stance dataset, model, and lexicons of framing devices are expected to contribute to future work on opinion-framing and the automatic detection of stance in the global warming debate.", "venue": "EMNLP", "year": 2020, "title": "DeSMOG: Detecting Stance in Media On Global Warming"}
{"pid": "5f993b7191e011a3fbe2fb13", "context": "Existing dialogue state tracking (DST) models require plenty of labeled data, which is costly to collect, especially when the number of domains increases.", "key_idea": "The paper presents two self-supervised objectives, preserving latent consistency and modeling conversational behavior, to address the problem of learning efficiently with limited labeled data in Dialogue State Tracking.", "method": "The authors introduce consistent latent distributions given a perturbed input, aimed at improving the models\u2019 robustness to unseen scenarios, and they use an auxiliary utterance generation task to model potential correlations between conversational behavior and dialogue states. They evaluate these strategies on the MultiWOZ dataset with varying proportions of labeled data.", "outcome": "Experimental results show that the proposed self-supervised signals can improve joint goal accuracy by 8.95% when only 1% labeled data is used, and an additional 1.76% improvement can be achieved when some unlabeled data is jointly trained for semi-supervised learning.", "future_impact": "The authors' analysis and visualization of how their proposed self-supervised signals help the DST task aims to stimulate future data-efficient DST research.", "venue": "EMNLP", "year": 2020, "title": "Improving Limited Labeled Dialogue State Tracking with Self-Supervision"}
{"pid": "6356022790e50fcafd3370ec", "context": "The task of context-dependent text-to-SQL aims to convert multi-turn user utterances to formal SQL queries. This task is challenging due to the scarcity of training data for learning complex contextual dependencies and generalizing to unseen databases.", "key_idea": "The paper proposes augmenting the training datasets using self-play, which leverages contextual information to synthesize new interactions to adapt the model to new databases.", "method": "The authors develop a SQL-to-text model conditioned on a sampled goal query, which converses with a text-to-SQL semantic parser to generate new interactions. The synthesized interactions are then filtered and the models are retrained with the augmented data.", "outcome": "The use of self-play improves the accuracy of a strong baseline on SParC and CoSQL, two widely used cross-domain text-to-SQL datasets. Self-play simulates various conversational thematic relations, enhances cross-domain generalization, and improves beam-search.", "future_impact": "The method of augmenting datasets using self-play can effectively enhance the ability of models to adapt to new databases, implying potential for wide application in other similar tasks requiring adaptation to new environments.", "venue": "EMNLP", "year": 2022, "title": "Augmenting Multi-Turn Text-to-SQL Datasets with Self-Play"}
{"pid": "60af76889e795e6b8e55c72c", "context": "Relational triple extraction is a key task for building knowledge graphs. However, current methods focus on directly expressed, explicit relational triples, often missing implicit triples that are not directly stated, which can lead to incompleteness in the constructed knowledge graphs.", "key_idea": "The paper introduces a unified framework to jointly extract both explicit and implicit relational triples. They propose using a binary pointer network and external memory to discover possible implicit relations between entities while retaining previously extracted triple information.", "method": "The validity of the framework is evaluated through experiments on several benchmark datasets, using a relation network to capture real-world relational reasoning patterns to identify the relation types of implicit relational triples.", "outcome": "Results from experiments on benchmark datasets confirm the effectiveness of the proposed method for extracting both explicit and implicit relational triples.", "future_impact": "The proposed model may improve the completeness of knowledge graphs by covering not only explicit but also implicit relational triples, potentially strengthening the usefulness and accuracy of such graphs in various applications.", "venue": "NAACL", "year": 2021, "title": "Jointly Extracting Explicit and Implicit Relational Triples with Reasoning Pattern Enhanced Binary Pointer Network"}
{"pid": "5f97e5c891e0112e0cda7afe", "context": "Enhancing model robustness through regularization is well-studied, specifically methods that regularize the model posterior difference between clean and noisy inputs. Two popular methods in this context are Jacobian Regularization and Virtual Adversarial Training.", "key_idea": "This work attempts to establish a connection between the Jacobian Regularization and Virtual Adversarial Training and further extends the posterior differential regularization to the family of $f$-divergences. The generalization of the framework is characterized in terms of the Jacobian matrix.", "method": "The authors compared the effectiveness of f-divergence regularizations and standard BERT training on a variety of tasks to investigate their impact on model in-domain and out-of-domain generalization performance, in both fully supervised and semi-supervised settings.", "outcome": "The findings show that regularizing the posterior differential with $f$-divergence improves model robustness, and with a proper $f$-divergence, a BERT-base model can achieve comparable generalization as its BERT-large counterpart for in-domain, adversarial, and domain shift scenarios.", "future_impact": "The results of this study indicate that the proposed framework has significant potential to enhance model generalization in natural language processing (NLP) models.", "venue": "NAACL", "year": 2021, "title": "Posterior Differential Regularization with f-divergence for Improving  Model Robustness"}
{"pid": "f3ee3bda-7146-4ffb-b2a0-da93c03f6456", "context": "Prior to this study, semantic role assignment in the Chinese language had not been explored in depth.", "key_idea": "The paper proposes a shallow semantic parser for the Chinese language that uses a small training set of 1100 sentences. It also involves the porting of the Collins parser to Chinese.", "method": "The researchers developed a semantic parser for Chinese using a small training set. The performance of this parser is measured and compared with English semantic parsing.", "outcome": "The results showed that good semantic parsing results for Chinese can be achieved with a small training set. The new parser reportedly delivers the best performance on Chinese syntactic parsing currently reported. Also, it was found that the performance was significantly better for Chinese than for English.", "future_impact": "This development can aid a deeper understanding of how grammatical differences between languages, such as the prevalence of passive voice in English and the strict word order constraints on adjuncts in Chinese, can affect semantic parsing performance.", "venue": "NAACL", "year": 2004, "title": "Shallow Semantc Parsing of Chinese."}
{"pid": "628304515aee126c0f6f0d6f", "context": "Training a good intent classifier for a task-oriented dialogue system with limited annotations is challenging. Recent studies have suggested that fine-tuning pre-trained language models with a small amount of labeled data is helpful, yet supervised pre-training tends to yield an anisotropic feature space potentially limiting semantic representation expressiveness.", "key_idea": "The authors propose to improve supervised pre-training by regularizing the feature space towards isotropy, through two regularizers based on contrastive learning and correlation matrix.", "method": "The authors tested the effectiveness of the method through extensive experiments. The performance of the isotropization regularizer was evaluated in the context of few-shot intent detection.", "outcome": "The authors found that regularizing supervised pre-training with isotropization can effectively enhance the performance of few-shot intent detection.", "future_impact": "This paper introduces the method of isotropization in pre-training language models, and the initial promising results suggest a new direction for future exploration in intent detection with few-shot learning.", "venue": "NAACL", "year": 2022, "title": "Fine-tuning Pre-trained Language Models for Few-shot Intent Detection: Supervised Pre-training and Isotropization"}
{"pid": "60af76479e795e6b8e55c6e5", "context": "Legal contract review is largely a manual process that is both expensive and laborious, prompting the need for more automated methods.", "key_idea": "The authors write about the creation of TECUS, a commercial system designed specifically for understanding contracts and has been operational for several years.", "method": "The paper discusses the challenges encountered and the design decisions made during the development of TECUS, as well as the system's data science life cycle.", "outcome": "TECUS has been deployed in several enterprises and has seen use for several years.", "future_impact": "While not explicitly mentioned in the abstract, the successful deployment and operation of a system like TECUS could serve as a case study for similar projects aiming to automate document-intensive workflows.", "venue": "NAACL", "year": 2021, "title": "Development of an Enterprise-Grade Contract Understanding System."}
{"pid": "1d0f4403-fdb7-4675-8fb4-b9f869a53664", "context": "Traditionally, the task of identifying the language of text or utterances is approached with character-level language models. However, the effectiveness of this approach depends on the length of the text in question.", "key_idea": "The paper proposes solving the problem of language identification of names using an approach based on Support Vector Machines (SVMs) utilizing n-gram counts as features.", "method": "The SVMs with n-gram counts as features approach was experimented with, including applications for pre-processing transliteration data for the training of separate models.", "outcome": "The SVMs with n-gram counts as features approach was shown to perform much better than traditional language models for language identification of names.", "future_impact": "The proposed SVM-based approach could be used to pre-process transliteration data for the training of dedicated models, potentially enhancing the performance of these resultant models.", "venue": "NAACL", "year": 2010, "title": "Language identification of names with SVMs"}
{"pid": "61076a625244ab9dcb330175", "context": "Th semantic tasks Word In Context (WiC), Topic Sentence Verification (TSV), and Word Sense Disambiguation (WSD) have been independently studied, with different NLP systems and tools being used for each.", "key_idea": "The authors aim to establish an exact relationship between WiC, TSV, and WSD and hypothesize that these semantic classification problems can be pairwise reduced to each other and are thus theoretically equivalent.", "method": "To verify this hypothesis, the authors perform a theoretical analysis of existing WiC datasets.", "outcome": "The analysis supports the hypothesis that WiC, TSV, and WSD are theoretically equivalent. It is shown that these semantic classification problems can be pairwise reduced to each other.", "future_impact": "This paper suggests that if more efficient and simpler methods are developed for one of these tasks, they could potentially be successfully applied to the other two tasks, enhancing overall semantic understanding in NLP.", "venue": "NAACL", "year": 2022, "title": "WiC = TSV = WSD: On the Equivalence of Three Semantic Tasks"}
{"pid": "62a2b6915aee126c0f4d659f", "context": "Text-based adversarial attacks are becoming more commonplace and impacting the robustness of models. Retraining models on adversarial data is one solution, but it doesn't handle all types of attacks and is resource-intensive.", "key_idea": "The authors propose the Adversarial Text Normalizer, a method designed to restore baseline performance on attacked content with a low computational cost.", "method": "The authors evaluate the normalizer on two areas prone to adversarial attacks: Hate Speech and Natural Language Inference.", "outcome": "The text normalization method provides a task-agnostic defense against character-level attacks and can supplement adversarial retraining solutions.", "future_impact": "The proposed solution can effectively serve as a lightweight, reusable defense against text-based adversarial attacks, which are growing in prevalence. In the future, its task-agnostic property might allow it to respond to a wider range of adversarial scenarios.", "venue": "NAACL", "year": 2022, "title": "Adversarial Text Normalization."}
{"pid": "617f5aa45244ab9dcbaa726b", "context": "Current few-shot learning methods often involve tuning a pretrained language model to perform in-context learning on a limited set of tasks, but may struggle with significant domain shifts and require task-specific templates or parameter updates.", "key_idea": "The authors introduce a new meta-training framework, MetaICL (Meta-training for In-Context Learning), which tunes a pretrained language model to perform in-context learning on a large set of training tasks, enabling the model to effectively learn new tasks at test time simply by conditioning on a few examples, without parameter updates or task-specific templates.", "method": "The authors conduct experiments on a diverse set of 142 NLP datasets including classification, question answering, natural language inference, paraphrase detection and more, across seven different meta-training/target splits, and compare MetaICL's performance against multiple baselines.", "outcome": "MetaICL outperforms baseline models, including in-context learning without meta-training and multi-task learning followed by zero-shot transfer, and demonstrates especially significant gains for target tasks that have domain shifts from the meta-training tasks. It also achieves performance on par with, and occasionally exceeds, models fully finetuned on the target task training data, even outperforming larger models with nearly 8x more parameters.", "future_impact": "The use of a diverse set of meta-training tasks in the MetaICL framework provides important insights for improving performance in few-shot learning scenarios, and especially in tasks undergoing domain shifts.", "venue": "NAACL", "year": 2022, "title": "MetaICL: Learning to Learn In Context"}
{"pid": "62708f625aee126c0fa6944e", "context": "The quality of peer review, which is central to both scientific progress and individual researcher careers, heavily depends on the paper-reviewer matching process. However, this has been mostly viewed as an automated recommendation problem, without significant consideration for the accumulated experiences of different stakeholders.", "key_idea": "The authors conducted a survey of the NLP community to gain insight into what factors should be considered in paper-reviewer matching systems, and to identify common issues and perspectives.", "method": "The authors performed a survey within the NLP community to capture their perspectives and experiences related to the paper-reviewer matching process.", "outcome": "The study garnered insights regarding common issues and perspectives in the NLP community on paper-reviewer matching systems.", "future_impact": "The study's recommendations can be an actionable guide for improving future NLP conferences and contribute to more interpretable peer review assignments.", "venue": "NAACL", "year": 2022, "title": "What Factors Should Paper-Reviewer Assignments Rely On? Community Perspectives on Issues and Ideals in Conference Peer-Review"}
{"pid": "62a2b6915aee126c0f4d6688", "context": "Article prediction in English language is a challenging task that has often been seen to defy accurate linguistic description. This makes it a suitable task to evaluate language models on their ability to reproduce native-speaker intuition.", "key_idea": "BERT, a pre-trained model, is examined on its capability to predict English articles set up as a three way choice (a/an, the, zero), with the aim of comparing its performance to that of native English speakers.", "method": "Experiments were performed comparing the performance of humans and BERT on article prediction with three choices. The focus points included analysing the alignment of BERT's predictions with either annotators or the corpus, particularly during varying levels of inter-annotator agreement.", "outcome": "BERT outperformed humans across all articles, especially in detecting the zero article. Moreover, as inter-annotator agreement decreases, BERT switches from agreeing more with annotators to the corpus, suggesting that BERT is not simply memorising article use.", "future_impact": "The superior performance of BERT over human judgement in article prediction and its behaviour, potentially indicative of high-level linguistic generalisation abilities rather than simple rule-based memory, may have implications for further research into the cognitive abilities of language models.", "venue": "NAACL", "year": 2022, "title": "Abstraction not Memory: BERT and the English Article System"}
{"pid": "609c2e92-88f3-4db9-b58a-41d0d002b4d6", "context": "The authors are addressing the challenges faced in aligning words in a parallel Romanian-English text, as it relates to their previous work on the translation equivalence approach.", "key_idea": "The authors highlight the development of a prototype system for word alignment, based on their previous translation equivalence approach.", "method": "The authors engage in an informal presentation, discuss the problems faced during their task, and present preliminary evaluation results.", "outcome": "Authors have successfully developed a prototype system and shared preliminary evaluation results, although specific metrics are not detailed in the abstract.", "future_impact": "The authors suggest that there are further ways of improving alignment accuracy, although specific directions are not provided.", "venue": "NAACL", "year": 2003, "title": "TREQ-AL: a word alignment system with limited language resources"}
{"pid": "6278861f5aee126c0f071b6a", "context": "Synthetic datasets like CLEVR have been used to assess visual reasoning abilities in visual question-answering tasks, but they mainly focus on comparisons of shapes, colors, sizes, numerical reasoning, and existence claims.", "key_idea": "The paper introduces a new diagnostic visual question-answering dataset, QLEVR, which improves upon existing datasets by including more complex quantifiers and their combinations.", "method": "The authors describe the process of creating the QLEVR dataset and evaluate it using state-of-the-art visual question-answering models.", "outcome": "The initial evaluation reveals that QLEVR represents a significant challenge for the current visual question-answering models.", "future_impact": "The introduction of QLEVR promotes an opportunity for future research to enhance models for visual question-answering, specifically with the ability to handle complex quantifiers and their combinations.", "venue": "NAACL", "year": 2022, "title": "QLEVR: A Diagnostic Dataset for Quantificational Language and Elementary Visual Reasoning."}
{"pid": "9d5be7e6-99a4-4191-a37c-2c5e4abd2722", "context": "Previous methods for generating multiple choice cloze questions for testing children's reading comprehension generate general distractors and typically only test comprehension of an individual sentence.", "key_idea": "This paper describes DQGen, an automated tool that generates multiple choice cloze questions with different types of distracters designed to diagnose different types of comprehension failure, and tests comprehension beyond just individual sentences, examining also the context that precedes it.", "method": "The quality of overall questions and individual distracters generated by DQGen is evaluated by eight human judges who are blind to the correct answers and intended distractor types.", "outcome": "The evaluation reveals limitations of DQGen, with the results, errors, and comments from the judges suggesting potential improvements.", "future_impact": "The identified limitations and the respective suggestions from the judges provide avenues for refining the DQGen system, potentially leading to more effective comprehension testing tools in the future.", "venue": "NAACL", "year": 2012, "title": "Generating Diagnostic Multiple Choice Comprehension Cloze Questions"}
{"pid": "60a3962d91e01115219ff936", "context": "Previous methods for linking social media accounts that belong to the same author need human-annotated data for training, which limits their scalability.", "key_idea": "The authors propose a new approach that learns an embedding to map variable-sized samples of user activity to a vector space, where samples from the same author map to nearby points, without the need for human-annotated data.", "method": "The approach is tested based on the content and metadata of the authors' document streams, using samples ranging from single posts to entire months of activity. A novel evaluation framework modeled after established recognition benchmarks in other domains is used.", "outcome": "The proposed model outperforms several competitive baselines under the novel evaluation framework, achieving high linking accuracy even for small, unannotated samples from accounts not seen at training time.", "future_impact": "The authors foresee potential practical applications of the proposed linking framework due to its high linking accuracy and independent operation from human-annotated data.", "venue": "NAACL", "year": 2021, "title": "A Deep Metric Learning Approach to Account Linking"}
{"pid": "41534c27-fff9-4d2e-b220-356e9cb8e774", "context": "Automatic post-editing (APE) systems aim at correcting the output of machine translation systems to produce higher quality translations and increase productivity.", "key_idea": "An APE system is presented that uses statistical models to enhance a commercial rule-based machine translation (RBMT) system, along with a procedure for effortless human evaluation.", "method": "Testing was conducted with two corpora of different complexity, namely the Parliament and Protocols corpus.", "outcome": "For the Parliament corpus, it was shown that the APE system significantly complements and improves the RBMT system. While the results for the Protocols corpus were less conclusive, they were still promising.", "future_impact": "Future system enhancements can be developed based on the identified sources of errors in the course of the study.", "venue": "NAACL", "year": 2009, "title": "Statistical Post-Editing of a Rule-Based Machine Translation System"}
{"pid": "6164fcc15244ab9dcb24cf8e", "context": "NLP models have trouble identifying and consolidating redundant information across multiple documents. A task called 'sentence fusion' helps research these challenges, but existing datasets for the task are limited in size and scope.", "key_idea": "The authors propose extending a notable earlier dataset for sentence fusion by making modifications, relabeling, and employing complementary data sources.", "method": "The authors triple the size of an earlier dataset for sentence fusion by modifying, relabeling and using complementary data sources, as well as analyzing the representation of texts for multi-document tasks.", "outcome": "Their redesigned version of the dataset becomes more representative for multi-document tasks and provides a larger and diverse training set, leading to significant improvements in model training.", "future_impact": "The extended dataset can be used for future research work in the area of multi-document tasks, including sentence fusion, as it offers more diverse and representative training samples.", "venue": "NAACL", "year": 2022, "title": "Extending Multi-Text Sentence Fusion Resources via Pyramid Annotations"}
{"pid": "635bca9890e50fcafd33aca9", "context": "Current models for building human-like cognitive agents lack the capability to accurately detect human emotions, particularly the combination of emotional and cognitive state known as confusion.", "key_idea": "The authors propose an approach to detect confusion from three modalities: video (facial features), audio (prosodic features), and text (transcribed speech features) using recurrent neural networks (RNNs) because of their ability to handle sequential data.", "method": "The authors improve the data collection process by allowing for continuous annotation of confusion levels, and carry out experiments with recurrent neural networks to predict confusion based on text, video, and audio data.", "outcome": "The experiments showed that text and video modalities are more important than audio in predicting confusion.", "future_impact": "The ability to detect confusion from multimodal inputs may enable the creation of more advanced and human-like cognitive agents.", "venue": "NAACL", "year": 2022, "title": "Multimodal Modeling of Task-Mediated Confusion"}
{"pid": "626603225aee126c0f233871", "context": "Logical approaches to representing language have developed and evaluated computational models of quantifier words since the 19th century, but today's Natural Language Understanding (NLU) models still struggle to capture their semantics.", "key_idea": "The authors use Generalized Quantifier Theory for language-independent representations of the semantics of quantifier words, to quantify their contribution to the errors of NLU models.", "method": "The authors analyzed prevalent NLU benchmarks with regard to the use of quantifiers and associated performance drops. They also introduced an adversarial generalized quantifier Natural Language Inference (NLI) task (GQNLI) to directly test pre-trained language models against quantifier reasoning.", "outcome": "Findings show that quantifiers are pervasive in NLU benchmarks and their occurrence at test time is associated with performance drops. Pre-trained language models were found to lack robustness in generalized quantifier reasoning.", "future_impact": "This study identifies a specific source of error in NLU benchmarks and provides a task (GQNLI) to facilitate directly targeted probing. This could pave the way for improving the robustness of language models in regard to generalized quantifier reasoning.", "venue": "NAACL", "year": 2022, "title": "Generalized Quantifiers as a Source of Error in Multilingual NLU Benchmarks"}
{"pid": "45361aad-b702-4f77-a8c6-09f7b3e1a6ba", "context": "Temporal information is currently underutilized for document and text processing purposes.", "key_idea": "The study introduces an unsupervised method to extract periodicity information from text, allowing for the creation of time series and filtering to develop sophisticated language models that can distinguish between repetitive trends and non-repetitive writing patterns.", "method": "The authors demonstrate the use of their algorithm through experiments aiming to discover periodicity patterns and date documents automatically using content. Specifically, the tests were conducted on news items spanning a nine year period.", "outcome": "Experimental results indicate that the proposed method and algorithms are effective in discovering periodicity patterns and in dating documents automatically based solely on their content.", "future_impact": "This work may spur the use of temporal information for automatic document dating and in more sophisticated language modeling tasks.", "venue": "NAACL", "year": 2006, "title": "Temporal Classification of Text and Automatic Document Dating"}
{"pid": "41289123-113b-4317-859b-c6d6abfd967a", "context": "Linear Context-free Rewriting Systems (LCFRS) is an expressive grammar formalism with applications in syntax-based machine translation and its parsing complexity is exponential in both the rank of a production, defined as the number of nonterminals on its right-hand side, and a measure for the discontinuity of a phrase, called fan-out.", "key_idea": "The authors propose an algorithm that transforms an LCFRS into a strongly equivalent form in which all productions have rank at most 2, and has minimal fan-out.", "method": "The method involves the transformation of an LCFRS using the proposed algorithm.", "outcome": "The algorithm successfully transforms the LCFRS into an equivalent form with rank of all productions at most 2 and minimal fan-out.", "future_impact": "This work can impact machine translation from or to languages that require syntactic analyses with discontinuous constituents.", "venue": "NAACL", "year": 2009, "title": "Optimal Reduction of Rule Length in Linear Context-Free Rewriting Systems"}
{"pid": "60af77079e795e6b8e55c7c3", "context": "Training slot tagging models for voice assistants at an industrial scale requires large amounts of accurately labeled user queries, which are often difficult and expensive to collect. While voice assistants typically gather plenty of unlabeled queries, these are often unexploited.", "key_idea": "This paper presents a weakly-supervised methodology for labeling large amounts of voice query logs, supplemented with a manual filtering step.", "method": "Experimental evaluations are conducted to compare slot tagging models trained on weakly-supervised data against models trained on hand-annotated or synthetic data. The method is then applied to bootstrap a slot tagging system for a major music streaming service.", "outcome": "Slot tagging models trained on weakly-supervised data outperform models trained on hand-annotated or synthetic data, at a lower cost. Manual filtering of weakly-supervised data results in a significant reduction in Sentence Error Rate, while drastically reducing human curation efforts from weeks to hours when compared with hand-annotation of queries.", "future_impact": "The methodology proposed could prove to be efficient in bootstrapping other systems requiring slot tagging or similar task in various services, potentially improving performance and reducing costs.", "venue": "NAACL", "year": 2021, "title": "Bootstrapping a Music Voice Assistant with Weak Supervision."}
{"pid": "b208839f-3025-4fd5-87f1-5d5a48ee39d9", "context": "Currently, there is a lack of systematic methods for identifying subtle modality in written discourse, such as the degree of writer's certainty (e.g., definitely true or somewhat true) in news discourses.", "key_idea": "This research investigates explicit certainty and doubt markers in epistemically modalized statements within written news discourse, and specifically evaluates the usage of five levels of writer's certainty in three pragmatic contexts: perspective, focus, and time.", "method": "The authors use a method of manual annotation with independent coders to categorize levels of certainty for epistemistically modalized statements in news texts.", "outcome": "The authors find that independent coders\u2019 perceptions of the boundaries between different levels of certainty are highly subjective, making manual annotation complicated and making automation for opinion extraction and sentiment analysis challenging.", "future_impact": "The study suggests the potential for reconsideration in the development of annotation instructions and coder training to improve intercoder agreement, and also raises uncertainty about whether a five-level distinction of certainty is preferable to a simpler distinction between statements with certainty and statements with doubt.", "venue": "NAACL", "year": 2007, "title": "Stating with Certainty or Stating with Doubt: Intercoder Reliability Results for Manual Annotation of Epistemically Modalized Statements"}
{"pid": "cd1495d0-ca59-4d58-8dc9-22a905c1a57b", "context": "Agreement among human annotators on how to segment written text into topically continuous segments is typically low, and most current methods for evaluating topical segmentation do not take into account the prominence of topical shifts.", "key_idea": "The authors suggested using the prominence of the topical shifts when evaluating topical segmentation, more severely penalizing errors on more important breaks, and proposed a simple modification of the windowDiff metric.", "method": "The authors performed a large-scale study involving 27 annotators marking topically continuous segments on 20 chapters of a novel. They also evaluated several topical segmenters using the proposed metric.", "outcome": "The authors revealed that, despite overall low agreement, the annotators show high agreement on a subset of topical breaks, particularly where most prominent topic shifts occur. The results also demonstrated the effectiveness of the modified windowDiff metric in evaluating topical segmenters.", "future_impact": "The research suggests a more insightful approach to evaluating topical segmenters considering the prominence of topical shifts, which could impact future developments in the field.", "venue": "NAACL", "year": 2012, "title": "Topical Segmentation: a Study of Human Performance and a New Measure of Quality."}
{"pid": "635bca9890e50fcafd33acb2", "context": "Current tree-based models rely on external parsers and independently learn their composition function and structure. These models can perform inconsistently due to the lack of joint learning of the parsing and composition functions.", "key_idea": "The authors introduce a novel tree-based model that jointly learns its composition function together with its structure. This model produces sentence embeddings by composing words according to an induced syntactic tree, creating an interpretable linguistic pattern.", "method": "The model is evaluated on downstream tasks, outperforming tree-based models that rely on external parsers. The flexibility of the model to support multiple parser architectures is explored through an ablation study, investigating the impact of different parser initializations.", "outcome": "The proposed model outperforms external parser-reliant tree-based models and is competitive with the BERT base model in some configurations. However, the authors observed that downstream supervision can trouble producing stable parses and preserving linguistically relevant structures.", "future_impact": "The model's ability to learn its composition function along with its structure introduces potential for advancements in sentence embedding generation according to interpretable linguistic patterns.", "venue": "NAACL", "year": 2022, "title": "Unifying Parsing and Tree-Structured Models for Generating Sentence Semantic Representations"}
{"pid": "fb831744-a2a8-4c90-9ee8-1e73273998b4", "context": "Natural language parsing can be improved through the use of machine learning techniques, but traditional parsers did not capitalize on all available solutions.", "key_idea": "The authors apply bagging and boosting, two machine learning techniques, to natural language parsing with a trainable statistical parser.", "method": "The authors conducted experiments with techniques using a trainable statistical parser and conducted error analysis of the result of the boosting technique.", "outcome": "The best resulting system from applying bagging and boosting delivered an improvement in F-measure equivalent to that achieved by doubling the corpus size. In addition, their method revealed some inconsistent annotations in the Penn Treebank.", "future_impact": "The strategies employed in this work may also be useful for semi-automatically finding inconsistent annotations in treebanks.", "venue": "NAACL", "year": 2000, "title": "Bagging and boosting a treebank parser"}
{"pid": "5f9692d791e01156ea5b3595", "context": "The need for semantic parsers that can be extended to novel domains and generate unseen programs at training has been recognized, and datasets for examining out-of-domain performance are growing. However, there is minimal exploration on learning algorithms or goals that promote domain generalization, with practically all modern approaches using standard supervised learning.", "key_idea": "In this paper, a meta-learning framework specifically designed for zero-shot domain generalization in semantic parsing is proposed. It applies a model-agnostic training algorithm that builds virtual train and test sets from separate domains to mimic zero-shot parsing.", "method": "A learning objective is used that takes advantage of the premise that gradient steps enhancing source-domain performance should correspondingly bolster target-domain performance, thereby supporting a parser to generalize well to new target domains.", "outcome": "The experimental results on the (English) Spider and Chinese Spider datasets show that the meta-learning objective can significantly enhance the performance of a baseline parser.", "future_impact": "The proposed novel meta-learning approach may encourage future research focusing on learning techniques for promoting domain generalization in semantic parsing and other language-related tasks.", "venue": "NAACL", "year": 2020, "title": "Meta-Learning for Domain Generalization in Semantic Parsing"}
{"pid": "635bca9890e50fcafd33ac06", "context": "In most Vision-Language models, position information (PI) about objects in the image is used to enable understanding of the image structure. Yet, there is a gap in understanding how much this PI is actually used and its impact on tasks like Visual Question Answering.", "key_idea": "The study probes the use of PI in the state-of-the-art LXMERT model and its effect on Visual Question Answering. It introduces two strategies, Positional Information Pre-training and Contrastive Learning on PI using Cross-Modality Matching, to improve the model's use of PI in image-text matching tasks.", "method": "The authors performs experiments probing the use of PI in the LXMERT model, introduce two strategies to improve how the model uses PI, and introduce object's depth as a feature for object localization. They evaluate these strategies on a challenge set where only position differs.", "outcome": "Though the model, after being improved using the introduced strategies, can correctly classify if images with detailed PI statements match, it only has a negligible effect on the downstream performance. The presence of information detectable by a probing classifier does not guarantee that the information is available in a cross-modal setup.", "future_impact": "The results bring out an important issue in multimodal modelling\u2014ensuring that detectable information is usable in cross-modal setups, potentially guiding future research in multimodal learning.", "venue": "NAACL", "year": 2023, "title": "Probing the Role of Positional Information in Vision-Language Models."}
{"pid": "61baae695244ab9dcb644043", "context": "Knowledge-grounded dialogue systems are challenging to build due to the lack of training data and heterogeneous knowledge sources. Existing systems perform poorly on unseen topics due to limited topics covered in the training data and they struggle to generalize to other tasks because knowledge sources in different knowledge representations require different knowledge encoders.", "key_idea": "The authors propose PLUG, a language model that homogenizes different knowledge sources to a unified knowledge representation for knowledge-grounded dialogue generation tasks. It is pre-trained on a dialogue generation task conditioned on a unified essential knowledge representation.", "method": "PLUG is used for generalizing to different downstream knowledge-grounded dialogue generation tasks with a few training examples and empirical evaluation is carried out on two benchmarks.", "outcome": "PLUG performs well across different knowledge-grounded tasks and achieved comparable performance with state-of-the-art methods under a fully-supervised setting while significantly outperforming other methods in zero-shot and few-shot settings.", "future_impact": "The approach of unifying knowledge representation to improve the performance of knowledge-grounded dialogue systems can influence the design and development of future dialogue generation models.", "venue": "NAACL", "year": 2022, "title": "Knowledge-Grounded Dialogue Generation with a Unified Knowledge Representation"}
{"pid": "b382277e-c24d-45da-b971-d91250e4a069", "context": "In the analysis and processing of Multiword Expressions (MWEs), their internal variability is a significant issue. Existing approaches for MWE representation and processing, such as storing MWEs in lexicons, identification, and extraction, often overlook some valid variations of MWEs. These methodologies fall short, especially in languages with rich morphology.", "key_idea": "The authors propose the idea of handling MWEs through more general patterns rather than individual variations. They believe these patterns exist and can be defined over Part of Speech (POS) sequences and they suggest combining this pattern repository with existing MWE lexicons.", "method": "Working on Italian, this research seeks to discover and define these variation patterns over POS sequences and propose a way to encode them in a repository. For the current phase, the focus is on contiguous MWEs and only morphological variation.", "outcome": "The paper reports on the results of ongoing research on finding and defining variation patterns for MWEs in Italian, and proposes a way of encoding these patterns in a repository that can be combined with existing MWE lexicons.", "future_impact": "The proposed approach of detecting more general patterns for MWEs and encoding them in a repository holds potential for improving MWE processing techniques in computational linguistics, albeit phenomena such as insertion and word order variation are areas for future work.", "venue": "NAACL", "year": 2013, "title": "A Repository of Variation Patterns for Multiword Expressions"}
{"pid": "61b80b6c5244ab9dcbf48c97", "context": "State-of-the-art dialogue models often have factual accuracy and self-contradiction issues. They have also been observed to fail in maintaining character identity throughout discourse and may take on the role of their interlocutor.", "key_idea": "This paper formalizes and quantifies the issue of dialogue models failing to consistently maintain character identity, and also proposes discriminative models to recognize who is speaking as a potential solution.", "method": "The authors conduct experiments involving human evaluations to assess the problem. They also use discriminative models trained specifically to recognize the speaker and measure their effectiveness. A variety of mitigation methods, including changes to model architecture, training protocol, and decoding strategy were evaluated.", "outcome": "The results show that the problem occurs as initially suspected. The models that were trained specifically to recognize the speaker performed well and they reduced the mistaken identity issues by nearly 65% according to human annotators while improving engagement.", "future_impact": "Despite the significant reduction in mistaken identity issues, maintaining character identity in dialogue models remains a challenging problem, indicating the need for further research in this area.", "venue": "NAACL", "year": 2021, "title": "Am I Me or You? State-of-the-Art Dialogue Models Cannot Maintain an Identity."}
{"pid": "c3e22fb0-b905-437c-bd00-318f0e501381", "context": "Semantic ellipsis and underspecification in natural language processing pose a challenge due to the need for understanding and reconstructing the meanings of semantically elided elements.", "key_idea": "The authors discuss the treatment of various types of semantic ellipsis and underspecification in the Ontological Semantics (OntoSem) text processing environment.", "method": "The authors provide descriptions of phenomena whose treatments in OntoSem have achieved different levels of progression: fully implemented, partially implemented, and algorithmically described outside of implementation.", "outcome": "Presentation of research results is being done prior to full implementation and extensive evaluation, with some results being described and algorithmically explained.", "future_impact": "Some subclasses of the phenomena of semantic ellipsis and underspecification will require long-term effort and their results will be best reported in future iterations.", "venue": "NAACL", "year": 2004, "title": "OntoSem methods for processing semantic ellipsis"}
{"pid": "315e4e4a-a4f5-48e2-b04f-851a86348eb0", "context": "Previous methods for correcting errors in non-native English speakers' writing primarily relied on a language model or error-specific classifiers trained on large English corpora.", "key_idea": "This study proposes a meta-classification approach, which combines the language model and the error-specific classifiers as input features to the meta-classifier. The meta-classifier is trained on error-annotated learner data, optimizing the error detection and correction performance on this domain.", "method": "A range of experiments were conducted on article and preposition error correction for non-native English speakers. This included comparing a language model and error-specific classifiers, combining these in a meta-classification approach, and investigating how much training data is needed to improve results.", "outcome": "The meta-classification approach results in substantial gains over the classifier-only and language-model-only scenario.", "future_impact": "This new approach can potentially make error correction for non-native English speakers more effective, but more evaluation is needed to determine the quantity of training data required for optimal results.", "venue": "NAACL", "year": 2010, "title": "Using mostly native data to correct errors in learners' writing: a meta-classifier approach"}
{"pid": "6075758d91e0110f6fe683a8", "context": "While new words are constantly being introduced to communities, not all of these words persist in the community's lexicon. The role of social networks in contributing to lexical change has been understudied thus far.", "key_idea": "The authors have undertaken a large-scale analysis of over 80k neologisms in 4420 online communities across a decade, with the key focus being the influence of a community's network structure on lexical change.", "method": "The study uses Poisson regression and survival analysis to understand the relationships between a community's network structure and lexical change.", "outcome": "The study found that the community's network structure significantly contributes to lexical change. Apart from overall size, properties such as dense connections, the lack of local clusters, and more external contacts promote lexical innovation and retention. Topic-based communities do not experience strong lexical levelling, but accommodate more niche words.", "future_impact": "The findings of this work support the sociolinguistic hypothesis that lexical change is partially shaped by the structure of the underlying network and uncover new insights specific to online communities, which could inform future research in the field.", "venue": "NAACL", "year": 2021, "title": "The structure of online social networks modulates the rate of lexical  change"}
{"pid": "60af76419e795e6b8e55c6df", "context": "Self-disclosure in online health conversations may offer a host of benefits, including earlier detection and treatment of medical issues that may have otherwise gone unaddressed. However, research analyzing medical self-disclosure in online communities is limited.", "key_idea": "The authors introduce a new dataset of health-related posts collected from online social platforms, categorized into three groups - No Self-Disclosure, Possible Self-Disclosure, and Clear Self-Disclosure.", "method": "The authors developed a predictive model, which was trained on the newly introduced dataset.", "outcome": "The predictive model trained on this dataset achieves an accuracy of 81.02%, establishing a strong performance benchmark for this task.", "future_impact": "The new dataset and trained model are made available to the research community, which could be used for further research and improvements.", "venue": "NAACL", "year": 2021, "title": "Identifying Medical Self-Disclosure in Online Communities"}
{"pid": "5eafe7e091e01198d3986544", "context": "Natural language often exhibits inherent hierarchical structure ingrained with complex syntax and semantics. However, most state-of-the-art deep generative models learn embeddings only in Euclidean vector space, without accounting for this structural property of language.", "key_idea": "The paper proposes an Adversarial Poincare Variational Autoencoder (APo-VAE), which leverage text generation in a hyperbolic latent space to learn continuous hierarchical representations of natural language.", "method": "In the APo-VAE model, both the prior and variational posterior of latent variables are defined over a Poincare ball via wrapped normal distributions. A primal-dual formulation of KL divergence is used to introduce an adversarial learning procedure for robust model training. The authors tested the proposed model through extensive experiments in language modeling and dialog-response generation tasks.", "outcome": "The extensive experiments demonstrated that the proposed APo-VAE model is superior to other VAE models in Euclidean latent space, thanks to its outstanding ability to capture latent language hierarchies in hyperbolic space.", "future_impact": "The APo-VAE model\u2019s superior ability to capture natural language\u2019s inherent hierarchical structure can lead to the development of more advanced language processing models.", "venue": "NAACL", "year": 2020, "title": "APo-VAE: Text Generation in Hyperbolic Space"}
{"pid": "ce33ba4a-ef72-4155-b7d8-89ce6a698537", "context": "In classification tasks, when linear classifiers cannot successfully classify data, combination features, which are products of several original features, are often added. But searching for effective combination features, also known as feature engineering, demands domain-specific knowledge and effort.", "key_idea": "The authors propose an efficient algorithm for learning an L1 regularized logistic regression model with combination features, without requiring enumerating all combination features.", "method": "The authors use the grafting algorithm with efficient computation of gradients to find optimal weights. The methodology is demonstrated in experiments with Natural Language Processing (NLP) tasks.", "outcome": "It is demonstrated that the proposed method can effectively extract combination features and achieve high performance with very few features.", "future_impact": "The algorithm proposed in this paper has the potential to significantly simplify feature engineering, facilitate efficient inference and be applicable in different tasks that involve classification.", "venue": "NAACL", "year": 2009, "title": "Learning Combination Features with L1 Regularization"}
{"pid": "5f900feb91e01125c27de032", "context": "Recent approaches towards passage retrieval have leveraged pretrained language models (LMs) for large effectiveness gains. However, they are limited to re-ranking scenarios due to high computational costs. BM25, a scalable bag-of-words retrieval model, is commonly used as a first-stage ranker but sometimes misses relevant passages.", "key_idea": "The authors propose CoRT, a neural first-stage ranking model that uses contextual representations from transformer-based language models to supplement candidates from term-based ranking functions, without causing significant delay.", "method": "The authors evaluate CoRT using the MS MARCO dataset to assess its capability to enhance first-stage ranking quality and recall, and to measure its impact on subsequent re-rankers.", "outcome": "CoRT was shown to significantly improve first-stage ranking quality and recall, allowing subsequent re-rankers to achieve superior results with fewer candidates. It is capable of representation-focused retrieval at web-scale with latencies as low as BM25.", "future_impact": "Going forward, CoRT's ability to improve and hasten retrieval processes could be adopted and further optimized in real-time, large-scale information retrieval scenarios.", "venue": "NAACL", "year": 2020, "title": "CoRT: Complementary Rankings from Transformers"}
{"pid": "627332775aee126c0f18d649", "context": "Existing word embeddings, which are fundamental in natural language processing, are high-dimensional and consume significant computational resources.", "key_idea": "The authors propose WordTour, an unsupervised one-dimensional word embedding solution. They adopt an approach that decomposes the desiderata of word embeddings into two parts: completeness and soundness, and focus on soundness.", "method": "The effectiveness of the proposed method WordTour is evaluated through a user study and document classification.", "outcome": "The proposed one-dimensional word embeddings method, WordTour, has been confirmed to be effective based on the results from user study and document classification test.", "future_impact": "WordTour provides a minimal, extremely efficient means to handle word embeddings, which could help in improving efficiency in natural language processing tasks.", "venue": "NAACL", "year": 2022, "title": "Word Tour: One-dimensional Word Embeddings via the Traveling Salesman Problem"}
{"pid": "671924ce-7ee4-499f-98e6-a2f4d1b96efe", "context": "Nested Named Entities (nested NEs) are commonly seen in biomedical text, e.g., accounting for 16.7% of all named entities in GENIA corpus. Although many works have been done in recognizing non-nested NEs, nested NEs have been largely neglected.", "key_idea": "In this work, the authors approach the task of recognizing nested NEs as a binary classification problem and aim to solve it using Support Vector Machines (SVMs).", "method": "For each token in nested NEs, two labeling schemes were used: labeling as the outmost entity or the inner entity.", "outcome": "Preliminary results suggest that the outmost labeling tends to work better in recognizing the outmost entities, whereas the inner labeling recognizes the inner NEs better.", "future_impact": "The results could be useful for improving methods of recognizing nested NEs in the future.", "venue": "NAACL", "year": 2006, "title": "Recognizing Nested Named Entities in GENIA corpus"}
{"pid": "7a82d341-d46d-4d86-b46b-48d0d5308463", "context": "Previous work has been done using Web selectors for sense disambiguation of nouns\u2014but verbs, adverbs, and adjectives have not been extensively explored. In addition, adverb context selectors have been largely ignored.", "key_idea": "The authors generalize the application of Web selectors, traditionally used just for nouns, to also disambiguate verbs, adverbs, and adjectives. They incorporate previously ignored adverb context selectors into their approach.", "method": "The effectiveness of each type of context selector based on its part of speech is experimentally evaluated. Variables such as each type of context selector assisting target selectors in disambiguation are considered in the experiments.", "outcome": "The system achieves results well above a random baseline and slightly below the most frequent sense baseline for verb, adjective, and adverb disambiguation. For noun and verb sense disambiguation tasks, each type of context selector was found to assist target selectors in disambiguation.", "future_impact": "This research could provide guidance for further studies in the disambiguation of verbs, adverbs, and adjectives using Web selectors by shedding light on the effectiveness of each type of context selector.", "venue": "NAACL", "year": 2009, "title": "Using Web Selectors for the Disambiguation of All Words"}
{"pid": "627483fc5aee126c0f07e4ba", "context": "Deep acoustic models learn linguistic information based on a large amount of data. However, such resources are often not available for regional languages and dialects.", "key_idea": "The authors aim to evaluate if deep acoustic models can learn linguistic information that transfers to low-resource languages, specifically distinguishing Dutch regional varieties.", "method": "The study extracts embeddings from hidden layers of various wav2vec 2.0 models (including ones pre-trained and/or fine-tuned on Dutch) and uses dynamic time warping to compute pairwise pronunciation differences. Differences are then clustered and compared to a gold standard and a partitioning based on phonetic transcriptions.", "outcome": "The results show that acoustic models outperform traditional transcription-based approaches without requiring phonetic transcriptions. The best performance was achieved by the multilingual XLSR-53 model fine-tuned on Dutch, with a clustering closely matching the gold standard based on just six seconds of speech.", "future_impact": "The results suggest there is potential for using deep acoustic models to analyze low-resource languages and dialects effectively without the need for large amounts of data.", "venue": "NAACL", "year": 2022, "title": "Quantifying Language Variation Acoustically with Few Resources"}
{"pid": "634d80f190e50fcafd4ef412", "context": "Previous solutions for parsing temporal dependency graphs from text documents are based on BERT and do not adequately incorporate longer range dependencies. Additionally, downstream tasks of temporal questions answering and Natural Language Interference (NLI) have room for improvement, and the domain of contractual documents has not been previously explored in this context.", "key_idea": "The paper introduces DocTime, a new temporal dependency graph (TDG) parser that models the problem as a graph-network with path-prediction loss to incorporate longer range dependencies. The authors also propose a new framework, Time-transformer, that incorporates the temporal dependency graph into the self-attention layer of Transformer models for improved temporal question answering and NLI.", "method": "The proposed TDG parser is tested on three datasets and evaluated against previous BERT-based solutions. The utility of the generated TDG graph is demonstrated through improvement in downstream tasks. A new temporal dependency graph dataset for the domain of contractual documents was also developed and used for evaluation.", "outcome": "DocTime outperforms previous BERT-based solutions by a relative 4-8% on three datasets. The temporal dependency graph was found to improve the downstream tasks of temporal question answering and NLI by a relative 4-10%.", "future_impact": "The novel methodology presented in this paper opens the possibility of improved parsing of temporal information from textual data, particularly contractual documents, potentially leading to improved performance in downstream tasks.", "venue": "NAACL", "year": 2022, "title": "DocTime: A Document-level Temporal Dependency Graph Parser"}
{"pid": "60af771c9e795e6b8e55c7dd", "context": "Adversarial attacks alter NLP model predictions by perturbing test-time inputs. However, it is much less understood whether, and how, predictions can be manipulated with small, concealed changes to the training data.", "key_idea": "The authors develop a new data poisoning attack that allows an adversary to control model predictions whenever a desired trigger phrase is present in the input.", "method": "The authors perform the attack by inserting poison examples into a sentiment model\u2019s training set that causes the model to frequently predict a certain sentiment whenever an input contains certain trigger phrases. They craft these poison examples using a gradient-based procedure so that they do not mention the trigger phrase. They apply their poison attack to language modeling and machine translation.", "outcome": "The authors reveal that their poisoning procedure causes the targeted models to produce manipulated predictions whenever specific trigger phrases appear in the input. They also propose three defenses that can mitigate their attack at some cost in prediction accuracy or extra human annotation.", "future_impact": "They suggest that the discovery and mitigation of concealed data poisoning attacks could lead to improvements in the robustness and security of NLP models.", "venue": "NAACL", "year": 2021, "title": "Concealed Data Poisoning Attacks on NLP Models"}
{"pid": "099f5a88-11e8-45f2-ba51-193595e6e6ad", "context": "Existing automatic feedback technologies for English as a Foreign Language (EFL) writers are not sufficient to develop lifelong language learning strategies, failing to help learners become independent in writing and proofreading.", "key_idea": "The authors propose a resource-rich toolkit designed to help EFL writers adopt a discovery-based approach in order to enhance their English writing accuracy and fluency. This system aids in identifying lexico-grammatical errors by comparing them to patterns from a large learner text corpus.", "method": "The toolkit was implemented and evaluated within several universities and secondary schools in Hong Kong.", "outcome": "The toolkit assists learners in writing and proofreading, nudging them towards discovering appropriate language patterns, and helps language tutors in reinforcing their students' independent writing skills.", "future_impact": "Despite the evolution of robust and fully automatic feedback technologies, the developed toolkit continues to serve as a necessary tool for second-language (L2) writers in nurturing practical life-long language learning strategies.", "venue": "NAACL", "year": 2010, "title": "A Toolkit to Assist L2 Learners Become Independent Writers"}
{"pid": "46478964-6381-4ea7-812e-192d9c9c6e48", "context": "The increased usage of relaxation approaches for maximum a posteriori (MAP) inference on NLP problems.", "key_idea": "The authors propose an extension of the relaxation approach to marginal inference used in conditional likelihood training, posterior decoding, confidence estimation, and other tasks. The study specifically focuses on its application in second-order dependency parsing.", "method": "The authors shifted the focus of the evaluation to performing inference over a small subset of the full factor graph. The marginal inference method is accompanied by a proposed bound on the error of the marginal probabilities by a sub-graph.", "outcome": "The extended relaxation approach resulted in a tenfold increase in parsing speed with no loss in accuracy. They also established a bound on the error of the marginal probabilities by a sub-graph.", "future_impact": "Though the approach is evaluated with belief propagation (BP) in this study, it's versatile enough to be applied with any marginal inference method in the inner loop of future research.", "venue": "NAACL", "year": 2010, "title": "Relaxed Marginal Inference and its Application to Dependency Parsing"}
{"pid": "fb8ecb70-719d-41cf-ab4f-bc47c218f9db", "context": "Computational cognitive psychology and computational linguistics have been principally devoted to theoretical studies, instead of focusing on addressing important real-world problems.", "key_idea": "The paper proposes that by adopting the research strategy of Pasteur's quadrant - starting and testing success with significant real-world problems - computational cognitive psychology and linguistics could make significant progress, particularly in the field of education.", "method": "The paper discusses some applications of Latent Semantic Analysis (LSA), explains how LSA works and what it is/is not capable of, including its use in automatic essay grading, optimizing sequences of study materials, and partial automation of metadata tagging.", "outcome": "LSA has been proven to be successful in certain areas, such as automatic essay grading, but its limitations are also pointed out, such as its inability to score mathematical and short textual answers.", "future_impact": "The author suggests that by employing the research strategy of Pasteur's quadrant, computational cognitive psychology and linguistics could significantly improve the science of language and potentially the field of education as well.", "venue": "NAACL", "year": 2003, "title": "Pasteur's quadrant, computational linguistics, LSA, education"}
{"pid": "62502e04-7e85-48b5-92cf-d8be76ba4a86", "context": "The problem of extracting abbreviation definitions from biomedical text has been done using various complex methods, but they lack precision, efficiency and generalization.", "key_idea": "The authors propose an alignment-based algorithm utilizing Hidden Markov Model (HMM) for extracting abbreviations and their definitions from biomedical text, which is faster, simpler, naturally generalizable, and can associate a probability with each predicted definition.", "method": "The proposed model is trained on a set of unlabeled examples and evaluated on a standard data set, as well as an additional test set.", "outcome": "The algorithm achieved a precision of 98% and recall of 93% on a standard data set, and 95% precision and 91% recall on an additional test set, demonstrating an improvement over previous methods. The model was able to extract over 1.4 million abbreviations, including 455,844 unique definitions, from a corpus of 200K full-text PubMed papers.", "future_impact": "The proposed model's natural generalizability to specific types of abbreviations, e.g., abbreviations of chemical formulas, suggests potential for it to be applied beyond current test cases, seeding further research.", "venue": "NAACL", "year": 2012, "title": "Alignment-HMM-based Extraction of Abbreviations from Biomedical Text"}
{"pid": "69b61e50-670b-41e2-bcf2-bae599a37b87", "context": "Previous work on metaphor interpretation relies heavily on hand-crafted knowledge about metaphor, which can be a limiting factor in terms of transferability and scalability.", "key_idea": "The authors propose a novel approach for metaphor interpretation that employs automatically induced selectional preferences and produces literal paraphrases for metaphorical expressions without any need of hand-crafted knowledge about metaphor.", "method": "The proposed method is instantiated in a system that generates literal paraphrases for metaphorical expressions.", "outcome": "The introduced system performs metaphorical expression paraphrasing with a high accuracy (scored at 0.81), showcasing its effectiveness.", "future_impact": "The fact that the presented representation is directly transferable can potentially benefit a range of other applications that require a metaphor processing component.", "venue": "NAACL", "year": 2010, "title": "Automatic Metaphor Interpretation as a Paraphrasing Task"}
{"pid": "c31a5260-6e51-4605-9edd-a429e0713cef", "context": "Decoding of single trial data in individual subjects is made possible by multivariate analysis. However, it becomes difficult to perform an analysis at the group level since different models are obtained for each subject.", "key_idea": "The authors introduce a new algorithm for Bayesian multi-task learning that imposes a coupling between single-subject models for better concept classification.", "method": "The authors test their algorithm on the CMU fMRI dataset and classify concepts based on the average activation of regions in the AAL atlas.", "outcome": "The algorithm finds common regions of interest to all subjects which facilitates interpretation of the obtained models. Concepts like shelter, manipulation, and eating which were most easily classified are in accordance with the literature.", "future_impact": "The new algorithm for Bayesian multi-task learning could be potentially beneficial in fields where group-level analysis of individual models is essential.", "venue": "NAACL", "year": 2010, "title": "Concept Classification with Bayesian Multi-task Learning"}
{"pid": "6070326d91e01101ef3d8bdd", "context": "In text classification, a significant branch of natural language processing, run-time of algorithms is a concern, as many depend on the size of the corpus' vocabulary due to their bag-of-words representation. The impact of preprocessing techniques on the correlation between vocabulary size, model performance, and model run-time has not been significantly explored.", "key_idea": "The research aims to fill this gap by conducting a comprehensive study to examine how preprocessing techniques affect vocabulary size, model performance, and model run-time.", "method": "The authors evaluate ten preprocessing techniques over four models and two datasets to establish their impact on vocabulary size, model performance, and model run-time.", "outcome": "They discovered that some individual methods could reduce run-time with no loss of accuracy, while some combinations of methods traded 2-5% of accuracy for up to a 65% reduction of run-time. Additionally, certain combinations of preprocessing techniques resulted in a 15% run-time reduction while also enhancing model accuracy.", "future_impact": "This study's rigor in evaluating preprocessing techniques in text classification may lead to advances in algorithmic optimization, potentially enhancing model efficiency without significant compromises to accuracy.", "venue": "NAACL", "year": 2021, "title": "Exploring the Relationship Between Algorithm Performance, Vocabulary,  and Run-Time in Text Classification"}
{"pid": "60af77b09e795e6b8e55c885", "context": "Prior works have proposed different ideas for interactive summarization, but these solutions are highly divergent and incomparable.", "key_idea": "The paper develops an end-to-end evaluation framework for interactive summarization, particularly for expansion-based interaction, looking at accumulating information along a user session.", "method": "The authors created a procedure to collect real user sessions and adapted evaluation measures based on summarization standards to reflect interaction. They used this framework to evaluate and compare baseline implementations, that they developed for this purpose.", "outcome": "The results of extensive experimentation and analysis support the viability of the proposed evaluation framework design.", "future_impact": "As the solutions and resources are publicly available, the framework can serve as a benchmark and encourage progress in the methodological evaluation of interactive summarization.", "venue": "NAACL", "year": 2021, "title": "Extending Multi-Document Summarization Evaluation to the Interactive Setting"}
{"pid": "a0230dfd-90c7-4e01-b174-4b743a165527", "context": "Readability studies have shown that deleting disfluencies (like fillers and speech repairs) does not affect the transcripts' meaning and can improve the accuracy of the parsing process. Yet, the benefit of deleting fillers early in the parsing of conversational speech has not been extensively studied.", "key_idea": "This research evaluates the benefit of an early deletion strategy for fillers during the parsing of conversational speech.", "method": "The method tests the effect of early deletion using a state-of-the-art parser (Charniak, 2000) under in-domain and out-of-domain parser training conditions.", "outcome": "The study found that early deletion contributes modest advantages for in-domain parsing but contributes significantly to improvements in out-of-domain adaptation.", "future_impact": "These findings indicate a potentially more expansive role for disfluency modelling in adapting text-based tools for processing conversational speech.", "venue": "NAACL", "year": 2006, "title": "Early Deletion of Fillers In Processing Conversational Speech"}
{"pid": "60af77d19e795e6b8e55c8ab", "context": "In the field of natural language processing (NLP), there's a threat of adversarial examples, designed by substituting words with synonyms under certain semantic and syntactic constraints, leading to incorrect predictions by well-trained models.", "key_idea": "This paper proposes WordDP, a technique that leverages differential privacy (DP) to provide certified robustness against word substitution attacks in text classification tasks.", "method": "The paper establishes a connection between DP and adversarial robustness in the text domain, proposing an exponential mechanism-based algorithm for achieving robustness. The authors empirically compare the utility of WordDP with existing defense algorithms.", "outcome": "WordDP provides a higher degree of accuracy and a 30-fold improvement in efficiency compared to the state-of-the-art certified robustness mechanism in typical text classification tasks.", "future_impact": "As the authors provide a rigorous analytic derivation of the certified condition and demonstrate the practical efficacy of WordDP, it may inform future developments in enhancing security and robustness in NLP applications.", "venue": "NAACL", "year": 2021, "title": "Certified Robustness to Word Substitution Attack with Differential Privacy"}
{"pid": "6279c9c55aee126c0fdade57", "context": "Pre-trained models have been successful in many natural language processing tasks. However, in the field of Automated Essay Scoring (AES), pre-trained models like BERT have not proven superior to deep learning models such as LSTM.", "key_idea": "This paper introduces a novel multi-scale essay representation for BERT that can be jointly learned. Multiple losses and transfer learning from out-of-domain essays are also employed to enhance performance.", "method": "The authors validate their approach and the effectiveness of the multi-scale essay representation through experiments on the ASAP task and the CommonLit Readability Prize data set.", "outcome": "The proposed approach, combining joint learning of multi-scale essay representation with multiple losses and transfer learning, achieved near state-of-the-art results on the ASAP task among all deep learning models.", "future_impact": "The proposed multi-scale essay representation is suggested as an effective choice for long-text tasks, implying that it could lead to enhancements in other applications involving long-text processing.", "venue": "NAACL", "year": 2022, "title": "On the Use of Bert for Automated Essay Scoring: Joint Learning of Multi-Scale Essay Representation"}
{"pid": "a7475077-86db-4d41-b315-8fa8401bbaf8", "context": "Prior work has not thoroughly investigated automatic disfluency detection on English and Mandarin conversational speech data.", "key_idea": "The researchers propose two systems for automatic speech disfluency detection: one combines various lexical and prosodic features using a Conditional Random Field model for detecting edit disfluencies, and the other combines acoustic and language model scores for detecting filled pauses via constrained speech recognition.", "method": "The authors employ two systems for automatic disfluency detection on English and Mandarin conversational speech data.", "outcome": "The researchers were able to compare the contributions of different knowledge sources to detection performance between English and Mandarin.", "future_impact": "The systems proposed in the paper could provide a foundation for improving automatic disfluency detection in speech data and enable further exploration of its implementation for other languages.", "venue": "NAACL", "year": 2013, "title": "A Cross-language Study on Automatic Speech Disfluency Detection"}
{"pid": "61baae695244ab9dcb643f04", "context": "There have been significant improvements in AMR parsing performance due to architecture and transfer learning advancements. However, for high-performance parsers, the effect of self-learning and silver data generation appears to be fading.", "key_idea": "This paper introduces a method to overcome the issue of diminishing returns from silver data, by combining Smatch-based ensembling techniques with ensemble distillation.", "method": "An extensive experimental setup was used, including single model English parser and cross-lingual AMR parsing for multiple languages. The proposed distillation technique was also applied to domain adaptation, tested on QALD-9 and BioAMR.", "outcome": "The single model English parser performance exceeded 85 Smatch for the first time and showed substantial gains. They also achieved a new state-of-the-art for cross-lingual AMR parsing for Chinese, German, Italian and Spanish, and for domain adaptation in QALD-9 and BioAMR.", "future_impact": "The proposed ensemble distillation technique that enhances the effectiveness of silver data in AMR parsing could inspire similar approaches in other areas of computational linguistics.", "venue": "NAACL", "year": 2022, "title": "Maximum Bayes Smatch Ensemble Distillation for AMR Parsing"}
{"pid": "c425b1a8-0de5-46e5-843c-04613764f9ee", "context": "Existing robots interact with people using pre-programmed responses, lacking comprehensive understanding of linguistic nuances.", "key_idea": "The authors propose a robotic architecture that allows for grounding of word meanings, using perceptual, procedural, and affordance representations.", "method": "The authors develop a perceptually-coupled on-line simulator that enables sensory-motor representations which can shift points of view, allowing for a varied conversational experience.", "outcome": "The researchers demonstrate that their architecture provides a rich set of data structures and procedures that lay the groundwork for meaningful interpretation of certain classes of words.", "future_impact": "This architecture paves the way for robots to move beyond pre-programmed responses and toward a true understanding of words, potentially enhancing their ability to engage in fluid conversations with humans.", "venue": "NAACL", "year": 2003, "title": "Conversational robots: building blocks for grounding word meaning"}
{"pid": "607968ba91e011f8093d8b33", "context": "Assessing an AI agent that has the ability to converse in human language and understand visual content is a challenging task. Existing evaluation metrics are inadequate in capturing either semantics (MRR) or accounting for ambiguous and synonymic answers (NDCG), making it challenging to excel in both aspects simultaneously.", "key_idea": "To address the evaluation challenge, the authors propose a two-step non-parametric ranking approach that can merge attributes of robust MRR and NDCG models.", "method": "The authors' approach integrates MRR and NDCG models in a way that it manages to keep most of the state-of-the-art performance of both models and put to test in the Visual Dialog 2020 challenge.", "outcome": "The proposed approach maintained most of the state-of-the-art performance for MRR (70.41% vs. 71.24%) and for NDCG (72.16% vs. 75.35%), and won the Visual Dialog 2020 challenge.", "future_impact": "The authors have made the source code available for future research, potentially enabling more sophisticated language and vision models that perform well on both MRR and NDCG metrics.", "venue": "NAACL", "year": 2021, "title": "Ensemble of MRR and NDCG models for Visua Dialog"}
{"pid": "6076c62191e0113d72574454", "context": "Associations between the forms and meanings of words across different languages have been deemed non-arbitrary. Previous works, such as Blasi et al., 2016 and Pimentel et al., 2019, have claimed these associations and established methods to detect within language non-arbitrariness.", "key_idea": "This paper introduces an approach to extend the previous methods to measure cross-linguistic associations using a very large concept-aligned cross-lingual lexicon, going beyond within-language non-arbitrariness.", "method": "The proposed methods control for the influence of language family and geographic proximity within a large concept-aligned cross-lingual lexicon to measure cross-linguistic associations.", "outcome": "Implemented methods identify a small but significant effect of cross-linguistic non-arbitrariness (less than 0.5% on average). The study also reveals that a quarter of the concepts considered exhibit a significant level of cross-linguistic non-arbitrariness.", "future_impact": "The methods outlined in this paper provide new ways to detect cross-linguistic associations on a larger scale, which could potentially impact the studies of comparative linguistics and linguistic anthropology.", "venue": "NAACL", "year": 2021, "title": "Finding Concept-specific Biases in Form\u2013Meaning Associations"}
{"pid": "61c145c65244ab9dcb851041", "context": "Previous 3D motion retargeting methods have relied on controlled environments and often require motion capture systems or 3D reconstruction, limiting their applicability to in-the-wild scenarios.", "key_idea": "The authors introduce a framework that enables 3D motion retargeting from a 2D monocular video to a 3D character without requiring a motion capture system or 3D reconstruction procedure, using mass online videos for training and utilizing two new canonicalization operations: structure canonicalization and view canonicalization.", "method": "The framework learns to disentangle a skeleton sequence into three semantic subspaces (motion, structure, and view angle) via canonicalization operations and derived regularizations, thereby enabling high-precision motion retargeting from 2D to 3D.", "outcome": "The method achieves superior performance on motion transfer benchmarks with large body variations and challenging actions. It also produces a canonicalized skeleton sequence that serves as a disentangled, interpretable representation of human motion.", "future_impact": "The interpretable representation of human motion produced by the proposed framework could potentially benefit action analysis and motion retrieval.", "venue": "AAAI", "year": 2022, "title": "MoCaNet: Motion Retargeting In-the-Wild via Canonicalization Networks."}
{"pid": "6995fd81-0320-4742-925c-4958d704da88", "context": "In large real-time search problems like path-finding in computer games and robotics, complete search methods like A* are not viable options due to the time complexity. Real-time heuristic methods are often used instead but these methods face problems such as sub-optimality due to incomplete searches and inaccuracies in the heuristic.", "key_idea": "The authors focus on lookahead pathologies, where a deeper search can lead to a decrease in the likelihood of selecting better actions, in the realm of real-time path-finding. For the first time, a large-scale investigation of lookahead pathologies is conducted.", "method": "The authors utilize maps from commercial computer games to explore how deeper searches influence path quality. They propose three explanations for such pathologies and empirically support them, followed by the introduction of a method for dynamic lookahead depth selection to counter the pathologies.", "outcome": "The paper finds that deeper searches often led to decrease in path quality apart from consuming more in-game CPU cycles. The remedy proposed, dynamic lookahead depth selection, resulted in substantial improvements in performance.", "future_impact": "The proposed remedy not only addresses lookahead pathologies but also eliminates the need for the user to adjust a control parameter, which indicates its potential for enhancing the efficiency and applicability of real-time heuristic methods.", "venue": "AAAI", "year": 2006, "title": "Lookahead Pathology in Real-Time Path-Finding."}
{"pid": "b74bda53-757c-4d0d-ae10-116241caf85e", "context": "Prior to this study, animation sequences for a small CAD system were not produced in a data-driven manner from a knowledge structure describing the user-system interaction for a given design operation.", "key_idea": "The paper introduces a system that creates explanatory animation sequences for a small CAD system. The animations are generated from a scriptal knowledge structure, which describes the interaction between user and system during a design operation.", "method": "The paper tests the proposal by using a unified data representation scheme, which offers the possibility of generating animation in coordination with natural language output from an existing knowledge-based system.", "outcome": "The paper describes a system that could be used to produce explanatory animations. However, it does not present specific results from tests or implementations.", "future_impact": "The proposed system could enable the generation of animations in coordination with natural language output from existing knowledge-based systems, leading to potential advancements in CAD systems.", "venue": "AAAI", "year": 1982, "title": "Graphical animation from knowledge"}
{"pid": "b5a6690b-8d33-430f-9735-629b3233f7be", "context": "Unsupervised learning approaches like autoencoders aim to construct their inputs, a methodology that may not be optimal for all cases.", "key_idea": "The paper presents a unique and alternative path to unsupervised feature learning called divergent discriminative feature accumulation (DDFA), which continually accumulates features that discriminate among the training set without prior knowledge of the eventual classification problem.", "method": "The proposed DDFA method's performance was tested on the MNIST dataset to validate the quality of its learned features.", "outcome": "The results show that DDFA leads to good performance on the MNIST dataset, indicating that it's a feasible approach for learning useful features in an unsupervised setting.", "future_impact": "DDFA provides a new direction for unsupervised feature learning that could result in the development of better models for complex datasets.", "venue": "AAAI", "year": 2015, "title": "Unsupervised feature learning through divergent discriminative feature accumulation"}
{"pid": "5dde4b463a55ac4c42972c4f", "context": "Machine learning is increasingly being used in many aspects of human life, but there's a need to incorporate fairness into predictive algorithms to avoid bias towards sensitive attributes such as gender and race in predicting the quality of public speeches.", "key_idea": "The authors propose a mathematical framework for fair prediction of public speaking quality using causal models, counterfactual fairness and neural language models. They apply this framework to TED talks data and incorporate a causal model to generate counterfactual data for training a fair predictive model.", "method": "The authors construct a causal model capturing how different attributes affect public speaking quality and generate counterfactual data to train a fair predictive model. The performance is evaluated through experimental results using a novel metric.", "outcome": "The experimental results show that while prediction accuracy is comparable to recent work on this dataset, the predictions are counterfactually fair with respect to a novel metric when compared to true data labels.", "future_impact": "The FairTED setup will allow organizers to make more informed and diverse selections of speakers from unobserved counterfactual possibilities and ensure viewers and new users are not influenced by unfair and unbalanced ratings when deciding to view a TED talk.", "venue": "AAAI", "year": 2020, "title": "Fairyted: A Fair Rating Predictor For Ted Talk Data"}
{"pid": "a596d368-f55a-4858-a6e2-71df244839ec", "context": "Collaborative Filtering systems, which base their recommendations on the judgment of a large number of people, can be manipulated by malicious users spreading lies or propaganda. Current detection algorithms for shilling profiles in these systems have low precision and require a large amount of training data.", "key_idea": "This work explores simpler, unsupervised alternatives that exploit the nature of shilling profiles and can easily add robustness to collaborative filtering systems.", "method": "The authors develop two statistical methods for detection of shilling attacks and perform experiments to evaluate their accuracy.", "outcome": "The proposed statistical methods provide high accuracy in shilling attack detection, according to the experiments performed in the study.", "future_impact": "The developed methods could be integrated into collaborative filtering systems to improve their robustness against malicious manipulation, offering a potential shift towards unsupervised approaches in manipulation detection.", "venue": "AAAI", "year": 2007, "title": "Unsupervised shilling detection for collaborative filtering"}
{"pid": "61b6b9a05244ab9dcbf118ab", "context": "In point cloud generation and completion, previous transformation methods from latent features to point clouds have been based on fully connected layers (FC-based) or folding operations (Folding-based). These methods have limitations such as generation of outliers and rough surfaces, large data flow, slow convergence speed, and difficulty handling the generation of non-smooth surfaces.", "key_idea": "The authors propose AXform, a novel attention-based method for transforming latent features to point clouds, which considers parameter sharing and data flow. AXform generates points in an interim space using a fully connected layer which are then aggregated to create the target point cloud.", "method": "They expand AXform to multiple branches for local generations, resulting in self-clustering and space consistency properties, which further enables unsupervised semantic segmentation. They propose AXformNet for point cloud completion and validate its effectiveness using experiments on different datasets.", "outcome": "AXform reduces the number of outliers and network parameters, increases the convergence speed, and improves generation of non-smooth surfaces. It achieves state-of-the-art results on point cloud completion tasks in multiple datasets.", "future_impact": "The properties of self-clustering and space consistency in AXform could enable unsupervised semantic segmentation, potentially leading to improved performance in point cloud generation tasks.", "venue": "AAAI", "year": 2022, "title": "Attention-Based Transformation from Latent Features to Point Clouds."}
{"pid": "bfd453e3-1da2-49fb-b575-4ec414793e0d", "context": "Previous approaches in the field have often failed to accurately map two-dimensional image cues into three-dimensional surface orientation information (aka 'shape')", "key_idea": "The authors demonstrate two new methods for deriving 'shape' from image cues: the method of affine-transformable patterns and the shape-from-texture paradigm, both of which are introduced within the context of the concept of skewed symmetry.", "method": "The methods are tested through their application to skewed symmetry, a concept which restricts the relationship of observed distortions in a known object regularity to a limited subset of possible underlying surface orientations.", "outcome": "The proposed methods are shown to generate surface constraints. They are successfully applied in line drawing analysis, shape understanding with the use of gravity, and global shape recovery.", "future_impact": "The newly presented methods could potentially lead to more accurate and diverse applications in areas such as shape understanding, line drawing analysis, and global shape recovery.", "venue": "AAAI", "year": 1980, "title": "Mapping image properties into shape constraints: skewed symmetry, affine-transformable patterns, and the shape-from-texture paradigm"}
{"pid": "6215a4242c35681594038743", "context": "Combined modeling and verification of dynamic systems and the data they operate on has gained momentum in AI and several application domains. The authors are investigating a framework known as data-aware dynamic systems (DDS) and seek to extend it with linear arithmetic.", "key_idea": "The authors introduce a new, semantic property called 'finite summary', which guarantees the existence of a faithful finite-state abstraction. They also show that this property allows for the decidable checking of whether a witness exists for a linear-time, finite-trace property in DDSs.", "method": "The authors illustrate the application of 'finite summary' through several decidability conditions previously studied in formal methods and database theory. They also present a prototype implementation to validate the feasibility of their approach.", "outcome": "They demonstrate that the 'finite summary' property leads to modularity results, allowing a system to be partitioned into smaller systems that possess this property. This enabled the analysis of systems that were previously unreachable with earlier approaches.", "future_impact": "The authors anticipate that the 'finite summary' property will enable more efficient and scalable analysis of data-aware dynamic systems in AI and related domains.", "venue": "AAAI", "year": 2022, "title": "Linear-Time Verification of Data-Aware Dynamic Systems with Arithmetic."}
{"pid": "6af01567-10dc-4f6c-9609-93dd43d9c90a", "context": "Pro attitudes such as goals, intentions, desires, wishes, and judgements of satisfactoriness are pivotal to how agents act rationally. However, providing a natural and satisfying formalization of these attitudes has been a longstanding problem in the field of agent theory. Existing modal logic approaches, based on Kripke structures, face the 'side-effect problem'.", "key_idea": "The authors propose a new modal logic to formalize agents' pro attitudes, leveraging neighborhood models. This new logic adheres to Bratman's requirements for agents' beliefs and pro attitudes and introduces novel, previously unexplored properties.", "method": "The authors develop a semantically based axiom system, introducing the concept of a linear neighborhood frame, to characterize valid properties of beliefs and pro attitudes. They argue how this logic satisfies the computational grounding requirement, providing it an interpretation in the lens of a specific computational model.", "outcome": "The proposed logic naturally meets Bratman's requirements for agents' beliefs and pro attitudes along with exploring new properties. The authors demonstrate that this logic's properties can be interpreted in terms of a probabilistic programming model with utilities.", "future_impact": "The new modal logic brings a fresh perspective to non-normal modal logics due to its establishment of the concept of a linear neighborhood frame. It is also likely to contribute effective approaches to problems in agent theory, specifically those dealing with formalizing agents' pro attitudes.", "venue": "AAAI", "year": 2007, "title": "A modal logic for beliefs and pro attitudes"}
{"pid": "be135195-8160-4070-9279-7a99d4e332e9", "context": "Abusive messages (flames) on the Internet are a source of frustration and a waste of time for users, and detecting these automatically is a pressing problem.", "key_idea": "The paper presents Smokey - a prototype system for flame recognition that builds a 47-element feature vector based on the syntax and semantics of each sentence, and combines these for each message.", "method": "A training set of 720 messages was used with Quinlanu0027s C4.5 decision-tree generator to establish feature-based rules for categorizing messages as flames vs nonflames.", "outcome": "Using a separate test set of 460 messages, the prototype system was capable of correctly categorizing 64% of the flames and 98% of the nonflames.", "future_impact": "The authors suggest that additional techniques for increasing accuracy and user customization could be explored in future research.", "venue": "AAAI", "year": 1997, "title": "Smokey: automatic recognition of hostile messages"}
{"pid": "5ed8c67b91e011366a34e30d", "context": "The unsupervised learning of disentangled representations aims to separate the independent explanatory factors of variation in data, but has been facing practical and theoretical challenges.", "key_idea": "This paper summarizes the results of Locatello et al. 2019b and focuses on their implications for practitioners, specifically discussing the result that unsupervised learning of disentangled representations is impossible without inductive biases.", "method": "The authors provide a commentary on past experimental findings, with a focus on the limitations of current approaches.", "outcome": "The study concludes that the unsupervised learning of disentangled representations is fundamentally impossible without inductive biases.", "future_impact": "The paper highlights the limitations of current approaches and suggests future research to overcome these limitations and improve unsupervised learning of disentangled representations.", "venue": "AAAI", "year": 2020, "title": "A Commentary On The Unsupervised Learning Of Disentangled Representations"}
{"pid": "6020df079e795e62379b0d5e", "context": "Normalization operations are vital for state-of-the-art neural networks, enabling its training with a large learning rate (LR). However, the real effect of Batch Normalization (BN) is not widely understood and has been a point of study.", "key_idea": "The paper proposes a shift in focus to the study of variance transmission, specifically by examining the relationship between BN and Weights Normalization (WN). Furthermore, the problem of the shift of the average gradient causing the amplification of the variance of every convolutional layer is identified.", "method": "The authors propose Parametric Weights Standardization (PWS), a module used for convolutional filters, that seeks to address the issue with the shift of the average gradient.", "outcome": "PWS results in similar speed-up benefits to BN, with less computation and without changing the output of a convolutional layer, enabling the network to rapidly converge without normalizing the outputs.", "future_impact": "The authors' findings reinforce the relevance of the shift of the average gradient concept and bring new explanations behind the workings of BN from a variance transmission perspective. This could motivate further studies in this direction, improving understanding and development of normalization operations in neural networks.", "venue": "AAAI", "year": 2021, "title": "Delving Into Variance Transmission And Normalization: Shift Of Average Gradient Makes The Network Collapse"}
{"pid": "9f13bb1b-6583-4a44-9c8c-085e0ba932b2", "context": "Monte Carlo Localization (MCL) is a widely used Bayesian algorithm for mobile robot localization based on particle filters. However, it has a counter-intuitive limitation - better sensors can yield worse results.", "key_idea": "Identifying the limitation of MCL with better sensors leads to the formulation of a new proposal distribution for the Monte Carlo sampling step aimed at mitigating this problem.", "method": "The new proposal distribution is tested through extensive experimentation with physical robots, comparing its performance to that of the plain MCL.", "outcome": "The experimental results suggest that the newly proposed algorithm is significantly more robust and accurate than the conventional MCL.", "future_impact": "The improvements to the MCL algorithm can potentially be applied in a range of particle filter applications beyond just mobile robot localization.", "venue": "AAAI", "year": 2000, "title": "Monte Carlo Localization with Mixture Proposal Distribution"}
{"pid": "32985773-6fc6-4bd8-b49d-da6e2f125421", "context": "Existing approaches to human behavior modeling have limitations in predicting human decisions in varying contexts.", "key_idea": "The authors develop a maximum entropy-based conditional probabilistic model for predicting human decisions in different contexts, within a Markov Decision Process framework.", "method": "The developed model is applied to predicting drivers' route preferences, and preliminary experiments are conducted on modeling time-usage.", "outcome": "The probabilistic model is reviewed and its results shown in application to drivers's context-sensitive route preferences and modeling time-usage.", "future_impact": "The potential expansions of the model's applicability to domains with stochastic dynamics are discussed, along with the ongoing challenges for applying this approach to other human behavior modeling problems.", "venue": "AAAI", "year": 2009, "title": "Human Behavior Modeling with Maximum Entropy Inverse Optimal Control"}
{"pid": "d37e13d5-0371-4801-9427-28f7ad3563ee", "context": "Design systems are embedded with significant value and improvements in them are typically achieved through upgrades rather than complete replacements. However, determining the best approach to upgrading requires a systems view of design.", "key_idea": "The conception of TAO (test-aspect-operator) graphs serves as a strategy to take a systems view of design and facilitate decision-making in the upgrade process. In these graphs, nodes represent aspects of the artifacts being designed while arcs represent operators (transforms between aspects) and tests (comparisons of aspects).", "method": "The authors demonstrate the utility of TAO graphs by discussing their application for upgrades in an automobile parts design system.", "outcome": "The authors describe the upgrade process involving TAO graphs in a system for designing certain automobile parts, which demonstrates the potential of TAO graphs in upgrading design systems.", "future_impact": "The formulated approach using TAO graphs can shape the way improvements are made in various design systems, leading to optimized upgrade strategies.", "venue": "AAAI", "year": 1988, "title": "Upgrading design systems"}
{"pid": "6020e3a59e795e62379b5b89", "context": "Visual recognition on challenging long-tailed distributions, which are characterized by extremely imbalanced frequencies among classes, has greatly advanced, mostly based on complex paradigms like meta learning. Simple refinements on training procedures, identified as tricks, which include adjustments in data distribution or loss functions, also contribute to these advancements. However, the application of these tricks may be inappropriate at times, possibly leading to reduced recognition accuracy, and guidelines on the use of these methods have been lacking in the literature.", "key_idea": "The authors propose to collect existing tricks in long-tailed visual recognition, implement systematic experiments, and present a detailed experimental guideline for an effective combination of these tricks. They also propose a novel data augmentation approach specifically fine-tuned for long-tailed recognition, compatible with re-sampling methods.", "method": "The authors perform extensive and systematic experiments on a collected set of tricks used in long-tailed visual recognition and on their proposed data augmentation approach. The evaluation is based on four long-tailed benchmark datasets, including ImageNet-LT and iNaturalist 2018.", "outcome": "By scientifically assembling these tricks, the authors achieved performance surpassing state-of-the-art methods on the tested benchmark datasets. Their novel data augmentation approach also demonstrated excellent results.", "future_impact": "The experimental guidelines provided in this paper could help the community better navigate the use of various tricks in long-tailed visual recognition, potentially leading to more precise and accurate models in the future.", "venue": "AAAI", "year": 2021, "title": "Bag Of Tricks For Long-Tailed Visual Recognition With Deep Convolutional Neural Networks"}
{"pid": "61f753205aee126c0f9c224d", "context": "In Bayesian posted price auctions, the seller usually has more knowledge about the item being sold than the buyers. The seller faces the problem of how much information to disclose to maximize revenue. The seller must correlate the signals sent to the buyers with price proposals, adding complexity to the problem.", "key_idea": "The authors introduc a unifying framework for both public and private signaling in Bayesian posted price auctions, along with a decomposition lemma that allows focus on a finite set of possible buyers' posteriors.", "method": "They devise different PTAS methods for the public and private signaling settings. For public signaling, they use techniques based on linear programming, while for private signaling, an exponentially-sized LP is solved in polynomial time using the ellipsoid method with a custom approximate separation oracle implemented with dynamic programming.", "outcome": "The initial findings show that maximising the seller's revenue in both settings does not admit an FPTAS, thereby justifying the use of PTASs.", "future_impact": "This method for dealing with information asymmetry in Bayesian posted price auctions could potentially change the way these transactions take place, although further research is needed.", "venue": "AAAI", "year": 2022, "title": "Signaling in Posted Price Auctions."}
{"pid": "b87b7c52-b54c-402b-96d8-62df12790813", "context": "Reputation-based approaches are used in crowdsourcing systems to identify reliable workers for task delegation. However, in systems modeled as multi-agent trust networks, existing reputation-based decision-making models fail to assist workers in deciding when and to whom to sub-delegate tasks when they cannot complete all tasks before stipulated deadlines.", "key_idea": "This paper introduces a Reputation Aware Task Sub-delegation (RTS) approach, which helps workers make sub-delegation decisions by considering the worker's reputation, workload, the cost of their effort, and their trust relationships with others.", "method": "RTS is tested as an intelligent agent in a distributed manner, with the aim to maximize social welfare through efficient utilization of collective capacity. Its performance is compared with state-of-the-art approaches based on the Epinions trust network.", "outcome": "Experimental results show significant advantages of RTS under high workload conditions when compared to current state-of-the-art approaches.", "future_impact": "The RTS approach can further the efficiency and effectiveness of task allocation in crowdsourcing systems, providing provable performance guarantees and maximizing social welfare by efficiently utilizing the collective capacity of crowd workers.", "venue": "AAAI", "year": 2015, "title": "Efficient task sub-delegation for crowdsourcing"}
{"pid": "721b075f-12ae-4f47-83e5-c8df7839b814", "context": "In the past, the scaling of performance of search algorithms has been confined to critically constrained problems at the phase transition, which limits the comprehensive understanding of their performance across other problem domains.", "key_idea": "This research introduces accurate numerical models of search cost for both backtracking and local search algorithms, based on a rescaled constrainedness parameter that can be applied across the full width of the phase transition.", "method": "The researchers illustrate the versatility of the approach by applying it to three distinct problem domains (satisfiability, constraint satisfaction and travelling salesperson problems) with both backtracking algorithms like the Davis-Putnam procedure and local search algorithms like GSAT.", "outcome": "The research successfully extended models of search cost to the full phase transition, allowing for the direct comparison of algorithms on both under-constrained and over-constrained problems. Accurate predictions were generated for results beyond the range of the experiments.", "future_impact": "This methodology and model can potentially lead to a more accurate evaluation of the efficiency of various search algorithms across a broad spectrum of problem domains.", "venue": "AAAI", "year": 1997, "title": "The scaling of search cost"}
{"pid": "ae8ac0fd-a213-4baa-b6af-533852448bfd", "context": "Previous methods for examining sentiment similarity lacked a firm grounding in emotional analysis, which is a crucial avenue for understanding the sentiment of word pairs in their diferent senses.", "key_idea": "This paper describes a new approach to acquire sentiment similarity of word pairs in relation to their senses, proposing a model that maps from the senses of words to vectors of twelve basic emotions, which are then used to measure sentiment similarity.", "method": "The paper demonstrates the utility of measuring sentiment similarity in two main natural language processing tasks, specifically, indirect yes/no question answer pairs (IQAP) Inference and sentiment orientation (SO) prediction.", "outcome": "Extensive experiments showcase that the proposed approach can effectively capture the sentiment similarity of word pairs and use this information to improve performance on the afore-mentioned tasks.", "future_impact": "The method's effectiveness suggests potential for it to be used in a broad range of sentiment analysis tasks and provide a novel vector representation for sentiment similarity.", "venue": "AAAI", "year": 2012, "title": "Sense sentiment similarity: an analysis"}
{"pid": "6020e1d39e795e62379b5a61", "context": "The Chinese ideographic writing system allows radicals to trigger semantic association, which can improve language comprehension. Despite it's prominence in real world understanding, this mechanism has been unexplored in the field of Chinese text representation and classification.", "key_idea": "The authors propose a Radical-guided Associative Model (RAM) for Chinese text classification that is inspired by cognitive principles between ideography and human associative behavior.", "method": "The RAM comprises two coupled spaces - Literal Space and Associative Space. In Literal Space, a serialized modeling structure is devised to capture the sequential information of Chinese text, while in Associative Space, an association module is designed with Radical-Word Association strategy to associate ideographic radicals and prior concept words. Also, an attention module is designed to balance the importance of each associative words under specific contexts.", "outcome": "Experiments on two real-world datasets validate the effectiveness and rationality of RAM.", "future_impact": "The authors suggest that their model, RAM, provides cognitive insights for future language modeling.", "venue": "AAAI", "year": 2021, "title": "Ideography Leads Us To The Field Of Cognition: A Radical-Guided Associative Model For Chinese Text Classification"}
{"pid": "07016901-4d34-4991-8b4c-b5263c50c856", "context": "Einstein's discovery of special relativity revolutionized both the content of physics and the research strategy used by theoretical physicists. The research strategy entails a mutual bootstrapping process between a hypothesis space for biases and a hypothesis space for physical theories, constrained by the invariance principle.", "key_idea": "The authors describe a rational reconstruction of this process, where the invarariance principle is used to detect inconsistencies in an evolving physical theory and its bias, and also generate a new bias when an inconsistency arises.", "method": "The authors implement their concept in the Erlanger program and use it to validate the rational reconstruction of Einstein's discovery of special relativity.", "outcome": "The invariance principle noted by the authors helps address inconsistencies in theories, serving as a practical validation of Einstein's discovery when implemented in the Erlanger program.", "future_impact": "The success of the method described here could inspire future efforts to use similar principles to address inconsistencies in other theories, allowing for the possibility of discovering new biases and reformulating theories as needed.", "venue": "AAAI", "year": 1992, "title": "Symmetry as bias: rediscovering special relativity"}
{"pid": "6020e1cd9e795e62379b5a5d", "context": "Neural dialogue models suffer from generating low-quality responses when engaged in practice, showing difficulty in generalization beyond training data. Knowledge distillation has been recently used to regularize the student by transferring knowledge from the teacher, but the teacher and the student are trained on the same dataset and learn similar feature representations, which hinders generalization.", "key_idea": "The authors propose a new training framework where general knowledge learning aligns more with the idea of consensus \u2014 identifying common knowledge beneficial to all datasets through diversified learning partners. Each student imitates multi-view feature representation aggregated from other peers to capture common knowledge among different tasks and alleviate overfitting.", "method": "The training task is divided into a group of subtasks with equal number of students, each optimized on their specific subtask and also imitating multi-view feature representation from other students. The authors also extend unidirectional distillation to bidirectional distillation where students exchange complementary knowledge with each other.", "outcome": "Empirical results show that the proposed training framework effectively improves the model's generalization without sacrificing training efficiency.", "future_impact": "This novel framework for discussing knowledge distillation and consensus among learning partners in neural dialogue models could guide future research exploring ways to improve model generalization.", "venue": "AAAI", "year": 2021, "title": "Multi-View Feature Representation For Dialogue Generation With Bidirectional Distillation"}
{"pid": "6c131b9a-f9ce-45ca-952c-7e7c0c482906", "context": "Designing lumped parameter models from first principles is typically guided by a qualitative representation of parameter interactions, as used in the IBIS system developed by Williams [1989, 1990].", "key_idea": "The authors introduce a new algorithm, SIE, to design lumped parameter models. The difference is that SIE uses a simpler interaction set representation compared to the complex space of potential and existing interactions used in IBIS.", "method": "The conduct and results of their tests to validate the SIE algorithm are not specified in the abstract.", "outcome": "Not provided in the abstract.", "future_impact": "Not provided in the abstract.", "venue": "AAAI", "year": 1993, "title": "Innovative design as systematic search"}
{"pid": "3979fd46-7851-4d6c-a73f-216c504fa6b6", "context": "Prior to this study, details on knowledge engineering behavior of those with experience in artificial intelligence (AI) were relatively unknown and not empirically analyzed.", "key_idea": "This paper studies how AI professionals behave when they design an AI program. It identifies behaviors such as focusing on a 'touchstone', or key issue, which much of the designer's behavior revolves around.", "method": "The study conducted empirical analysis of six persons with extensive AI experience by having them design an AI program. Their design sessions were videotaped and they were asked to talk aloud about their actions and rationale.", "outcome": "The study identified several recurrent behaviors common to all six AI designers. It also distinguished several components of the designers' goal structures and the importance of a touchstone.", "future_impact": "The paper suggests potential implications of the research for improving the design of knowledge engineering tools.", "venue": "AAAI", "year": 1987, "title": "Modelling human expertise in knowledge engineering: some preliminary observations"}
{"pid": "6019317f91e0110e3bb2bec2", "context": "Data heterogeneity is a key feature in federated learning, but often overlooked in the lens of robustness to adversarial attacks, particularly backdooring attacks.", "key_idea": "This study examines the impact of data heterogeneity on the effectiveness of backdooring attacks in federated learning, initial findings suggested that data heterogeneity might act as a defensive mechanism by making the attack less efficient and less predictable.", "method": "The authors conducted comprehensive experiments using synthetic and the LEAF benchmarks to investigate the effects of data heterogeneity on the robustness of federated learning systems against backdooring attacks.", "outcome": "The study found that data heterogeneity is more of a curse than a redemption in terms of robustness to adversarial attacks in federated learning as the attack's effectiveness can be significantly improved by adjusting client-side backdooring timing and overfitting at the local training of benign clients can be exploited by attackers to hide and trick skewed-feature based defenses.", "future_impact": "The results and insights obtained from this study could provide guidance for designing more robust federated learning methods and systems in the presence of data heterogeneity.", "venue": "AAAI", "year": 2021, "title": "Curse Or Redemption? How Data Heterogeneity Affects The Robustness Of Federated Learning"}
{"pid": "cdf9fc14-5423-4ad4-bfdb-389abb0d4e10", "context": "The Keystone Fire Brigade is a robotic rescue team that has previously competed in Robocup, AAAI, and IJCAI, featuring an emphasis on vision and fully autonomous solutions implemented on inexpensive robot bases.", "key_idea": "This paper focuses on the iteration of the Keystone Fire Brigade that competed at the IJCAI in 2003, with main emphasis being placed on visual processing, map-making, and victim identification.", "method": "The authors provide an overview of the hardware employed, procedures for visual processing, map-creation, and victim identification. They also reflect on the experiences in the testing domain.", "outcome": "The paper describes the experience at the 2003 IJCAI competition and the implementation of the Keystone Fire Brigade's methods and systems.", "future_impact": "Given the insights shared about the experiences in the test domain, these could potentially inform and provide recommendations for future competitions.", "venue": "AAAI", "year": 2003, "title": "The Keystone Fire Brigade 2003"}
{"pid": "566bf7f2-c869-41b0-bed1-d0ab4fc3c189", "context": "Self-organizing models can develop realistic cortical structures when given approximations of the visual environment as an input and are an effective way to model the development of face recognition abilities. However, they cannot account for the fact that newborn human infants preferentially attend to face-like stimuli immediately after birth. Internal pattern generators may help express complex structures from minimal genetic information in a highly plastic system.", "key_idea": "The authors propose that internally generated input patterns, such as those found in the developing retina and in PGO waves during REM sleep, may have the same effect on self-organization as the external environment, thereby forming a computational framework that can explain newborn face preferences.", "method": "Simulations were conducted with the RF-LISSOM model to test the idea that internal pattern generators can affect self-organization in the same way as external environments.", "outcome": "The authors found through simulations that the proposed computational framework can indeed account for newborn face preferences.", "future_impact": "This work shows that genetic influences interact with experience to construct a complex system, leading to a better understanding of the development of face recognition abilities in humans and potentially influencing future research in the understanding of perceptual organization.", "venue": "AAAI", "year": 2000, "title": "Self-Organization of Innate Face Preferences: Could Genetics Be Expressed through Learning?"}
{"pid": "ba7f263d-651c-43ee-8ed4-b317060fcdf3", "context": "Retaining workers on micro-task crowdsourcing platforms is crucial for timely completion of batches of Human Intelligence Tasks (HITs). Traditional pricing methods (constant reward for all HITs in a batch) may not effectively motivate workers to stay longer on a given batch.", "key_idea": "The study introduces novel pricing schemes aimed at improving the retention rate of workers on long batches of similar tasks by varying the monetary reward over time.", "method": "The authors empirically examined how the number of tasks a worker is willing to complete in a batch and the overall task latency are affected by their new pricing schemes, further comparing them with traditional pricing methods.", "outcome": "The experiments revealed that the best pricing scheme in terms of worker retention uses punctual bonuses paid when workers reach predefined milestones.", "future_impact": "The findings may have implications for improving worker retention on crowdsourcing platforms and potentially introducing SLAs on these platforms.", "venue": "AAAI", "year": 2014, "title": "Scaling-Up the Crowd: Micro-Task Pricing Schemes for Worker Retention and Latency Improvement"}
{"pid": "5fd73a6391e011efa3cf5e40", "context": "User modeling is crucial in personalized services. Traditionally, user representations are learned based on users' interests or preferences for different tasks requiring the training of task-specific models.", "key_idea": "The authors propose a universal user representation model using a Self-supervised User Modeling Network (SUMN) that encodes user behavior data into a representation suitable for various downstream applications without modification, alleviating the need for task-specific model training.", "method": "SUMN includes a new learning objective under a self-supervised learning framework and a multi-hop aggregation layer geared for the aggregation of diverse behaviors. These elements were tested in extensive experiments on benchmark datasets.", "outcome": "The experiments showed that the proposed approach outperforms state-of-the-art unsupervised representation methods and is competitive with supervised methods.", "future_impact": "The success of SUMN provides potential for the development of more efficient, effective user modeling systems that do not require the cumbersome process of training task-specific models for every downstream task.", "venue": "AAAI", "year": 2021, "title": "Exploiting Behavioral Consistence For Universal User Representation"}
{"pid": "c10fd493-2770-4d83-83d0-9799592875cd", "context": "Interactive layout assistance systems often fail to arrange layouts in a way that conforms to the user's expectations, underscoring the need for improvement according to the principle of least astonishment.", "key_idea": "The paper proposes a framework for transformation-based similarity between two-dimensional spatial configurations, aimed at measuring user expectations when presented with a system-generated layout.", "method": "The proposed framework is applied to validate existing layout algorithms and design new ones, with its use being illustrated through UML class diagrams.", "outcome": "The similarity framework was demonstrated to be effective in designing new algorithms that respect the principle of least astonishment and in validating existing layout algorithms for their ergonomic adequacy using UML class diagrams as example domain.", "future_impact": "The newly proposed framework may be applied to further improve interactive layout assistance systems and algorithms, leading to better alignment with user expectations in other domains.", "venue": "AAAI", "year": 2005, "title": "Similarity of Spatial Configurations in Interactive Layout"}
{"pid": "6215a4242c35681594038579", "context": "Active learning algorithms are used to identify salient and exemplar samples from large amounts of unlabeled data, to reduce human annotation effort. However, in areas like text mining and video classification, human oracles review data instances incrementally to derive class labels, and it might be unnecessary for the human oracles to review an entire unlabeled sample to provide a label.", "key_idea": "The authors propose a framework to further reduce labeling burden on human oracles by identifying an optimal subinstance size (percentage of the sample from the start) for each unlabeled sample, rather than the whole data sample.", "method": "The authors pose the sample and subinstance size selection as a constrained optimization problem and derive a linear programming relaxation to select a batch of exemplar samples, along with the optimal subinstance size of each. The proposed methodology is tested on six datasets from the text mining domain.", "outcome": "Empirical studies on six text mining datasets show that the proposed framework is practical and efficient, outperforming competing baselines.", "future_impact": "The proposed framework can be employed in a range of classification tasks to efficiently label data, reducing labour and time costs and improving the efficiency of the learning models.", "venue": "AAAI", "year": 2022, "title": "Active Sampling for Text Classification with Subinstance Level Queries."}
{"pid": "60128d4891e011b3f52c13eb", "context": "Sentence ordering, or arranging a list of sentences in their correct order, is often reliant on different types of information at different distances. However, the current approaches do not consider multiple types of order information or utilize graph neural networks to integrate sentence content and order information entirely.", "key_idea": "The authors introduced a unique approach to sentence ordering that considers multi-granular orders between sentences. These orders form multiple constraint graphs, which are encoded by Graph Isomorphism Networks and integrated into sentence representations.", "method": "The proposed approach is evaluated across five benchmark datasets for sentence ordering.", "outcome": "The experiments show significantly superior results of the proposed method compared to existing baselines, achieving a new state-of-the-art performance.", "future_impact": "This work may enhance the quality of models that require sentence ordering due to its strong performance and potential for integration with other models as demonstrated in the study. It's likely to encourage further exploration of integrating multiple types of order information using graph neural networks.", "venue": "AAAI", "year": 2021, "title": "Neural Sentence Ordering Based On Constraint Graphs"}
{"pid": "a0558def-b142-4c95-be87-a4cbe59e9edf", "context": "Machine learning algorithms are widely applied in financial markets, with the majority of systems for stock selection using neural-network techniques. However, for complex problems such as financial analysis, neural network structures can be difficult to interpret.", "key_idea": "The authors propose DL- $elect, a decision-list-based data-mining system for financial analysis, which adopts inductive logic approaches. DL- $elect uses BruteDL - an algorithm better suited to handle  financial-market noise, to create easily understandable 'if-then-else' decision rules.", "method": "The authors assemble 11 attributes for 600 stocks, clean the data, randomly partition it into training, testing, and pruning sets and then input it into BruteDL. Their tool operates on the premise that markets exhibits short-term inefficiencies and trends carry over from the previous week to the next.", "outcome": "The generated rules from the DL- $elect system help determine which variables make an 'excellent' stock.", "future_impact": "The approach proposed by the authors might change how financial analysis systems are developed by emphasizing interpretability and handling of noisy data. It provides a different perspective on stock selection strategies, focusing on short-term trends rather than a buy-and-hold strategy.", "venue": "AAAI", "year": 1998, "title": "DL-$;elect: a decision-list-based data-mining system"}
{"pid": "90ec6518-18f3-4a87-8bd1-6761aac6660f", "context": "The development of intelligent tutoring systems and learning environments for physical domains and complex systems, such as thermodynamics, was a primary motivation for research in qualitative physics.", "key_idea": "The authors develop CyclePad, an intelligent learning environment for students learning to design and analyze thermodynamic cycles. This is based on a combination of qualitative physics and other AI techniques.", "method": "The authors developed CyclePad to capture a substantial portion of a thermodynamics textbook\u2019s knowledge, designed to assist students who are learning the principles of such cycles.", "outcome": "CyclePad has been fully implemented and is able to capture a significant fraction of a thermodynamics textbook's knowledge.", "future_impact": "The authors plan future classroom experimentation with CyclePad, which indicates the potential for wide adoption of AI-enhanced learning tools in thermodynamics education.", "venue": "AAAI", "year": 1994, "title": "Using qualitative physics to build articulate software for thermodynamics education"}
{"pid": "4aa8ad88-acea-425f-b9d1-eba84872e717", "context": "Two efficient planners for planning in nondeterministic domains are MBP and ND-SHOP2. MBP employs Binary Decision Diagrams (BDDs) to represent common states to enhance planning. ND-SHOP2 employs HTN task decomposition to focus search. The performance between the two methods vary depending on the environment.", "key_idea": "This paper proposes a new planning algorithm, YoYo, which combines the HTNs of ND-SHOP2 with the BDDs of MBP to perform task decompositions over classes of states represented as BDDs.", "method": "Efficiency of proposed YoYo is evaluated in experiments relative to both MBP and ND-SHOP2.", "outcome": "YoYo outperforms both MBP and ND-SHOP2\u2014often by several orders of magnitude\u2014in the authors' experiments.", "future_impact": "The authors predict that combining techniques originally developed for classical planning domains with a BDD representation will lead to significant speed up in nondeterministic domains. The same principle can be extended to other areas such as planning with Markov Decision Processes, synthesizing controllers for hybrid systems, and composing Semantic Web Services.", "venue": "AAAI", "year": 2006, "title": "Controlled search over compact state representations, in nondeterministic planning domains and beyond"}
{"pid": "8b076c59-26c3-4cca-8cfa-3536a14c429a", "context": "Many Semantic Web query answering systems sacrifice completeness to improve scalability, which means they do not guarantee to return all query answers. This may result in lost information, which could be significant to system designers and users.", "key_idea": "The authors propose a method for generating test data that can provide partial insights into what kind and how much information might be lost due to incompleteness of Semantic Web query answering systems.", "method": "The authors develop a framework to formalize the problem and describe data generation algorithms for popular ontology languages. They then use these algorithms for a preliminary evaluation.", "outcome": "The paper shows encouraging results from the preliminary evaluation of the proposed method, indicating that it could provide valuable insights into the information potentially lost by incomplete Semantic Web query answering systems.", "future_impact": "The proposed method can assist in understanding and potentially mitigating the impact of incompleteness in Semantic Web query answering systems, thereby improving the performance of ontology-based applications.", "venue": "AAAI", "year": 2010, "title": "How Incomplete Is Your Semantic Web Reasoner"}
{"pid": "21a66e1b-a866-4e35-b6f8-ee1219de936d", "context": "Crowdsourcing information distributed among many individuals is quite prevalent, and to obtain accurate outcomes, various game-theoretic incentive schemes have been proposed. However, only prediction markets have been used in practical applications.", "key_idea": "The authors propose an experimental platform, Swissnoise, for comparing the performance of prediction markets with peer prediction schemes, which have been recently developed in AI research.", "method": "The authors use the Swissnoise platform to compare the performance of prediction markets with peer prediction schemes.", "outcome": "The study shows that peer prediction schemes can achieve similar performance to prediction markets while being applicable to a broader range of questions.", "future_impact": "The findings from this paper can be helpful in demonstrating the applicability of peer prediction schemes to a broader range of questions, potentially revolutionizing crowdsourcing strategies.", "venue": "AAAI", "year": 2014, "title": "Swissnoise: online polls with game-theoretic incentives"}
{"pid": "5dd50ed43a55ac513761789e", "context": "Weakly supervised object detection (WSOD) typically shows lower performance than fully supervised methods, especially when detecting objects belonging to rare classes with limited examples. Human-object interactions (HOI) have previously been used as a context for supervising complex semantics in images.", "key_idea": "The authors propose a novel WSOD framework that leverages transferable knowledge from HOI. The framework contains a new module called RRPN (relational region proposal network) that predicts an object-localizing attention map using only human poses and action verbs.", "method": "The RRPN and an object detector are fully trained with full supervision of HOI in the source domain. In the target domain, transferred knowledge about the localization map from the trained RRPN is used to learn unseen objects without the need for bounding box annotations.", "outcome": "Experimental results on the HICO-DET dataset demonstrated the potential of the proposed method to be a cost-effective alternative for supervised object detection paradigms. The model was able to localize unseen objects effectively on the HICO-DET and V-COCO datasets.", "future_impact": "The RRPN, designed to be an add-on, could potentially be applied to fields beyond object detection, such as semantic segmentation.", "venue": "AAAI", "year": 2020, "title": "Tell Me What They'Re Holding: Weakly-Supervised Object Detection With Transferable Knowledge From Human-Object Interaction"}
{"pid": "6020e1f69e795e62379b5a80", "context": "Current methods for predicting the trend of one firm based on relevant firms use graph convolution networks (GCNs) with predefined firm relations. However, several implications exist, such as momentum spillovers being propagated via a variety of firm relations whose importance varies over time and the inability of GCNs to consider states of both connected firms once a connection is built. Furthermore, the attribute-sensitive momentum spillovers of listed firms are not taken into consideration.", "key_idea": "An attribute-driven graph attention network (AD-GAT) is proposed which addresses the problems in modeling momentum spillovers by focusing on attribute-sensitive momentum spillovers and inferring dynamic firm relations from observed market signals.", "method": "Experiments were conducted on three-year data from the S&P 500, with the attributes of connected firms and the source firm being considered in the model.", "outcome": "The attribute-driven graph attention network outperformed other state-of-the-art algorithms such as GCN, eLSTM, and TGC when tested on the three-year S&P 500 data.", "future_impact": "This model offers a stronger approach for predicting stock trends based on momentum spillovers of related firms, potentially improving future strategies in the financial sector.", "venue": "AAAI", "year": 2021, "title": "Modeling The Momentum Spillover Effect For Stock Prediction Via Attribute-Driven Graph Attention Networks"}
{"pid": "272dbb11-7087-4f65-967d-4656238775ce", "context": "Robotic soccer is a multi-agent system which has been used as a platform for research in robotics and artificial intelligence. However, handling global perception, distributed cognition and action in a highly dynamic environment such as robotic soccer has been a substantial problem.", "key_idea": "This paper introduces the CMUnited-98 small robot team which addresses this problem. The solution includes a robust and effective hardware design, a global vision processing algorithm, a reactive robot motion algorithm, role-based behaviors and a collaboration algorithm.", "method": "Through various functionalities, including a reactive motion control algorithm for target pointing, desired robot orientation, and obstacle avoidance, the authors created an effective role-based decision-making system, put it into operation, and participated in the RoboCup-98 games.", "outcome": "CMUnited-98 small robot team performed effectively during RoboCup-98 games, scoring a total of 25 goals and conceding only 6 goals in the 5 games that it played.", "future_impact": "The model introduced in the paper presents new opportunities for further research in the areas of multi-agent robotic systems, specifically around team collaboration and strategic positioning in dynamic environments.", "venue": "AAAI", "year": 1999, "title": "CMUnited-98: a team of robotic soccer agents"}
{"pid": "ab433de3-ee61-4add-acd3-220b186c6637", "context": "While model-based diagnosis has been successful in multi-agent settings, it has left open the diagnosis of coordination failures, a problem as multi-agent and distributed systems are increasingly deployed.", "key_idea": "The authors propose a model-based coordination diagnosis, which employs coordination primitives such as concurrence and mutual exclusion, to manage coordination failures between agents.", "method": "The authors formalize the model-based coordination diagnosis and define the consistency-based and abductive diagnosis problems within this formalization.", "outcome": "The authors showed that both the consistency-based and abductive diagnosis problems are NP-Hard by mapping them to other known problems.", "future_impact": "This work opens the possibility for novel solution approaches and systems that can diagnose coordination failures in multi-agent and distributed systems.", "venue": "AAAI", "year": 2005, "title": "Towards model-based diagnosis of coordination failures"}
{"pid": "6230bd43-ffe3-489e-90df-f8dc11283570", "context": "Assembly line balancing problems (ALBP) have been a critical part of industry since the days of Henry Ford. They aim to maximize the production rate while respecting various constraints, necessitating the placement of tasks among workstations. This problem can be modelled as a bin packing problem with precedence constraints (BPPC). Existing global constraints for bin-packing do not consider precedence constraints.", "key_idea": "This study introduces redundant constraints for BPPC, combining precedences and bin packing, and also designs a global constraint for BPPC that introduces further pruning in the search tree.", "method": "The authors developed a constraint programming model for BPPC and applied it to solve ALBP. They proposed two search heuristics and evaluated their approach on standard ALBP benchmarks.", "outcome": "The authors demonstrated the efficiency of their approach on standard ALBP benchmarks. Their method provides improved flexibility as it can handle new constraints that emerge in real applications.", "future_impact": "While it is not explicitly stated in the abstract, it can be inferred that the proposed model and techniques could be widely applicable in industries that deal with assembly line balancing problems.", "venue": "AAAI", "year": 2008, "title": "A global constraint for bin-packing with precedences: application to the assembly line balancing problem"}
{"pid": "3f45bd80-7327-4582-a950-a652ea016608", "context": "Existing clustering algorithms use objective functions such as normalized cut and k-means, which are NP-hard optimization problems. These algorithms usually relax the elements of the cluster indicator matrix to continuous ones, leading to a relaxed continuous solution that often deviates from the true solution, creating difficulty in obtaining the cluster labels.", "key_idea": "The proposed algorithm addresses these issues by introducing an explicit nonnegative constraint during the relaxation for a more accurate solution and a discriminative regularization into the objective to prevent overfitting.", "method": "The authors propose a new iterative approach to optimize the objective, and they conducted experiments to test their proposed solution.", "outcome": "Experiments showed that the proposed algorithm performed effectively.", "future_impact": "The authors suggest that their algorithm is general and can naturally lead to other extensions, indicating potential for future improvements and applications in the broader field of data mining.", "venue": "AAAI", "year": 2011, "title": "Nonnegative spectral clustering with discriminative regularization"}
{"pid": "6020e4569e795e62379b5bf2", "context": "Sentiment analysis on user-generated content has improved by considering individual user's preference and language use. However, most existing models fail to handle data sparsity issues, failing to capture discriminative user features when data is limited.", "key_idea": "This study proposes a neural group-wise sentiment analysis model cognizant of data sparsity. The model posits that grouping users based on their rating biases and consistency allows for more accurate analysis when individual user data is scarce. User-centered document representations are generated by a group-based user encoder.", "method": "A multi-task learning framework is used to model user rating biases and their consistency alongside the main task of sentiment analysis. The proposed approach is validated through experiments on three real-world datasets.", "outcome": "The proposed approach outperforms some existing methods in sentiment analysis. Further model analysis and case studies demonstrate the model's effectiveness in handling user rating biases and variances.", "future_impact": "The proposed model provides a potential strategy for other areas dealing with data sparsity issues, particularly in user-generated content analysis, by considering user grouping in machine learning modelling strategies.", "venue": "AAAI", "year": 2021, "title": "A Neural Group-Wise Sentiment Analysis Model With Data Sparsity Awareness"}
{"pid": "3b9c0606-ae49-4efb-b174-6051cc5c722f", "context": "Prior to this study, semantic network processing was hindered by computational resources and limitations in processing capabilities.", "key_idea": "The authors introduce IXM2, a parallel associative processor developed for semantic network processing, which offers a new approach with its large associative memory and parallel processing capabilities.", "method": "IXM2, which consists of 64 associative processors and 9 network processors with a total of 256K words of associative memory, is developed and its performance in semantic network processing is analysed. The processor is designed to process 65,536 semantic network nodes in parallel.", "outcome": "The utilization of a large associative memory capacity in IXM2 reduces the order of algorithmic complexity to O(1) in basic semantic net operations, thus achieving superior performance in fundamental operations required for semantic network processing such as intersection, marker-propagation, and arithmetic operations.", "future_impact": "The introduction of the IXM2 processor has a potential impact on the design of parallel associative processors for knowledge processing tasks in the future.", "venue": "AAAI", "year": 1991, "title": "IXM2: a parallel associative processor for knowledge processing"}
{"pid": "6020e3eb9e795e62379b5bb9", "context": "Wasserstein GANs (WGANs) are theoretically sound GAN models utilizing the Kantorovich-Rubinstein (KR) duality of Wasserstein distance. However, they don't outperform other GAN variants due to imperfect implementation of the Lipschitz condition. This condition is hard to implement perfectly in practice despite extensive attempts.", "key_idea": "This study questions the need for the strong Lipschitz constraint and instead proposes to relax this constraint. It presents the Sobolev duality, a more generalized dual form of Wasserstein distance that relaxes the Lipschitz constraint, maintaining the desirable gradient property of the Wasserstein distance.", "method": "The authors show theoretically that the KR duality is a special case of the Sobolev duality, and using the relaxed duality propose a generalized WGAN training scheme named Sobolev Wasserstein GAN. They evaluate this method through extensive empirical experiments.", "outcome": "The new training scheme proposed, the Sobolev Wasserstein GAN, improved over existing methods according to empirical results.", "future_impact": "The study lays groundwork for more efficient and effective GAN training schemes that do not strictly need to live up to the strong Lipschitz constraint but can still maintain the favorable attributes of Wasserstein distance.", "venue": "AAAI", "year": 2021, "title": "Towards Generalized Implementation Of Wasserstein Distance In Gans"}
{"pid": "57cbb6eb-f0ee-4807-a12c-fb058a8b5e35", "context": "The realm of task automation in manufacturing necessitates the integration of multiple technologies such as Artificial Intelligence (AI) and robotics, particularly in dynamic or unstructured environments. The current manual inspection process of the F-15 bulkhead, for instance, is time-consuming and inefficient.", "key_idea": "The Martin Marietta Intelligent Task Automation Project (ITA) aims to develop a system that integrates AI task planning, path planning, vision, and robotics technologies to autonomously perform manufacturing tasks, specifically dimensional measurement of an F-15 bulkhead.", "method": "The ITA project was conducted in two phases. Phase 1 demonstrated the readiness of the technologies in each area, and Phase 2 showcased the integrability of these technologies into a working system and its potential transferability to other applications.", "outcome": "The project demonstrated readiness of the technologies in all areas making up the ITA system and their integration into a working system that can be applied to other applications. The intended application of F-15 bulkhead inspection aims to be an order of magnitude faster than the existing manual method.", "future_impact": "While the abstract does not explicitly anticipate future impacts, the successful completion of the project suggests potential for improving the efficiency and speed of manufacturing tasks across a wide range of applications through intelligent task automation.", "venue": "AAAI", "year": 1987, "title": "An architecture for intelligent task automation"}
{"pid": "5f648dbc91e011f934ad2613", "context": "Mitigating risks arising from extreme events is an important goal with many applications. While Generative Adversarial Networks (GANs) are great at generating realistic samples, they usually generate typical samples instead of extreme ones.", "key_idea": "This study introduces ExGAN, a GAN-based approach designed to generate extreme, yet realistic, samples. ExGAN incorporates the probabilistic principles from Extreme Value Theory to model the extremes of a training distribution.", "method": "ExGAN is configured to accept user-defined extremeness measures and extremeness probabilities. It has been tested using real US precipitation data.", "outcome": "Experiments show that ExGAN generates realistic and extreme samples efficiently, based on both visual scrutiny and quantitative measures. Moreover, generating extreme samples using ExGAN takes constant time in comparison to the O(1/T) time taken by the baseline approach.", "future_impact": "The ExGAN method provides a new, principled way for modelling and generating extreme events, which could bring about advancements in risk management across different domains.", "venue": "AAAI", "year": 2021, "title": "Exgan: Adversarial Generation Of Extreme Samples"}
{"pid": "dbb91b6d-bf9a-4a9e-b367-ab3d227fc158", "context": "Research has indicated a role for perceptual similarity in visual metaphor processing, where perceptual similarity between two objects enhances a conceptual link between the two. However, the specific impact of perceptual features on establishing this link is not well understood.", "key_idea": "The study aims to explore the impact of perceptual features on visual metaphor processing by examining combinations of conceptually and perceptually similar picture pairs, expecting perceptual processing effects at short delays and conceptual processing at a long delay.", "method": "A same-different task is administered to participants using conceptually and perceptually similar picture pairs. The delay between the two successively presented pictures is manipulated to observe differences in perceptual and conceptual processing effects.", "outcome": "No evidence was found supporting the hypothesis that specific processes bound to time ranges are present. It was found that participants took longer to provide a 'different' response when two objects shared perceptual features, this led to more response errors; when objects shared only perceptual features, participants in the long delay condition produced more errors.", "future_impact": "The results may lead to a better understanding of visual metaphor processing and could potentially impact future models of metaphor processing.", "venue": "AAAI", "year": 2010, "title": "Perceptual similarity in visual metaphor processing"}
{"pid": "8038578a-8ae4-4141-af6b-641e12089d09", "context": "Neighborhood Interchangeability (NI) helps discern equivalent values in the domain of a variable of a Constraint Satisfaction Problem (CSP). Currently, an efficient method exists for calculating NI values in binary CSPs.", "key_idea": "The paper introduces an algorithm for calculating NI values in non-binary CSPs, noting that generalizing the algorithm from binary CSPs is not straightforward. It also introduces a 'dynamic bundling strategy' by integrating this mechanism with search for solving CSPs.", "method": "The authors interleave the proposed mechanism with search for solving CSPs and carry out empirical studies.", "outcome": "The empirical evidence suggests that the dynamic bundling strategy does not increase the cost of search, but significantly reduces it.", "future_impact": "The work has potential implications in producing multiple robust solutions for non-binary finite CSPs.", "venue": "AAAI", "year": 2005, "title": "Neighborhood interchangeability and dynamic bundling for non-binary finite CSPs"}
{"pid": "5ed8c67b91e011366a34e25f", "context": "Most of the current algorithms are used to aid human decision-making but there isn't a well-established framework to study these systems and their social impacts.", "key_idea": "A new framework named 'algorithm-in-the-loop' is introduced, which centers human decision making, providing a more precise lens for studying the social impacts of algorithmic decision making aids.", "method": "The authors conducted two experiments to evaluate the effectiveness of the 'algorithm-in-the-loop' decision-making framework.", "outcome": "Through the experiments, the authors found significant limits to 'algorithm-in-the-loop' systems.", "future_impact": "Establishing 'algorithm-in-the-loop' systems could help in studying the social impacts of algorithmic decision-making aids more effectively.", "venue": "AAAI", "year": 2020, "title": "Algorithm-In-The-Loop Decision Making"}
{"pid": "6020e18f9e795e62379b5a3d", "context": "Generating talking-head videos based on textual input has been a challenging task due to the complexity of accurately matching facial expressions and head motions with the rhythm of the speech and the emotion conveyed in the text.", "key_idea": "The authors propose a two-staged framework for text-based talking-head video generation; a speaker-independent stage, with three parallel networks generating animation parameters for mouth, upper face, and head from text; followed by a speaker-specific stage utilising a 3D face model guided attention network to synthesise tailored individual videos. The attention mask manipulates facial expression changes for the input individuals.", "method": "The authors use a high-accuracy motion capture dataset to establish correspondences between visual motions, i.e., facial expression changes and head movements, and audios. Next, they validate their model by conducting extensive experiments on qualitative and quantitative results where the algorithm is trained in an end-to-end fashion.", "outcome": "The method achieves high-quality photo-realistic talking-head videos that include various facial expressions and head motions according to speech rhythms and significantly outperforms the state-of-the-art.", "future_impact": "The proposed framework can be used to improve the quality of generated video content, especially in virtual reality and animation media where high-fidelity facial expressions and head motions are necessary.", "venue": "AAAI", "year": 2021, "title": "Write-A-Speaker: Text-Based Emotional And Rhythmic Talking-Head Generation"}
{"pid": "c21a66e5-8646-402f-920d-beee0af92ac9", "context": "A major goal for AI is to create agents that learn in real-time, revolutionizing interactive simulations, training applications, and digital entertainment. However, such technologies are not yet accessible to laymen without prior knowledge of AI or machine learning.", "key_idea": "This paper introduces a novel learning technology, real-time NeuroEvolution of Augmenting Topologies (rtNEAT), and an accompanying implementation, NeuroEvolving Robotic Operatives (NERO) video game, which represents a new genre of machine learning games.", "method": "The authors employed rtNEAT to create the NERO video game, where players can train agents in real time to perform tasks in a virtual environment.", "outcome": "The rtNEAT allowed laymen to successfully train agents in NERO, demonstrating that it's feasible for non-experts to use AI technology to effectively train agents in real-time.", "future_impact": "This approach to introducing AI has compelling implications for promoting AI, making its advancements accessible to the general public, and facilitating the development of new types of interactive simulations, training applications, and digital entertainment.", "venue": "AAAI", "year": 2006, "title": "Real-time evolution of neural networks in the NERO video game"}
{"pid": "6167a03c5244ab9dcbcd9d05", "context": "Zero/few-shot transfer to unseen services is a significant challenge in task-oriented dialogue research. The Schema-Guided Dialogue (SGD) dataset introduced a paradigm for enabling models to support any service in zero-shot through schemas, which describe service APIs to models in natural language.", "key_idea": "The authors design SGD-X, a benchmark that extends SGD by incorporating semantically similar yet stylistically diverse variants for every schema to test the robustness of dialogue systems to linguistic variations in schemas. Additionally, they present a simple model-agnostic data augmentation method to improve schema robustness.", "method": "The authors evaluate the performance of two top state tracking models on SGD-X, and their performance is measured by joint goal accuracy and a novel metric for measuring schema sensitivity.", "outcome": "The authors note that these state tracking models fail to generalize well across schema variants.", "future_impact": "The SGD-X benchmark and the data augmentation method might inspire future research on improving the robustness of dialogue systems to linguistic variations in schemas.", "venue": "AAAI", "year": 2022, "title": "SGD-X: A Benchmark for Robust Generalization in Schema-Guided Dialogue Systems."}
{"pid": "5fae6ceed4150a363ceaac28", "context": "Learning from crowds often operates on an active learning paradigm to improve learning performance and reduce labeling cost by selecting workers to label critical instances. However, current active learning methods for learning from crowds lack a proactive mechanism to effectively improve the worker reliability, preventing the attainment of a steadily rising learning curve.", "key_idea": "This paper proposes an novel Interactive Learning framework with Proactive Cognitive Enhancement (ILPCE) for crowd workers, aiming to improve their reliability while performing tasks.", "method": "The ILPCE framework includes a novel probabilistic truth inference model and an interactive labeling scheme, which are testing in three real-world learning tasks.", "outcome": "The experimental results demonstrate that the proposed ILPCE significantly outperforms five representative state-of-the-art methods.", "future_impact": "The study did not explicitly anticipate any potential impacts or further research based on their study. N/A", "venue": "AAAI", "year": 2020, "title": "Interactive Learning With Proactive Cognition Enhancement For Crowd Workers"}
{"pid": "0185a3b8-5cb1-42a9-9669-3fba454baaa1", "context": "Previous planning algorithms such as SNLP, SIPE, and NOAH, apply varying strategies for threat removal, from immediate removal to partial or complete delay.", "key_idea": "The authors propose the exploration of alternative threat removal strategies in planning algorithms, suggesting that the efficiency of these planners can be significantly improved.", "method": "The authors discuss and analyze five different threat removal strategies, proving dominance based on the size of the search space. They confirm their results through experimental evaluation using a large number of planning examples.", "outcome": "The authors prove that two of the discussed threat removal strategies create a provably smaller search space than the others, and confirm this result experimentally. Systematicity of the planning algorithm is maintained across all strategies.", "future_impact": "This study provides an opportunity to refine existing planning algorithms for improved efficiency, potentially impacting how future planning algorithms are designed.", "venue": "AAAI", "year": 1993, "title": "Threat-removal strategies for partial-order planning"}
{"pid": "02ea454d-9151-4936-92cf-59619d93a137", "context": "Distance rationalizability is a compelling paradigm for developing and studying voting rules, but this approach faces the challenge of relating the selected distance measure and consensus notion to an operational measure of social desirability.", "key_idea": "The paper proposes a decision-theoretic framework named dynamic social choice, utilizing a social choice Markov decision process (MDP) to model voter preference dynamics in response to winner selection.", "method": "In the paper, a social choice MDP is constructed with designated preference dynamics and rewards to study and validate the framework for a prominent class of distance functions.", "outcome": "The study demonstrates that for specific distance functions, a voting rule is rationalizable with respect to the unanimity consensus, if and only if it is a deterministic optimal policy in the social choice MDP.", "future_impact": "This research provides a novel rationale for distance rationalizability, establishing an equivalence between rationalizable voting rules in a static sense and winner selection for maximizing societal utility in a dynamic process.", "venue": "AAAI", "year": 2012, "title": "A dynamic rationalization of distance rationalizability"}
{"pid": "6020e3909e795e62379b5b7a", "context": "Adversarial attack can misguide deep neural networks (DNNs) by adding small-magnitude perturbations to normal examples. This is determined by the gradient of the loss function with respect to inputs. While various strategies have been proposed to enhance the performance of adversarial attacks, these methods only utilize the gradients in the present and past to generate adversarial examples, without considering the trend of gradient change in the future (i.e., the derivative of gradient).", "key_idea": "The study proposed a new proportional-integral-derivative (PID)-based approach for generating adversarial examples that considers gradients in the present and past as well as the derivative of gradient, which correspond to the components of P, I, and D in the PID controller, respectively.", "method": "The proposed PID-based approach was tested extensively, comparing its performance (attack success rates and transferability) with the state-of-the-art gradient-based adversarial attacks.", "outcome": "The results from the experiments showed that the proposed method achieved higher attack success rates and exhibited better transferability compared to the state-of-the-art gradient-based adversarial attacks.", "future_impact": "The PID-based approach possesses good extensibility and can be applied to almost all available gradient-based adversarial attacks, potentially improving future adversarial attempts.", "venue": "AAAI", "year": 2021, "title": "Pid-Based Approach To Adversarial Attacks"}
{"pid": "13ed2d74-ea8e-4a44-98b0-c309f1a67a83", "context": "In operative disruption management, decision support systems have to evaluate options to respond to disturbances. One common approach is using generic scheduling frameworks such as the Resource-Constrained Project Scheduling Problem (RCPSP), which often lack support for switching from one process variant to another.", "key_idea": "The authors propose to extend the RCPSP with the concept of alternative activities, enabling models to account for and search within alternative process execution paths.", "method": "A novel genetic algorithm is proposed to solve the generalized rescheduling problems arising from the extension of RCPSP.", "outcome": "The authors present a formal description of the conceptual extension to the RCPSP and report promising results from its detailed evaluation.", "future_impact": "This extension of RCPSP could support decision making in operative disruption management by modeling and evaluating alternative process execution paths in response to disturbances.", "venue": "IJCAI", "year": 2007, "title": "Handling alternative activities in resource-constrained project scheduling problems"}
{"pid": "382f4fcb-4fd4-49f6-b08d-cc312c678fd8", "context": "Despite the widely recognized use of restarts in SAT solvers, the task of determining an optimal restart policy has received surprisingly minimal attention. While results have been reported for different restart policies in combinatorial search algorithms, these findings are not directly applicable to SAT solvers as they intrinsically perform a different operation, namely resolution.", "key_idea": "The authors propose exploring different restart policies in clause learning SAT solvers through a prototype that allows restarts at any given point, aiming to show that a careful restart policy could drastically improve the efficiency of a SAT solver.", "method": "The authors implement a prototype clause learning SAT solver capable of facilitating restarts at arbitrary points, conducting experiments on a broad selection of industrial benchmarks using various restart policies. The policies used include those from renowned SAT solvers, as well as a universal policy suggested in 1993 by Luby et al.", "outcome": "The experiments show that the choice of restart policy significantly impacts the efficiency of the SAT solver, providing compelling evidence that thoughtful design of restart policies, especially dynamic ones, can greatly enhance the solver's efficiency.", "future_impact": "These findings motivate further research into the design of superior and dynamic restart policies, possibly leading to more efficient SAT solvers.", "venue": "IJCAI", "year": 2007, "title": "The effect of restarts on the efficiency of clause learning"}
{"pid": "488723a8-dcfe-4179-a174-9b44988cd23e", "context": "The existing work on measuring the distance between two points in a fuzzy set primarily relies on the traditional notion of geodesic distance.", "key_idea": "This paper proposes a novel definition of a distance between two points in a fuzzy set, and argues that this new definition better generalizes the concept of a geodesic distance.", "method": "The paper proposes a set of properties that this new type of distance should satisfy. Several definitions are evaluated in terms of their ability to satisfy these properties, and one definition, based on fuzzy connectivity, is found to be optimal.", "outcome": "The proposed definition, which relies on fuzzy connectivity, is found to satisfy all the desirable properties set forth. Example applications in image processing briefly demonstrate the utility of this new measure for fuzzy geodesic distance.", "future_impact": "The paper hints in general terms that the proposed concept of fuzzy geodesic distance can have broad applicability in the field of image processing.", "venue": "IJCAI", "year": 1995, "title": "Fuzzy Geodesic Distance in Images"}
{"pid": "c2e8ae4e-abaa-4b37-8d1b-4f915c4688c1", "context": "The need for improved debugging performance in functional programming languages.", "key_idea": "The authors propose the concept of expression replacement as a fundamental heuristic for searching the source of an error in debugging functional programs.", "method": "The authors employ a logic-based system description for a simple functional language to examine how a diagnosis system can utilize system description to improve debugging. They formally define replacements in terms of fault modes, define a replacement order, and apply the replacement heuristic to find diagnoses.", "outcome": "The authors demonstrate the application of their concept of expression replacement in debugging functional programs, but specific results or metrics are not detailed in the abstract.", "future_impact": "The authors suggest the incorporation of multiple test cases as a means to distinguish between diagnoses, indicating a potential direction for future investigation and further development of their proposed heuristic.", "venue": "IJCAI", "year": 1999, "title": "Debugging functional programs"}
{"pid": "70a8ddcf-1374-4024-a3b6-fcda50c90052", "context": "In swarm intelligence, one of the key tasks is to devise decentralized, homogenous strategies for controlling agent swarms. Current strategies include cyclic pursuit laws, where agents pursue each other in a predefined cycle, controlling the point of convergence and motion.", "key_idea": "This paper introduces centroidal cyclic pursuit, a generalization of cyclic pursuit where an agent pursues a point based on a weighted average position of remaining agents tied to a specific pursuit sequence.", "method": "The study explores how agents' behavior changes by adjusting their gains to control their rendezvous points. It also investigates how directed linear motion can be achieved, and how agents' trajectories can be altered by switching pursuit sequences while some behaviors remain invariant. The validation of these concepts is supported by simulation experiments.", "outcome": "The authors conclude that the rendezvous point, direction of motion, and agent trajectories can be modified by manipulating the agents' gains and switching pursuit sequences.", "future_impact": "This research could inspire the development of more effective strategies for controlling swarms of autonomous agents.", "venue": "IJCAI", "year": 2007, "title": "Control of agent swarms using generalized centroidal cyclic pursuit laws"}
{"pid": "609b9c0491e0113c3c76923f", "context": "Robots assisting us in factories or homes need to learn how to use objects as tools for various tasks. However, generalization of existing tools and their interactions for accomplishing high-level tasks in unseen environments remains a challenge.", "key_idea": "The paper introduces TANGO, a novel neural model, that learns to predict task-specific tool interactions from instructions, by encoding the world state using a graph neural network. It uses goal knowledge and action history to attend the scene and decode symbolic actions.", "method": "TANGO was trained using demonstrations obtained from human teachers instructing a virtual robot in a physics simulator. The experiment also includes augmenting the environment representation with pre-trained embeddings from a knowledge-base for generalization to novel environments.", "outcome": "Experimental results show a 60.5-78.9% improvement over the baseline in predicting successful symbolic plans in unseen settings for a simulated mobile manipulator.", "future_impact": "The work enables robots to generalize effectively to unseen environments where some known tools may be missing, but other unseen tools that can serve as alternatives are present.", "venue": "IJCAI", "year": 2021, "title": "TANGO - Commonsense Generalization in Predicting Tool Interactions for Mobile Manipulators."}
{"pid": "d4b28310-416c-4a99-8912-c8c331a459a2", "context": "The composition of high-level programs over situation calculus action theories has been a topic of interest in the CS and AI literature, with prior work focusing on finite state settings.", "key_idea": "This paper explores the problem of composing fragments of available ConGolog programs to realize target programs not within the library, extending the context to infinite domain settings that may go through an infinite number of states as a result of actions.", "method": "To tackle the undecidable nature of the problem in infinite domains, the authors apply recent results in AI literature to devise a technique for solving the problem.", "outcome": "A sound and well characterized technique is developed to solve the problem of composing ConGolog programs in infinite domain settings.", "future_impact": "This work introduces a new technique for handling program composition in complex scenarios with infinite domains, which has the potential to impact future research in AI and computer science.", "venue": "IJCAI", "year": 2009, "title": "Composition of ConGolog programs"}
{"pid": "3c3c2196-5345-446f-8945-fc21188e8bd3", "context": "Prior models or techniques for perception of structural image features lacked specificity in terms of extracting partial geometric features and structure features under positional constraints.", "key_idea": "A new model for extracting image structure features is proposed. It consists of two parts: extracting partial geometrical features and using them to extract structure features under positional constraints.", "method": "An algorithm was developed to extract the structural feature as a maximal set of common sub-images satisfying positional constraints, with the applied experimental conditions selected through a statistical method.", "outcome": "The model was tested on images of human faces and yielded fairly good results.", "future_impact": "This model could significantly contribute to studies that involve animal perception of images, specifically when an animal perceives an image at a glance.", "venue": "IJCAI", "year": 1979, "title": "A model for perception of structural image feature"}
{"pid": "7471ed38-e24e-41e1-a107-dd4d228e0671", "context": "Ensemble classification traditionally requires learning multiple predictors for single test labels.", "key_idea": "The authors propose a new approach to ensemble classification that requires learning only a single base classifier. This is achieved by learning a classifier that simultaneously predicts pairs of test labels and coordinating the assignment of individual labels by propagating beliefs on a graph over the data.", "method": "The proposed approach is presented with experimental results across a range of independent identically distributed (iid) data sets and a set of base classifiers.", "outcome": "The experimental results showed improvements in classification accuracy over single-example classifiers for both a range of iid data sets and a set of base classifiers.", "future_impact": "Like boosting, this new technique increases representational capacity while controlling variance through a principled form of classifier combination, potentially revolutionizing ensemble classification.", "venue": "IJCAI", "year": 2005, "title": "Learning coordination classifiers"}
{"pid": "9fd86b25-28b4-49ec-9fc4-def584ccd165", "context": "Prior to this work, the ways of representing concepts and antecedent-consequent productions, as well as methodologies to induce knowledge from these representations, were not well-discussed.", "key_idea": "This study proposes a learning method called 'interference matching' that induces abstractions by identifying relational properties common to two or more exemplars.", "method": "A program implementing the interference matching algorithm was used to solve three different tasks, providing a practical test for the proposed methodology.", "outcome": "The paper elaborates on the tasks solved using interference matching, indicating that the method was successfully applied, although the specific results are not stated.", "future_impact": "The paper discusses some issues concerning the relational representation of examples and the induction of knowledge by interference matching, suggesting future research and improvements in these areas.", "venue": "IJCAI", "year": 1977, "title": "Knowledge acquisition from structural descriptions"}
{"pid": "70c3ed2c-449f-4283-a8e0-0a7877c53450", "context": "The Trailblazer Search (TBS) is a systematic and effective search method for the moving target search problem, where the location of the goal may change during the search process. However, as the maintained map grows, the decision-making time for search steps increases.", "key_idea": "The authors propose the Trailblazer Search with an Abstract map (TBSA), an algorithm that aims to reduce the cost of map maintenance, thereby improving reactiveness", "method": "The proposed algorithm partitions information about the problem space into local maps, and builds an abstract map that oversees maintenance of the local maps. The efficiency of this method is evaluated.", "outcome": "The proposed TBSA can systematically manage information about the problem space and utilize the map at less cost. Significant cost reduction in map maintenance can be achieved using a two-layered map.", "future_impact": "The proposed algorithm could potentially help in improving efficiency and reactiveness for solving moving target search problems in the future.", "venue": "IJCAI", "year": 1995, "title": "The trailblazer search with a hierarchical abstract map"}
{"pid": "cfd9fc5e-984f-4825-81b8-7272a9b6617b", "context": "Halpern and Shoham's interval logic (HS) has been extensively used for examining Allenu0027s relations. Despite this, there has not been a complete set of inter-definability equations between the modal operators, leading to a lack of complete classification in all possible variants of HS.", "key_idea": "This study establishes a comprehensive set of inter-definability equations to understand the relationships between modal operators in Halpern and Shoham's interval logic (HS), thus providing a complete classification of its variations.", "method": "The researchers used their new set of inter-definability equations and a computer program to examine all possible fragments and variations of Halpern and Shoham's interval logic (HS).", "outcome": "The researchers found and classified 1347 expressively different interval logics based on Halpern and Shoham's (HS) logic over the class of all linear orders.", "future_impact": "This work could provide a basis for future research into interval logic, Allen's relations, and their applications, as it offers a robust means to understand and classify variations within interval logic.", "venue": "IJCAI", "year": 2011, "title": "Expressiveness of the interval logics of Allen's relations on the class of all linear orders: complete classification"}
{"pid": "9b67cb75-6644-4009-879f-f946d94c1fd9", "context": "The traditional methods for solving puzzles such as the tower of cubes lack precision and efficiency.", "key_idea": "The authors propose a number theory approach for problem-solving where special numbers are used to represent different colours on the sides of the cubes and a description matrix is utilized to compress the problem representation.", "method": "The authors apply their number theory approach to the tower of cubes problem. The efficiency of the solution method is evaluated based on how concise the problem representation becomes.", "outcome": "The application of the number theory approach resulted in a very efficient solution due to the concise representation of the problem. To verify the solution, two theorems were developed and found valid.", "future_impact": "The authors discuss how this new approach could be potentially applied to a generalized version of the puzzle, suggesting future research avenues.", "venue": "IJCAI", "year": 1973, "title": "A number theory approach to problem representation and solution"}
{"pid": "5d1c7ccb3a55ac8c230aa9b9", "context": "Although the optimization of expensive to evaluate, black-box, mixed-variable functions is a pervasive problem in science and engineering, few methods exist specifically for mixed-variable domains. Existing methods under the umbrella of Bayesian optimization have tackled either fully continuous or fully discrete domains, leaving a gap in addressing mixed-variable domains.", "key_idea": "The main contribution is the introduction of MiVaBo, a novel Bayesian optimization algorithm for the efficient optimization of mixed-variable functions that combines a linear surrogate model based on expressive feature representations with Thompson sampling.", "method": "To evaluate the performance of MiVaBo, two methods were proposed to optimize its acquisition function, a challenging task for mixed-variable domains. A convergence analysis was also provided. The performance of MiVaBo is benchmarked against other state-of-the-art mixed-variable BO algorithms on hyperparameter tuning tasks.", "outcome": "The authors demonstrated that MiVaBo could handle complex constraints over the discrete part of the domain which other methods cannot take into account. Compared with state-of-the-art mixed-variable BO algorithms, MiVaBo showed significantly more sample efficiency on hyperparameter tuning tasks.", "future_impact": "The introduction of MiVaBo provides a new method to handle optimization of mixed-variable functions, with an ability to handle complex constraints over the discrete part of domain, making it beneficial for future research and applications in domains where mixed-variables optimization is crucial.", "venue": "IJCAI", "year": 2020, "title": "Mixed-Variable Bayesian Optimization"}
{"pid": "c43a2c4d-3402-49d3-902d-ff2aaab7dc13", "context": "Hierarchical type fuzzy systems are used to represent complex systems in a structured way. However, the construction of these models, especially when dealing with priorities and incomplete information, remains a challenge.", "key_idea": "The authors introduce a model called Hierarchical Prioritized Structure (HPS), which can handle the construction of fuzzy systems where rules are provided by an expert and, importantly, consider the issue of completing incomplete priorities.", "method": "The authors review the structure, operation, and inter-level aggregation algorithm of the HPS, and apply a mathematical programming method for implementing the principle of maximal buoyancy in the context of incomplete priorities.", "outcome": "The paper provides a detailed exploration of the HPS, its construction, and its handling of incomplete priorities via the principle of maximal buoyancy.", "future_impact": "The discussion about tuning hierarchical models suggests that future research could address the optimization of these models, potentially improving their effectiveness in various applications.", "venue": "IJCAI", "year": 1995, "title": "Constructing Prioritized Fuzzy Models"}
{"pid": "63365552-6f81-49e9-a041-72e30ae32ea7", "context": "Transforming f-structures into discourse representation structures (DRSs) has been a complex task due to the order in the attributes and indeterminacy of scoping.", "key_idea": "The paper proposes a new bottom-up algorithm that can translate f-structures into DRSs without pre-imposing any arbitrary order on the attributes and handles indeterminacy of scoping using sets of translations.", "method": "The proposed algorithm is used to transform f-structures into DRSs.", "outcome": "The results show an efficient interaction of different components of a natural language processing model.", "future_impact": "The exploratory nature of the work may influence further research in the efficient construction of natural language processing models.", "venue": "IJCAI", "year": 1985, "title": "Grammatical functions, discourse, referents, and quantification"}
{"pid": "169fdb25-bb2e-4a80-9f59-436f88fa8597", "context": "The prediction of output in an oilfield is difficult due to the impact of multiple variables, plus the precision demanded by the nonlinear and uncertain system goes beyond what classic statistical methods and static models can meet.", "key_idea": "The authors propose a back propagation (BP) neural network model that uses effective depth, permeability, porosity, and water content as input and oilfield output as output to predict oilfield output with greater accuracy.", "method": "The authors build a back propagation neural network model using effective depth, permeability, porosity, and water content as the input and oilfield output as the output.", "outcome": "The back propagation neural network model was found to be effective with accuracy comparable to other classic methods in predicting oilfield output.", "future_impact": "The successful application of this approach can aid in supplying reliable data for the development of oilfields and decrease the risks for exploitation.", "venue": "IJCAI", "year": 2009, "title": "Application of Artificial Neural Network in the Prediction of Output in Oilfield"}
{"pid": "8ee8aa44-d0b0-4993-a2ed-0ce78ce01857", "context": "Markov decision processes (MDPs) are traditionally solved using dynamic programming techniques that require explicit enumeration of the state or action spaces, which is computationally intensive and may not be feasible for problems with large state or action spaces.", "key_idea": "The authors propose a new dynamic programming approach for solving first-order MDPs using a variant of the situation calculus that allows for stochastic actions, and an operation called 'decision-theoretic regression'. This approach generates a logical description of the optimal value function and policy without the need for explicit enumeration of state or action spaces.", "method": "The proposed technique uses a dynamic programming approach that constructs a set of first-order formulae that minimally partition state space according to distinctions made by the value function and policy through an operation known as decision-theoretic regression.", "outcome": "This method allows problems containing relational fluents and quantification to be solved without requiring explicit state space enumeration or conversion to propositional form.", "future_impact": "The presented solution might improve the computational efficiency of solving large-scale MDPs with complex action and state spaces and further expand the applicability of MDPs in various domains.", "venue": "IJCAI", "year": 2001, "title": "Symbolic dynamic programming for first-order MDPs"}
{"pid": "8d8e1e14-a06a-49be-968c-dc89fa530d60", "context": "The task of realizing complex high-level tasks in robotics often involves developing a set of modular, cooperating behaviors. However, a general framework for describing and constructing sensor-based behaviors is lacking.", "key_idea": "The authors propose a general framework that formulates each behavior in a modular fashion, which can be decomposed into local control actions interpretable as linguistic 'IF-THEN' rules.", "method": "The proposed framework is applied to a range of real-world robotic systems, including a mobile gripper system equipped with proximity sensors and a two arm system with force/torque sensors.", "outcome": "The framework was successfully applied in different settings representing its capability of working with controllers without sensor-action models, following a proper selection of system inputs.", "future_impact": "The paper mentions the possibility of integrating 'common sense' knowledge and rapid adaptation of control parameters through incremental learning, indicating potential areas of extension for the proposed framework.", "venue": "IJCAI", "year": 1997, "title": "From Numerical Interpolation to Constructing Intelligent Behaviors"}
{"pid": "22cc14b9-45c7-4084-86dc-5af9fdfbe3e2", "context": "Stereo vision systems are critical for autonomous vehicles, but achieving high resolution, accurate matches with confidence estimates, and differentiating ground from other objects in 3D data still pose challenges.", "key_idea": "The authors propose several techniques for use in a stereo vision system such as a stereo camera model solver, a high resolution stereo correlator, a dense sampling search technique, and a ground surface finder.", "method": "While specifics of the experiments are not provided in the abstract, the authors mention they showcase the use of these techniques in an autonomous vehicle, using an example to detect objects from a stereo pair of pictures.", "outcome": "The authors provided an example showing the detection of objects from a stereo pair of pictures using the proposed techniques.", "future_impact": "The authors state that the proposed techniques could be used in an autonomous vehicle designed to explore its environment, suggesting potential future impact in this field, though specific future directions are not explicitly mentioned in the abstract.", "venue": "IJCAI", "year": 1977, "title": "A stereo vision system for an autonomous vehicle"}
{"pid": "0127fd73-c9d3-4107-8164-a69c15d220cd", "context": "Sensitivity analysis of neural network is beneficial for network design. However, previous models like Piche's stochastic model for Multilayer Perceptron (MLP) don't match the functionality of the MLP closely and have notable limitations on both input and weight perturbations.", "key_idea": "The authors aim to generalize Piche's stochastic model of the MLP and derive a universal expression of MLP's sensitivity for all sigmoidal activation functions, free from any restrictions on input and output perturbations.", "method": "The effects of network design parameters such as the number of layers, the number of neurons per layer, and the chosen activation function are analyzed to provide insights for network design decision-making. The sensitivity expression is applied to design MLP for a specific application.", "outcome": "Useful information for network design decision-making is provided through the analysis of network design parameters, and a new MLP is designed for a distinct application using their sensitivity expression.", "future_impact": "The generalized sensitivity expression derived in this work can assist in the design of the network structure, as well as the training of MLP for future applications.", "venue": "IJCAI", "year": 2001, "title": "Sensitivity analysis of multilayer perceptron"}
{"pid": "60da8fc20abde95dc965f8b3", "context": "Multiwinner elections have been widely studied due to their many real-world applications, focusing on the computational complexity of computing optimal committees given a set of candidates and voters. Utilitarian and leanitarian ordered weight average scoring rules are extensively researched family of rules.", "key_idea": "The authors refine previously established findings by improving results of Betzler et al. (JAIR 47:475\u2013519, 2013) regarding the Chamberlin\u2013Courant rule, and expanding the research to cover the parameterized complexity of the Pessimist voting rule, and introducing two new rules of egalitarian median and egalitarian mean.", "method": "The authors provide an improved algorithm to compute winners under the Chamberlin\u2013Courant rule, and study its parameterized complexity. They also explore both tractable and intractable cases of the Pessimist voting rule and the newly introduced egalitarian median and egalitarian mean rules.", "outcome": "The authors achieved improved results for the Chamberlin\u2013Courant rule, reducing the computation time from \ud835\udcaa(n^n) to \ud835\udcaa(2^n), which is optimal. They also identified tractable and intractable cases for the Pessimist, egalitarian median, and egalitarian mean voting rules.", "future_impact": "The new computational bounds and concepts introduced in this paper could lead to further advancements in research towards efficient and fair committee selection in multiwinner election cases.", "venue": "IJCAI", "year": 2023, "title": "Even More Effort Towards Improved Bounds and Fixed-Parameter Tractability for Multiwinner Rules"}
{"pid": "5e0333623a55aca24ec3edb8", "context": "The unsupervised scene adaptation problem involves learning from both labeled source data and unlabeled target data. Existing methods focus on minimizing the inter-domain gap between the source and target domains. However, the intra-domain knowledge and inherent uncertainty learned by the network are under-explored.", "key_idea": "The authors propose an orthogonal method, called memory regularization in vivo, to exploit intra-domain knowledge and regularize model training. They use the segmentation model itself as the memory module and minimize the discrepancy of two classifiers (the primary classifier and the auxiliary classifier) to reduce prediction inconsistency.", "method": "The effectiveness of memory regularization is validated on two semantic segmentation datasets: GTA5 -> Cityscapes and SYNTHIA -> Cityscapes.", "outcome": "The proposed method is able to improve the performance of existing domain adaptation methods without extra parameters. It yields +11.1% and +11.3% mIoU improvement over the baseline model on the respective datasets.", "future_impact": "The proposed method could generally improve the performance of existing domain adaptation methods, suggesting potential for further improvements and applications in unsupervised scene adaptation.", "venue": "IJCAI", "year": 2020, "title": "Unsupervised Scene Adaptation with Memory Regularization in vivo"}
{"pid": "9c847b1e-eca8-414a-9170-acd0748c9d68", "context": "RCPSP/max, the resource-constrained project scheduling problem with time windows, is a well-studied problem within the operations research community. Existing solutions focus on pairwise conflict analysis and often struggle with the search space size.", "key_idea": "The authors propose an iterative sampling procedure for RCPSP/max, dubbed as ISES (Iterative Sampling Earliest Solutions), that generalizes previous profile-based approaches by focusing on global analysis of minimal conflicting sets, offering more effective conflict resolution.", "method": "The proposed ISES approach is embedded within a multi-pass iterative sampling procedure and is applied to a set of benchmark problems for comparison with existing methods.", "outcome": "ISES is shown to perform exceptionally well, particularly when search space size becomes limiting for systematic procedures, thereby improving upon the current state-of-the-art procedures for RCPSP/max.", "future_impact": "The introduction of ISES brings the potential for improved and more efficient solutions to the RCPSP/max and similar, complex scheduling problems in the future.", "venue": "IJCAI", "year": 1999, "title": "An Iterative Sampling Procedure for Resource Constrained Project Scheduling with Time Windows"}
{"pid": "62b52c625aee126c0f459b90", "context": "Previous research mainly focuses on how to solve analogies, in the form of 'A is to B as C is to D', with less attention given to the feasibility of solving such analogies.", "key_idea": "The paper suggests a new way to quantify the transferability of a source case (A and B) in order to solve a target problem (C). The approach is based on a complexity minimization principle proven effective for solving analogies.", "method": "The methodology of this study is exemplified through morphological analogies. The connection of the proposed method with machine learning, specifically Unsupervised Domain Adaptation, is also explored.", "outcome": "The paper mainly lays out the proposed quantification of analogy transferability based on a complexity minimization principle and explores its connection with machine learning.", "future_impact": "The proposed method for quantifying transferability of analogies has potential implications in the field of machine learning, particularly in relation to Unsupervised Domain Adaptation.", "venue": "IJCAI", "year": 2022, "title": "Measuring the Feasibility of Analogical Transfer using Complexity."}
{"pid": "361e9e3f-5158-40f4-9623-f105d14c9b34", "context": "Much information nowadays is stored as multilingual textual data, therefore advanced classification systems that can manage this text-based information efficiently are required. Traditional methods have not provided high-accuracy and flexible multilingual classification that can adapt to user needs.", "key_idea": "The authors propose integrating hierarchical pattern matching and information extraction to provide flexible multilingual classification adaptable to different user needs.", "method": "They used hierarchical pattern matching for accurate and fast categorization over a large number of classes, while information extraction was used for fine-grained classification for a reduced number of classes.", "outcome": "The resulting system was adopted by the main Italian financial news agency providing a pay-to-view service showing its practical applicability.", "future_impact": "The application of this system in different fields (other than the Italian financial news agency) could yield more efficient knowledge management by seamlessly integrating new information with pre-existing knowledge.", "venue": "IJCAI", "year": 1999, "title": "FACILE: classifying texts integrating pattern matching and information extraction"}
{"pid": "72bd69c6-2ed2-4d37-bbd0-7a117e920665", "context": "Subjective assessments (SAs) are common in reviews/tags on many online sites, but their usage in improving recommendations has been ineffective due to few users assigning the same subjective assessments to the same items, which in turn triggers a sparsity problem in collaborative filtering.", "key_idea": "The authors propose a novel algorithm that links a taxonomy of items to a taxonomy of SAs to detail user interests, merging the SAs assigned by users against an item into subjective classes (SCs), and reflecting the SAs/SCs assigned to an item to its classes. This allows measuring user similarity based on SAs/SCs assigned not just to items but also to their classes.", "method": "The proposed algorithm is implemented and its performance is assessed using data from a popular restaurant review site, comparing the accuracy of recommendations generated by the proposed algorithm to those of previous methods.", "outcome": "The evaluation of the proposed method resulted in more accurate recommendations than previous methods. The study also found that SAs frequently assigned to a few classes of items were more useful in terms of recommendation accuracy than those widely assigned to many item classes.", "future_impact": "The proposed algorithm potentially offers a more effective method of utilising subjective assessments in recommendation systems, a common feature in online platforms, by overcoming the sparsity problem prevalent in collaborative filtering techniques.", "venue": "IJCAI", "year": 2011, "title": "User similarity from linked taxonomies: subjective assessments of items"}
{"pid": "5dbab6453a55aced56e13b35", "context": "With the increase in the number of surveillance cameras, video surveillance has evolved as a powerful tool for tracking perpetrators in events of terrorism in urban centers. The vast amount of data produced by these cameras presents an opportunity for intelligent real-time event monitoring and enabling predictive capabilities.", "key_idea": "The authors propose a hybrid platform for video intelligence capture, automated data extraction and supervised Machine Learning for urban video surveillance. This research also applies Knowledge Management principles to enhance understanding and implement efficient information-sharing decision support systems. The work introduces a common language for human-machine and machine-to-machine communication and a security ontology.", "method": "The paper focuses on the development and implementation of a hybrid platform for video intelligence capture, automated data extraction, and intelligent urban video surveillance. Video analytics are enhanced via supervised machine learning.", "outcome": "The researchers have successfully created a platform that fosters efficient information and experience sharing decision support systems that assist both field teams and operation centers. They also introduced a 'common' human-machine and machine-to-machine language and security ontology.", "future_impact": "The research explores the extension of the proposed model to other components of a global security system. This could help leverage vast amounts of video data, provide fast access to video evidence and predictive capacities that assist operators in surveillance tasks.", "venue": "IJCAI", "year": 2022, "title": "Video Intelligence as a component of a Global Security system"}
{"pid": "58ac6f4b-fe7d-48ff-847a-4decfef973a1", "context": "Most multi-class classifiers do not take advantage of the potential structural relationships among class labels, which can be beneficial in improving machine learning model performance.", "key_idea": "The authors propose a novel multi-class large margin classifier that not only identifies, but also exploits class relationships. This classifier learns a matrix to capture these relationships, which is separate from the feature weights. This representation can potentially decrease the required number of classifiers, thus simplifying the learning model.", "method": "The authors propose a bi-convex formulation to learn a matrix that captures class relationships. The efficiency of this model in terms of speed and memory is also examined.", "outcome": "Their model was able to maintain high accuracy while substantially reducing the number of classifiers used, thereby compressing the model.", "future_impact": "This work could deepen our understanding of classification problems by providing insights into the relationships among class labels, potentially enriching interpretability of machine learning models and their results.", "venue": "IJCAI", "year": 2009, "title": "Multi-class classifiers and their underlying shared structure"}
{"pid": "1448208c-716c-4fd7-84ef-b68c440358c6", "context": "Current learning systems typically perform supervised concept formation directly in the initial space defined by instances alone.", "key_idea": "The authors introduce MIRO, a learning system that performs concept formation in a constructed abstraction space. The abstraction space is derived by deduction over instances based on a given domain theory before performing induction.", "method": "Empirical studies were conducted to validate the proposition that learning in an abstraction space can result in a substantial speedup and reduce false negative and false positive classifications.", "outcome": "The studies showed that learning in an abstraction space successfully speeds up the learning process and reduces both false positive and false negative classifications by filtering coincidental patterns during the deduction process.", "future_impact": "The method opens up potential for extending incomplete domain theories with a set of rules representing a disjunctive concept derived from a batch of training instances.", "venue": "IJCAI", "year": 1989, "title": "Induction in an abstraction space: a form of constructive induction"}
{"pid": "78513c54-ae60-4af3-9658-c3779e6a64ce", "context": "While truth conditions for conditional sentences have been well-studied, there have been few attempts to define means of evaluating iterated or nested conditionals and most approaches impose very few constraints on the set of conditionals an agent can hold after revision of its belief set.", "key_idea": "The authors propose a method of natural revision that ensures the preservation of conditional beliefs after revision by an objective belief through a model based on a simple modal logic for beliefs and conditionals.", "method": "The method, which extends the AGM theory of belief revision, is developed to account for sentences of objective revisions of a belief set. It uses the Ramsey test to provide truth conditions for arbitrary right-nested conditionals, and reduces the acceptance of any such nested conditional to acceptance tests for unnested conditionals.", "outcome": "With this model, the authors show that the problem of determining acceptance of any nested conditional can be reduced to acceptance tests for unnested conditionals, thereby simulating iterated revision by virtual updates.", "future_impact": "The model and its informational properties provide a basis to describe reductions to propositional inference, which may demonstrate certain tractable solutions.", "venue": "IJCAI", "year": 1993, "title": "Revision sequences and nested conditionals"}
{"pid": "603e18b291e01129ef28fcff", "context": "Topic modelling, a successful technique for text analysis, has combined with deep neural networks leading to an increasingly popular research area, neural topic models, with over a hundred models developed and a wide range of applications in neural language understanding.", "key_idea": "The authors propose to provide a focused yet comprehensive overview of neural topic models, which is a fast-growing research area.", "method": "The paper is a survey and thus does not have a conventional experimental method. Instead, it provides an overarching review of the topic of neural topic models.", "outcome": "The authors have provided a comprehensive overview of the rapidly growing field of neural topic models. It is the first review focusing on this specific topic.", "future_impact": "This paper is meant to facilitate researchers in the AI community to easily navigate and innovate in the fast-growing research area of neural topic models.", "venue": "IJCAI", "year": 2021, "title": "Topic Modelling Meets Deep Neural Networks - A Survey."}
{"pid": "6416a13d-d13b-45e5-a5fd-01b885aa3156", "context": "Before this study, there wasn't an efficient method for automatically analyzing the logical structure of programs.", "key_idea": "The paper introduces a new method for automatically analyzing programs, which is based on the notion that the logical structure of programs is built in a few basic ways.", "method": "An experiment is carried out to show that this method accounts for the structure of a large class of programs. They also described an automatic system that implements the presented method.", "outcome": "The experiment demonstrated that the proposed method can successfully account for the structure of a large class of programs.", "future_impact": "The paper anticipates that the method can aid in analyzing the structure of a program, and the resulting analysis can be used to guide a proof of correctness for the program, thus influencing new ways to analyze and validate programs.", "venue": "IJCAI", "year": 1979, "title": "A method for automatically analyzing programs"}
{"pid": "a5a1266f-0f04-4ae1-ab41-766bb464d396", "context": "Digital circuits' structural representations are often written using horn clauses, but diagnosing faulty circuits has been a challenge.", "key_idea": "This paper introduces the idea of using horn clauses representations for diagnosing faulty digital circuits through algorithmic program debugging techniques originally developed by Shapiro.", "method": "The paper lays out an approach based on program debugging techniques for diagnosing faulty circuits, although the specific experiments are not detailed in the abstract.", "outcome": "The sound theoretical basis of these techniques is highlighted as one of the major advantages of the approach.", "future_impact": "The approach provides a new perspective on hardware diagnosis techniques suggested in the literature, hinting at potential for advancing the field of hardware diagnosis.", "venue": "IJCAI", "year": 1987, "title": "Hardware diagnosis as program debugging"}
{"pid": "de351aa5-a225-46bd-807e-bd8eedc605be", "context": "As artificial societies and e-commerce grow, agents base their decisions on trust and reputation, though system designs have largely focused on direct interactions. Current trust updating schemes often decouple updates for positive and negative feedback, which can allow untrustworthy agents to go undetected.", "key_idea": "The authors propose the need to address 'con-man' type behaviour where positive feedback cycles are followed by single negative feedbacks, avoiding detection of untrustworthy agents. They propose a con-resistant trust scheme as a mechanism to detect this behaviour.", "method": "The proposed con-resistant trust scheme is compared with existing models like FIRE, Regret, and Yu and Singh's model, using simulation experiments.", "outcome": "Simulation experiments demonstrate the usefulness of the proposed con-resistant scheme in detecting untrustworthy agents.", "future_impact": "The proposed con-resistant trust scheme may improve the detection of untrustworthy agents in artificial societies and e-commerce, potentially improving the reliability of these systems.", "venue": "IJCAI", "year": 2009, "title": "Towards con-resistant trust models for distributed agent systems"}
{"pid": "53892f59-564a-4df5-9f41-c6050507d865", "context": "First order theories can be used in proving properties of programs and have relevance in representation theory. However, to represent first order theories in a computer in a feasible way, the need to discuss meta mathematical notions is essential.", "key_idea": "The authors present two different types of first order axiomatizations of the metamathematics of the logic that POL (First Order Logic proof checker) checks, with the difference being one defines the metamathematics in a many sorted logic and the other does not.", "method": "By using these two axiomatizations, the authors examine and compare several proofs.", "outcome": "The checked proofs are used to discuss the adequacy of some First Order Logic features.", "future_impact": "The use of metamathematics in this way could advance the construction of systems which can formally discuss how they reason.", "venue": "IJCAI", "year": 1975, "title": "Checking proofs in the metamathematics of first order logic"}
{"pid": "5eafe7e091e01198d39865dc", "context": "Acquiring commonsense knowledge for artificial intelligence is typically a labor-intensive and costly task requiring extensive human input, making it infeasible on a large scale.", "key_idea": "This paper proposes a method for mining commonsense knowledge from linguistic graphs, aiming to convert relatively low-cost knowledge gleaned from linguistic patterns into more valuable commonsense knowledge. It results in the creation of TransOMCS, a resource comparable to ConceptNet but significantly larger.", "method": "The authors convert ASER, a large-scale selectional preference knowledge resource, into TransOMCS. The effectiveness of this approach is evaluated in terms of quantity, novelty, and quality.", "outcome": "The experiments demonstrate the ability to transfer linguistic knowledge to commonsense knowledge effectively, demonstrating the success of the proposed method in terms of quantity, novelty, and quality of the knowledge acquired.", "future_impact": "The availability of TransOMCS as a publicly available resource could have a significant impact on future artificial intelligence applications by providing a more expansive source of commonsense knowledge.", "venue": "IJCAI", "year": 2020, "title": "TransOMCS: From Linguistic Graphs to Commonsense Knowledge"}
{"pid": "39fcb092-7bc2-40c3-9174-e8ae69ff654b", "context": "In complex games, common equilibrium solutions may be too difficult to compute or aren't relevant, presenting a challenge for humans making decisions.", "key_idea": "The authors propose a method that uses reasoning patterns to derive localized evaluation functions for each decision in a game and presents their output to humans, in part to augment the human decision-making process.", "method": "The proposed method was implemented in a repeated principal-agent game and was used to generate advice given to subjects in an experiment.", "outcome": "Humans who received advice from the model performed better than those who did not.", "future_impact": "The authors anticipate that, if computers were capable of generating and presenting similar arguments from the mathematical description of a game to a human, the synergies would result in better performance overall.", "venue": "IJCAI", "year": 2009, "title": "Using reasoning patterns to help humans solve complex games"}
{"pid": "ccc0175c-1b2f-41a6-8955-b318bec2582e", "context": "Analogical planning provides a way to solve problems in unfamiliar domains by aligning with a successful plan in a similar domain. However, the analogical planning process is expensive and inflexible, with many of the limiting factors residing in the base selection step.", "key_idea": "The authors propose two methods to increase the effectiveness and efficiency of analogical planning: a parallel graph-match base selection algorithm and a base-case merge algorithm.", "method": "The authors present a parallel implementation of the graph-match base selection algorithm on the Connection Machine, and demonstrate the effectiveness of the base-case merge algorithm with examples from the domain of automatic programming.", "outcome": "The paper shows that the parallel graph-match base selection algorithm substantially decreases the complexity of base selection, and that the base-case merge algorithm increases the flexibility of analogical planning. This increased flexibility is beneficial when no single plan contributes enough information to the analogy.", "future_impact": "This approach could potentially enhance the efficiency and flexibility of analogical planning, particularly in the domain of automatic programming.", "venue": "IJCAI", "year": 1991, "title": "The base selection task in analogical planning"}
{"pid": "628707325aee126c0f78bf26", "context": "Reinforcement Learning (RL) algorithms struggle in real-world applications like financial trading and logistics due to noisy observations and shifting environments between training and evaluation. Traditional RL algorithms often perform poorly in these scenarios, hence requiring both high sample efficiency and generalization.", "key_idea": "In view of the success of ensemble methods in supervised learning on accuracy and generalization, the authors propose a new method: Ensemble Proximal Policy Optimization (EPPO), which employs ensemble policies in an end-to-end fashion. EPPO notably integrates each policy with the policy ensemble and optimizes both together, and employs a diversity enhancement regularization over the policy space to improve generalization to unseen states and encourage exploration.", "method": "The authors prove theoretically that EPPO increases exploration efficacy, and they carry out extensive experimental evaluations on various tasks to validate their method.", "outcome": "The experimental results demonstrate that EPPO achieves higher efficiency and more robust performance for real-world applications compared to traditional policy optimization algorithms and other ensemble methods.", "future_impact": "The robustness and high efficiency of EPPO can potentially improve performance and applicability of reinforcement learning algorithms in real-world scenarios such as financial trading and logistic systems.", "venue": "IJCAI", "year": 2022, "title": "Towards Applicable Reinforcement Learning: Improving the Generalization and Sample Efficiency with Policy Ensemble."}
{"pid": "72f776f9-3a08-4436-81f0-5b90869d73a2", "context": "The AGM postulates for belief revision and the DP postulates for iterated belief revision are generally accepted criteria for designing operators by which intelligent agents adapt their beliefs to new information. However, these postulates are too permissive and allow for operators in which newly acquired information is discarded when it contradicts current beliefs.", "key_idea": "The paper identifies a deficiency in the DP postulates and proposes a solution in the form of an additional 'independence' postulate, which is intended to prevent newly acquired information being discarded too readily.", "method": "The authors provide a formal analysis of the DP postulates, then present and prove a representation theorem for the 'independence' postulate.", "outcome": "The analysis shows a deficiency in the DP postulates and the representation theorem for the 'independence' postulate is shown to be compatible with the AGM and DP postulates.", "future_impact": "This work can influence the design of operators by which intelligent agents adapt their beliefs incrementally to new information by considering the proposed 'independence' postulate.", "venue": "IJCAI", "year": 2005, "title": "Iterated belief revision, revised"}
{"pid": "7749b227-738f-43ef-afd6-7fe8945eaedc", "context": "Theoretical analyses suggest that in many cases, the minimax principle used in game-playing programs amplifies the noise introduced by the heuristic function used to evaluate the leaves of the game tree, leading to what is known as pathological behavior, where deeper searches produce worse evaluations.", "key_idea": "The authors propose an alternative explanation for why minimax works, based not on value dependence but instead on the idea that if real numbers are used for position values, position values will tend to diverge further at lower levels of the game tree, which leads to a larger proportion of more extreme positions where error is less probable.", "method": "The paper presents a theoretical analysis using real numbers for position values in the minimax principle.", "outcome": "The analysis shows that decreased probability of error in searches to greater depths is sufficient to eliminate the pathology of the minimax principle.", "future_impact": "This new understanding of why minimax works could inform the design of more efficient game-playing programs that avoid the presumed pathological behavior.", "venue": "IJCAI", "year": 2005, "title": "Why minimax works: an alternative explanation"}
{"pid": "5ef96b048806af6ef277200b", "context": "Artificial intelligence techniques, including ML/DL models, are being increasingly used to assist in complex social decision problems such as the allocation of resources in social programs. However, due to limitations in their design, these models may not effectively use all factors in decision making, resulting in improper allocation of resources.", "key_idea": "To address the aforementioned limitations, the authors propose a new strategy called 'fairgroups', based on the legal doctrine of disparate impact, to improve fairness in machine learning prediction outcomes.", "method": "To validate the proposed strategy, experiments were conducted on various datasets.", "outcome": "The experiments show that the authors' 'fairgroup' approach effectively improves fairness in automated decision making while maintaining high prediction accuracy.", "future_impact": "The introduction of 'fairgroups' can improve the fairness of resource allocation in social programs, potentially leading to better-designed algorithms for social decision problems.", "venue": "IJCAI", "year": 2020, "title": "Achieving Outcome Fairness in Machine Learning Models for Social Decision Problems"}
{"pid": "301aa7a3-3ee4-48aa-9507-55bde8ab4978", "context": "Attempts at automatic function inference traditionally require extensive and specific datasets.", "key_idea": "SISP/I is an interactive system that seeks to infer LISP functions based on a finite set of examples, ideally working with a single example but able to request new ones as needed.", "method": "SISP/I uses a method of generating new partial sub-problems to iteratively refine its function until it finds an accurate one.", "outcome": "SISP/I is a successfully implemented system able to infer many linear recursive LISP functions and their stop conditions.", "future_impact": "The ability of SISP/I to iteratively refine functions based on a small number of examples could have significant implications for the future of automatic function inference.", "venue": "IJCAI", "year": 1977, "title": "SISP/L an interactive system able to synthesize functions from examples"}
{"pid": "12d4431f-9a43-49d0-814b-36af32128fd1", "context": "There is a need for efficient methods to acquire complex classification rules and automate the knowledge acquisition process, but membership queries alone might not be sufficient.", "key_idea": "The paper introduces an extension to membership queries with the meta query concept to derive complex classification rules more efficiently.", "method": "The authors apply their method to relevant concept classes where a small number of queries is enough, and they develop a knowledge acquisition tool, KAC-Z, to test it.", "outcome": "The system's usefulness is demonstrated through application in the domain of the manufacturing (cutting) industry.", "future_impact": "The proposed method can provide the foundations for automating the knowledge acquisition process more efficiently.", "venue": "IJCAI", "year": 1991, "title": "Acquiring knowledge by efficient query learning"}
{"pid": "5ef96b048806af6ef27720d0", "context": "Previous studies have investigated bipolar argumentation where attacks are combined with another relations between arguments, such as deductive support, evidential support, necessities, etc. from a Dung semantics perspective.", "key_idea": "The authors aim to investigate the ranking semantics in the context of argumentation systems with necessities. This is a novel scope that has not been explored before.", "method": "They set about this by providing a set of postulates specifically designed for necessities and propose the first ranking-based semantics shown to respect these postulates.", "outcome": "The authors successfully propose the first ranking-based semantics in the literature to be shown to respect their specifically designed set of postulates for necessities.", "future_impact": "This work on ranking semantics for argumentation systems with necessities could be foundation for future studies into argumentation systems with other relationships, and could enhance the effectiveness of these systems.", "venue": "IJCAI", "year": 2020, "title": "Ranking Semantics for Argumentation Systems With Necessities"}
{"pid": "f0e021cd-71ab-4661-899c-11bac95d3bef", "context": "While occlusions are central to multi-object computer vision, formal analyses in the spatial reasoning literature largely ignore many distinctions crucial to computer vision, causing these algebras to be also largely ignored in vision applications.", "key_idea": "A new formal model of occlusion states, OCS14, is presented, which accounts for distinctions whether the occluder is a moving object or part of the static background, and whether the visible part of an object is a connected blob or fragmented, in addition with overlap distinctions modeled in spatial reasoning.", "method": "The authors applied their occlusion states model in a test application involving static camera based scene analysis, where it was used for identifying static occluders and modeling a class of interactions represented as transitions of occlusion states.", "outcome": "The authors demonstrated that their occlusion states model, OCS14, is representationally complete and partitioned all possible occlusion situations based on the criteria. Their test application results also showed the formalism's direct relevance to actual vision applications.", "future_impact": "The research's formalism could be potentially employed in future computer vision applications and help resolve occlusion issues more effectively.", "venue": "IJCAI", "year": 2011, "title": "OCS-14: you can get occluded in fourteen ways"}
{"pid": "202dbe1f-5c71-4c2b-9a21-ee76af33b564", "context": "Conventional methods of communication between electronic agents do not embody the natural, rule-governed form of behaviour seen in speech and are often reduced to simple method invocation.", "key_idea": "The authors suggest that speaking a natural language is to engage in a rule-governed form of behavior. This analysis is translated to define constitutive rules for agent communication languages, which is a marked departure from method invocation.", "method": "The authors carry out a theoretical analysis of rule-governed behavior in natural language and apply the principles to define the semantics of an agent communication language.", "outcome": "The authors demonstrate that using constitutive rules to define the semantics of an agent communication language distinguishes agent communication from method invocation and offers computational advantages.", "future_impact": "The proposed constitutive rules for agent communication languages can be a fundamental aspect of future electronic agents' communication and can provide a significant computational advantage.", "venue": "IJCAI", "year": 2003, "title": "Constitutive rules for agent communication languages"}
{"pid": "76388cd2-ee66-42b0-bd0a-467bc9f246e8", "context": "Government Agencies across the world are progressively making efforts to make their information available for public in an open format. The data ranges in variety from traffic, weather, geographical, tourist information, statistics, business, public sector budgeting, performance levels to all kinds of data about policies and inspections.", "key_idea": "Open Government Data is an emerging trend with around two hundred data portals globally, encouraging the development of applications over the data platform for public good. The data released in open formats under licenses that allow use, reuse and redistribution has immense potential to increase the quality of life for communities, businesses, and government.", "method": "The Open Data Initiative of the Indian Government - National Data Sharing and Accessibility Policy (NDSAP) was launched to allow access to Government owned shareable data in machine readable form. NIC has set up an open government data platform to provide single point access to datasets, with a cloud-based solution being developed to expedite this process.", "outcome": "The outcome of this approach is the availability of datasets for individuals to browse and utilize according to their need. The data can even be transformed into a variety of charts or maps, aiding citizen engagement and community participation. State governments and municipal corporations are embracing this trend in order to drive innovation in service delivery.", "future_impact": "The continued implementation of Open Data by governments, particularly at the state and city level, is expected to drive a new wave of innovation by providing platforms for community engagement and citizen participation. This could lead to more efficient and inclusive public services via the use of technology.", "venue": "IJCAI", "year": 2013, "title": "Open data for inclusive governance"}
{"pid": "c5803cf6-772b-4697-bec1-4d83bccd3b9d", "context": "The study is built on the previous works on package contraction and general belief changes which was a method of multiple belief change.", "key_idea": "The paper develops further on the theory of multiple belief changes and introduces an additional principle known as Limit Postulate for infinite belief changes.", "method": "The authors present two main representation theorems for general contractions, one based on partial meet models and the other on nice-ordered partition models.", "outcome": "The authors provided a foundation for investigating the connection between infinite nonmonotonic reasoning and multiple belief revision.", "future_impact": "The principles and theorems introduced in this paper could potentially aid in further investigations on the connection between infinite nonmonotonic reasoning and multiple belief revisions.", "venue": "IJCAI", "year": 1997, "title": "Representation theorems for multiple belief changes"}
{"pid": "724f01e2-333c-43ac-99d8-f4de1f6070c6", "context": "Prior work has explored enabling single agents to control their reasoning in dynamic environments through filtering strategies aimed at bypassing options not in alignment with their own goals.", "key_idea": "A generalization of the filtering strategy is proposed, called multi-agent filtering, where agents bypass options incompatible with known or presumed goals of other agents, and not just their own goals.", "method": "Different versions of multi-agent filtering varying from purely implicit to minimally explicit were studied. A series of experiments were conducted to evaluate the feasibility of using multi-agent filtering for coordination.", "outcome": "The initial results from the experiments show that multi-agent filtering can be used to achieve coordination without explicit negotiation.", "future_impact": "The application of multi-agent filtering can potentially simplify coordination tasks in multi-agent systems by omitting the need for explicit negotiation, which could lead to more efficient and autonomous systems.", "venue": "IJCAI", "year": 1995, "title": "Deriving multi-agent coordination through filtering strategies"}
{"pid": "ea30062c-52e0-4bec-ac04-b68d2c540f2b", "context": "Uncertainty and vagueness are common phenomena in real-life knowledge, and have been addressed by extended description logics that adapt classical description logics to deal with numerical probabilities or fuzzy truth degrees.", "key_idea": "The paper promotes the concept of 'probably', which is essentially a fuzzy qualification of probabilities, and offers the development of existing propositional logics of fuzzy probability into a complete description logic.", "method": "The authors have built a novel generic framework of fuzzy coalgebraic logic that includes standard crisp roles and crisp numerical probabilities with fuzzy roles and fuzzy probabilities.", "outcome": "Several versions of the newly developed logic under \u0141ukasiewicz semantics have been decided and proven by the paper.", "future_impact": "The generic framework of fuzzy coalgebraic logic developed in this study may be extended to logics that combine crisp components, including standard crisp roles and crisp numerical probabilities, with fuzzy roles and fuzzy probabilities.", "venue": "IJCAI", "year": 2011, "title": "Description logics and fuzzy probability"}
{"pid": "3d417ff5-e61e-4721-ac3b-9e2172803fe6", "context": "Automatic recognition of human activities is key for many intelligent systems with vision/perception. Most existing approaches require sophisticated feature extraction before classification can be performed.", "key_idea": "This paper presents a novel approach for human action recognition using only simple low-level visual features, specifically motion captured from direct frame differencing.", "method": "A codebook of key poses is created from the training data through unsupervised clustering. Videos of actions are then coded as sequences of super-frames, represented by key poses augmented with discriminative attributes. A weighted-sequence distance is proposed for comparing two super-frame sequences, which is further engineered as a kernel embedded in a SVM classifier for classification.", "outcome": "The proposed method outperformed the existing state-of-the-art on the widely-used KTH human activity dataset, demonstrating its effectiveness.", "future_impact": "The paper provides a flexible non-parametric sequential structure with a corresponding distance measure for human action representation and classification without requiring complex feature extraction, which could influence future research in human activity recognition.", "venue": "IJCAI", "year": 2009, "title": "Human activity encoding and recognition using low-level visual features"}
{"pid": "dd601cef-8a60-4b9a-8357-1ee832a072eb", "context": "Traditional Description Logics (DL) lack the handling of approximate concept definitions in a qualitative way.", "key_idea": "The authors propose an addition to traditional Description Logics that allows for the handling of approximate concept definitions, which is based on rough-set semantics and introduces two main concepts - lower and upper approximations.", "method": "The authors applied the proposed Rough Description Logics in a medical study of trials about sepsis patients to demonstrate its applicability.", "outcome": "The study showed that Rough DL-based reasoning can be executed in a realistic use case and that modeling vague knowledge helps answer important questions in the design of clinical trials.", "future_impact": "The integration of Rough Description Logics can improve decision-making in complex and practical applications, such as the design of clinical trials, where high-quality answers are needed despite vague data.", "venue": "IJCAI", "year": 2007, "title": "Description logics with approximate definitions precise modeling of vague concepts"}
{"pid": "83135f83-c6bd-470e-b568-431bc06b3939", "context": "The classical two-player game model has players sharing the same evaluation function. The technique of alpha-beta pruning improves efficiency in such games but it isn't clear if these results are applicable when the model is extended to more than two players or to different evaluation functions for each player.", "key_idea": "The authors propose two generalizations of the standard two-player game model: using different evaluation functions for the players, and extending the model to games with more than two players.", "method": "The authors generalize the minimax algorithm to the maxn algorithm, applied to vectors of N-tuples representing evaluations for each of the players. They also explored the possibility of alpha-beta pruning in this new model when making assumptions about upper and lower bounds on the components for each player.", "outcome": "Alpha-beta pruning is found to be effective only in the special case of two players with a common evaluation function. In the best-case scenario, the asymptotic branching factor is reduced to (1 + \u221a46-3)/2; however, in the average case, pruning does not reduce the asymptotic branching factor.", "future_impact": "This generalized game tree could serve as a baseline for evaluating the performance of multiplayer games beyond classic two-player scenarios or games where players have different evaluation functions.", "venue": "IJCAI", "year": 1989, "title": "Generalized game trees"}
{"pid": "93d0eb79-dcf4-4d78-b3ae-2159eabb183c", "context": "In Explanation-based learning, the theory of the domain is used in generalizing the explanation from a single example. However, problems arise when the domain theory is intractable.", "key_idea": "The authors suggest that approximations, which are well-founded simplifications based on real-world knowledge, can be used to handle the intractability problem in mathematical domains.", "method": "The authors demonstrate the efficacy of the approximation technique through an implementation in the chemistry domain.", "outcome": "The approximation technique was shown to effectively deal with intractability in mathematical domains, supporting the use of mixed quantitative and qualitative reasoning.", "future_impact": "The approximation method may strengthen the use of a mix of quantitative and qualitative reasoning over a purely quantitative or qualitative approach in explanation-based learning in mathematical domains.", "venue": "IJCAI", "year": 1987, "title": "Approximation in mathematical domains"}
{"pid": "5167c9cc-d6a1-4911-b093-97df39b802ab", "context": "Previous works in reinforcement learning such as Kearns and Singh [1998] and in repeated games like Monderer and Tennenholtz [1997] have informed the research landscape. However, the exploration vs. exploitation dilemma in stochastic games, which grows in complexity with respect to Markov decision processes, remains an open challenge.", "key_idea": "The paper proposes a new algorithm for near-optimal, polynomial-time learning in stochastic games. This algorithm integrates existing research on reinforcement learning and repeated games and specifically addresses the exploration vs. exploitation issue within the class of single-controller stochastic games.", "method": "The authors develop a new algorithm, although the paper does not provide specific details on the methodology employed in the abstract.", "outcome": "The abstract does not provide specific measurable outcomes related to the new algorithm.", "future_impact": "The algorithm proposed here is applicable to the broader category of stochastic games, not just the limited class of single-controller games initially considered, expanding its future applications.", "venue": "IJCAI", "year": 1999, "title": "A near-optimal poly-time algorithm for learning in a class of stochastic games"}
{"pid": "5f0c30d491e01165a98e19c1", "context": "Constraint optimization problems are typically solved using decision diagrams and a recently introduced branch-and-bound approach by Bergman et al., improves the ability to solve dynamic programs to optimality. There is however no generic library to solve combinatorial optimization problems with this approach.", "key_idea": "The paper presents 'ddo', a generic library designed to solve constraint optimization problems using decision diagrams and implementing the branch-and-bound approach.", "method": "The authors leveraged ddo to reproduce the results of Bergman et al. for several problems and tested its ability to exploit parallel computing without imposing any constraint on the user, beyond memory safety.", "outcome": "The library was successfully used to reproduce the results of Bergman et al., and demonstrated an ability to successfully exploit parallel computing.", "future_impact": "Ddo, being released as an open-source rust library, may serve as a resource for solving combinatorial optimization problems using the branch-and-bound approach with decision diagrams, which could potentially enhance the efficiency of solutions in multiple problem scenarios.", "venue": "IJCAI", "year": 2020, "title": "Ddo, a Generic and Efficient Framework for MDD-Based Optimization."}
{"pid": "6ebd88d1-2635-4f92-a59d-8c330033c60b", "context": "Cost-Based Abduction (CBA) is an AI model for reasoning under uncertainty, and constructing Genetic Regulatory Networks (GRN) using multiple data sources is a fundamental problem in computational biology.", "key_idea": "The paper presents a novel application method of using CBA to model GRNs and to explain genetic knock-out effects by integrating multiple biological data sources, namely Protein-DNA, Protein-Protein and gene knock-out data. The CBA annotates the graph created from this data by assigning a sign and a direction to each edge.", "method": "The authors model GRNs using CBA, and to do this, they use three different biological data sources: Protein-DNA, Protein-Protein, and gene knock-out data. They create an un-annotated graph using this data, and then CBA annotates it with a sign and direction for each edge.", "outcome": "While the biological results of the approach are promising, the paper primarily presents the mathematical modeling. The authors also explain CBA's advantages and its relation to Bayesian inference.", "future_impact": "The article implies potential for continued exploration of CBA in computational biology, particularly in modeling GRNs and explaining genetic knock-out effects, although no specific future implications were explicitly stated.", "venue": "IJCAI", "year": 2011, "title": "Explaining genetic knock-out effects using cost-based abduction"}
{"pid": "5ee3526a91e011cb3bff732d", "context": "As transaction activities in online payment systems grow exponentially, real-time regulation becomes a critical issue. A major challenge of AI-based regulation is how to utilize multimedia information or multimodal signals in Financial Technology (FinTech), and the need for interpretability of complex machine learning models.", "key_idea": "The authors propose a novel cross-modal and intra-modal attention network (CIAN) that integrates text and transaction information to improve the learning of text-trade joint embedding. They also introduce a CIAN-Explainer for interpreting how the attention mechanism interacts with the original features.", "method": "The authors use real datasets from the largest online payment system, WeChat Pay of Tencent, to conduct experiments to validate the practical application value of CIAN.", "outcome": "In experiments, the proposed method outperforms state-of-the-art methods, indicating its effectiveness for real-time financial regulation in online payment systems.", "future_impact": "The authors anticipate further study on the design and interpretable learning of AI models for FinTech, to enhance transparency and regulatory compliance.", "venue": "IJCAI", "year": 2020, "title": "Interpretable Multimodal Learning for Intelligent Regulation in Online  Payment Systems"}
{"pid": "dd47dafa-e11b-4ba6-a12c-5c4802bd87f5", "context": "Industrial applications often require embedded solutions for compacting hardware occupation, reducing energy consumption, and for achieving high speed performance. In industrial applications for banknote analysis and classification, an efficient system for correcting image skew is needed that can run on a fixed-point DSP with limited computational resources.", "key_idea": "The authors propose three innovative improvements to basic and general-purpose image processing techniques to correct image skew efficiently. These improvements include efficient labeling with an union-find approach for hole filling, a fast Hough transform implementation, and a very high-speed estimation of affine transformation for skew correction.", "method": "A computer vision system is developed to incorporate the three proposed improvements for skew correction in banknote analysis.", "outcome": "The system demonstrated accuracy and efficiency, including in the presence of severe skew. The computational time was reduced by about two orders of magnitude.", "future_impact": "The three innovative improvements proposed in this paper can be potentially helpful in other computer vision applications on embedded devices.", "venue": "CVPR", "year": 2011, "title": "A real-time embedded solution for skew correction in banknote analysis"}
{"pid": "50e07666-6e23-4a94-bd48-6a2ea197e284", "context": "New-view synthesis (NVS) using texture priors can yield high quality results but the standard formulation is in terms of large-clique Markov random fields (MRFs). Local optimization methods that are prone to local minima problems are practical for solving these problems.", "key_idea": "This paper replaces the large-clique energies with pairwise potentials by restricting the patch dictionary for each clique to image regions suitable for that clique, and employs a robust, truncated quadratic kernel to reject outliers. The paper introduces a fast method for enumerating color modes of the per-pixel unary potentials.", "method": "This study uses a global optimization method, such as tree-reweighted message passing, to solve the NVS problem with image-based priors, and compares the results of the technique with other rendering methods.", "outcome": "The paper establishes a fast, robust way to solve NVS problems. This optimisation enables the use of global methods and significantly speeds up computing the unary potentials, which becomes the new performance bottleneck.", "future_impact": "This paper sets groundwork for improving new-view synthesis techniques and may lead to more efficient and accurate rendering methods being developed in the future.", "venue": "CVPR", "year": 2007, "title": "Efficient new-view synthesis using pairwise dictionary priors"}
{"pid": "06b7c9eb-1321-4846-a42f-8f42eea489fd", "context": "Linear Discriminant Analysis (LDA) is a classical technique in machine learning, however, it does not consider ranking order of classes centroids on the projected subspace.", "key_idea": "The authors propose an extension of LDA, called Linear Ranking Analysis (LRA), by considering the ranking order of classes centroids on the projected subspace, with a focus on two specific criteria: minimizing classification error under Guassian distribution assumption for homogeneous classes and maximizing the sum of minimum distances of all neighboring-class pairs.", "method": "The authors use convex optimization for calculating the one-dimensional subspace. A greedy algorithm is used for the extension of these results to the multi-dimensional subspace. The performance of LRA is evaluated on tasks of ranking learning and zero-shot learning.", "outcome": "The LRA with both proposed criteria achieve competitive performance on the tasks of ranking learning and zero-shot learning. The maximum-margin criterion provides a significant improvement in the class separation problem compared with several representative extensions of LDA.", "future_impact": "The Linear Ranking Analysis resulting from this study could potentially improve performance on tasks of ranking learning and zero-shot learning and offer a new method for selection of a discriminative subspace.", "venue": "CVPR", "year": 2014, "title": "Linear Ranking Analysis"}
{"pid": "841a0df7-6e68-4531-a526-65bb46bb51b2", "context": "There is a need for an unsupervised method for mining activities in videos that not only identifies recurrent temporal activity patterns (or motifs) but also determines when they occur in unlabeled video sequences.", "key_idea": "The authors propose an unsupervised method that uses non-parametric Bayesian methods to find both the underlying number of motifs and the number of motif occurrences in each document.", "method": "The authors validate the model's robustness on synthetic data and then apply it to a large set of video data from state-of-the-art papers to extract and locate temporal motifs.", "outcome": "The proposed model effectively recovers temporal activities with high semantics for humans and strong temporal information. It is also used for prediction where it is shown to be as efficient as other approaches.", "future_impact": "The authors posit that their method can be directly applied to various kinds of time series where multiple activities occur simultaneously, providing implications for broader area of application.", "venue": "CVPR", "year": 2011, "title": "Extracting and locating temporal motifs in video scenes using a hierarchical non parametric Bayesian model"}
{"pid": "1a4626f4-0b5a-4c76-809b-c199cf25a310", "context": "The question of determining whether a video is running forwards or backwards using machine learning and computer vision techniques has not been adequately addressed.", "key_idea": "The authors are exploring three distinct methods to detect Time's Arrow, or the direction of time, in video sequences based on the asymmetry of motions in time.", "method": "The authors evaluated their approaches on a selection of YouTube video clips and on natively captured sequences with no temporally-dependent video compression.", "outcome": "The three methods demonstrated good video forwards/backwards classification results, although the specific quantitative results were not provided in the abstract.", "future_impact": "This paper might help in understanding what motions the models have learned that help discriminate forwards from backwards time, opening up further research in this area.", "venue": "CVPR", "year": 2014, "title": "Seeing the Arrow of Time"}
{"pid": "91369823-c975-480c-b610-6f133b921d04", "context": "Most of the keystroke dynamics research focuses on the typing patterns found in fixed texts. Digraphs and trigraphs have been found to be discriminative features in this regard. With increasing interest in free-text keystroke dynamics, where users type any desired text, it is unclear whether digraphs and trigraphs maintain their discriminative value as opposed to fixed text.", "key_idea": "This paper investigates the claim that word-specific digraphs/trigraphs are needed for free-text keystroke dynamics as generic digraphs and trigraphs, computed without context, lose their discriminative value.", "method": "The authors examine the discriminative value of digraphs/trigraphs in the context of free-text keystroke dynamics. They also investigate how the dynamics of typing certain words change based on whether they form part of a larger word.", "outcome": "The research finds that generic digraphs/trigraphs, if computed without context, aren't discriminative in free-text keystroke dynamics and instead, word-specific digraphs/trigraphs are necessary. Additionally, the typing dynamics for some words vary depending on whether they're part of a larger word.", "future_impact": "This first-of-its-kind investigation into word-specific keystroke dynamics can serve as valuable guidance for researchers working on identifying effective features for free-text keystroke dynamics.", "venue": "CVPR", "year": 2007, "title": "Are Digraphs Good for Free-Text Keystroke Dynamics?"}
{"pid": "b275a780-b418-4241-9d6c-34d444af5b97", "context": "Traditional fingerprint authentication devices can have their performance degraded by factors such as the condition of the finger surface or the use of artificial gummy fingers.", "key_idea": "The authors developed a new fingerprint authentication device that uses optical characteristics of a finger's interior to form a fingerprint image and tell fake gummy fingers from real ones.", "method": "The authors use scattered transmission light to capture images of the internal structures of a finger. The detailed processes and algorithms used by this device are discussed in the paper.", "outcome": "The proposed device can capture fingerprint images regardless of the condition of the finger surface or the operation environment and can distinguish between real and synthetic fingers.", "future_impact": "The proposed device has the potential to achieve higher authentication performance by combining multiple characteristics within the finger, opening up new possibilities for biometric authentication applications.", "venue": "CVPR", "year": 2006, "title": "Fingerprint Authentication Device Based on Optical Characteristics Inside a Finger"}
{"pid": "5cea6af5-9e13-4c02-8763-7726e6102306", "context": "Existing methods for matching sets of 3D lines depend on whether line lengths are finite or infinite, leading to three cases: finite to finite, finite to infinite, and infinite to infinite. The third case has been treated by Faugeras and Hebert method, but it's not convergent and invariant to coordinate transforms.", "key_idea": "The authors present new convergent iterative algorithms for the first two cases and propose an alternative convergent method for the third case of matching sets of 3D lines.", "method": "The authors create and test convergent iterative algorithms to handle all three cases of matching sets of 3D lines.", "outcome": "The proposed iterative algorithms successfully solve the first two cases, while the solution to the third case, while convergent, is not invariant with respect to coordinate transforms.", "future_impact": "The authors suggest alternatives for representing infinite lines, which may lead to an invariant solution for the third case of matching 3D lines, potentially improving the direction of future research in this area.", "venue": "CVPR", "year": 2001, "title": "An open problem in matching sets of 3D lines"}
{"pid": "628464625aee126c0faca44a", "context": "Lossy image compression strategies are necessary for efficient storage and transmission of data, particularly for training with larger datasets in environments with limited storage. However, even mild compression can significantly degrade the performance of deep Convolution Neural Network (CNN) architectures, as the compressed imagery, though visually indistinguishable, may alter the critical information needed by these networks.", "key_idea": "This study investigates the effects of lossy JPEG compression with varying levels of intensity on the performance of several object detection architectures (Cascade-RCNN, FSAF and Deformable DETR) while applied to infrared band (thermal) imagery.", "method": "The authors apply six discrete levels of JPEG compression to infrared imagery and assess the resulting performance of three object detection architectures in relation to the varying sizes of objects in the dataset. The effect of retraining the models on the lossy compressed imagery is also evaluated.", "outcome": "The impact of lossy compression is more profound at higher compression levels across all three architectures. Retraining on lossy compressed imagery significantly improves performance, with an average increase of approximately 76% at the highest compression level. Smaller object areas were found to be more sensitive to compression than larger ones. Cascade R-CNN achieved the highest mean Average Precision (mAP) across most object area categories.", "future_impact": "The findings can influence the design and training strategies of CNN architectures for object detection, particularly when the data used for training or inference have undergone lossy compression. It could guide practitioners in balancing the use of lossy compression for efficiency while preserving performance.", "venue": "CVPR", "year": 2022, "title": "Lost in Compression: the Impact of Lossy Image Compression on Variable Size Object Detection within Infrared Imagery"}
{"pid": "5ea9504391e0118eb1e1a0a1", "context": "Recent work suggests that self-attention can serve as a basic building block for image recognition models.", "key_idea": "This study assesses the effectiveness of different variations of self-attention for image recognition, namely pairwise self-attention, which generalizes standard dot-product attention, and patchwise self-attention, which is more powerful than convolution.", "method": "The effectiveness of pairwise and patchwise self-attention is evaluated against their convolutional counterparts in the context of image recognition. Experiments probing the robustness of learned representations were also conducted.", "outcome": "Pairwise self-attention networks match or outperform their convolutional counterparts, and the patchwise models substantially outperform the convolutional baselines. Test on robustness of learned representations concludes that self-attention networks may have significant benefits in terms of robustness and generalization.", "future_impact": "The results suggest that self-attention networks could be harnessed for their robustness and generalization capabilities in image recognition scenarios, presenting a promising avenue for future research.", "venue": "CVPR", "year": 2020, "title": "Exploring Self-attention for Image Recognition"}
{"pid": "5be4e9c4-f36e-42ee-b73f-a11cd2003ff9", "context": "Appearance-based human action models are typically built using methods like k-means algorithm, however, these systems face limitations due to the fixed number of clusters and lack of correlation with groups of actions.", "key_idea": "This paper presents an approach for learning a compact and discriminative appearance-based human action model that uses a bag of spatiotemporal features (video-words) obtained through the maximization of mutual information (MMI) to automatically optimize the number of video-word clusters.", "method": "MMI is used to cluster video-words, which are highly correlated to groups of actions. To capture the structure of the clusters, the correlation of the compact video-word clusters is explored using a modified correlogram. The approach is tested on the KTH dataset and the IXMAS multiview dataset.", "outcome": "The proposed method demonstrated impressive results on both the KTH and the IXMAS multiview dataset.", "future_impact": "The proposed model could influence the way human action models are built, moving towards automatic discovery of cluster numbers and improved data representation. Furthermore, this is the first time the bag of video-words approach has been used on a multiview dataset, opening a potential new area of research.", "venue": "CVPR", "year": 2008, "title": "Learning human actions via information maximization"}
{"pid": "84948e17-ff5b-4635-b46f-00a599f27416", "context": "Non-central catadioptric cameras, consisting of perspective cameras and curved mirrors, do not have a single viewpoint, complicating their use in 3D reconstruction tasks.", "key_idea": "The authors present a technique to auto-calibrate non-central catadioptric cameras and compute a 3D metric reconstruction automatically from two uncalibrated non-central catadioptric images.", "method": "The authors present a method for solving the correspondence problem and demonstrate this on spherical, parabolic, and hyperbolic mirrors.", "outcome": "The authors observed that reconstruction and auto-calibration with non-central catadioptric cameras is as straightforward as with central catadioptric cameras, given that the correspondence problem can be solved with a suitable approximate central model.", "future_impact": "The technique potentially provides a way to autoclibrate catadioptric cameras even with genuinely non-central mirrors such as spheres (simple model, low blur, easy to manufacture) or uniform resolution mirrors (optimized projection).", "venue": "CVPR", "year": 2004, "title": "Autocalibration & 3D reconstruction with non-central catadioptric cameras"}
{"pid": "62c2a8695aee126c0fce8aca", "context": "Current deep learning methods for 3D object detection require a large amount of 3D bounding box annotations for training, which is time-consuming and costly. Sparsely annotated object detection is particularly challenging as the instances with missing annotations are generally treated as the background during training.", "key_idea": "The paper introduces a sparsely-supervised 3D object detection method, known as SS3D, which aims to negate the impact of missing annotations. SS3D includes a missing-annotated instance mining module with stringent filtering strategies to pinpoint positive instances.", "method": "The authors created a reliable background mining module and a point cloud filling data augmentation strategy within SS3D to generate confident data for iterative learning with reliable supervision. The feasibility and efficiency of the proposed SS3D were tested on the KITTI dataset.", "outcome": "SS3D was shown to achieve comparable performance to fully-supervised methods with only 20% of the required annotations across different 3D detectors. Furthermore, when compared to the current best semi-supervised and weakly-supervised 3D objection detection methods on the KITTI dataset, SS3D showed significant improvement.", "future_impact": "Since SS3D is a general framework, it has the potential to be used to train any modern 3D object detector, thus reducing the reliance on extensive annotations and greatly improving efficiency.", "venue": "CVPR", "year": 2022, "title": "SS3D: Sparsely-Supervised 3D Object Detection from Point Cloud"}
{"pid": "577df195-7302-42a6-ba2a-69c9d65a92d2", "context": "Stereo vision-based applications are common in diverse domains, but the use of stereo confidence cues has not been thoroughly explored. Mostly, a threshold-based approach is used for further processing of confidence values, which doesn't make full use of the available information.", "key_idea": "The paper proposes the use of all available stereo confidence cues, propagating them with measured disparities in a Bayesian manner. Moreover, it introduces an extension to the Stixel World, a 3D representation model, to utilize stereo confidence cues during a maximum a posteriori estimation process.", "method": "The paper uses disparity statistics from labeled video data to map confidence values to disparity outlier probability rates. The revised Stixel World model and the use of stereo confidence cues are tested on real-world traffic data.", "outcome": "The proposed approach allows significant reduction in the number of false object detections by a factor of six, while maintaining nearly constant detection rates.", "future_impact": "This work provides a more effective use of stereo confidence cues, which could impact various applications based on stereo vision and influence the methods of processing these cues in the future.", "venue": "CVPR", "year": 2013, "title": "Exploiting the Power of Stereo Confidences"}
{"pid": "f6e80063-74da-4fd4-bd47-271e0b7aae2e", "context": "The difficulty in collecting high quality, large scale fine-grained computer vision datasets is a significant challenge, especially in specific domains like bird or airplane identification. Popular datasets like CUB-200-2011 and ImageNet have been found to contain class label error rates of at least 4% which can affect the performance of learning algorithms.", "key_idea": "The paper proposes using citizen scientists, individuals who are passionate and knowledgeable about specific domains, for the creation of high-quality, large-scale datasets. In this context, they introduce NABirds, a new dataset of North American birds with detailed annotations.", "method": "The study uses citizen scientists and domain experts to collect and annotate data for NABirds and compares their accuracy to workers from Amazon Mechanical Turk. They also measure the effect of training data corruption in learning algorithms.", "outcome": "Citizen scientists are demonstrated to be significantly more accurate than Mechanical Turk workers at zero cost. Despite some level of training data corruption, learning algorithms still exhibited robustness, with only an acceptably small increase in test error as long as the training set is sufficiently large. Furthermore, using NABirds, a high-quality, expert-curated test set, is shown to be crucial for accurately measuring the performance of fine-grained computer vision systems.", "future_impact": "The methodologies and tools introduced for the collection of fine-grained datasets by citizen scientists can be beneficial for similar tasks in other specific domains. Moreover, NABirds has been used to train a publicly available bird recognition service, demonstrating the practical relevance and potential impact of such high-quality datasets.", "venue": "CVPR", "year": 2015, "title": "Building a bird recognition app and large scale dataset with citizen scientists: The fine print in fine-grained dataset collection"}
{"pid": "5eccb534e06a4c1b26a837a3", "context": "Recent studies in single image super resolution (SISR) have benefited from generative adversarial networks (GANs) to recover photo-realistic images. However, undesired structural distortions often occur in the recovered images.", "key_idea": "A structure-preserving super resolution method is proposed, which leverages gradient maps of images to guide the recovery process in order to mitigate structural distortions, while maintaining the merits of GAN-based methods in generating perceptually-pleasing details.", "method": "The recovery process is guided through two main methods: restoring high-resolution gradient maps via a gradient branch to provide structure priors for the SR process, and establishing a gradient loss that imposes a second-order restriction on the super-resolved images.", "outcome": "Experimental results show that the proposed method achieves the best PI and LPIPS performance and comparable PSNR and SSIM to state-of-the-art perceptual-driven SR methods.", "future_impact": "The proposed method is model-agnostic and can potentially be applied to off-the-shelf SR networks, which could broaden the domains of its application.", "venue": "CVPR", "year": 2020, "title": "Structure-Preserving Super Resolution With Gradient Guidance"}
{"pid": "76401f4b-ab7b-45de-872c-50f542b379c9", "context": "Current scene categorization models do not adequately consider the interconnected components of a scene: the scene category, the context-specific appearance of objects, and their layout.", "key_idea": "The authors propose a method to learn scene structures that can encode the scene category, the context-specific appearance of objects, and their layout.", "method": "The authors perform experimental evaluations to compare their learned scene structures to the state-of-the-art method of Deformable Part Models in object detection within a scene, and also test their model for scene categorization.", "outcome": "The authors' scene structures outperform the state-of-the-art Deformable Part Models in object detection, and display promising results in scene categorization.", "future_impact": "The scene structures can also generate features that could be useful for future scene categorization tasks and may provide an improved level of scene understanding, suitable for deep visual inferences.", "venue": "CVPR", "year": 2014, "title": "Incorporating Scene Context and Object Layout into Appearance Modeling"}
{"pid": "537ea884-f38a-4c50-b4ab-d21998c05a58", "context": "The \u201cvisual echo\u201d problem is prevalent in full-duplex projector-camera systems and existing techniques do not account for full color images or the variety of the surface reflectance or the photometric response of the projector or camera.", "key_idea": "The authors developed a comprehensive set of techniques including a calibration procedure that records the geometric and photometric transfer between the projector and camera in a look-up table to address the \u201cvisual echo\u201d problem in a full-duplex projector-camera system.", "method": "The predicted camera view of the projected image is compared against the captured camera image to find echo pixels. Only non-echo pixels are used for display.", "outcome": "The proposed techniques were successful in handling full color images, being robust to geometric registration errors and quantization effect, especially effective for high-frequency contents such as texts and hand drawings.", "future_impact": "The effectiveness of these comprehensive techniques demonstrated in various real images in a full-duplex projector-camera system holds promise for overcoming the 'visual echo' issue in such systems.", "venue": "CVPR", "year": 2006, "title": "Robust and Accurate Visual Echo Cancelation in a Full-Duplex Projector-Camera System"}
{"pid": "fb29346a-5814-49ac-897b-8b640dbfedd2", "context": "Current hand shape classification systems are reliant on color or temporal information and are sensitive to lighting conditions, which can result in a need for hand registration steps.", "key_idea": "This paper introduces a novel algorithm that uses randomized classification forests (RDF) for hand shape classification using depth sensors, independent of lighting conditions and without the need for a hand registration step.", "method": "The authors implemented the method using a depth sensor to acquire images and classified hand shapes using RDF. The performance was tested on an American Sign Language (ASL) dataset consisting of 65k images and a subset of the ChaLearn Gesture Dataset with static and dynamic hand shapes.", "outcome": "The proposed method achieved a success rate of 97.8% on the ASL dataset, a precision rate of 87.88% when there were multiple gestures, and 94.35% when there was a single gesture in the sample. Classification success rate was 94.74% for nine specific gestures and lower for the leave-one-subject-out scheme (74.3%), and when trained on an external dataset of the same gestures (67.14%).", "future_impact": "The novel approach can provide a significant improvement in hand shape classification, with potential for further speed improvement when implemented on a GPU.", "venue": "CVPR", "year": 2012, "title": "Randomized decision forests for static and dynamic hand shape classification"}
{"pid": "8c80d541-3043-4f87-b7c7-524f15a41f69", "context": "Cascaded classifiers have become a popular choice for many classification problems. However, the setting of the thresholding parameters of all the node classifiers within the cascade is not optimally addressed.", "key_idea": "Authors present two optimization algorithms that use a high-level abstraction model to represent each node classifier in a cascade, aiming to jointly optimize the setting of the thresholding parameters of all the node classifiers.", "method": "Both algorithms were applied to optimize the Viola and Jones face detector, a popular cascaded classifier.", "outcome": "The application of the proposed algorithms to the Viola and Jones face detector significantly improved its performance.", "future_impact": "The proposed algorithms could serve as a useful post-processing process for the general design of cascaded classifiers.", "venue": "CVPR", "year": 2005, "title": "Optimization design of cascaded classifiers"}
{"pid": "8998ac40-0c68-4213-99a2-6b7a159c7580", "context": "Previous approaches to the 3D skeletal representation of a shape lack a complete characterization based on the structure of its medial axis.", "key_idea": "The authors propose a novel hypergraph skeletal representation for 3D shape based on a formal derivation of the generic structure of its medial axis, defining five types of points and organizing them into sheets, curves, and points.", "method": "Each skeletal point is classified by its order of contact, allowing the authors to derive a pointwise reconstruction formula to reconstruct a surface from this medial axis hypergraph.", "outcome": "The resulting hypergraph representation consists of nodes, links between pairs of nodes, and hyperlinks between groups of links, completely characterizing 3D shape.", "future_impact": "This work lays the theoretical foundation for potential future usage in recognition, morphing, design, and manipulation of shapes.", "venue": "CVPR", "year": 2000, "title": "A formal classification of 3D medial axis points and their local geometry"}
{"pid": "6a4406c9-7817-49b1-bca9-ffc3cac68177", "context": "Feature definition and selection are crucial for visual analysis of motion, but harnessing static and dynamic information from different spatiotemporal resolutions remains a challenge.", "key_idea": "The paper introduces a method of computing spatiotemporal local binary patterns at multiple resolutions to describe dynamic events - capturing both static and dynamic information. It also uses AdaBoost algorithm for learning the principal appearance and motion from spatiotemporal descriptors.", "method": "The authors implement their proposed technique on visual analysis tasks, including facial expression recognition and visual speech recognition, taking information derived from three orthogonal planes into consideration.", "outcome": "The experiments demonstrate the effectiveness of the proposed methodology, but no specific numerical results or performances are provided.", "future_impact": "The method provides important location and feature type information, suggesting its utility for future research and advancements in visual analysis tasks, including facial expression and visual speech recognition.", "venue": "CVPR", "year": 2008, "title": "Principal appearance and motion from boosted spatiotemporal descriptors"}
{"pid": "eede6678-8fb4-41bb-abc1-7cc1c3a88f59", "context": "The previous GPU-based stereo implementations lacked advanced features and resulted in slower performance, occupying the main processor for high-level interpretation of the stereo results.", "key_idea": "The paper presents an advanced real-time correlation-based stereo algorithm that runs completely on the graphics processing unit (GPU) and incorporates advanced features like adaptive windows and cross-checking.", "method": "The authors implemented their proposed algorithm on an ATI Radeon 9800 graphics card and measured its performance by considering the number of disparity evaluations per second, including overhead to download images and read-back the disparity map.", "outcome": "The implementation of the proposed algorithm on an ATI Radeon 9800 graphics card achieved over 289 million disparity evaluations per second, which is several times faster than commercially available CPU-based implementations.", "future_impact": "The proposed algorithm could free up the main processor for other tasks including high-level interpretation of stereo results, potentially improving the efficiency of related applications.", "venue": "CVPR", "year": 2004, "title": "Improved Real-Time Stereo on Commodity Graphics Hardware"}
{"pid": "62451c2b5aee126c0f47aa2e", "context": "Learning how humans manipulate objects requires understanding object affordances and human interactions based on these affordances. However, current databases lack comprehensive awareness of these knowledge bases.", "key_idea": "The authors propose the creation of a multi-modal and rich-annotated knowledge repository called OakInk, which is designed to facilitate the visual and cognitive understanding of hand-object interactions.", "method": "The authors gathered data on 1,800 common household objects, recording human interactions with 100 selected objects and their virtual counterparts using a novel method called Tink. The database called OakInk is benchmarked on pose estimation and grasp generation tasks.", "outcome": "The result is OakInk, a repository containing 50,000 distinct affordance-aware and intent-oriented hand-object interactions. The database has been used for pose estimation and grasp generation tasks, as well as for intent-based interaction generation and handover generation applications.", "future_impact": "OakInk, with its rich annotation and large scale, can be used in a number of practical applications including intent-based interaction generation and handover generation to further the understanding of complex hand-object interactions.", "venue": "CVPR", "year": 2022, "title": "OakInk: A Large-scale Knowledge Repository for Understanding Hand-Object Interaction"}
{"pid": "b1bc83f9-2416-4dbc-be85-068b4a177181", "context": "Depth-map merging is a common technique in multi-view stereo (MVS) reconstruction. However, guaranteeing accuracy with existing algorithms usually requires either sub-pixel level stereo matching precision or continuous depth-map estimation, making the merging of inaccurate depth-maps a challenge.", "key_idea": "The paper introduces a bundle optimization method for robust and accurate depth-map merging, with two stages of bundle optimization and the ability to be easily parallelizable on multi-core processors.", "method": "DAISY feature is used to generate depth-maps, which are optimised through two stages of bundle optimization -- optimising the track of connected stereo matches to generate initial 3D points in the first stage and optimizing the position and normals of these 3D points in the second. Then, a high quality point cloud is meshed as geometric models.", "outcome": "The proposed method demonstrates high efficiency among non-GPU algorithms and maintains high accuracy as per Middlebury evaluation. It is also shown to be effective on various real-world, high-resolution, self-calibrated datasets of varying complexity.", "future_impact": "The approach could improve accuracy in depth-map merging for multi-view stereo reconstructions, even in cases involving inaccurate depth maps or complex real-world applications.", "venue": "CVPR", "year": 2010, "title": "Bundled depth-map merging for multi-view stereo"}
{"pid": "629ec1f95aee126c0fb705a7", "context": "Face manipulation techniques are developing rapidly, causing widespread concern. Convolutional neural networks, while achieving acceptable performance, suffer from overfitting. A popular method for addressing this is to introduce erasing-based augmentations, which implicitly induce more consistent representations of differently augmented images. However, due to the lack of explicit regularization, the consistency between different representations is not satisfactory.", "key_idea": "A simple yet effective framework termed COnsistent REpresentation Learning (CORE) is proposed. It explicitly regularizes the consistency of different representations by capturing different representations with different augmentations and then regularizes the cosine distance of those representations to enhance their consistency.", "method": "The effectiveness of CORE is tested through extensive in-dataset and cross-dataset experiments.", "outcome": "The experimental results show that CORE performs favorably against state-of-the-art face forgery detection methods.", "future_impact": "The proposed framework can advance the field of face forgery detection by addressing the overfitting issue through consistent representation learning.", "venue": "CVPR", "year": 2022, "title": "CORE: Consistent Representation Learning for Face Forgery Detection"}
{"pid": "59642274-beef-48a4-a4dc-1c5557a7528b", "context": "Earlier approaches to video event detection and localization may be less effective due to scale and intra-class variations of events, as well as false and missed local detections.", "key_idea": "The authors propose a novel algorithm that treats video event detection and localization as the problem of optimal path discovery in spatio-temporal video space.", "method": "The authors test their algorithm by applying it to different types of event detection tasks, such as abnormal event detection and walking pedestrian detection, on various realistic video datasets.", "outcome": "The proposed algorithm demonstrates it can robustly detect and accurately locate events in videos regardless of scale and intra-class variations, also it is robust to false and missed local detections.", "future_impact": "This work could pave the way for improved video event detection algorithms that handle the scale and intra-class variations of the event and are robust to false and missed detections.", "venue": "CVPR", "year": 2011, "title": "Optimal spatio-temporal path discovery for video event detection"}
{"pid": "624278fa5aee126c0fd7931d", "context": "Human-Object Interaction (HOI) detection can be bifurcated into two main problems: human-object association and interaction understanding. Conventional query-driven HOI detectors have certain disadvantages, such as complex post-matching in two-branch methods or the overlooking of feature distinction in task-specific cases in single-branch methods. There's also the challenge of the long-tailed distribution and zero-shot discovery in interaction understanding.", "key_idea": "The authors propose a Guided-Embedding Network (GEN) for a more streamlined two-branch pipeline that obviates the need for post-matching, using instance decoding and a position Guided Embedding for pairing. Additionally, to enhance interaction understanding, the study introduces a Visual-Linguistic Knowledge Transfer (VLKT) training approach by leveraging a pre-trained model, CLIP.", "method": "The researchers implement the GEN for human and object detection and the VLKT for understanding interactions, drawing on the power of the pre-trained model CLIP to initialize the classifier and adopt a mimic loss to minimize the visual feature distance between GEN and CLIP.", "outcome": "The proposed GEN-VLKT model significantly improved performance on multiple datasets, improving the mAP score by +5.05 on the HICO-Det dataset, marking a new state of the art.", "future_impact": "As the proposed GEN-VLKT outperformed current methods, it has potential to significantly influence future research in Human-Object Interaction (HOI) detection. It also shows promise for helping to improve understanding of complex interactions in visual tasks.", "venue": "CVPR", "year": 2022, "title": "GEN-VLKT: Simplify Association and Enhance Interaction Understanding for HOI Detection"}
{"pid": "aeaa9790-3337-4655-9a2d-e7612955bcda", "context": "Vision algorithm sequences involve operations like edge finding, edge linking, and gap filling, however, determining the performance of these vision algorithms can be challenging due to variable input data.", "key_idea": "The authors propose using random perturbation models, starting with an appropriate noise model for the input data, as a way to derive models for the output data at each stage of a vision algorithm sequence for performance analysis.", "method": "The authors apply random perturbation models to a sequence of vision algorithms involving edge finding, edge linking, and gap filling. Parameters of these models are related to measures of error such as the probability of misdetection of feature units, false alarms, and incorrect grouping.", "outcome": "The parameters of the random perturbation models serve as indicators of performance, and they propose these models could be used for the automation of the selection of various free parameters of the vision algorithms.", "future_impact": "The application of random perturbation models could automate the selection of various parameters of algorithms, potentially facilitating more accurate and efficient performance of vision algorithms.", "venue": "CVPR", "year": 1992, "title": "Random perturbation models and performance characterization in computer vision"}
{"pid": "2143da09-c49b-40e3-8a28-dbc6b044f208", "context": "So far, stability of image features across video frames in an image sequence has lacked effective assessment methodologies.", "key_idea": "A novel method is developed for assessing image-feature stability which utilizes the discrete wavelet transform applied to the image features throughout a sequence of video frames.", "method": "The method involves recovering image feature vectors for each video frame and tracking them through a series of consecutive frames. It applies the discrete wavelet transform to the constructed time series from pairwise Euclidean distances for each of the studied image features and uses the wavelet transform coefficients for stability assessment.", "outcome": "Stable features are recovered by clustering together those time series which exhibit largely constant low-pass wavelet coefficients. The analysis of stability for Harris corners, Maximally Stable Extremal Regions, and Scale Invariant Feature Transform regions extracted from real-world video sequences demonstrated promising results.", "future_impact": "Potential applications of the proposed method are anticipated in the domains of indexing, retrieval, and compression of stable image feature vectors.", "venue": "CVPR", "year": 2006, "title": "A Wavelet-Based Approach to Image Feature Stability Assessment"}
{"pid": "70deb9d6-fd00-433b-804b-ef0bebf1e1a6", "context": "Binary split grammar is extensively used to parse facade, characterizing repetitive patterns with different layouts. However, it might struggle with efficiency and robustness.", "key_idea": "This study suggests that binary split grammar parsing can be viewed as approximating a facade by rank-one matrices, and proposes an efficient algorithm to decompose matrices in such a way. Further, the authors develop a new block-wise partition method for parsing a more general facade.", "method": "The authors validate their approach through extensive experiments on facade data sets, comparing their method against state-of-the-art techniques and benchmarks.", "outcome": "The experiments show that the proposed method outperforms contemporary techniques and benchmarks in both robustness and efficiency.", "future_impact": "The proposed algorithms could lead to more efficient and robust methods for parsing a more diverse range of fa\u00e7ade structures.", "venue": "CVPR", "year": 2012, "title": "Parsing fa\u00e7ade with rank-one approximation"}
{"pid": "62620f1c5aee126c0f686c34", "context": "Continual learning algorithms aim to mitigate catastrophic forgetting but are often complicated and possess long training times which limit their viability. The real-world issue of noisy labels haven't been extensively addressed within continual learning studies.", "key_idea": "The authors propose a simple purification technique to cleanse the online data stream which is then used in a semi-supervised fine-tuning of the model for continual learning.", "method": "The proposed purification technique and semi-supervised fine-tuning is tested on three benchmark datasets; MNIST, CIFAR10 and CIFAR100.", "outcome": "The proposed approach shows its effectiveness by delivering a 24.8% performance gain for CIFAR10 with 20% noise, outperforming previous methods.", "future_impact": "The presented new purification technique and semi-supervised fine-tuning approach for continual learning under noisy labels can help in designing more accurate and cost-effective continual learning solutions.", "venue": "CVPR", "year": 2022, "title": "CNLL: A Semi-supervised Approach For Continual Noisy Label Learning"}
{"pid": "36ce6cd9-49cd-41ca-a9b8-3ff566c36752", "context": "The subspace properties and the recovery of articulated motion are vital aspects to understanding and replicating complex motion, but prior research does not fully address how the global motion subspace of an articulated object is affected by intersecting rigid motion subspaces of the parts.", "key_idea": "The authors propose that the global motion subspace of an articulated object is a combination of numerous intersecting rigid motion subspaces of the parts, resulting in rank loss depending on whether a link of two parts is a joint or an axis. They suggest that this relation can be used for the recovery of articulated shape and motion.", "method": "The authors detail the rank constraint of the global motion subspace of an articulated object and propose a novel but simple approach using subspace clustering to recover articulated shape and motion from a single-view image sequence.", "outcome": "The paper delivers a methodology and algorithm that can recover the image motion of a linked joint or axis within an articulated object.", "future_impact": "The findings present a novel approach to articulated motion recovery, contributing towards further advancements in the understanding and modeling of complex movements, which could be important for future research in areas like robotics or animation.", "venue": "CVPR", "year": 2005, "title": "A factorization-based approach to articulated motion recovery"}
{"pid": "cb47900f-78e9-421b-bbe5-8468aa1ab394", "context": "Sequential least-squares application for scene and motion reconstruction from image features has been established, but current algorithms require the same features to be visible throughout the sequence. Moreover, handling new features could lead to degradation of results.", "key_idea": "The authors propose a new formulation of sequential least-squares that could handle new features without affecting the quality of the results and illustrates how to adjust the system information matrix when scene/camera parameters are removed from the reconstruction.", "method": "The sparseness of the information matrix was evaluated to understand the efficiency of the proposed recursive solution to the reconstruction problem.", "outcome": "The authors demonstrated an efficient way to adjust the system information matrix when scene/camera parameters are removed from the reconstruction. This method allowed them to achieve a more efficient recursive solution to the reconstruction problem.", "future_impact": "This new formulation could be pivotal for real-time control applications and interactive vision applications.", "venue": "CVPR", "year": 2000, "title": "A batch/recursive algorithm for 3D scene reconstruction"}
{"pid": "62c2a6805aee126c0fcd9035", "context": "Previous LiDAR scene flow estimation methods, such as recurrent neural networks, often encounter issues with structure distortion in challenging situations, including sparse reflection and motion occlusions.", "key_idea": "The authors propose a novel weakly supervised optimization method based on a recurrent neural network. This network utilizes direct rigidity constraints to maintain the geometric structure of the warped source scene during iterative alignment.", "method": "An error awarded optimization strategy is implemented to update the LiDAR scene flow by minimizing point measurement error rather than cost volume reconstruction. The network is then trained on two autonomous driving datasets.", "outcome": "Trained on two autonomous driving datasets, the proposed network outperforms recent state-of-the-art networks on lidarKITTI by a large margin.", "future_impact": "The authors have made the code and models available, which could facilitate further research and improvements in the field of LiDAR scene flow estimation.", "venue": "CVPR", "year": 2022, "title": "Exploiting Rigidity Constraints for LiDAR Scene Flow Estimation."}
{"pid": "5ea16b3491e011fa08b8fa90", "context": "Text Spotting in the wild, which consists of detecting and recognizing text appearing in images, is a challenging problem due to uneven backgrounds, shading, occlusions, perspective distortions, etc. Only a few approaches exploit the relation between text and its surrounding environment to better recognize text in the scene.", "key_idea": "The authors propose a visual context dataset for Text Spotting in the wild, extending the publicly available dataset COCO-text with information about the scene such as objects and places appearing in the image. This extended dataset is designed to include semantic relations between texts and scene in Text Spotting systems.", "method": "For each text in an image, three kinds of context information are extracted: objects in the scene, image location label and a textual image description (caption). State-of-the-art out-of-the-box available tools are used to extract this additional information.", "outcome": "The extracted information is represented in textual form and can be used to leverage text similarity or semantic relation methods into Text Spotting systems, either as a post-processing or in an end-to-end training strategy.", "future_impact": "This visually enriched dataset can inspire researchers to include the semantic relation between texts and their surrounding scene in their Text Spotting systems. It offers a common framework for such approaches due to its availability for public use.", "venue": "CVPR", "year": 2020, "title": "Textual Visual Semantic Dataset for Text Spotting"}
{"pid": "61a596655244ab9dcbdfe5fc", "context": "Generic Event Boundary Detection (GEBD) is a newly suggested video understanding task with the goal of finding deeper semantic boundaries of events. The existing solvers for GEBD are simple extensions of related video understanding tasks and disregard the distinctive characteristics of GEBD.", "key_idea": "The authors propose a novel framework for unsupervised/supervised GEBD that leverages the Temporal Self-similarity Matrix (TSM) for video representation. To detect boundaries, the Recursive TSM Parsing (RTP) algorithm is used, in combination with the Boundary Contrastive (BoCo) loss for training the encoder to produce more informative TSMs.", "method": "The authors use their novel method to detect boundaries in videos within both unsupervised and supervised settings.", "outcome": "The proposed framework achieves state-of-the-art performance in the GEBD benchmark, surpassing previous models by a large margin. The unsupervised method in particular outperforms the previous state-of-the-art 'supervised' model, highlighting its efficacy.", "future_impact": "GEBD has various potential applications, including interpretable and semantically valid video parsing.", "venue": "CVPR", "year": 2022, "title": "UBoCo: Unsupervised Boundary Contrastive Learning for Generic Event Boundary Detection"}
{"pid": "625e1a3c5aee126c0fecaccf", "context": "Most existing work on continual learning in clinical settings focuses on convolutional architectures and image classification. However, radiologists prefer working with models that outline specific regions of interest, such as segmentation models.", "key_idea": "The authors propose using transformer mechanisms for semantic segmentation in sequential learning scenarios, with the hypothesis that the self-attention mechanism of transformers might mitigate catastrophic forgetting in medical image segmentation.", "method": "The authors evaluate different recently proposed transformer mechanisms for semantic segmentation in a continual learning setting. The evaluation is carried out on hippocampus segmentation, comparing these mechanisms with purely convolutional architectures.", "outcome": "Results show that transformer mechanisms effectively mitigate catastrophic forgetting for medical image segmentation compared to purely convolutional architectures. Particularly, the regularization of ViT modules should be done with caution.", "future_impact": "The findings from this work can open the way for more robust medical image segmentation techniques by adapting transformer mechanisms in sequential learning scenarios and could shape recommendations on how best to regularize ViT modules.", "venue": "CVPR", "year": 2022, "title": "Continual Hippocampus Segmentation with Transformers"}
{"pid": "1d745944-5d35-4a32-bcaa-5d02d2cc2b47", "context": "Functional magnetic resonance imaging (fMRI) provides a sequence of 3D brain images representing brain activations. Traditional fMRI analysis techniques have focused on finding the most significantly activated brain area for different sensations or activities.", "key_idea": "This study proposes a novel application of machine learning techniques for a challenging problem: classifying subjects into groups based on their 3D brain images, specifically separating drug-addicted individuals from non-drug-using individuals.", "method": "A variety of classification approaches were explored, including a newly introduced algorithm that integrates side information into the use of boosting for classification.", "outcome": "The newly introduced classification algorithm outperformed established classifiers, as documented in extensive experimental results. This is the first use of machine learning techniques based on 3D brain images for clinical diagnosis that is currently only performed via patient self-report.", "future_impact": "The tools developed in this research can provide information not addressed by traditional analysis methods and can substantially improve diagnosis, particularly in the context of identifying drug addiction.", "venue": "CVPR", "year": 2005, "title": "Machine learning for clinical diagnosis from functional magnetic resonance imaging"}
{"pid": "63281de190e50fcafd4ecf87", "context": "Image quality in long distance capture is affected by Atmospheric Turbulence (AT), leading to lower performance in vision-based biometric systems like face recognition. Current methods to restore face-images from atmospheric turbulence have only had limited success, indicating a knowledge gap in understanding how AT affects recognition performance.", "key_idea": "The authors study the effects of atmospheric turbulence in the feature space of deep-learning-based face recognition, providing insights into feature space transformation with varying levels of AT.", "method": "The authors conduct experiments to study the effect of differing levels of Atmospheric Turbulence on recognition performance and the transformation of the feature space in deep learning-based face recognition systems.", "outcome": "The authors report the identification of a trend, 'feature defection', that makes face recognition under atmospheric turbulence particularly difficult, alongside other phenomena such as increasing feature magnitudes, contrary to expectations based on literature.", "future_impact": "The findings from this study offer several areas for potential improvement and provide guidance for further progress in developing models that are robust to atmospheric turbulence.", "venue": "CVPR", "year": 2022, "title": "On the Effect of Atmospheric Turbulence in the Feature Space of Deep Face Recognition"}
{"pid": "9753542d-9267-4fbb-85d5-4b7c0a51f90e", "context": "Text segmentation is the process of splitting the images of handwritten text document into pieces corresponding to single lines, words and characters. This is a challenging task as handwritten documents often contain curved text lines with different skew and slant angles. After segmentation, these individual words or strokes have to be sequenced in order to retain the meaningful interpretation of the document.", "key_idea": "The paper proposes the use of a novel connectivity strength parameter with a depth first search approach for extraction of connected components of the same line from complete connected components of the document. The sequencing information is stored in the sequential vector containing labels of the components.", "method": "The proposed cursive stroke sequencing technique is implemented and tested on the IAM database. The performance of this technique was compared against existing segmentation techniques.", "outcome": "The proposed technique gives better outcomes compared to existing segmentation techniques and successfully handles challenges with Hill-and-dale writing styles and overlapped and touched lines. The accuracy of the sequencing technique was found to be 98%.", "future_impact": "No specific future impact is mentioned in the abstract.", "venue": "CVPR", "year": 2013, "title": "Cursive stroke sequencing for handwritten text documents recognition"}
{"pid": "b3477f58-5331-4752-accf-cfe03531439a", "context": "Many computer vision studies have focused on the sensitivity and robustness of existing techniques. Specifically, the problem of classical structure from motion and how the quality of the input video affects the quality of the output reconstruction has been a significant research focus.", "key_idea": "The paper proposes a study to formulate analytical expressions that demonstrate how first and second order statistics (bias and error covariance) of the structure-from-motion solution are affected by the statistics of the input video, particularly in the context of reconstruction from a monocular video.", "method": "Authors analyze the statistics representing the quality of the input video and how it affects the quality of the output reconstruction. The study uses the implicit function theorem of real analysis to derive an expression relating the error covariance of reconstruction to the error covariance of the feature tracks in the input video, and to prove statistical bias in the 3D reconstruction.", "outcome": "The study show that 3D reconstruction is statistically biased with numerically significant results. These results were also used to establish a new bound on the minimum error in depth reconstruction.", "future_impact": "The proposed method of propagating the statistical error and bounding the minimum error in depth reconstruction from monocular video may influence future studies to improve the robustness and sensitivity of 3D modeling procedures.", "venue": "CVPR", "year": 2003, "title": "Statistical Error Propagation in 3D Modeling From Monocular Video"}
{"pid": "d6c7387f-cd67-4071-a573-6821a1d04b5d", "context": "Prior work on corridor reconstruction typically requires resources beyond what is available in a consumer-grade RGB camera. There is a need for a low-resource, real-time solution that lets visually impaired people or robots navigate indoor environments effectively.", "key_idea": "The authors introduce a new approach for 3D hallway modeling using a single image. They propose a perspective-based Hough transform algorithm to detect vertical lines, which are used to determine the edges of the corridor.", "method": "The authors create a 3D model using the features extracted from a single image. They combine multiple 3D models to increase confidence and build a global 3D model. They also discuss the challenges of implementing their approach in real-time on a smartphone.", "outcome": "The authors present experimental results that validate the effectiveness of their corridor modeling approach. They don't provide specific detail on these results in the abstract.", "future_impact": "The proposed approach has potential applications in environments with properties similar to corridors, such as highways, sidewalks, and city blocks.", "venue": "CVPR", "year": 2014, "title": "3D Hallway Modeling Using a Single Image"}
{"pid": "2db24580-b76e-4cca-8ab9-8eb6c20f1aba", "context": "Object detection is a crucial but challenging task in computer vision. Existing methods often struggle to balance high accuracy and efficiency.", "key_idea": "The paper introduces a new method, which combines a simplified version of APCF features, termed as Joint Ranking of Granules (JRoG) features, and a novel collaborative learning approach including a Simulated Annealing (SA) module and an incremental feature selection module. This architecture allows efficient search of the enormous JRoG feature space for discriminating features.", "method": "These discriminative features are fed into a boosted cascade for object detection, and a dynamic search method is proposed to improve the Bayesian combination part detection results, particularly under occlusions in crowded conditions. Real-time detection tasks were conducted as part of the experiments.", "outcome": "Experiments on several challenging datasets demonstrated that the proposed method significantly improved both detection accuracy and computational efficiency, providing sufficient capability for practical real-time detection tasks on a single-threaded Xeon 3GHz computer.", "future_impact": "The method's balance of high efficiency and accuracy, and its ability to cope with occlusions in populated environments implies this approach may be beneficial for future real-time object detection implementations.", "venue": "CVPR", "year": 2010, "title": "High performance object detection by collaborative learning of Joint Ranking of Granules features"}
{"pid": "e5d46407-267b-4c25-b5bd-5a1fb8a35e85", "context": "Current labelling problems are typically approached using conditional random fields with pairwise contrast sensitive smoothness potentials.", "key_idea": "The authors propose a new framework for labelling problems, leveraging higher order conditional random fields and potentials defined on sets of pixels generated from unsupervised segmentation algorithms, manifested as a robust Pn model.", "method": "The proposed method is tested on the problem of multi-class object segmentation by augmenting the conventional conditional random field with higher order potentials defined on image regions.", "outcome": "Experiments on challenging datasets demonstrated that the integration of higher order potentials quantitatively and qualitatively improved results, particularly in the definition of object boundaries.", "future_impact": "The authors anticipate that the proposed method will yield similar improvements for many other labelling problems.", "venue": "CVPR", "year": 2008, "title": "Robust higher order potentials for enforcing label consistency"}
{"pid": "8945f8e8-8cb6-455e-a4fa-16a8ae8e06b4", "context": "There are existing approaches to recover 3D object shape and camera motion from an extended sequence of video images, characterized by their unique manner of computing the so-called shape space. However, most of these approaches are computationally complex or require the estimation or updating of a large measurement or covariance matrix.", "key_idea": "The authors present a recursive least-squares method for recovering 3D object shape and camera motion that updates the shape space with a complexity of O(P) per frame, which is an improvement over existing methods.", "method": "The authors test the proposed recursive least-squares method using real and synthetic image sequences to gauge its computational complexity and performance.", "outcome": "Experiments confirm the method's low computational complexity and good performance, and demonstrate its suitability for real-time applications.", "future_impact": "The recursive approach presented in this paper may enable more efficient and real-time applications for recovering 3D object shape and camera motion.", "venue": "CVPR", "year": 1999, "title": "An efficient recursive factorization method for determining structure from motion"}
{"pid": "a3724110-1477-4021-8b4b-210c5d702f7e", "context": "Medial descriptions, such as shock graphs, are used in shape-based object recognition due to their invariance to translation, rotation, scale, and articulation and their ability to deal with moderate amounts of within-class deformation. However, these decompositions can suffer from ligature-induced instability, meaning the addition of a small part can dramatically impact the representation in the vicinity of its attachment.", "key_idea": "The paper introduces an algorithm for identifying and representing the ligature structure of an object shape, and restoring the non-ligature structures that remain, leading to a 'bone graph', a new medial shape abstraction.", "method": "The authors demonstrate the advantages of bone graphs over shock graphs using a series of view-based object recognition and pose estimation trials.", "outcome": "The study indicates that the newly proposed bone graph offers improved stability and within-class deformation invariance, capturing a more intuitive notion of an object's parts than a skeleton or a shock graph.", "future_impact": "Though not explicitly mentioned, the development of the 'bone graph' could lead to advancements in the field of shape-based object recognition, providing a more stable and intuitive method of abstraction.", "venue": "CVPR", "year": 2008, "title": "From skeletons to bone graphs: Medial abstraction for object recognition"}
{"pid": "63281de190e50fcafd4ecf88", "context": "The coplanar two-line room layout with two parallel junction lines is often seen in an egocentric indoor vision when facing a wall or walking in a corridor. However, camera pose estimation from this kind of room layouts cannot be handled by existing vanishing point-based algorithms or Perspective-n-Line (PnL) methods due to the lack of line correspondences.", "key_idea": "A new coplanar Perspective-three-Line (CP3L) method is proposed to handle the coplanar two-line room layouts by embedding a Perspective-three-Line (P3L) method into the NSGA-II, a multi-objective optimization method.", "method": "The proposed CP3L algorithm estimates the initial camera pose and the 3D correspondences of four image outer corners related to the two junction lines, and optimizes the camera pose in the iterative Gauss-Newton algorithm. The robustness of CP3L solutions under different configurations of auxiliary lines from estimated image outer corners are studied and compared. The authors tested the method on simulated images and real ones from the Matterport3D-Layout database.", "outcome": "The proposed method demonstrated accuracy and robustness per the results of experiments conducted on both simulated images and real ones from the Matterport3D-Layout database.", "future_impact": "The proposed approach can be potentially adapted or expanded to improve camera pose estimation from different types of room layouts.", "venue": "CVPR", "year": 2022, "title": "Egocentric Indoor Localization from Coplanar Two-Line Room Layouts"}
{"pid": "61a444b45244ab9dcb6e23c9", "context": "In transfer learning, models pretrained on large 'upstream' datasets are adapted for 'downstream' specialized datasets. A common belief is that more accurate models on the 'upstream' dataset tend to provide better transfer accuracy 'downstream'. This has been less explored in the context of convolutional neural networks (CNNs) trained on the ImageNet dataset, which have been pruned or compressed by sparsifying their connections.", "key_idea": "The authors propose an in-depth investigation of how well pruned or sparse CNN models trained on the ImageNet perform in transfer learning tasks, using several state-of-the-art pruning methods such as magnitude-based, second-order, regrowth, lottery-ticket, and regularization approaches.", "method": "Pruned models are applied to twelve standard transfer tasks to investigate their performance and potential benefits including inference and training speed-ups.", "outcome": "The results demonstrate that sparse models can match or even outperform the transfer performance of dense models at high sparsities, leading to significant inference and training speed-ups. Additionally, significant differences in the behaviour of different pruning methods are observed.", "future_impact": "Understanding the behaviour and performance of sparse models in transfer tasks can inform the development of more efficient models and training methods for transfer learning.", "venue": "CVPR", "year": 2022, "title": "How Well Do Sparse ImageNet Models Transfer?"}
{"pid": "f2db8d3b-e4f6-4c68-b308-c8f4a49f47cd", "context": "Current methods for dynamic scene analysis by computer vision are lacking an integrated approach that combines 3-D shape models, dynamical models, and the laws of perspective projection.", "key_idea": "The authors propose a novel method for dynamic scene analysis that integrates 3-D shape models, dynamical models from modern control theory, and the laws of perspective projection using recursive state estimation by Kalman filtering and feature-based image sequence analysis.", "method": "The authors test their proposed method on realistic tasks such as three-degree-of-freedom planar docking, road vehicle guidance at speeds up to 60 mph, and six-degree-of-freedom landing approach of a business jet plane (hardware in the loop simulation).", "outcome": "The proposed method leads to image evaluation cycle times of about 0.1s for tested tasks, enabling motion control in the dynamic range of humans.", "future_impact": "The proposed method could potentially be applied to complex and dynamic scenarios such as road vehicle guidance and aircraft landing, thereby revolutionizing the application of computer vision in automated systems.", "venue": "CVPR", "year": 1988, "title": "An integrated approach to feature based dynamic vision"}
{"pid": "e4edad9f-2997-456a-9a8e-da3bcde064c0", "context": "Organizing large structural model bases can be computationally expensive, and the search for the best interprimitive mapping function in these models can become exponentially complex.", "key_idea": "The authors propose a hierarchically structured approach to organizing large structural model bases using an information theoretic criterion, wherein objects are modeled in the form of random parametric structural descriptions (RPSDs), an extension of the parametric structural description graph-theoretic formalism.", "method": "In order to validate the proposed method, the authors use a process of hierarchical clustering of the RPSDs, which reduces the computational workload.", "outcome": "Through the implementation of this approach, computational work is significantly reduced, and the process of mapping between the observation and a stored representation at one level is simplified, eliminating the exhaustive search for interprimitive mapping.", "future_impact": "The approach in this study has the potential to enhance efficiency and complexity management in organizing large structural model bases.", "venue": "CVPR", "year": 1993, "title": "Information theoretic clustering of large structural modelbases"}
{"pid": "43551950-a301-49b6-bb22-af0a376015d2", "context": "Existing methods for characterizing photometric properties of a camera, including vignetting effects, require extensive measurement at various device configurations such as aperture and focal length.", "key_idea": "The authors propose a compact, device-independent representation of a camera's photometric properties that can be computed from photometric parameters measured at a sparse selection of device configurations.", "method": "The model's parameters are recovered from sparse and varied device configurations, and then used to accurately predict photometric parameters at new, unmeasured device configurations.", "outcome": "The proposed model is able to accurately predict photometric parameters at new, unmeasured device configurations.", "future_impact": "The proposed model could enable more accurate prediction of photometric properties in a variety of device configurations, potentially improving camera performance and digital image quality.", "venue": "CVPR", "year": 2010, "title": "Device-independent representation of photometric properties of a camera"}
{"pid": "4a11e1b9-5df5-49b4-822d-4295da234ad7", "context": "Minutiae, the endpoints and bifurcations of fingerprint ridges, provide a strong basis for fingerprint classification, but handling them involves dealing with unordered sets and various deformations such as translation, rotation, and scaling.", "key_idea": "The authors introduce a novel method to represent a minutiae set as a fixed-length feature vector that is invariant to translation and treats rotation and scaling as translations, making them easily compensable.", "method": "Two spectral minutiae matching algorithms are presented in conjunction with the proposed representation method. These were presumably tested through an unspecified set of experiments.", "outcome": "The abstract mentions the presentation of experimental results, but does not provide any actual outcomes or specific figures from these experiments.", "future_impact": "The proposed method will enable integration of the fingerprint recognition system with a template protection scheme, that requires a fixed-length feature vector.", "venue": "CVPR", "year": 2008, "title": "Spectral minutiae: A fixed-length representation of a minutiae set"}
{"pid": "aaca24a7-9f47-4ee8-84ec-9109f9c9cce8", "context": "The challenge of recovering motion and structure from optical flow is typically a complex, nonlinear problem.", "key_idea": "The authors observe that when the viewing camera is appropriately positioned on a vehicle moving on a planar surface, the problem of motion and structure recovery from optical flow becomes linear and can be resolved locally.", "method": "The proposed approach focuses on computing angular velocity and depth from one component only of the optical flow. The authors validate the approach with experiments on synthetic and real sequences.", "outcome": "Their results show that the accuracy in the estimation of depth from the vertical component of optical flow is higher than from the horizontal component.", "future_impact": "The findings could simplify the process of motion and structure recovery from optical flow by making it a linear problem when the camera is appropriately mounted on a moving platform, which could be further explored in more diverse contexts.", "venue": "CVPR", "year": 1994, "title": "Motion and structure from one dimensional optical flow"}
{"pid": "54c799a1-d62a-4799-b81e-6f35dec4f3cc", "context": "Visually impaired people often require additional human assistance when shopping at grocery stores, due to the challenge of detecting and distinguishing between various items.", "key_idea": "The paper introduces ShelfScanner, a system designed to assist visually impaired users by offering real-time grocery detection. It detects items on the shopping list directly from video streams and takes advantage of grocery store shelves' approximate planarity using an optical flow algorithm.", "method": "The authors use a multiclass naive-Bayes classifier inspired by NIMBLE, trained on enhanced SURF descriptors extracted from images in the GroZi-120 dataset. The system computes per-class probability distributions on video keypoints for final classification.", "outcome": "The study demonstrates the potential effectiveness of ShelfScanner in scenarios where high-quality training data is available.", "future_impact": "The successful development of ShelfScanner could pave the way for more advanced systems aimed at offering real-time detection to aid the visually impaired in different environments.", "venue": "CVPR", "year": 2010, "title": "Toward real-time grocery detection for the visually impaired"}
{"pid": "2e509be0-f0f7-4858-bfdd-6ec41eb09b0b", "context": "Prior to this study, deep convolutional networks were used for face recognition, but there were still limitations to achieve higher performance on benchmarks like LFW and YouTube Faces.", "key_idea": "The authors propose a high-performance deep convolutional network (DeepID2+) for face recognition, which is learned with the identification-verification supervisory signal and achieves new state-of-the-art performance by increasing the dimension of hidden representations and adding supervision to early convolutional layers.", "method": "DeepID2+ is trained and its performance evaluated on the LFW and YouTube Faces benchmarks. Furthermore, the authors run empirical studies to observe the properties of DeepID2+'s neural activations.", "outcome": "On the LFW and YouTube Faces benchmarks, DeepID2+ achieves new state-of-the-art performance. It is observed that neural activations are moderately sparse and it can still achieve high recognition accuracy even after neural responses are binarized. Its neurons in higher layers are highly selective to identities and identity-related attributes, and it is more robust to occlusions.", "future_impact": "The DeepID2+ model demonstrates the importance of sparsity, selectiveness, and robustness in face recognition neural networks, which can guide the future design and training of models for face recognition.", "venue": "CVPR", "year": 2015, "title": "Deeply learned face representations are sparse, selective, and robust"}
{"pid": "5f2e783e91e011fa4e2aedc2", "context": "Traditional navigation models in autonomous driving heavily rely on metric maps, which greatly limit their application in large scale environments due to their complexity and requirement of intensive computing resources.", "key_idea": "The paper presents a novel two-level navigation architecture for autonomous driving that uses a topological-metric memory structure for learning driving commands, and a deep image-based controller for reacting to real-time visual inputs. This approach relies on a convolutional neural network to extract visual features.", "method": "The system is tested in a teach-and-repeat experiment in an urban driving simulator for its ability to adapt quickly to new environments and conditions, training in one environment and testing in another with different illumination and weather conditions.", "outcome": "Results show that the proposed system, after being trained in a separate environment, could quickly adapt to novel environments, successfully following routes under various illumination and weather conditions.", "future_impact": "This two-level architecture and its ability to quickly adapt to novel environments and conditions may represent a significant improvement in navigation capability in autonomous driving systems.", "venue": "CVPR", "year": 2020, "title": "Topometric Imitation Learning For Route Following Under Appearance Change."}
{"pid": "4097de1f-0b93-4af7-ad57-e05ddbc7989c", "context": "Existing zero-shot learning methods, used for applications in robotics and mobile communications, tend to be offline batch learning, either based on direct-attribute-prediction (DAP) or indirect-attribute-prediction (IAP) models. Challenges with these methods are they may not handle inconsistencies in attribute labeling which can arise from online user interactions, and lack an effective way of learning new attributes or updating existing ones incrementally.", "key_idea": "The paper proposes an online incremental zero-shot learning method, distinctively based on the indirect-attribute-prediction (IAP) model, and using self-organizing and incremental neural networks (SOINN) as the learning mechanism. This method can learn and update attributes in an online, incremental manner while maintaining accuracy.", "method": "The proposed method was evaluated through two experiments. The first experiment compared the proposed method against a previous IAP-based offline method for time and accuracy. The second experiment examined how the proposed method would handle situations where object attributes are labeled gradually via user interaction, including when such labels may be incorrect.", "outcome": "The proposed method outperforms the IAP-based offline method in both time and accuracy, achieves approximately the same accuracy as the DAP-based offline method, and successfully copes with situations where object attributes are gradually labeled through interaction with many users, even with possibly incorrect labels. The proposed method also reduced computation time by more than 99% compared to offline methods.", "future_impact": "The robustness of the proposed method to labeling inconsistencies, and its ability to learn new attributes incrementally, highlight its potential for improved performance in applications such as robotics and mobile communication where objects and attributes may be initially unknown and must be learned online.", "venue": "CVPR", "year": 2012, "title": "Online incremental attribute-based zero-shot learning"}
{"pid": "13472988-cab1-4a32-b853-0b0b8bfd034b", "context": "The problem of nonnegative graph embedding was initially studied by J. Yang et al., 2008. The process combines the benefits of nonnegative data factorization and the specific scenarios characterized by intrinsic and penalty graphs. The major hurdle is the high computational cost due to the iterative process involving the calculation of an inverse M-matrix.", "key_idea": "The paper presents two notable contributions: (1) a multiplicative iterative procedure for nonnegative graph embedding to reduce computational costs, and (2) expressing the nonnegative graph embedding framework in a broader way by characterizing each piece of data as a tensor of arbitrary order.", "method": "The entered proposal is validated through extensive experiments benchmarked against state-of-the-art algorithms concerning nonnegative data factorization, graph embedding, and tensor representation.", "outcome": "Experimental results demonstrate the proposed approach improves in computation speed, sparsity, discriminating power, and robustness against realistic image occlusions.", "future_impact": "The proposed nonnegative graph embedding method, reinterpreted using tensor representation, opens possibilities for new nonnegative tensor factorization algorithms that provide admissible time and memory cost benefits.", "venue": "CVPR", "year": 2009, "title": "Multiplicative nonnegative greph embedding"}
{"pid": "a7e06cd8-65f2-426b-ba6f-517246abdea4", "context": "The existing optimization methods for Markov random fields (MRF) over images struggle with speed and parallelization.", "key_idea": "A new fast and simple algorithm for optimizing MRF over images is proposed, which uses block coordinate descent by optimally updating a horizontal or vertical line at each step.", "method": "The algorithm's performance is evaluated on traditional benchmark problems, and its application is demonstrated in the context of increasing the accuracy of consumer depth cameras.", "outcome": "While not as accurate as state-of-the-art MRF solvers on traditional benchmarks, the proposed algorithm is trivially parallelizable, producing competitive results in a fraction of a second, and substantially increasing the accuracy of produced range images when applied to depth reconstruction.", "future_impact": "The proposed algorithm, by enabling high-resolution MRF optimization at several frames per second, has the potential to improve the speed and effectiveness of MRF-based image processing applications.", "venue": "CVPR", "year": 2014, "title": "Fast MRF Optimization with Application to Depth Reconstruction"}
{"pid": "b73794ad-1a19-4a8f-8aa4-bf5b31abfe9b", "context": "Traditional locality-sensitive hashing (LSH) techniques aim to tackle the large scale of data in computer vision tasks, but their potential in large-scale optimization has only been explored recently.", "key_idea": "This paper proposes a new hashing scheme that accelerates min/max inner product operations, known as the computational bottleneck of numerous optimization algorithms in large-scale settings. The proposed scheme exploits properties of order statistics of statistically correlated random vectors.", "method": "The proposed hashing scheme is used to perform approximate l1 regularized least squares optimization with dictionaries containing millions of elements.", "outcome": "The proposed hashing scheme is shown to improve recall at a lower computational cost as compared to other existing schemes. Applications involving large dictionaries, which exceeds the capacity of known solvers, were successfully demonstrated.", "future_impact": "This work exploits a new application for hashing techniques in computer vision and proposes a general framework for accelerating a wide variety of optimization procedures, potentially affecting a broad range of large-scale optimization problems in the future.", "venue": "ECCV", "year": 2012, "title": "Accelerated large scale optimization by concomitant hashing"}
{"pid": "d8a82978-ed8d-45a4-a18e-fab0f1419532", "context": "Anisotropic Gaussian filtering is traditionally computed in a computationally intensive manner, limiting its practical applicability in orientation scale-space analysis and other applications.", "key_idea": "The authors derive the decomposition of the anisotropic Gaussian in a one-dimensional Gauss filter in the x-direction followed by a one-dimensional filter in a non-orthogonal direction, demonstrating that also the anisotropic Gaussian can be decomposed by dimension.", "method": "The authors propose an implementation scheme for normal convolution and for recursive filtering, and apply the decomposed anisotropic Gaussian for calculating edge and ridge maps. Its performance on tracking applications and feature detection applications is also assessed.", "outcome": "The proposed method of anisotropic Gaussian filtering allows fast calculation of edge and ridge maps with high spatial and angular accuracy, and performs a filtration of a 512 \u00d7 512 image within 65 milliseconds, which is independent of the standard deviations and orientation of the filter.", "future_impact": "The proposed computational filtering method enables the practical applicability of orientation scale-space analysis, with potential applications in tracking such as detection of dashed lines in engineering drawings, and in feature detection such as affine invariant edge and ridge detection in computer vision.", "venue": "ECCV", "year": 2002, "title": "Fast Anisotropic Gauss Filtering"}
{"pid": "62d8c4595aee126c0f764c8a", "context": "Deep image classifiers can learn biases from datasets, and most previous methods for mitigating these biases require full-supervision through the labeling of protected attributes like age or skin tone. However, this approach has limitations when the labels are unavailable and is incapable of mitigating unknown biases that are not preconceived by humans.", "key_idea": "The authors propose Debiasing Alternate Networks (DebiAN), a method comprising of a Discoverer and a Classifier that alternately train to discover multiple unknown biases without any annotations of biases, and unlearn these discovered biases.", "method": "The authors apply DebiAN to a newly created Multi-Color MNIST dataset designed to benchmark the mitigation of multiple biases. They also perform extensive experiments on real-world datasets.", "outcome": "The discoverer in DebiAN is successful in identifying unknown biases. Furthermore, it demonstrates strong bias mitigation performance, showing its ability to mitigate multiple biases simultaneously.", "future_impact": "The proposed method can help mitigate unknown biases in deep image classifiers, potentially improving the fairness of these models and making it harder for unknown biases to influence outputs.", "venue": "ECCV", "year": 2022, "title": "Discover and Mitigate Unknown Biases with Debiasing Alternate Networks."}
{"pid": "5ff8803991e011c832668cc0", "context": "Image-based high throughput plant phenotyping refers to the process of computing phenotypes non-destructively by analyzing images of plants captured at regular time intervals. Currently, predicting phenotypes for missing imaging days or for a future time based on past measurements is a challenge.", "key_idea": "The authors propose using time series modeling for phenotypic prediction and phenotype-genotype mapping, including predicting a derived or composite phenotype from its one or more constituents.", "method": "The authors use long short-term memory, a variant of recurrent neural networks, for phenotype-genotype mapping, while autoregressive neural networks, autoregressive neural network with exogenous input, and non-linear input-output neural networks are used for phenotypic prediction.", "outcome": "The experimental analyses on the benchmark dataset called Phenoseries shows the efficacy of the proposed models.", "future_impact": "The potential to contribute to the study of improved crop breeding and understanding the genetic regulation of temporal variation of phenotypes.", "venue": "ECCV", "year": 2020, "title": "Time Series Modeling for Phenotypic Prediction and Phenotype-Genotype Mapping Using Neural Networks."}
{"pid": "6b7cc603-5c03-4ffb-a5eb-a92ee6587965", "context": "The one-shot and zero-shot learning problems, where each object category has only one or no training example respectively, are challenging research areas in machine learning.", "key_idea": "The authors approach these problems by transferring knowledge from known categories, termed as source categories, to new categories, referred to as target categories, via object attributes (descriptions of object categories, such as color, texture, shape, etc.).", "method": "The authors propose an attribute-based transfer learning framework featuring a generative attribute model. They use this model to learn the probabilistic distributions of image features for each attribute, termed as attribute priors. These priors are then used for zero-shot learning and one-shot learning. The methods are evaluated using the Animal with Attributes dataset.", "outcome": "The proposed approaches demonstrated state-of-the-art performance in both zero-shot and one-shot learning tests when validated on the Animal with Attributes dataset.", "future_impact": "The authors' approach has introduced a new way to address the one-shot and zero-shot learning problems, which could inspire future research in these areas.", "venue": "ECCV", "year": 2010, "title": "Attribute-based transfer learning for object categorization with zero/one training example"}
{"pid": "62d7730e5aee126c0f9009f3", "context": "Incremental Task Learning (ITL) trains a single network for multiple tasks sequentially, but the neural networks often suffer from catastrophic forgetting where they forget older tasks when trained for newer tasks. Existing ITL methods try to address this issue with episodic memory, parameter regularization, masking and pruning, or extensible network structures.", "key_idea": "The authors propose a new ITL framework based on low-rank factorization, representing the network weights for each layer as a linear combination of several rank-1 matrices. They introduce an additional selector vector that assigns different weights to the low-rank matrices learned for previous tasks.", "method": "In order to update the network for a new task, they learn a rank-1 (or low-rank) matrix and add that to the weights of every layer.", "outcome": "Their proposed model performs better than the current state-of-the-art methods in terms of accuracy and forgetting, and offers better memory efficiency compared to episodic memory- and mask-based approaches.", "future_impact": "This novel ITL framework might influence future techniques for avoiding catastrophic forgetting in ITL and improve efficiency and performance of ITL models.", "venue": "ECCV", "year": 2022, "title": "Incremental Task Learning with Incremental Rank Updates."}
{"pid": "ac914474-8017-4b25-a0ef-c16291c7f91a", "context": "Multiview reconstruction typically focuses on accurately reproducing a 3D scene from various viewpoints. However, handling inaccuracies in calibration information and constructing coarse scene models from multiple views are challenging tasks.", "key_idea": "The authors propose a new multiview reconstruction problem termed 'approximate N-view stereo', aiming to recover a one-parameter family of volumes that are increasingly tighter supersets of an unknown, arbitrarily-shaped 3D scene.", "method": "The authors develop an algorithm called Approximate Space Carving. The algorithm organizes the 3D shapes that reproduce the input photographs, up to a special image transformation called a 'shuffle' transformation, into nested supersets of the scene.", "outcome": "The authors prove that the proposed method allows for the shapes to be organized hierarchically into nested supersets of the scene and that this can be computed using the Approximate Space Carving algorithm, which is provably correct for arbitrary discrete scenes.", "future_impact": "The methodology's design is aimed at solving practical reconstruction problems, such as recovering shape from images with inaccurate calibration information and building coarse scene models from multiple views, indicating a potential impact in diverse practical fields.", "venue": "ECCV", "year": 2000, "title": "Approximate N-View Stereo"}
{"pid": "41d2fba3-63eb-4e04-b4f5-3cd0a1890f30", "context": "Existing work in localizing objects in an image and estimating their fine-pose make use of CAD models and some training images with aligned models but often lacks in accuracy and speed.", "key_idea": "The authors propose FPM, a fine pose parts-based model that leverages both geometric information in the form of shared 3D parts from CAD models and appearance information from real images for accurate fine pose estimation.", "method": "The authors use real training images with aligned CAD models to train the FPM model.", "outcome": "The FPM model outperforms state-of-the-art algorithms in both accuracy and speed for object localization and fine pose estimation.", "future_impact": "The improvement in both accuracy and speed of fine pose estimation could potentially benefit many applications that require object location and orientation information.", "venue": "ECCV", "year": 2014, "title": "FPM: Fine Pose Parts-Based Model with 3D CAD Models"}
{"pid": "89214d67-9f3a-4da5-a474-01649ea5a5ca", "context": "Matching 3-D curves is a significant problem in machine vision, but the existing methods tend to be slow or inefficient.", "key_idea": "This study proposes an algorithm to find the longest common subcurve of two 3-D curves using splines, transformation into 1-D numerical strings of shape signatures, an efficient hashing technique for matching, and a robust, least-squares, 3-D curve matching technique for verification and transformation recovery.", "method": "The introduced algorithm, which has an average complexity of O(n), is tested in assembly and object recognition tasks.", "outcome": "The paper quotes positive results from assembly experiments \u2013 however, specific quantitative outcomes are not provided within the abstract.", "future_impact": "The algorithm presented in this study has potential use in real-world applications such as assembly and object recognition tasks.", "venue": "ECCV", "year": 1990, "title": "3-D curve matching using splines"}
{"pid": "635024b790e50fcafd303961", "context": "Camera re-localization, which is crucial in many computer vision tasks like visual odometry, structure from motion (SfM), and SLAM, has traditionally relied on methods where pose regression is guided by photometric consistency. This approach does not effectively incorporate image features, camera pose information and inter-frame relative camera motions, and lacks computational efficiency.", "key_idea": "The authors introduce a neural network solution called GTCaR (Graph Transformer for Camera Re-localization) that aims to resolve multi-view camera re-localization problems utilizing a graph Transformer architecture to integrate image features, camera pose data and relative camera motions into encoded graph attributes.", "method": "GTCaR is trained for graph consistency and pose accuracy, and the model utilizes graph Transformer layers with edge features and an adjacency tensor. The system is tested on various public benchmarks, considering both global attention and evolving structures of the pose graph for accuracy and robustness. The model may also employ optional temporal Transformer layers for sequential inputs.", "outcome": "Experimental evaluations show that GTCaR outperforms existing state-of-the-art approaches in camera re-localization tasks on several public benchmarks.", "future_impact": "The proposed model and its novel use of a graph Transformer architecture to address camera re-localization problems may inspire future advancements in the field of computer vision, particularly in tasks related to visual odometry, SLAM, and structure from motion.", "venue": "ECCV", "year": 2022, "title": "GTCaR: Graph Transformer for Camera Re-localization."}
{"pid": "5f6dbc7191e01153370054bc", "context": "Modern object detection methods are divided into one-stage approaches, which are efficient due to straightforward architectures, and two-stage ones, which have higher accuracy. While recent work has attempted to improve the accuracy of one-stage detectors by mimicking the structural design of two-stage detectors, a significant accuracy gap remains.", "key_idea": "The authors propose MimicDet, a novel framework to train a one-stage detector by directly mimicking the features of a two-stage detector. Unlike conventional mimic methods, MimicDet contains a shared backbone for both types of detectors, then branches into two well-designed heads with compatible features.", "method": "Implementations focus on specific design considerations such as dual-path mimicking and staggered feature pyramid. The effectiveness of MimicDet is tested on the challenging COCO detection benchmark.", "outcome": "MimicDet achieves 46.1 mAP with ResNeXt-101 backbone on the COCO test-dev set, which significantly surpasses current state-of-the-art methods.", "future_impact": "MimicDet presents an efficient way to improve the accuracy of one-stage detectors, potentially influencing the design of future object detection methods.", "venue": "ECCV", "year": 2020, "title": "MimicDet: Bridging the Gap Between One-Stage and Two-Stage Object Detection"}
{"pid": "5f47a1699e795ee5412eaf6d", "context": "The application of computer vision systems in real-world tasks is facing challenges due to unexpected behavior on unseen examples and lack of systematic methods to identify model failures.", "key_idea": "The paper proposes semantic adversarial editing, a method to synthesize plausible but difficult datapoints that may lead a chosen model to fail, utilizing a differentiable object synthesizer which can change an object's appearance but still maintain its pose.", "method": "The authors conducted experiments to validate their approach, which involved an adversarial optimization of object appearance through the synthesizer to mislead the target object detector, specifically the YOLOv3 detection architecture.", "outcome": "Their method effectively synthesized complicated test data, causing the performance of the YOLOv3 detector to drop by over 20 mAP points when changing the appearance of a single object and identifying failure modes of the model. The generated adversarial data helped to enhance the detector's robustness through data augmentation, consistently improving its performance in both standard and out-of-dataset-distribution test sets, across three different datasets.", "future_impact": "The paper's proposed method has the potential to improve the robustness of object detection models by generating test data that identify breaking points in the model, potentially leading to advancements in the field of computer vision.", "venue": "ECCV", "year": 2020, "title": "Towards Automated Testing and Robustification by Semantic Adversarial Data Generation"}
{"pid": "392cd895-c3d4-46d1-a139-60f9f516e13e", "context": "Previous methods of creating building models from aerial LiDAR point clouds may not guarantee creating crack-free models composed of complex roofs and vertical walls connecting them.", "key_idea": "A robust extension to classic dual contouring into a 2.5D method is proposed, which optimizes both three dimensional surfaces and the two dimensional boundaries of roof layers. The authors also introduce a new adaptive grid to simplify model geometry.", "method": "The presented approach involves extending classic dual contouring into a 2.5D method and introducing an adaptive grid to accurately simplify model geometry. The efficiency and effectiveness of the approach is demonstrated through sharp feature detection and preservation.", "outcome": "The method is able to create building models with arbitrarily shaped roofs while maintaining the verticality of connecting walls. It is also able to detect and preserve sharp features in an efficient manner.", "future_impact": "This method's ability to create robust and accurate building models from aerial LiDAR point clouds can improve the usage of LiDAR point clouds in 3D modeling, architecture and other related fields.", "venue": "ECCV", "year": 2010, "title": "2.5D dual contouring: a robust approach to creating building models from Aerial LiDAR point clouds"}
{"pid": "5ff8803991e011c832668cc4", "context": "The current strategy for estimating homographies among images in agricultural contexts uses complex vehicles with advanced telemetry to take images from a grid of waypoints, simplifying homography estimation for mosaicking crop fields. However, the inflexibility of this approach hinders the collection of richer information and limits practicability for many researchers and farmers.", "key_idea": "The authors propose CorNet, an unsupervised deep learning network that estimates the sequence of planar homography matrices from agricultural imagery without relying on any metadata for error correction. CorNet has the capability to process imagery collected by consumer-grade aerial vehicles flown over various trajectories.", "method": "The authors trained their model on images collected by freely flying a consumer-grade vehicle over a variety of trajectories and camera views in corn fields.", "outcome": "The CorNet system performed faster than and with comparable accuracy to the gold standard ASIFT algorithm in many challenging cases.", "future_impact": "The proposed method can simplify the process of homography estimation in agricultural phenotyping by using consumer-grade vehicles, making this process more practical and accessible for many researchers and farmers.", "venue": "ECCV", "year": 2020, "title": "CorNet - Unsupervised Deep Homography Estimation for Agricultural Aerial Imagery."}
{"pid": "635024b990e50fcafd303cca", "context": "Action Quality Assessment (AQA) in sports is a challenging task due to the complexity of modeling diverse athletes' actions. A conventional approach is to treat this as a regression problem mapping input videos to final scores given by referees, but this fails to capture the subtle and critical differences between videos.", "key_idea": "The researchers propose the Pairwise Contrastive Learning Network (PCLN), an end-to-end model for AQA that includes a basic regression network and considers differences between videos by learning relative scores for video pairs.", "method": "The PCLN was tested on the AQA-7 and MTL-AQA datasets, with several ablation studies conducted to confirm the effectiveness of each component in the proposed method.", "outcome": "Experimental results show that the PCLN achieves state-of-the-art performance in AQA.", "future_impact": "Considering the effectiveness of PCLN, it may encourage further research on contrastive learning in video understanding tasks, especially in the context of sports analytics.", "venue": "ECCV", "year": 2022, "title": "Pairwise Contrastive Learning Network for Action Quality Assessment."}
{"pid": "62d8c4565aee126c0f762a77", "context": "Learning accurate object detectors often requires large-scale training data with precise object bounding boxes. However, labeling such data is expensive and time-consuming, and the process may often result in inaccuracies and noise in the bounding box annotations, which can affect the performance of the object detectors.", "key_idea": "This work proposes to overcome the challenge of learning robust object detectors with inaccurate bounding boxes by leveraging classification as a guidance signal for refining localization results. The authors introduce an Object-Aware Multiple Instance Learning approach (OA-MIL), which uses object-aware instance selection and object-aware instance extension to select accurate instances for training, and to generate high-quality instances for selection.", "method": "The authors conducted extensive experiments on synthetic noisy datasets (i.e., noisy PASCAL VOC and MS-COCO) and a real noisy wheat head dataset to evaluate the effectiveness of the OA-MIL.", "outcome": "The results of the experiments reveal that the proposed OA-MIL approach is effective in improving the performance of object detection in the presence of inaccurate bounding box annotations.", "future_impact": "This work could enable more robust object detection algorithms that can work with inaccurately labeled training data, thus reducing the need for high-precision bounding box annotations and making the labeling process less time-consuming and expensive.", "venue": "ECCV", "year": 2022, "title": "Robust Object Detection with Inaccurate Bounding Boxes."}
{"pid": "5ff68d3bd4150a363cd4d03e", "context": "Temporal Activity Localization via Language (TALL) in video is a recently proposed task that requires fine-grained understanding of video content, a feature overlooked by most previous works.", "key_idea": "The authors propose a Hierarchical Visual-Textual Graph for TALL, modelling interactions between objects and words, as well as among the objects, and a convolutional network with a cross-channel communication mechanism.", "method": "A novel TALL method is applied and a new loss function that enforces alignment of the visual representation of the localized activity and the sentence representation is proposed. The method is evaluated on two popular benchmark datasets: Charades-STA and ActivityNet Captions.", "outcome": "The proposed method achieved state-of-the-art performance on both the Charades-STA and ActivityNet Captions datasets.", "future_impact": "With finer understanding of video content, this study could potentially improve the accuracy of Temporal Activity Localization via Language in the future. However, the authors did not specifically mention the future impacts in the abstract.", "venue": "ECCV", "year": 2020, "title": "Hierarchical Visual-Textual Graph for Temporal Activity Localization via Language"}
{"pid": "9e0f9b20-8ffb-4349-bf3a-b7f67a3821f1", "context": "Hierarchical shape representation in the field typically does not adapt based on the proximity of data points, potentially leading to inefficiency and less accuracy in object shape representation.", "key_idea": "The authors propose a physics-based algorithm for hierarchical shape representation using deformable models with locally adaptive finite elements. This algorithm locally subdivides the triangular finite elements based on the distance between the given data points and the model.", "method": "The authors use their algorithm to subdivide the triangular finite elements based on the distance between the given data points and the model. This is combined with the model's global deformations to construct a hierarchical representation of the given 3D data.", "outcome": "The presented algorithm can represent the shape of an object very efficiently and accurately with a small number of model nodes, improving on conventional representation methods.", "future_impact": "The proposed locally adaptive finite element algorithm has the potential to enhance efficiency and accuracy in hierarchical representation of 3D object shapes, paving the way for improved applications of this technology.", "venue": "ECCV", "year": 1994, "title": "Hierarchical shape representation using locally adaptive finite elements"}
{"pid": "5a2873dc-cc37-460b-a021-8c5acacfabc8", "context": "Traditional methods of texture image description often fail to adequately describe the spatial patterns of image keypoints, which are vital for texture recognition.", "key_idea": "The paper introduces a new texture image descriptor that characterizes the spatial patterns of visual keypoints, viewing them as realizations of a marked point process and defining texture features from multivariate spatial statistics. The descriptor uses cooccurrence statistics of neighboring keypoint pairs for different neighborhood radii.", "method": "The approach relies on constructing a codebook of visual signatures of keypoints, derived from SIFT feature vectors and codebooks issued from a hierarchical clustering algorithm. The authors apply the method to the k-NN, SVM, and Random Forest classifiers and test it on the UIUC texture database and real sonar textures.", "outcome": "The proposed approach favorably compares to previous work when applied to texture recognition, as demonstrated through case studies on the UIUC texture database and real sonar textures.", "future_impact": "The authors suggest further exploration of the properties of the proposed descriptor, including its dimensionality aspects, which may lead to refined texture recognition techniques.", "venue": "ECCV", "year": 2010, "title": "Spatial statistics of visual keypoints for texture recognition"}
{"pid": "6f463b75-475c-4c85-b742-b4ee3b319984", "context": "The Earth Mover's Distance (EMD) is a widely used metric for comparing histograms or probability distributions. In traditional usage, the ground distance between bins of histograms is pre-defined and not optimized.", "key_idea": "Instead of using pre-defined ground distance, the authors propose to jointly optimize the ground distance matrix and the EMD flow-network based on a partial ordering of histogram distances within an optimization framework.", "method": "The authors extend their method to accept information from general labeled pairs and put it to the test in two computer vision applications: face verification on the PubFig and the LFW datasets, and face attribute changes analysis.", "outcome": "The optimized EMD method shows state-of-the-art performance on face verification tasks for both PubFig and LFW datasets. It also realizes consistent paths that demonstrate intuitive transitions on certain facial attributes in the face attribute change analysis.", "future_impact": "The proposed method of optimizing EMD with a ground distance matrix could lead to more accurate EMD values and flow-networks, and consequently improve performance in a variety of applications where histogram comparisons are required.", "venue": "ECCV", "year": 2012, "title": "Supervised earth mover's distance learning and its computer vision applications"}
{"pid": "fd511eba-b59f-450b-849b-e8705dd157ff", "context": "The current methods for interpreting motion computation from oceanographic satellite images use complex physical modeling techniques.", "key_idea": "The paper proposes an alternative motion computation and interpretation framework for oceanographic satellite images that uses a non-quadratic regularization technique in optical flow computation to preserve flow discontinuities, and a phase portrait model to interpret the obtained displacement field.", "method": "The effectiveness of the proposed method is validated by applying it to process oceanographic and atmospheric image sequences.", "outcome": "This new framework demonstrates its capability in processing oceanographic and atmospheric image sequences, offering a viable alternative to the existing complex physical modeling techniques.", "future_impact": "The newly proposed method could potentially be adopted for more accurate and efficient processing of oceanographic and atmospheric image sequences in the future.", "venue": "ECCV", "year": 1996, "title": "Optical Flow and Phase Portrait Methods for Environmental Satellite Image Sequences"}
{"pid": "f894608c-be1d-4c2a-9a10-45ee44561233", "context": "Existing approaches to estimate dense scene flow and structure from stereo sequences rely on a fully calibrated camera setup. These methods are primarily focused on cases where both intrinsic and extrinsic camera parameters are known.", "key_idea": "The authors propose a novel variational method for joint estimation of motion, structure, and geometry from stereo sequences where only the intrinsic camera parameters are known. This method is conceived around a joint energy functional that integrates spatial and temporal information from two subsequent image pairs subject to an unknown stereo setup.", "method": "Their method involves a normalization of image and stereo constraints and introduces a separate discontinuity-preserving regularization. Experiments were conducted on both calibrated and uncalibrated data to test the performance.", "outcome": "Experiments on both calibrated and uncalibrated data demonstrate excellent performance of the proposed approach, and it even outperforms recent techniques for the rectified case that make explicit use of the simplified geometry.", "future_impact": "This new method contributes to the field by allowing for the estimation of dense scene flow and structure from stereo sequences without the need for complete calibration, potentially making this type of analysis more accessible in environments with limited or unknown calibrations.", "venue": "ECCV", "year": 2010, "title": "Joint estimation of motion, structure and geometry from stereo sequences"}
{"pid": "635024b290e50fcafd302e76", "context": "Given an unlabeled dataset and an annotation budget, the standard approach is to propagate labels from labeled data to the rest unlabeled data in semi-supervised learning (SSL). However, this does not ensure that the most effective instances for SSL are labeled.", "key_idea": "The authors propose the idea of unsupervised selective labeling where instances to be labeled are chosen based on their representativeness and diversity, to ensure label propagation and coverage of the entire dataset. The instances are selected as cluster prototypes either in a pretrained feature space, or along with feature optimization.", "method": "The authors apply their unsupervised selective labeling approach to a range of SSL methods and compare its performance with state-of-the-art active learning methods using labeled data.", "outcome": "Their method shows substantial improvements in label efficiency (8-25 times) over existing active learning methods. For example, it improves the FixMatch algorithm by 10% (14%) accuracy on CIFAR-10 (ImageNet-1K) with 0.08% (0.2%) labeled data.", "future_impact": "This work sets a new standard for practical and efficient SSL, particularly in scenarios with a low annotation budget.", "venue": "ECCV", "year": 2022, "title": "Unsupervised Selective Labeling for More Effective Semi-supervised Learning."}
{"pid": "a06a2a2a-f15f-4986-8fa4-f800ff327371", "context": "The recently introduced medoid-shift algorithm in clustering has been thought to be slower than mean shift, and there is an observed problem of over-fragmentation under certain conditions when using medoid shift for clustering data points.", "key_idea": "The authors argue that the medoid shift algorithm is considerably faster than mean shift when the underlying distance is Euclidean and propose an improved version of the medoid shift algorithm and a novel clustering algorithm, called quick shift, that explicitly trades off under- and over-fragmentation.", "method": "The authors exploit kernel methods to extend both mean shift and the improved medoid shift to a large family of distances. They apply these algorithms to clustering data on manifolds and image segmentation tasks, as well as the automatic discovery of visual categories.", "outcome": "The study demonstrates that medoid shift algorithm is indeed faster than mean shift when the underlying distance is Euclidean. The proposed quick shift algorithm effectively handles over-fragmentation issues with medoid shift.", "future_impact": "The new quick shift algorithm can be a useful tool for tasks such as clustering, image segmentation, and visual category discovery. Additionally, the accelerated medoid shift can be used to initialize mean shift for increased efficiency.", "venue": "ECCV", "year": 2008, "title": "Quick Shift and Kernel Methods for Mode Seeking"}
{"pid": "5ecf8d2391e01149f850f4b7", "context": "Current organ/pathology segmentation models trained on publicly available datasets do not adequately represent the diverse modalities, phases, pathologies, and clinical scenarios found in real environments. At the same time, many modern clinical centers have large amounts of unlabelled patient imaging scans.", "key_idea": "The paper proposes a novel segmentation strategy, co-heterogenous and adaptive segmentation (CHASe), which uses a small labeled cohort of single-phase data to adapt to any unlabeled cohort of heterogeneous multi-phase data, including new clinical scenarios and pathologies. The strategy synthesizes appearance-based semi-supervision, mask-based adversarial domain adaptation, and pseudo-labeling and introduces co-heterogeneous training, a combination of co-training and hetero-modality learning.", "method": "The authors evaluate the CHASe approach using a large dataset of multi-phase computed tomography (CT) imaging studies, from 1147 patients and 4577 3D volumes. They test on a set of 100 patients.", "outcome": "Compared to previous state-of-the-art baselines, CHASe improves pathological liver mask Dice-S\u00f8rensen coefficients by ranges of 4.2% to 9.4%, depending on the phase combinations, for example, an increase from 84.6% to 94.0% on non-contrast CTs.", "future_impact": "The proposed method can potentially enable better adaptation of segmentation models to diverse clinical scenarios and pathologies using limited labeled data, thereby enhancing their practical utility in real-world clinical environments.", "venue": "ECCV", "year": 2020, "title": "Co-heterogeneous and Adaptive Segmentation from Multi-source and Multi-phase CT Imaging Data: A Study on Pathological Liver and Lesion Segmentation"}
{"pid": "5ff68d4ed4150a363cd512e1", "context": "Existing facial attribute editing methods typically employ an encoder-decoder architecture with the attribute information being expressed as a conditional one-hot vector spatially concatenated with the image or intermediate feature maps. These methods focus mainly on local semantic mapping, ignoring global facial statistics.", "key_idea": "The authors propose a method for editing global channel-wise information denoted as 'style feature'. The central concept is a generative adversarial network known as SSCGAN (Style Skip Connection Generative Adversarial Network) that manipulates facial attributes through style skip paths between the encoder and decoder.", "method": "The method injects target attribute information into multiple style skip connection paths between the encoder and decoder. Each connection extracts the style feature of the latent feature maps in the encoder and performs a residual learning-based mapping function in the global information space. Additionally, a skip connection based spatial information transfer module is introduced to preserve spatial details.", "outcome": "Experimental results show that the proposed method is capable of producing more accurate attribute generation and higher image quality compared to previous methods.", "future_impact": "The proposed approach may lead to improvements in facial attribute editing and could potentially influence future development in generative adversarial networks for similar tasks.", "venue": "ECCV", "year": 2020, "title": "SSCGAN: Facial Attribute Editing via Style Skip Connections"}
{"pid": "130ffc05-dd5b-4e19-b934-0f020a982bc6", "context": "Estimating the 3D configuration and pose of a human body from a single 2D image is a complex problem in the field of computer vision.", "key_idea": "The paper suggests using the technique of shape context matching in conjunction with a kinematic chain-based deformation model to match the test shape with a stored view that has manually marked joint locations, and use this to estimate the 3D configuration and pose.", "method": "The authors develop a store of 2D views of the human body in a variety of different configurations and viewpoints with manually marked and labelled joint locations. The method is then tested by matching test shapes to these stored views and transferring the joint locations from the exemplar view to the test shape.", "outcome": "The method is successfully used to estimate 3D body configuration and pose from 2D images, demonstrated through results on a variety of datasets.", "future_impact": "The proposed technique can be applied to video analysis by treating each frame independently, which could revolutionize the field of motion tracking, leading to repeated recognition.", "venue": "ECCV", "year": 2002, "title": "Estimating Human Body Configurations Using Shape Context Matching"}
{"pid": "ec0adc99-04c1-440d-b367-45b7020cdecd", "context": "Multi-label problems are common in many applications such as image and video annotations, multi-topic text categorization, music classification, etc. High dimensionality is a key challenge in these tasks. Linear discriminant analysis (LDA) is a known method for tackling high dimensionality but it only works for single-label multi-class classifications.", "key_idea": "This paper proposes a new Multi-label Linear Discriminant Analysis (MLDA) method which extends the classical LDA to deal with multi-label multi-class problems and exploits label correlations to improve classification accuracy.", "method": "The authors test their proposed MLDA method on five public multi-label data sets.", "outcome": "The MLDA method demonstrates excellent performance in extensive experimental evaluations on the five public multi-label datasets.", "future_impact": "Their proposed MLDA approach could potentially provide a generalized solution for multi-label multi-class problems leveraging label correlations.", "venue": "ECCV", "year": 2010, "title": "Multi-label linear discriminant analysis"}
{"pid": "62fb0af090e50fcafd5fd315", "context": "The current state of collaborative robots in industrial environments requires improvements, and the existing graph convolutional networks (GCNs) need better efficiency and sparsity in handling spatial, temporal, and channel-wise dimensions.", "key_idea": "The study introduces a new network, Separable-Sparse Graph Convolutional Network (SeS-GCN), that bottlenecks the interaction of the spatial, temporal and channel-wise dimensions in GCNs and leverages a teacher-student framework to learn sparse adjacency matrices. It also presents a new benchmark, Cobots and Humans in Industrial COllaboration (CHICO), which includes multi-view videos, 3D poses and trajectories of human operators and cobots engaging in realistic industrial actions.", "method": "SeS-GCN is tested on the new CHICO benchmark for two important perception tasks in robotics: human pose forecasting and collision detection by comparing the forecasted human motion with the known cobot motion.", "outcome": "SeS-GCN uses only 1.72% of the parameters and is approx. four times faster than existing state-of-the-art models, it achieves an average error of 85.3 mm (MPJPE) at 1 sec in the future with a runtime of 2.3 msec in human pose forecasting, and an F1-score of 0.64 in collision detection on the CHICO benchmark.", "future_impact": "The introduced SeS-GCN and the CHICO benchmark could lead to improvements in human-robot collaboration in industrial environments by helping cobots be more aware of human operators and improving their pose forecasting and collision detection capabilities.", "venue": "ECCV", "year": 2022, "title": "Pose Forecasting in Industrial Human-Robot Collaboration."}
{"pid": "62f07ec190e50fcafde5abb3", "context": "Recent studies have shown that Deep Neural Networks (DNNs) are vulnerable to backdoor attacks, which lead to malicious behaviors when specific triggers are attached to input images. Existing mitigation strategies involve pruning sensitive channels within the DNNs.", "key_idea": "The paper introduces the concept of Channel Lipschitz Constant (CLC), derived from the Lipschitz constant of channel mapping, capable of identifying potential backdoor channels. The authors propose a Channel Lipschitzness based Pruning (CLP) method to mitigate backdoor attacks.", "method": "The authors investigate the correlation between an Upper bound of the CLC (UCLC) and the trigger-activated change on the channel activation. They use empirical evidence to showcase the direct calculation of UCLC from weight matrices and implement their proposed CLP method for pruning the identified backdoor channels.", "outcome": "Testing shows that the CLP method, a data-free, simple, and fast approach, achieves state-of-the-art results among mainstream defense methods, even without any data.", "future_impact": "The proposed concept and method have the potential to influence the development of robust defenses against backdoor attacks on Deep Neural Networks in a data-free manner.", "venue": "ECCV", "year": 2022, "title": "Data-Free Backdoor Removal Based on Channel Lipschitzness."}
{"pid": "5c696b36-3074-4b99-ad49-e6f9fdf4af7f", "context": "Causal estimation of three-dimensional motion from a sequence of two-dimensional images is a known issue in computer vision, usually addressed by implementing complex filtering problems.", "key_idea": "The authors propose an algorithm to solve the problem of three-dimensional motion estimation from two-dimensional images, which ensures uniform observability, minimal realization and stability. They also offer a solution to handle occlusions, drift in scale factors and filter tuning, and extend the approach to partially calibrated camera models.", "method": "The authors evaluate their proposed algorithm by applying it to several long sequences of real images.", "outcome": "The authors do not provide specific, measurable outcomes in terms of performance, but they mention that they have made their real-time implementation publicly available for testing.", "future_impact": "The implementation is made available to the public, anticipating its potential for widespread use and further testing in real-world applications.", "venue": "ECCV", "year": 2000, "title": "3-D Motion and Structure from 2-D Motion Causally Integrated over Time: Implementation"}
{"pid": "5f21449891e011f62007b043", "context": "Prior volumetric performance capture and novel-view rendering approaches relied on expensive multi-view systems or cumbersome pre-acquisition of a personalized template model. Current high-resolution reconstruction methods, like Pixel-Aligned Implicit Function (PIFu), are computationally expensive, preventing their deployment for real-time applications.", "key_idea": "The authors propose a novel, real-time approach to volumetric performance capture from monocular video. They leverage Pixel-Aligned Implicit Function (PIFu) for high-resolution and memory-efficient reconstruction but introduce a novel hierarchical surface localization algorithm and direct rendering method to circumvent the computational expense.", "method": "A hierarchical surface localization algorithm and direct rendering without explicit surface meshes are used. An Online Hard Example Mining (OHEM) technique that modifies sampling probability based on reconstruction accuracy is also introduced. The system is tested for robustness against various angles, illuminations, poses, and clothing styles.", "outcome": "The proposed method manages to accelerate the reconstruction by two orders of magnitude from the baseline without compromising the quality. The system demonstrates robustness in various situations and compares favorably with the state-of-the-art in monocular performance capture.", "future_impact": "The proposed approach eliminates the need for multi-view studio settings, thereby paving the way for a consumer-accessible solution for volumetric capture.", "venue": "ECCV", "year": 2020, "title": "Monocular Real-Time Volumetric Performance Capture"}
{"pid": "d281041c-603d-4d58-bb18-a14a8bb7cfac", "context": "The problem the study addresses is the separation of specular and diffuse reflection components in images and videos of textured scenes, which typically requires explicit segmentation or manual intervention.", "key_idea": "The authors propose a unified framework which begins with a partial separation supported by an illumination-dependent color space and completes the separation by evolving a partial differential equation (PDE) that erodes the specular component at each pixel.", "method": "The developed framework is tested on high-quality images and video recorded in the laboratory, as well as images sourced from the Internet. The authors also demonstrate an application called dichromatic editing, where the diffuse and specular components are processed separately to produce various visual effects.", "outcome": "The proposed method effectively handles images and videos with different sources, prior information or computations, without the need for explicit segmentation or manual action. It also shows resilience to low dynamic range, JPEG artifacts, and lack of knowledge of illuminant color.", "future_impact": "The authors introduce dichromatic editing as a potential application of their framework, where the diffuse and specular components can be processed independently to create different visual effects. This suggests their work could have a wider impact in the field of image and video editing.", "venue": "ECCV", "year": 2006, "title": "Specularity removal in images and videos: a PDE approach"}
{"pid": "60742017e4510cd7c8725b0c", "context": "Gesture recognition and 3D hand pose estimation are two highly related tasks but they are often treated independently in existing models.", "key_idea": "A novel collaborative learning network is proposed for joint gesture recognition and 3D hand pose estimation, using a multi-order multi-stream feature analysis method. The network uses joint-aware features that boost both tasks, and can be trained even when only gesture or pose labels are available.", "method": "The authors apply the proposed method to gesture recognition and 3D hand pose estimation tasks, utilising intermediate feature maps of videos to learn posture and multi-order motion information efficiently.", "outcome": "Experimental results illustrate that the proposed method offers superior performance in gesture recognition and 3D hand pose estimation tasks compared to state-of-the-art methods.", "future_impact": "The method's capability to learn gesture recognition and 3D hand pose estimation with reduced data labeling efforts could foster advancements in weakly supervised network learning.", "venue": "ECCV", "year": 2020, "title": "Collaborative Learning of Gesture Recognition and 3D Hand Pose Estimation with Multi-order Feature Analysis"}
{"pid": "600fe848d4150a363c240adb", "context": "While there exist many methods for trajectory forecasting, most do not enforce dynamic constraints and do not account for environmental information such as maps.", "key_idea": "The authors present Trajectron++, a modular, graph-structured recurrent model that forecasts the trajectories of a diverse number of agents while incorporating agent dynamics and heterogeneous data like semantic maps.", "method": "Trajectron++ is designed to be tightly integrated with robotic planning and control frameworks and produce predictions optionally conditioned on ego-agent motion plans. Its performance is demonstrated in several real-world trajectory forecasting datasets.", "outcome": "Trajectron++ outperforms a wide array of state-of-the-art deterministic and generative methods in terms of performance for trajectory forecasting in several real-world datasets.", "future_impact": "The ability to tightly integrate Trajectron++ with robotic planning and control frameworks, and its ability to consider ego-agent motion plans, makes it a promising method for use in interactive systems such as self-driving cars.", "venue": "ECCV", "year": 2020, "title": "Trajectron++: Dynamically-Feasible Trajectory Forecasting with Heterogeneous Data"}
{"pid": "e2c1df75-f081-4f33-8016-6029833d20d6", "context": "Catadioptric sensors, widely used on mobile robots, have varying imaging quality based on the mirror shape. Traditional approaches for estimating the blur region typically use numericalor ray tracing methods, with limited understanding of influence of the mirror shape on image blur.", "key_idea": "The authors propose an approach to estimate image blur caused by the shape of the mirror in catadioptric sensors by calculating the locations of the virtual image points for axially symmetrical mirrors using second order approximations. They also present two different omnidirectional stereo sensors designs with single camera and equi-angular mirrors.", "method": "They used their analytical approach to calculate the caustic surfaces and approximated the stereo configuration with two single view points for two different omnidirectional stereo designs. They also demonstrated the use of a physiologically motivated stereo algorithm for panoramic disparity computation.", "outcome": "The proposed equations were shown to be useful in estimating the image blur caused by the mirror shape. The stereo configuration could be approximated by two single view points, yielding an effective vertical stereo baseline of about 3.7cm.", "future_impact": "This work provides a new way to estimate image blur in catadioptric sensors, helping to improve the image quality in mobile robots. It opens up potential for optimizations in sensor design and might also influence approaches to panoramic disparity computation.", "venue": "ECCV", "year": 2004, "title": "The Quality of Catadioptric Imaging \u2013 Application to Omnidirectional Stereo"}
{"pid": "5ff68d44d4150a363cd4e9df", "context": "Current computer-aided diagnosis (CAD) models are far from clinical practice in glaucoma detection due to biases stemming from class imbalance between normal and abnormal cases, and the difficulty of significant samples in fundus images.", "key_idea": "The authors propose EGDCL, a new curriculum learning paradigm that trains an unbiased glaucoma diagnosis model with an adaptive dual-curriculum strategy, addressing training biases using evidence maps.", "method": "EGDCL\u2019s dual-curriculum is jointly optimized with model parameters, emphasizing training contributions from data ranging from easy to hard and normal to abnormal. The performance of EGDCL is evaluated on challenging glaucoma datasets compared with baseline models.", "outcome": "Experimental results show the EGDCL model significantly improves the convergence speed of the training process and obtains superior performance, demonstrated by diagnostics metrics such as sensitivity (0.9721), specificity (0.9707), AUC (0.993), and F2-score (0.966).", "future_impact": "The ability of EGDCL to deliver unbiased diagnosis makes it highly applicable to clinical CAD, potentially improving diagnosis of glaucoma in clinical settings.", "venue": "ECCV", "year": 2020, "title": "EGDCL: An Adaptive Curriculum Learning Framework for Unbiased Glaucoma Diagnosis"}
{"pid": "bd008d66-f0ca-4a58-bcee-2a3e79334137", "context": "Many computer vision applications involve algorithms that can be decomposed into two main steps: detection of events or objects, and assignment of detections to classes. Current evaluation frameworks, such as the classical Precision-Recall, have limitations when applied to these 'detection plus classification' problems, like depth ordering on single images.", "key_idea": "The authors propose an extended evaluation framework called 'Precision-Recall-Classfication' (PRC) to better address the limitations of existing frameworks for 'detection plus classification' problems.", "method": "The PRC framework is applied to depth ordering problems, with specific PRC measures designed to evaluate both local and global depth consistencies. The authors then extend the method of [2] by applying an optimal graph cut on a hierarchical segmentation structure.", "outcome": "The proposed PRC evaluation framework and the extension of the method of [2] demonstrated better performance in evaluating depth ordering systems for monocular images compared to state-of-the-art algorithms.", "future_impact": "The PRC framework can improve the evaluation of 'detection plus classification' problems in many computer vision applications and lead to better algorithms.", "venue": "ECCV", "year": 2014, "title": "Precision-Recall-Classification Evaluation Framework: Application to Depth Estimation on Single Images"}
{"pid": "635024b290e50fcafd302e1c", "context": "Neural Architecture Search (NAS) attempts to automatically generate network architectures suitable for specific tasks on given datasets. Existing NAS strategies are based on reinforcement learning, genetic algorithms, Bayesian optimization, and differential programming.", "key_idea": "The authors propose a novel Neural Architecture Search approach (MF-NAS) that defines the search space and designs the search strategy in a fully graphic manner. It treats the NAS task as a Max-Flow problem on the search space consisting of a Directed Acyclic Graph (DAG).", "method": "The proposed MF-NAS combines different operations, such as skip connection, convolutions and pooling, to induce parallel edges with capacities. The weights and capacities of these parallel edges are updated iteratively during the search process. The approach is evaluated across different datasets with various search spaces used in DARTS/ENAS and NAS-Bench-201.", "outcome": "The paper does not mention the specific outcomes of the experiment conducted.", "future_impact": "The study hints, although doesn't state explicitly, that the presented method, by framing NAS as a Max-Flow problem, might open new perspectives in the NAS field, and encourage new ways to better understand and interpret the relationship between the architecture and the performance of neural networks.", "venue": "ECCV", "year": 2022, "title": "A Max-Flow Based Approach for Neural Architecture Search."}
{"pid": "fbc77422-8386-43fe-81ab-03cd2487e17f", "context": "Existing clustering methods struggle with handling complex relations beyond pairwise between the data points.", "key_idea": "This paper proposes a new way of clustering data given complex n-wise relations by introducing a super-symmetric non-negative factorization of the closest hyper-stochastic version of the input n-way affinity array.", "method": "The researchers derive an algorithm for finding a local minimum solution to the factorization problem, whose computational complexity is proportional to the number of n-tuple samples drawn from the data. The algorithm is applied to a number of visual interpretation problems including 3D multi-body segmentation and illumination-based clustering of human faces.", "outcome": "Not explicitly mentioned in the abstract.", "future_impact": "Not explicitly mentioned in the abstract.", "venue": "ECCV", "year": 2006, "title": "Multi-way clustering using super-symmetric non-negative tensor factorization"}
{"pid": "48c9a9f7-98ec-4a16-b16c-5250cf4d0905", "context": "Automatic detection and tracking of 3D human motion is a complex problem due to the complexities of the human body and its motions. Existing approaches primarily focus on 2D cues, typically exploiting object appearance or static background knowledge.", "key_idea": "The paper suggests exploiting 2D optical flow information for the automatic detection and tracking of human motion in image sequences. This is combined with a newly-developed representation of human motion using low-dimensional spatio-temporal models that are learned from captured human motion data.", "method": "Detection and tracking of motion are considered within a Bayesian framework using a posterior probability distribution over model parameters. Particle filtering is applied to represent and predict the non-Gaussian posterior distribution over time. The model parameters of these samples are related to the pose parameters of a 3D model.", "outcome": "Experimental results on real image sequences indicate that the proposed method can effectively detect and track human motion under different viewpoints with complex backgrounds.", "future_impact": "The described approach could be useful for initializing more complex probabilistic models of human motion.", "venue": "ECCV", "year": 2002, "title": "Automatic Detection and Tracking of Human Motion with a View-Based Representation"}
{"pid": "e954812a-cece-4783-bf44-edd57ce6b86e", "context": "The problem of estimating the 6D Pose of specific objects from a single RGB-D image is currently solved using template-based techniques, which struggle with generic objects and varying lighting conditions.", "key_idea": "The authors propose a flexible approach that uses a learned, intermediate representation in the form of a dense 3D object coordinate labelling paired with a dense class labelling, and can handle both textured and texture-less objects.", "method": "The authors tested their approach on a common dataset with texture-less objects, where template-based techniques are usually applied. They also created a new ground truth dataset with 10k images of 20 objects each captured under three different lighting conditions to test the robustness of their approach.", "outcome": "The proposed approach was found to be slightly superior in terms of accuracy to template-based techniques when used on a common dataset with texture-less objects. It also showed better robustness with respect to varying lighting conditions.", "future_impact": "The proposed approach scales well with the number of objects and is capable of quick execution, showing potential future applications in real-time object pose estimation tasks.", "venue": "ECCV", "year": 2014, "title": "Learning 6D Object Pose Estimation Using 3D Object Coordinates"}
{"pid": "63350ce790e50fcafd350ec9", "context": "Current state-of-the-art methods for image animation typically use convolutional neural networks (CNNs) to predict motion information. However, these CNN-based methods do not explicitly model the interactions between motions, potentially leading to noticeable artifacts in the generated animation video.", "key_idea": "The authors propose a new motion estimator method, the motion transformer, based on a vision transformer. The motion transformer uses two types of tokens: image tokens formed from patch features and position encoding, and motion tokens encoded with motion information.", "method": "The authors introduce the image tokens and motion tokens into vision transformers to promote interactions through multi-head self attention blocks. The embedded motion tokens are then used to predict motion keypoints and local transformations. Experiments are conducted on benchmark datasets.", "outcome": "Experimental results on benchmark datasets show that the proposed motion transformer method achieves promising results compared to the state-of-the-art baselines.", "future_impact": "The authors' source code will be publicly available, potentially impacting the development of future image animation techniques and methods.", "venue": "ECCV", "year": 2022, "title": "Motion Transformer for Unsupervised Image Animation."}
{"pid": "d307db0c-70da-4454-b55d-6a51d1ace12a", "context": "Constraining the evolution of a region-based active contour with respect to a set of reference shapes has been challenged by the issue of shape alignment and the ability to handle different shape topologies.", "key_idea": "The authors introduce a novel way of constraining active contours, using intrinsic affine invariance, by measuring distance between descriptors of the evolving curve and a reference shape via Legendre moments.", "method": "The approach is implemented with any contour evolution algorithm, and tested within a two-class segmentation functional to demonstrate its utility under severe occlusions and clutter.", "outcome": "The examples illustrated the model's capability to handle large affine deformations and to take into account sets of reference shapes with different topologies.", "future_impact": "The proposed method may change the way active contours are constrained, especially in the contexts where large affine deformation and different shape topologies are present.", "venue": "ECCV", "year": 2006, "title": "Affine-Invariant multi-reference shape priors for active contours"}
{"pid": "5f27da6491e0116d6719f869", "context": "Gaze estimation is a key task in many applications however, the methods are trained and tested on custom datasets, making comparisons difficult. Existing gaze estimation datasets also have limited head pose and gaze variations and evaluations use different protocols and metrics.", "key_idea": "The paper proposes a new gaze estimation dataset, ETH-XGaze, consisting of over one million high-resolution images of varying gaze under extreme head poses. This dataset is collected from 110 participants with custom hardware including 18 digital SLR cameras and adjustable illumination conditions.", "method": "A system was set up to record ground truth gaze targets, using a customized hardware setup. The effectiveness of the dataset is validated by showing that it improves the robustness of gaze estimation methods across different head poses and gaze angles.", "outcome": "The launch of the ETH-XGaze dataset improves the robustness of gaze estimation methods across different head poses and gaze angles.", "future_impact": "The authors have set up a standardized experimental protocol and evaluation metric on ETH-XGaze, in order to unify gaze estimation research in the future.", "venue": "ECCV", "year": 2020, "title": "ETH-XGaze: A Large Scale Dataset for Gaze Estimation Under Extreme Head Pose and Gaze Variation"}
{"pid": "ae05e93b-7e8f-4cf4-9242-6229076afa77", "context": "Information related to a fluent human-robot handover process can be complex and is currently not managed effectively in a single system.", "key_idea": "The authors present the design and development of a novel system named OBEliSK for storing, querying, managing all data related to a fluent human-robot handover process by bridging the gap between visual perception and control systems in a robotic setup.", "method": "The authors used a semantic-ontological approach in order to favor system interoperability and extensibility. The method also includes a set of ad-hoc utilities developed to ease knowledge inference, query, and management.", "outcome": "The proposed system provides a level of completeness not previously achieved in other state-of-the-art approaches.", "future_impact": "The proposed knowledgebase in OBEliSK could facilitate more effective and fluid human-robot interactions by managing all the necessary data related to robotic handovers.", "venue": "ECCV", "year": 2014, "title": "OBEliSK: Novel Knowledgebase of Object Features and Exchange Strategies"}
{"pid": "3653313d-bc78-4b44-a14d-ef5cb9805ba4", "context": "An experimental vehicle is being developed for the precise treatment of crops with the goal of reducing chemical use, improving quality, and lowering costs and environmental contamination. To achieve differential treatment of crops and weeds, the vehicle needs to discriminate between crop, weed, and soil.", "key_idea": "The authors present a two-stage algorithm designed for differentiating between crops, weeds, and soil. They also demonstrate the utility of empirical discrepancy methods like type I and II statistical errors and receiver operating characteristic curves for comparing algorithm performance.", "method": "The authors evaluate the performance of the proposed algorithm using a set of test images representative of the vehicle's typical working conditions. The analysis is conducted for the two stages of the algorithm separately as well as for the combined algorithm.", "outcome": "Through their analysis, the authors show how different types of misclassification errors can impact overall algorithm performance.", "future_impact": "This analysis approach can be a valuable methodology for computer vision engineers, providing insights into the effects of misclassification errors on overall algorithm performance.", "venue": "ECCV", "year": 2000, "title": "On the Performance Characterisation of Image Segmenation Algorithms: A Case Study"}
{"pid": "60001c8891e011c8f78fd35d", "context": "Registering images from different imaging modalities is necessary to correlate morphological changes with genetic events in the study of embryonic development. However, traditional methods such as using point clouds have limitations, and cannot simultaneously establish biologically meaningful correspondences.", "key_idea": "The proposed computational pipeline identifies cell-to-cell correspondences between images from multiple modalities, and uses these correspondences to register 3D images within and across imaging modalities. This approach brings two sources of information into a single domain and combines dynamic information on morphogenesis with static gene expression data.", "method": "The proposed pipeline is demonstrated by combining four-dimensional recording of embryogenesis of the Spiralian annelid ragworm Platynereis dumerilii with three-dimensional scans of fixed Platynereis dumerilii embryos stained for the expression of different developmental genes. The approach is compared with traditional methods for aligning point clouds.", "outcome": "The proposed approach outperforms traditional methods on real biological imaging datasets and matches the accuracy of state-of-the-art registration pipelines on synthetic data. Importantly, it provides matching of corresponding, biologically meaningful entities within the registered specimen.", "future_impact": "The proposed pipeline, available for public use through a Fiji plugin, will enable researchers to generate biological insights from combined datasets by not only registering images from different modalities but also establishing cellular correspondences.", "venue": "ECCV", "year": 2020, "title": "Registration of Multi-modal Volumetric Images by Establishing Cell Correspondence."}
{"pid": "62d7731a5aee126c0f90400d", "context": "Lane detection is a critical method for autonomous systems. Numerous approaches have been presented, however, the challenge is not fully resolved as most techniques either consider lane detection as a dense prediction or a detection task, disregarding the distinctive lane marker topologies.", "key_idea": "The paper proposes a new method for lane detection based on relay chain prediction. The model predicts a segmentation map and determines foreground and background regions, then for each pixel in the foreground, the forward and backward branches are used to recover the complete lane.", "method": "The method involves decoding a transfer map and a distance map for each branch to provide the direction towards the next point and calculate the steps needed to predict a relay station (next point).", "outcome": "Despite its simplicity, this strategy allowed the establishment of a new state-of-the-art on four major benchmarks such as TuSimple, CULane, CurveLanes, and LLAMAS.", "future_impact": "This new method for lane detection based on relay chain prediction, with its ability to capture keypoints along lanes, could inform future designs and advances in autonomous systems.", "venue": "ECCV", "year": 2022, "title": "RCLane: Relay Chain Prediction for Lane Detection."}
{"pid": "99ee5d91-3000-4088-9cf9-eb4533674c07", "context": "Obstacle detection during the motion of a mobile robot has been a challenge with the contemporary methodologies.", "key_idea": "The authors introduce an innovative obstacle detection methodology based on the estimation of the optical flow. The method computes the optical flow only on one row of the image relative to the ground plane, making it more efficient.", "method": "The detection algorithm is based on a correlation scheme which stabilizes the position of the focus of expansion using a Kalman filter. The authors make use of the knowledge of the focus position of the flow field computed in the previous times to reduce the search space of corresponding patches and to predict the flow field in the successive one.", "outcome": "The method successfully detects obstacles lying on the ground on the path of a mobile platform with no extra calibration procedure required.", "future_impact": "The proposed method could significantly enhance the obstacle detection capability and speed in mobile robotics, marking it a potential choice for implementing in real-world robotic and autonomous systems.", "venue": "ECCV", "year": 1992, "title": "A Fast Obstacle Detection Method based on Optical Flow"}
{"pid": "5f33bee291e011861cfa101d", "context": "There has been a need identified for a real-time sign language detection model in videoconferencing situations.", "key_idea": "The authors propose a lightweight, real-time sign language detection model that uses optical flow features based on human pose estimation and a linear classifier.", "method": "The proposed model is evaluated on the DGS Corpus. The authors applied a recurrent model directly on the input to improve the classifier's accuracy.", "outcome": "The proposed model achieved an accuracy of 80% and up to 91% accuracy when a recurrent model is applied directly on the input. The model works under 4ms.", "future_impact": "The authors provided a demo application for sign language detection in the browser to demonstrate its possible use in videoconferencing applications, which could have broad impacts in making communication more accessible.", "venue": "ECCV", "year": 2020, "title": "Real-Time Sign Language Detection using Human Pose Estimation"}
{"pid": "5e7495c591e0111c7cee12f6", "context": "Current methods for instance segmentation in videos involve multi-stage pipelines that view a video clip as a sequence of images, detect objects in individual frames, and then associate these detections over time. These methods are often non-end-to-end trainable and highly tailored to specific tasks.", "key_idea": "The authors propose a single-stage, proposal-free network that models a video clip as a single 3D spatio-temporal volume and uses spatio-temporal embeddings to segment and track instances across space and time in one go.", "method": "The authors introduced novel mixing functions to enhance the feature representation of spatio-temporal embeddings and trained an end-to-end network to learn these embeddings and the parameters needed for clustering them.", "outcome": "The proposed method achieves state-of-the-art results across multiple datasets and tasks.", "future_impact": "The new approach proposed in this paper may inspire further research in various tasks involving instance segmentation in videos. It could potentially simplify and improve the process of video segmentation and tracking.", "venue": "ECCV", "year": 2020, "title": "STEm-Seg: Spatio-Temporal Embeddings for Instance Segmentation in Videos"}
{"pid": "5ea9503e91e0118eb1e19f78", "context": "Recent research on learned visual descriptors has shown improvements in correspondence estimation, which is important for many 3D vision tasks. However, existing descriptor learning frameworks typically require ground-truth correspondences between feature points, which are challenging to acquire at scale.", "key_idea": "This paper proposes a weakly-supervised framework, called CAPS descriptors, that can learn feature descriptors from relative camera poses between images, eliminating the need for pixel-level ground-truth correspondences.", "method": "The authors devise a new loss function that uses the epipolar constraint given by camera poses, and a new model architecture that makes the whole learning pipeline differentiable and efficient.", "outcome": "CAPS descriptors, though trained with weak supervision, outperform prior fully-supervised descriptors and achieve state-of-the-art performance on a variety of geometric tasks.", "future_impact": "The proposed framework paves the way for training on much larger and more diverse datasets, potentially leading to better and unbiased descriptors for the field of 3D vision tasks.", "venue": "ECCV", "year": 2020, "title": "Learning Feature Descriptors Using Camera Pose Supervision"}
{"pid": "7a633eba-0cf7-46fc-975a-381b1bdb5a2b", "context": "The current state of texture recognition systems involve complex processes and methodologies, and tend to trade off between speed and accuracy.", "key_idea": "The authors propose a new texture recognition system which provides locally and globally invariant representations through the combination of a multi-resolution convolutional network, a novel multifractal descriptor, a generative PCA classifier combined with multiclass SVMs, and training set augmentation strategies.", "method": "To validate the proposed solution, experiments were conducted on three challenging public benchmark datasets.", "outcome": "The proposed solution outperformed existing methods on all tested public benchmark datasets while maintaining computational efficiency.", "future_impact": "This new texture recognition system presents an improvement in both speed and accuracy over existing methods, which can have a significant impact on applications where texture recognition plays a critical role.", "venue": "ECCV", "year": 2014, "title": "Fast and Accurate Texture Recognition with Multilayer Convolution and Multifractal Analysis"}
{"pid": "5f1569cc91e011d7db223a98", "context": "In current research, there is the problem of spatio-temporally localizing visual relations in videos to provide supportive visual facts for high-level video-language tasks. Existing methods face challenges including: (1) the necessity of localizing both the subject and object to ground a relation, (2) the difficulty in capturing the dynamic nature of visual relations in videos, and (3) the need to achieve grounding without direct supervision in space and time.", "key_idea": "The paper introduces a novel task, visual Relation Grounding in Videos (vRGV), and proposes a new approach of collaboratively optimizing two sequences of regions over a constructed hierarchical spatio-temporal region graph with relation attending and reconstruction.", "method": "To validate their approach, the authors designed experiments using a message passing mechanism by spatial attention shifting between visual entities.", "outcome": "Experimental results showed that their proposed model significantly outperforms baseline approaches, and can produce visually meaningful facts to support visual grounding.", "future_impact": "The proposed visual Relation Grounding in Videos (vRGV) task can potentially contribute to the field of high-level video-language tasks, such as video-language grounding and video question answering.", "venue": "ECCV", "year": 2020, "title": "Visual Relation Grounding in Videos"}
{"pid": "5f75b36691e0111c1eb4d467", "context": "Existing approaches for applying Deep Neural Networks (DNNs) to image compression either train a post-processing DNN on the decoder side or propose end-to-end learning. These approaches require the trained DNNs in the decoder, which leads to incompatibility with standard image decoders (e.g., JPEG) in personal computers and mobiles.", "key_idea": "This paper proposes learning to improve the encoding performance while maintaining compatibility with the standard decoder, exemplified with JPEG. The authors introduce a frequency-domain pre-editing method to optimize the distribution of Discrete Cosine Transformation (DCT) coefficients and propose learning the JPEG quantization table in conjunction with the pre-editing network.", "method": "Experiments are conducted to validate the performance of the proposed method to improve the rate-distortion performance of JPEG, measured by various quality metrics such as PSNR, MS-SSIM, and LPIPS. This includes retaining overall color when strong compression is applied.", "outcome": "The experiments confirm the success of the proposed method in improving the rate-distortion performance of JPEG, leading to better overall color retention, especially when strong compression is applied.", "future_impact": "The study is likely to promote the development of techniques that improve image encoding while ensuring compatibility with standard decoders, thereby enhancing the practical use of DNNs in image compression tasks.", "venue": "ECCV", "year": 2020, "title": "Learning to Improve Image Compression without Changing the Standard  Decoder"}
{"pid": "6216f7615aee126c0fc5fe23", "context": "Building an instance segmentation model for a large number of classes in complex scenes faces the challenge of lack of training examples, especially for rare objects.", "key_idea": "The paper explores the possibility of increasing the training examples without laborious data collection and annotation. The authors propose a simple and scalable framework, FreeSeg, which extracts and leverages 'free' object foreground segments to facilitate model training in long-tailed instance segmentation.", "method": "The authors investigate the similarity among object-centric images of the same class to propose candidate segments of foreground instances. They then rank the segment quality, with the high-quality object segments used to augment the existing long-tailed datasets by copying and pasting the segments onto the original training images.", "outcome": "Extensive experiments show that FreeSeg significantly improves upon strong baselines and achieves state-of-the-art accuracy for segmenting rare object categories.", "future_impact": "The insights and approach proposed in this paper could play a crucial role in facilitating model training in long-tailed instance segmentation, especially in scenarios with a lack of training examples for rare objects.", "venue": "ECCV", "year": 2022, "title": "Learning with Free Object Segments for Long-Tailed Instance Segmentation."}
{"pid": "626b49625aee126c0fffd161", "context": "4D human sensing and modeling are fundamental tasks in vision and graphics, and with advances in sensors and algorithms, there is a need for more versatile datasets.", "key_idea": "The authors introduce HuMMan, a new large-scale multi-modal 4D human dataset with 1000 human subjects, 400k sequences, and 60M frames, including multiple kinds of data and annotations and being capable of addressing multiple tasks.", "method": "The authors created a dataset using popular mobile devices to capture multi-modal data on various actions, including color images, point clouds, keypoints, SMPL parameters, and textured meshes, used in various tasks.", "outcome": "Their extensive experiments on HuMMan highlight ongoing challenges such as fine-grained action recognition, dynamic human mesh reconstruction, point cloud-based parametric human recovery, and cross-device domain gaps.", "future_impact": "This dataset could enable the development of new methods and further research in various areas such as action recognition, pose estimation, parametric human recovery, and textured mesh reconstruction.", "venue": "ECCV", "year": 2022, "title": "HuMMan: Multi-modal 4D Human Dataset for Versatile Sensing and Modeling."}
{"pid": "5f3660ff91e011372ac2d915", "context": "Robustness to small image translations is desirable for object detectors. However, it's known that CNN-based classifiers are not shift invariant. The extent to which this could impact object detection is unclear, given the architectural differences and the dimensionality of the prediction space of modern detectors.", "key_idea": "The authors propose an evaluation metric to assess the shift equivariance of object detection models. This metric uses a greedy search of the lower and upper bounds of the mean average precision on a shifted image set.", "method": "The authors use this metric to evaluate modern one-stage, two-stage, anchor-based, and anchor-free object detection architectures. They test several solutions to the problem of shift variance, both from the literature and newly proposed, using this metric.", "outcome": "Results show that modern object detection architectures are sensitive to even one pixel shift to the input images. Furthermore, none of the investigated methods provide full shift equivariance.", "future_impact": "Measuring and analyzing the extent of shift variance of different models and the contributions of possible factors could be the first step towards devising methods that mitigate or even leverage such variabilities.", "venue": "ECCV", "year": 2020, "title": "Shift Equivariance in Object Detection"}
{"pid": "9840af8a-e6d5-403b-a37b-2ce3f1e137bb", "context": "Learning to perform class-based segmentation traditionally requires fully segmented training examples, with the segmentation of objects in the training examples being performed manually.", "key_idea": "The authors propose a new approach for learning class-based segmentation that only requires unsegmented training examples by first extracting fragments with common object parts and then segmenting those parts into their figure and ground regions through an automatic learning process.", "method": "The method involves an initial approximation that produces figure-ground labeling of individual image fragments using the unsegmented training images. This step utilizes the fact that points inside the object are covered by more fragments than points outside it. The initial labeling is then refined through an iterative process which iteratively produces a segmentation of complete objects in the training images that further refines the figure-ground labeling of individual fragments.", "outcome": "The novel scheme starts from unsegmented training images, learns the figure-ground labeling of image fragments, and then uses this labeling to segment new images achieving the same level of accuracy as methods requiring manual segmentation of training images.", "future_impact": "The new approach has the potential to provide an automatic and robust top-down segmentation solution, reducing the need for extensive manual segmentations during training.", "venue": "ECCV", "year": 2004, "title": "Learning to Segment"}
{"pid": "6066fa2a91e011f2d6d47ca1", "context": "Most neural video codecs address P-frame coding which involves predicting each frame from past ones.", "key_idea": "The paper extends conventional P-frame coding to B-frame compression, where frames are predicted using both past and future reference frames, by interpolating the two reference frames to generate a single reference frame and then using it with an existing P-frame codec.", "method": "The proposed B-frame coding method was incorporated into an existing neural codec and tested on the UVG dataset.", "outcome": "By using their proposed method with an existing P-frame codec, a 28.5% bit-rate saving is achieved on the UVG dataset, compared to using the P-frame codec only, while generating the same video quality.", "future_impact": "The B-frame coding solution presented can be easily integrated into existing neural codecs, providing a simple way to enhance compression efficiency.", "venue": "ICCV", "year": 2021, "title": "Extending Neural P-frame Codecs for B-frame Coding."}
{"pid": "6528c21d939a5f408299d993", "context": "Traditional architecture designs for vision learning models focus on enhancing expressiveness through channel expansion or additional building blocks, often at the expense of increased computational resources.", "key_idea": "The authors propose a new architecture that incorporates multiple head classifiers and employs attention-based aggregation, using pairwise feature similarity compute Gramian matrices to enhance class tokens in each attention layer for each head. Furthermore, they introduce a learning algorithm that minimizes correlation for aggregation.", "method": "The authors conducted their experiments on various tasks, such as imaging training on the ImageNet-1K, COCO object instance segmentation, ADE20k semantic segmentation and fine-grained visual classification datasets.", "outcome": "The proposed models surpass the state-of-the-art CNNs and ViTs in terms of the accuracy-throughput trade-off on ImageNet-1K and deliver strong performance on other tasks such as COCO object instance segmentation, ADE20k semantic segmentation, and fine-grained visual classification datasets.", "future_impact": "The new model architecture, which provides enhanced expressiveness and representation learning capacity, may change the way vision learning models are constructed, potentially leading to better performance on a variety of tasks with minimal resource overhead.", "venue": "ICCV", "year": 2023, "title": "Gramian Attention Heads are Strong yet Efficient Vision Learners"}
{"pid": "a6f4fb15-fd2d-461f-85d3-58559864fd0a", "context": "In the past, there was no efficient method to estimate a continuous transformation that maps one N-dimensional distribution to another.", "key_idea": "The paper introduces an original, iterative, and non-linear method to estimate a continuous transformation that maps one N-dimensional distribution to another, using only 1D marginal distribution, reducing computation costs.", "method": "The authors illustrate the method's application through color transfer between two images of different contents.", "outcome": "The paper demonstrates that the proposed method converges.", "future_impact": "This paper could serve as a central focal point for further research in this area, potentially leading to advances in automated color grading.", "venue": "ICCV", "year": 2005, "title": "N-dimensional probability density function transfer and its application to color transfer"}
{"pid": "f55d99a7-e6aa-43e6-8b50-4e3c1db63a5e", "context": "Energies with high-order non-sub modular interactions are very useful in vision due to their high modeling power. But optimization of such energies is generally NP-hard. A naive approach for small problem instances is exhaustive search by enumeration of all possible labelings of the underlying graph.", "key_idea": "The authors propose a minimization approach for large graphs based on enumeration of labelings of certain small patches, which reduces complex high-order energy formulations to pairwise Constraint Satisfaction Problems with unary costs (uCSP).", "method": "The proposed partial enumeration technique is applied on well known difficult problems such as curvature regularization, stereo, deconvolution, and evaluated using a novel integral geometry approach.", "outcome": "The proposed approach outperforms a number of existing state-of-the-art algorithms on well known difficult problems, providing near global minimum and better speed.", "future_impact": "The novel application of the proposed technique is in curvature regularization, within the context of segmentation, enabling direct evaluation of curvature on small patches using a novel integral geometry approach.", "venue": "ICCV", "year": 2013, "title": "Partial Enumeration and Curvature Regularization"}
{"pid": "61022ef65244ab9dcb92322e", "context": "Reconstruction-based methods are key in unsupervised anomaly detection in images. However, controlling the generalizability of deep neural networks, such as autoencoders, for these tasks is challenging.", "key_idea": "The authors propose a novel divide-and-assemble approach where image reconstruction is viewed as a divide-and-assemble procedure and varying the granularity of division on feature maps can affect the reconstruction quality. Furthermore, a novel multi-scale block-wise memory module is introduced into an autoencoder network.", "method": "Adversarial learning is introduced and the semantic latent representation of the discriminator is explored. The divide-and-assemble method is tested on the challenging MVTec AD dataset.", "outcome": "The divide-and-assemble approach achieves state-of-the-art performance on the MVTec AD dataset, improving the vanilla autoencoder model by 10.1% in terms of the AUROC score.", "future_impact": "This novel approach to unsupervised anomaly detection, if further developed, has the potential to significantly improve the efficiency and accuracy of detecting subtle anomalies in image data.", "venue": "ICCV", "year": 2021, "title": "Divide-and-Assemble - Learning Block-wise Memory for Unsupervised Anomaly Detection."}
{"pid": "619656b66750f82d7d6de59d", "context": "Free-hand sketches present unique challenges to computer vision models due to their inherent abstraction and flexibility. Current methods may struggle to accommodate this abstract nature.", "key_idea": "The authors propose a novel sketch representation for human sketches, intended to accommodate their abstract nature. This is done by interpreting sketch abstraction on two levels: appearance and structure, with the structure abstracted as a pre-defined coarse-to-fine visual block hierarchy and the appearance modeled by averaging visual features within each block.", "method": "The authors validate the proposed representation method across a range of sketch analysis tasks, including sketch recognition, fine-grained sketch-based image retrieval, and generative sketch healing. They also discuss three strategies to exploit feature synergy across different levels of the abstraction hierarchy.", "outcome": "The abstract sketch representation yields strong results across all tested tasks, demonstrating its superiority in explicitly handling sketch abstraction.", "future_impact": "The proposed design could improve performance on various downstream tasks in computer vision involving sketches, owing to its intuitive feature granularity control. The authors plan to make the code publicly available, potentially allowing for broader use and development of this methodology.", "venue": "ICCV", "year": 2021, "title": "SketchAA - Abstract Representation for Abstract Sketches."}
{"pid": "6115ff2f5244ab9dcb6a6699", "context": "Deep neural networks (DNNs) for image classification often rely on easy-to-represent visual factors or shortcut opportunities (SO), leading to poor generalization. However, these networks also suffer from shortcut learning when predicting basic visual object factors of variation (FoVs) such as shape, color, or texture.", "key_idea": "The authors argue that DNNs also need to exploit generalization opportunities (GO), which arise from partial independence between predicted classes and FoVs, to counteract shortcut learning.", "method": "The authors introduce the Diagnostic Vision Benchmark suite DiagViB-6, including datasets and metrics to study a network's vulnerability to shortcuts and generalization capability for six independent FoVs. The authors control the type and degree of SO and GO in a dataset and benchmark a range of popular vision architectures.", "outcome": "The benchmarking of popular vision architectures on DiagViB-6 showed that these architectures exploit generalization opportunities only to a limited extent.", "future_impact": "The DiagViB-6 could be helpful in future research to study networks' vulnerability to shortcuts and generalization capabilities, which could lead to improvements on the exploitation of generalization opportunities.", "venue": "ICCV", "year": 2021, "title": "DiagViB-6 - A Diagnostic Benchmark Suite for Vision Models in the Presence of Shortcut and Generalization Opportunities."}
{"pid": "e547d6dd-ce6a-4de3-bfce-624f092bc4de", "context": "Existing methods for controlling home appliances remotely often involve specific controllers or remote devices, and do not offer personalized control based on the user's identity.", "key_idea": "The authors propose a system for controlling home appliances that utilizes face and hand sign recognition, assigning unique commands to individual users' hand signs and restricting access to certain appliances and functions based on user recognition.", "method": "The authors implemented their proposed method using hierarchical discriminant analysis on a laptop computer, developing a real-time system capable of controlling home appliances by recognizing faces and hand signs.", "outcome": "The proposed system can control various appliances in the home remotely and is capable of recognizing users and assigning distinct commands based on their hand signs.", "future_impact": "The proposed system may pave the way for more personalized and secure control of home appliances through face and hand sign recognition.", "venue": "ICCV", "year": 2001, "title": "Control of home appliances using face and hand sign recognition"}
{"pid": "4931b617-706e-461e-b0e2-e46829c97904", "context": "In previous works of face recognition, the similarity between faces is measured by comparing corresponding face regions (matching eyes with eyes and mouths with mouths).", "key_idea": "The paper proposes that a face can be recognized by matching non-corresponding facial regions (like matching eyes with mouths). The problem addressed is how to measure the possibility whether two non-corresponding face regions belong to the same face.", "method": "The authors propose measuring this possibility using canonical correlation analysis, and validate it through undisclosed experimental methods.", "outcome": "Experimental results show that it is feasible to recognize a face via non-corresponding region matching, proving the proposed method to be an effective alternative for face recognition.", "future_impact": "The proposed method provides a more flexible way to recognize faces, which may broaden the capabilities and applications of face recognition technologies.", "venue": "ICCV", "year": 2011, "title": "Face recognition based on non-corresponding region matching"}
{"pid": "c09d864a-dc68-4558-b6f7-fb7ed1d7f573", "context": "Acquisition and preparation of 3D imaging data is a significant aspect in application areas such as orthodontics and cultural heritage that entail scanning services for museum exhibits and other historic objects.", "key_idea": "The paper discusses the use of specific scanning devices by the research team for the acquisition of 3D imaging data.", "method": "The authors use specific scanning devices to acquire 3D imaging data of museum exhibits and other historic objects. The presentation of these 3D data across various hardware contexts and for different user categories is also described.", "outcome": "The paper demonstrates successful acquisition and preparation of 3D imaging data using the discussed scanning devices, although specific results are not presented in the abstract.", "future_impact": "The study does not explicitly lay out potential research directions, but the successful acquisition of 3D data could pave the way for advancements in orthodontics and the preservation of cultural heritage.", "venue": "ICCV", "year": 2008, "title": "Collecting 3D Content: Examples from Art and Medicine"}
{"pid": "3399a521-9586-4c8c-9f82-0f210f854436", "context": "While dense stereo algorithms can estimate disparities at all pixels, including untextured regions, they typically evaluate these disparities at integer disparity steps. Most sub-pixel estimation algorithms primarily focus on textured image areas, often failing to propagate smoothness constraints on a sub-pixel level.", "key_idea": "The paper proposes the improvement of the sub-pixel accuracy in low-textured regions through three ways: evaluation of the disparity space at fractional disparities, the introduction of a new disparity smoothing algorithm that enforces smoothness at a sub-pixel level, and a novel stereo constraint (gravitational constraint) that reduces false matches in low-textured regions.", "method": "Large-scale 3D reconstruction was used to test the improvements, particularly with a multi-baseline extension. Evaluation was done using semi-global matching on the Middlebury stereo ground truth data sets and in urban scenes.", "outcome": "The implemented improvements, termed ImproveSubPix, were shown to be amongst the top-performing algorithms in evaluating the set on a sub-pixel level while being computationally efficient, based on results from the Middlebury stereo ground truth data sets and urban scenes.", "future_impact": "These improvements, applicable independently of the underlying type of stereo algorithm, can also be applied to sparse stereo algorithms, potentially improving large-scale 3D reconstruction.", "venue": "ICCV", "year": 2007, "title": "Improving Stereo Sub-Pixel Accuracy for Long Range Stereo"}
{"pid": "99f7ad1b-26a6-425b-b18b-c3aea8175879", "context": "In the existing literature, image dissimilarity measures have been based on distributions of color and texture features, but a comprehensive comparison of these measures is missing.", "key_idea": "This paper introduces an empirical comparison of nine different image dissimilarity measures based on color and texture features.", "method": "Over 1,000 hours of computational experiments were conducted, and ground truth data was collected via a novel random sampling scheme for color and an image partitioning method for texture. The performances of the dissimilarity measures were evaluated quantitatively on classification, image retrieval, and segmentation tasks.", "outcome": "The authors demonstrate that the selection of a dissimilarity measure, based on large scale evaluation, substantially improves the quality of classification, retrieval, and unsupervised segmentation of color and texture images.", "future_impact": "Based on the empirical evaluation provided in this study, future research can better select dissimilarity measures that would significantly improve performance outcomes in image processing tasks.", "venue": "ICCV", "year": 1999, "title": "Empirical evaluation of dissimilarity measures for color and texture"}
{"pid": "196d6266-7e40-45e2-81aa-cace2e4a2e8b", "context": "The observed fall-off in irradiance for off-axis points in real lenses has been attributed to the cosine-fourth and vignetting effects. However, disparities between the observed and accounted for fall-off have been observed.", "key_idea": "The authors propose that even without vignetting, a point light source does not uniformly illuminate the aperture due to an effect known as pupil aberration. This effect, which contributes to the fall-off in irradiance away from the image center, strongly depends on the aperture size and shape.", "method": "The paper critically evaluates the roles of cosine-fourth and vignetting effects and demonstrates the significance of the pupil aberration on the fall-off in irradiance away from image center through two sets of experiments with three real lenses.", "outcome": "The authors found the variation due to pupil aberration for a 16 mm lens to be as large as 31% for a field angle of 10/spl deg/. The research concluded that pupil aberration is a third cause of fall in irradiance, in addition to the cosine-fourth and vignetting effects.", "future_impact": "The discovery of the impact of pupil aberration on irradiance fall-off should be considered in applications that rely heavily on photometric variation such as shape from shading and mosaicing.", "venue": "ICCV", "year": 2001, "title": "On cosine-fourth and vignetting effects in real lenses"}
{"pid": "8e39112e-1b6c-49db-88d3-fb56e41ca5c0", "context": "The image reflectance function mapping from surface normals to intensities under varying lighting conditions is a fundamental question in computer vision, which has not previously been effectively modelled within a low-dimensional linear subspace.", "key_idea": "The authors propose that reflectance functions produced by Lambertian surfaces under distant, isotropic lighting can be accurately approximated within a 9D linear subspace.", "method": "The authors developed a simple analytic characterization of the linear space. Their approach relies on representing lighting using spherical harmonics and describing the effects of Lambertian materials as the analog of a convolution.", "outcome": "The findings provide a convincing approximation for the image reflectance function in a 9D linear space, explaining prior empirical results.", "future_impact": "This approach enables the construction object recognition algorithms based on linear methods as well as algorithms that use convex optimization to enforce non-negative lighting functions, promoting progress in computer vision applications.", "venue": "ICCV", "year": 2001, "title": "Lambertian reflectance and linear subspaces"}
{"pid": "550283c7-322a-497a-9120-f011e1adfe99", "context": "The problem of reconstructing the shape of a surface with an arbitrary, spatially varying isotropic bidirectional reflectance distribution function (BRDF) has yet to be successfully solved.", "key_idea": "The paper introduces a stratified photometric stereo method that employs a special configuration of lights. This allows symmetry in image measurements which in turn gives the plane containing the surface normal at every point on differentiable surfaces.", "method": "Using real and synthetic data, the technique is validated by successfully recovering the isocontours of the depth map from images.", "outcome": "The technique managed to estimate the topological information of the surface and resolve the metric structure by estimating the unknown height of each isocontour from images.", "future_impact": "The stratified photometric stereo method could pave the way for further development and improvement of techniques for reconstructing the shape of surfaces with isotropic BRDF.", "venue": "ICCV", "year": 2007, "title": "Toward Reconstructing Surfaces With Arbitrary Isotropic Reflectance : A Stratified Photometric Stereo Approach"}
{"pid": "0f2e525d-67a1-46d0-b6f3-d756e77737ef", "context": "Evolved space curves arise when computing the Torsion and Curvature Scale Space representation of a space curve. They have properties like uniform scaling, rotation and translation invariance, and connectedness and closedness preservation during evolution.", "key_idea": "The authors investigate a number of evolution properties of space curves, including invariance under rotation, uniform scaling, and translation, preservation of connectedness and closedness during evolution, and maintaining the center of mass as the curve evolves.", "method": "The study examines an evolved curve just before and after the formation of a cusp point. It convolves a parametric representation of the curve with a Gaussian function of variance (labeled 'evolution'). The ordered sequence of curves obtained from this process is investigated. Lemmas are used to validate the stated properties.", "outcome": "The space curve's evolution has been shown to be invariant under rotation, uniform scaling, and translation. Other properties such as connectedness and closedness during evolution, stability of the center of mass during evolution, and confinement inside its convex hull during evolution were demonstrated.", "future_impact": "The results obtained in the paper could be integral and beneficial for practical applications involving the evolution of space curves, potentially influencing shape representation and object recognition research.", "venue": "ICCV", "year": 1988, "title": "Evolution Properties Of Space Curves"}
{"pid": "6180ac435244ab9dcb793afb", "context": "Traditional Deep Neural Network (DNN) quantization frameworks typically assign uniform quantization schemes within layers of the DNN weight matrix, often resulting in limitations in terms of hardware inference operations and accuracy.", "key_idea": "This study introduces a novel DNN quantization framework called RMSMP, which utilizes a row-wise mixed-scheme and multi-precision approach. This framework enables different levels of precision within layers of the DNN weight matrix, allowing for more efficient hardware operations while preserving accuracy.", "method": "The RMSMP quantization algorithm uses the Hessian and variance-based method to effectively assign schemes and precisions for each row. The authors tested RMSMP on image classification and natural language processing (BERT) applications and implemented it on FPGA devices, comparing its performance with a 4-bit Fixed-point baseline.", "outcome": "The RMSMP framework resulted in superior accuracy performance among state-of-the-art models under the same equivalent precisions. When implemented on FPGA devices, it achieved 3.65 times speedup in end-to-end inference time for ResNet-18 on ImageNet compared with the 4-bit Fixed-point baseline.", "future_impact": "The unusual observation in this study, that quantization error can be mitigated as long as a certain portion of weights in every layer are in higher precisions, has potential to guide further layer-wise adjustment strategies in hardware implementation for better inference acceleration.", "venue": "ICCV", "year": 2021, "title": "RMSMP - A Novel Deep Neural Network Quantization Framework with Row-wise Mixed Schemes and Multiple Precisions."}
{"pid": "37602918-856f-43e9-ae9d-0bcaf1bfaf6b", "context": "Human speech is inherently multi-modal, consisting of both audio and visual components. Recent research has shown that adding information about lip position to acoustic speech recognizers enhances the robustness of noisy speech recognition.", "key_idea": "This paper proposes the real-time tracking of unadorned lips (both the inner and outer contours) on general-purpose workstations as an aid to robust speech recognition.", "method": "To achieve real-time lip tracking, the authors employ efficient algorithms with three key components: shape models, motion models, and focused color feature detectors, all of which are learnt from examples.", "outcome": "The research demonstrates that using visual signals, such as tracking the position of the lips, can stabilize the alignment of states in Hidden Markov Model-recognition.", "future_impact": "The real-time tracking of unadorned lips may significantly contribute to improving speech recognition systems, particularly in noisy environments.", "venue": "ICCV", "year": 1998, "title": "Accurate, real-time, unadorned lip tracking"}
{"pid": "6514e2043fda6d7f062dcafb", "context": "The current focus in dealing with distribution shifts in data during the deployment of neural networks involves trying to anticipate and counter the shift at the training time. This approach can be limited in handling unexpected shifts.", "key_idea": "The authors propose a closed-loop system that uses a test-time feedback signal to adapt a network on the fly, resulting in a learning-based function that acts as an amortized optimizer for the network. They call this Rapid Network Adaptation (RNA).", "method": "The authors validate their method through a range of experiments using various adaptation signals and target tasks on different datasets, tasks, and distribution shifts.", "outcome": "RNA displayed promising results in terms of flexibility and speed, outperforming baseline methods significantly in numerous scenarios involving varying datasets, tasks, and distribution shifts.", "future_impact": "The authors suggest further research into generalized methodologies for handling distribution shifts and anticipate a paradigm shift from focused training-time robustness mechanisms to more flexible test-time adaptation mechanisms.", "venue": "ICCV", "year": 2023, "title": "Rapid Network Adaptation: Learning to Adapt Neural Networks Using   Test-Time Feedback"}
{"pid": "6064680291e011538305d1af", "context": "Gradient-based algorithms are key to modern computer-vision and graphics applications. Such differentiable rendering pipelines have been successful for color images applications that need to map 2D and 3D domains, but their extension to the generation of depth (2.5D) images has remained unexplored due to the complexity of simulating structured-light depth sensors.", "key_idea": "The authors introduce a novel end-to-end differentiable simulation pipeline for the generation of realistic 2.5D scans, built on physics-based 3D rendering and custom block-matching algorithms.", "method": "The new depth sensor simulation pipeline can be differentiated with respect to sensor and scene parameters. It is used to tune the simulation for new devices over some provided scans and to train deep-learning methods for various depth-based recognition tasks such as classification, pose estimation, and semantic segmentation.", "outcome": "Using the proposed pipeline for the training of deep-learning methods for various depth-based recognition tasks resulted in significant improvements to the performance of the resulting models on real scans, thereby demonstrating the fidelity and value of its synthetic depth data compared to previous static simulations and learning-based domain adaptation schemes.", "future_impact": "The new physics-based differentiable depth sensor simulation can be utilized as a 3D-to-2.5D transformer within larger computer-vision applications.", "venue": "ICCV", "year": 2021, "title": "Physics-based Differentiable Depth Sensor Simulation."}
{"pid": "606d921491e011c5ec0d7e18", "context": "Recent advances have shown that Vision Transformers can achieve state-of-the-art results on many image classification tasks. However, while convolutional neural networks have been carefully studied with respect to adversarial attacks, the robustness of Vision Transformers against adversarial examples has not been well explored.", "key_idea": "The study aims to analyze the robustness of Vision Transformers to adversarial examples and the transferability of adversarial examples between CNNs and transformers, and to evaluate the security of a simple ensemble defense system composed of CNNs and transformers.", "method": "The analysis is done using six types of white-box attacks and two types of black-box attacks on multiple Vision Transformers, Big Transfer Models and CNN architectures trained on CIFAR-10, CIFAR-100 and ImageNet. The transformer is tested under standard white-box and black-box attacks, and a new attack, the self-attention blended gradient attack, is created to examine the security of the ensemble defense.", "outcome": "The study finds that adversarial examples do not readily transfer between CNNs and transformers. An ensemble of CNNs and transformers is not secure against a white-box adversary as shown through the self-attention blended gradient attack but can achieve unprecedented robustness without sacrificing clean accuracy under a black-box adversary.", "future_impact": "This study paves the path towards understanding adversarial robustness in Vision Transformers and their interactions with CNNs, which can guide the development of more robust models or defenses against adversarial attacks in the future.", "venue": "ICCV", "year": 2021, "title": "On the Robustness of Vision Transformers to Adversarial Examples."}
{"pid": "87854aa4-a40b-4375-855b-693bd204660d", "context": "In the field of computer vision, viewpoint and lighting ambiguities pose challenges for accurately interpreting the properties of objects in an image. Prior work has discussed the Generalized Bas Relief (GBR) ambiguity.", "key_idea": "The authors introduce a new type of viewpoint-lighting ambiguity, referred to as the KGBR, which touches upon orthographic projecting and Lambertian reflectance functions, inclusive of attached shadows and multiple light sources.", "method": "The authors provide a comprehensive description of the KGBR ambiguity, which includes a geometric and albedo alteration of objects, and demonstrate how this ambiguity can generate identical images under different viewing and lighting conditions.", "outcome": "The authors show that the KGBR can be understood as a wider encapsulation of the existing GBR ambiguity and reveal that generic viewpoint and lighting assumptions can resolve the KGBR ambiguity by favoring objects with planar geometry.", "future_impact": "The resolution of the KGBR ambiguity could improve the accuracy of object interpretation in images for future research and applications in computer vision.", "venue": "ICCV", "year": 2001, "title": "The KGBR viewpoint-lighting ambiguity and its resolution by generic constraints"}
{"pid": "5ff68e8fd4150a363cd83600", "context": "Owing to the rapid growth of municipal solid waste (MSW), only part of the waste is treated innocuously, and there's a slow MSW treatment rate and low level of garbage classification intelligence.", "key_idea": "This paper proposes a MSW classification and recycling algorithm based on deep learning technology. The authors use a convolutional neural network to build a garbage intelligence simultaneous interpreting and classification algorithm.", "method": "The proposed algorithm is compared with the traditional BP neural network algorithm through simulation.", "outcome": "The simulation results indicate that the proposed algorithm operates 30% faster than the traditional algorithm, with a quicker response speed, better accuracy, and stronger robustness.", "future_impact": "The results may imply the potential to improve the speed and accuracy of municipal waste treatment through implementing deep learning technology.", "venue": "ICCV", "year": 2020, "title": "Research on the algorithm of urban waste classification and recycling based on deep learning technology"}
{"pid": "b6130bea-cff1-4551-94e0-cc312f92a2f7", "context": "Existing algorithms for finding a proxy surface from a series of calibrated pictures of an object are often not robust, especially where the object doesn't possess well-defined reflectance properties, leading to unusable proxy for most datasets. Traditional outlier identification methods are based on photoconsistency, which might not work well under these conditions.", "key_idea": "The authors propose a robust algorithm that finds a proxy surface without assuming any reflectance properties of the object, and the proxy surface is optimized to reduce view interpolation errors by globally minimizing the frequency criterion.", "method": "The authors apply their algorithm on various challenging datasets, Lambertian and non-Lambertian, and analyze the performance of the algorithm using view interpolation results and proxies.", "outcome": "View interpolation results and proxies for challenging datasets, both Lambertian and not, are successfully generated by the method, demonstrating the robustness and ability of the proposed algorithm.", "future_impact": "The proposed robust estimation method and novel framework for merging multiple depth hypotheses has the potential to improve accuracy and reliability in multi-view stereo tasks.", "venue": "ICCV", "year": 2009, "title": "Robust multi-view stereo without matching"}
{"pid": "64c9d5313fda6d7f0637e62e", "context": "Image harmonization is a technique used to adjust the foreground illumination of an image to be consistent with its background. Previous methods focused on transforming foreground features, but faced some limitations.", "key_idea": "The authors introduce a new approach to image harmonization that uses global information to guide the transformation of foreground features and transfers foreground-background relationships from real to composite images for more effective adjustment.", "method": "The authors test their method through extensive experiments on the iHarmony4 dataset and a newly contributed dataset called ccHarmony, which was developed to simulate natural illumination variation.", "outcome": "The experimental results show that the proposed method outperforms other methods in image harmonization tasks on the iHarmony4 and ccHarmony datasets.", "future_impact": "The newly contributed ccHarmony dataset, which has been released publicly, could be extensively used in future research in image harmonization for simulating natural illumination variation.", "venue": "ICCV", "year": 2023, "title": "Deep Image Harmonization with Globally Guided Feature Transformation and   Relation Distillation"}
{"pid": "3e802e6c-5b9c-409e-abd2-0a1d25eb45e2", "context": "Creating grating images that, when superimposed, form a moire pattern resembling a target image is a challenging task. The existing methods do not address how to improve the visual appearance of the grating images and the hiding capability of the embedded image.", "key_idea": "The paper introduces a method for generating two grating images so that their superimposed moire pattern resembles a target image. The method involves a phase modulation constraint and a smoothness term for improving the visual appearance and hiding capability of the embedded image.", "method": "The authors devise a method grounded on the fundamental moire theorem, focusing on the visually dominant (1,-1)-moire component. They add a smoothness term and an appearance phase function to improve visual appearance and hide embedded images effectively.", "outcome": "The proposed method enables the creation of moire art and decoding the embedded image without relying on computers. The grating images thus prepared can be printed on transparencies and overlaid to reveal the hidden image.", "future_impact": "Visualizing hidden images without relying on computers may open up new possibilities for creating moire art and could potentially expand its applications in various fields.", "venue": "ICCV", "year": 2013, "title": "Target-Driven Moire Pattern Synthesis by Phase Modulation"}
{"pid": "091a5f01-ff04-4f2d-bc66-c5654d082a1b", "context": "The task at hand is the unsupervised discovery of object categories in a set of unlabeled images.", "key_idea": "The authors propose a novel approach which involves using a probabilistic latent semantic analysis (pLSA) model, commonly used in text corpus topic discovery, on images, considering object categories as topics in an analogous manner to 'bag-of-words' document representation.", "method": "Images are processed by applying pLSA to vector quantized SIFT-like region descriptors, essentially treating object categories as 'topics'. Extension of the bag-of-words vocabulary to include 'doublets' that encode spatially local co-occuring regions is also tested.", "outcome": "The proposed tool managed to categorize objects and predict their spatial layout without supervision. When compared to the supervised approach of Fergus et al. (2003), the performance on a one object per image data was found comparable. The tool also demonstrated clean image segmentation with the extended vocabulary.", "future_impact": "The development of object class models from an unsupervised analysis of images has been proven feasible, suggesting potential for further research and improvement in this model or similar unsupervised object categorization methods.", "venue": "ICCV", "year": 2005, "title": "Discovering objects and their location in images"}
{"pid": "d7b2999c-ece9-4d72-9197-352e5650e721", "context": "In the existing literature, the problem of clustering large image sets for 3D reconstruction typically focuses on visibility information, and processing large multi-view data sets with traditional algorithms often results in high memory costs and slow processing times.", "key_idea": "The authors propose an algorithm for clustering large sets of images into smaller subsets that cover different parts of a scene, making them suitable for 3D reconstruction. The approach utilizes a new similarity measure considering relative camera orientations and their distance from the scene, which formalizes the clustering problem as a graph partitioning task that can be solved using spectral clustering.", "method": "The proposed algorithm is tested against a number of multi-view data sets to determine its suitability for 3D reconstruction and data partitioning.", "outcome": "The image clusters created with the proposed algorithm reduce the amount of data consumed by reconstruction algorithms, enabling faster processing and less use of memory compared to full-image datasets. The results confirm the algorithm's suitability for 3D reconstruction and that its clustering aligns with human-assessed good clustering standards.", "future_impact": "The proposed algorithm has potential to improve image processing capabilities by reducing data processing costs and enabling traditional algorithms to effectively handle large multi-view data sets.", "venue": "ICCV", "year": 2009, "title": "Spectral camera clustering"}
{"pid": "b3912064-d3a8-49b0-8478-6b093c11a366", "context": "Recognition and classification of events represented by Mixture distributions of location and flow are typically challenged by varying view points and distinct locations across different datasets.", "key_idea": "The paper presents a new approach of classifying observed events into semantically meaningful groups using motion patterns represented by mixtures of multivariate Gaussians, which are obtained by hierarchical clustering of optical flow in four dimensional space (x, y, u, v).", "method": "The method compares and matches two motion pattern mixture distributions by estimating the similarity transformation between them, that minimizes their Kullback-Leibler (KL) divergence. The method is tested on different datasets captured from both static and moving cameras, involving real world pedestrian as well as vehicular motion.", "outcome": "The proposed method has shown encouraging results which demonstrate its feasibility and validity in classifying events across several datasets.", "future_impact": "The approach has potential in handling event recognition and classification from different viewpoints and locations, and could invigorate further research in robust matching of high-dimensional sampled point sets representing statistical distributions.", "venue": "ICCV", "year": 2011, "title": "Similarity invariant classification of events by KL divergence minimization"}
{"pid": "deb68279-25c1-4386-a5c9-946db786f34b", "context": "Recent advancements in computer vision and machine learning imply that various problems can be better tackled by considering non-Euclidean geometry. Traditional approaches have sought to solve sparse dictionary learning using Euclidean spaces, but this approach may not be suitable for all types of problems.", "key_idea": "The authors propose to address problems using sparse dictionary learning over the linear subspace space, forming Riemannian structures known as Grassmann manifolds. They propose to map the Grassmann manifolds into the area of symmetric matrices and create a closed-form solution for updating a Grassmann dictionary.", "method": "To accommodate non-linearity in data, the authors propose a kernelised version of the dictionary learning algorithm. The method is tested on several classification tasks including face recognition, action recognition, and dynamic texture classification.", "outcome": "The proposed approach shows substantial improvements in discrimination accuracy when compared with state-of-the-art methods such as the kernelised Affine Hull Method and graph-embedding Grassmann discriminant analysis.", "future_impact": "The method proposed in this paper, which allows for enhanced discrimination accuracy in various classification tasks could potentially redefine state-of-the-art techniques in dealing with non-linearity in data.", "venue": "ICCV", "year": 2013, "title": "Dictionary Learning and Sparse Coding on Grassmann Manifolds: An Extrinsic Solution"}
{"pid": "5fbf84d691e011a96823f11b", "context": "Uncertainty quantification in image retrieval is a challenging and largely unexplored problem. Current methods for estimating uncertainties are poorly calibrated, computationally expensive, or based on heuristics.", "key_idea": "The authors propose a method that views image embeddings as stochastic features rather than deterministic ones and introduce two main contributions: a likelihood that matches the triplet constraint and a prior over the feature space that justifies l2 normalization.", "method": "To ensure computational efficiency, the authors derive a variational approximation of the posterior, creating a Bayesian triplet loss.", "outcome": "The proposed method produces state-of-the-art uncertainty estimates and matches the predictive performance of current state-of-the-art methods.", "future_impact": "The method proposed for uncertainty quantification in image retrieval may have broad implications for downstream decisions and could improve efficacy of image retrieval tasks.", "venue": "ICCV", "year": 2021, "title": "Bayesian Triplet Loss - Uncertainty Quantification in Image Retrieval."}
{"pid": "d0676d99-beda-4a84-90ee-298b83301391", "context": "The study examines the inconsistencies and failures in human perception of structure from motion, a topic that has not previously been explored.", "key_idea": "The paper investigates the idea that object motion can affect the perceived shape constancy, with a focus on sinusoidal oscillation about a vertical axis and shape variation in the vicinity of a degenerate state, where shape information is lacking.", "method": "The authors conducted four experiments to evaluate human perception of structure from motion, two of which measure the perceived depth of an object undergoing sinusoidal oscillation about a vertical axis, and two that evaluate how the shape of an object varies near a degeneracy within the stimulus domain.", "outcome": "The experiments illustrate systematic failures of shape constancy related to object motion. Their trials show that the perceived depth of an object undergoing sinusoidal oscillation about a vertical axis increases with the oscillation's amplitude. Additionally, the shape of an object fluctuates near a degeneracy within the stimulus domain.", "future_impact": "These findings contribute to a better understanding of the processes underlying human perception of structure from motion, which could have future implications for the field of cognitive neurosciences and the development of related technologies.", "venue": "ICCV", "year": 1988, "title": "Perceiving Structure From Motion: Failure Of Shape Constancy"}
{"pid": "6082a1cc91e0118612e3f5e7", "context": "Current video and image recognition methods rely on transformer models that are computationally expensive and require large-scale external pre-training. These models do not robustly incorporate the concept of multiscale feature hierarchies.", "key_idea": "Multiscale Vision Transformers (MViT) are introduced, connecting the concept of multiscale feature hierarchies with transformer models. MViT expands the channel capacity while reducing spatial resolution through different scale stages, creating a pyramid of features from simple low-level visual information to complex high-dimensional features.", "method": "The authors evaluate the MViT model on a variety of video recognition tasks and compare its performance with concurrent vision transformers. The model is also applied for image classification as part of the testing.", "outcome": "MViT outperforms concurrent vision transformers that rely on large scale external pre-training and are 5-10x more costly in computation and parameters. It also surpasses previous work on vision transformers for image classification.", "future_impact": "The new MViT model, with its efficient processing and apparent advantages in video recognition tasks and image classification, may influence future approaches in these fields.", "venue": "ICCV", "year": 2021, "title": "Multiscale Vision Transformers."}
{"pid": "6125b6a95244ab9dcb41d8b7", "context": "Existing markerless 3D human motion capture and object trajectory estimation techniques from monocular RGB videos struggle to recover scale, object trajectories, human bone lengths and the orientation of the ground plane due to lack of awareness of gravity constraints on object motions.", "key_idea": "The authors propose GraviCap, a new approach that adopts a gravity-aware strategy for joint markerless 3D human motion capture and object trajectory estimation, ensuring geometric consistency of the 3D reconstructions and improved physical plausibility of human poses.", "method": "GraviCap's objective function is parametrized by the object's initial velocity and position, gravity direction and focal length, and optimized jointly for one or several free flight episodes. The method is evaluated on a new dataset with ground-truth annotations for persons and different objects undergoing free flights.", "outcome": "In the experiments, GraviCap achieves state-of-the-art accuracy in 3D human motion capture on various metrics.", "future_impact": "The authors have released the source code and dataset for GraviCap, which can potentially facilitate further research and advancements in the field of 3D human motion capture and object trajectory estimation.", "venue": "ICCV", "year": 2021, "title": "Gravity-Aware Monocular 3D Human-Object Reconstruction."}
{"pid": "786ca263-7422-4888-b620-16d4668d3904", "context": "Existing semantic segmentation methods based on fully convolutional networks have limitations, and struggle to identify detailed structures and handle objects in multiple scales naturally.", "key_idea": "The authors propose a semantic segmentation algorithm that learns a deep deconvolution network on top of the convolutional layers adopted from the VGG 16-layer net.", "method": "The proposed deconvolution network, composed of deconvolution and unpooling layers, is applied to each proposal in an input image. The final semantic segmentation map is constructed by combining the results from all proposals.", "outcome": "The proposed algorithm demonstrates strong performance in the PASCAL VOC 2012 dataset and achieved the best accuracy (72.5%) among methods trained without using the Microsoft COCO dataset.", "future_impact": "The integration of a deep deconvolution network with proposal-wise prediction may improve the identification of detailed structures and offer natural handling of objects in multiple scales in semantic segmentation tasks.", "venue": "ICCV", "year": 2015, "title": "Learning Deconvolution Network for Semantic Segmentation"}
{"pid": "d44916fa-71d8-4ade-9707-ad70b755720e", "context": "The problem of shadow extraction from a single image of a complex natural scene is a challenging task and current state-of-the-art techniques do not produce satisfactory results.", "key_idea": "The authors propose a unique method using a Bayesian approach to handle the shadow extraction problem, without making any simplifying assumptions about the camera and light source, except the Lambertian assumption.", "method": "The method takes user-supplied hints to translate into effective likelihood and prior functions for Bayesian optimization. The likelihood function uses a reasonable estimation of the shadowless image obtained by solving the associated Poisson equation.", "outcome": "The Bayesian method allows for optimal extraction of smooth shadows while preserving the texture appearance under the extracted shadow. The method shows significant improvements over current state-of-the-art techniques, resulting in better shadow removal using a single input image.", "future_impact": "The authors suggest the potential application of this Bayesian technique in shadow compositing and image repair.", "venue": "ICCV", "year": 2005, "title": "A Bayesian approach for shadow extraction from a single image"}
{"pid": "6528c22f939a5f40829a0c7b", "context": "Deep neural networks (DNNs) are exposed to backdoor attacks, which subtly manipulate the network behavior when a trigger pattern is added. This manipulation does not affect the network\u2019s performance on clean data. Existing defense methods have reduced the success rate of these attacks but have not sufficiently maintained prediction accuracy on clean data.", "key_idea": "The authors propose a defense framework that injects non-adversarial backdoors targeted at the poisoned samples, which once triggered, suppresses the attacker's backdoor on the poisoned data and minimally affects clean data.", "method": "The proposed defense methodology first detects suspected poisoned samples, and then applies a poisoning strategy to them. This defense is carried out during data preprocessing, without any alterations to the standard end-to-end training pipeline. The authors perform experiments on multiple benchmarks using different architectures and representative attacks.", "outcome": "The experiments show that the proposed method provides the most effective defense against backdoor attacks to date, with the least amount of performance drop on clean data.", "future_impact": "The demonstrated effectiveness of this framework suggests more research should be conducted into utilizing backdoors for defensive purposes against backdoor attacks.", "venue": "ICCV", "year": 2023, "title": "Beating Backdoor Attack at Its Own Game."}
{"pid": "611b74365244ab9dcbc5acd7", "context": "High spatial resolution (HSR) remote sensing images typically use bitemporal supervised learning for change detection from many pairwise labeled images. However, this process can be expensive and time-consuming.", "key_idea": "This paper introduces single-temporal supervised learning (STAR) for change detection, allowing changes to be detected from unpaired images, and the training of a higher accuracy change detector using these unpaired labelled images.", "method": "The authors propose a simple yet effective change detector named ChangeStar, which is built using any deep semantic segmentation architecture by the ChangeMixin module.", "outcome": "The experimental results demonstrate that ChangeStar performs significantly better than the baseline under single-temporal supervision and superior under bitemporal supervision.", "future_impact": "The introduction of STAR and ChangeStar might provide a more efficient means for change detection in remote sensing imagery, reducing the need for time-consuming pairwise labeling of bitemporal images.", "venue": "ICCV", "year": 2021, "title": "Change is Everywhere - Single-Temporal Supervised Object Change Detection in Remote Sensing Imagery."}
{"pid": "2640fc4e-fddd-4972-8927-70dd7a175735", "context": "The mining of duplicates or near-duplicates in video sequences is of considerable interest for many multimedia applications, yet designing an effective and scalable system can be challenging.", "key_idea": "The authors propose an unsupervised method that relies on a product k-means quantizer specifically purposed to generate hash keys that are aligned with the data distribution for frame descriptors, for detecting recurrent sequences in large-scale TV streams.", "method": "The method proposed employs a hashing technique in combination with a temporal consistency check in order to identify meaningful repetitions in TV streams, applicable on a 22-day long TV broadcast containing about 47 million frames.", "outcome": "The system is able to identify all repetitions within 15 minutes, excluding the computation of the frame descriptors, indicating an effective approach to scalability and efficiency.", "future_impact": "The authors note future implications involving the ability of their approach to handle very large video databases, pointing to the prospect of it becoming a popular solution.", "venue": "ICCV", "year": 2012, "title": "Efficient mining of repetitions in large-scale TV streams with product quantization hashing"}
{"pid": "b024b1b7-aeb9-424c-a3d4-51f8e2642723", "context": "Dimensionality reduction is a big challenge, especially in the context of high-dimensional hyperspectral images where information quality needs to be preserved.", "key_idea": "The paper studies the stability of non-parametric and unsupervised projection and bands selection methods used for dimensionality reduction at different noise levels and with varying number of data points. An hybrid method combining Band Clustering (BandClust) with Multidimensional Scaling (MDS), is proposed for achieving better stability.", "method": "Quality criteria based on the norm and correlation are used to evaluate the preservation of data in reduced dimensions. The performance of the hybrid method is verified on artificial data sets.", "outcome": "The hybrid method demonstrates good preservation of data in reduced dimensions across different noise levels and different numbers of data points.", "future_impact": "The paper suggests that the proposed hybrid method for dimensional reduction can provide enhanced stability and could be applied to high-dimensional hyperspectral images, although further work is required to confirm its practical application.", "venue": "ICCV", "year": 2012, "title": "Stability of Dimensionality Reduction Methods Applied on Artificial Hyperspectral Images"}
{"pid": "5fd74b4691e011efa3cf5f89", "context": "3D hand pose estimation from monocular videos is a challenging problem that current solutions using single RGB or depth cameras have been unable to solve efficiently, especially when it comes to high temporal resolution and large data throughput.", "key_idea": "The paper proposes EventHands, a novel approach utilizing a single event camera, an asynchronous vision sensor that reacts to brightness changes to achieve high temporal resolution and real-time performance.", "method": "A new neural network approach is designed which accepts a novel event stream representation, trained on synthetic event streams, aiming to generalise to real data.", "outcome": "EventHands outperforms recent monocular methods using a color (or depth) camera in terms of accuracy and its ability to capture hand motions of unusual speed.", "future_impact": "The authors will make the methodology, event stream simulator, and the dataset publicly available, which will likely facilitate further research and improvements in the field.", "venue": "ICCV", "year": 2021, "title": "EventHands: Real-Time Neural 3D Hand Reconstruction from an Event Stream"}
{"pid": "605b14fb91e0119ebe7e5cac", "context": "Existing real-time SLAM systems for handheld RGB-D cameras typically rely on standard dense SLAM techniques for scene representation.", "key_idea": "This paper introduces iMAP, an innovation showing that a multilayer perceptron (MLP) can be used as the only scene representation in a real-time simultaneous localization and mapping (SLAM) system for a handheld RGB-D camera, building a dense, scene-specific implicit 3D model of occupancy and color without prior data.", "method": "iMAP uses a keyframe structure and multi-processing computation flow, with dynamic information-guided pixel sampling for speed, to enable real-time SLAM via continual training of a neural network against a live image stream.", "outcome": "iMAP manages to deliver tracking at 10 Hz and global map updating at 2 Hz, showing efficient geometry representation with automatic detail control and smooth, plausible filling-in of unobserved regions such as the back surfaces of objects.", "future_impact": "The introduction of implicit MLPs for scene representation in real-time SLAM systems could pave the way for more efficient geometry representations with automatic detail control in future systems.", "venue": "ICCV", "year": 2021, "title": "iMAP - Implicit Mapping and Positioning in Real-Time."}
{"pid": "22077fc1-78dd-4ad9-b904-92ce59a51dda", "context": "Clouds have been traditionally observed and analyzed from meteorological satellites for estimating cloud-top heights (structure) and their wind speeds (semi-fluid motion). These estimations have typically relied on stereo image pairs from geostationary satellites.", "key_idea": "This paper presents an improved algorithm for automatic stereo analysis of cloud top heights using a massively parallel Maspar computer, and introduces a new category of motion behavior known as semi-fluid motion for more precise modeling and tracking of cloud winds.", "method": "The authors applied their automatic stereo analysis algorithm and semi-fluid motion extraction methodology on time-varying data of the visible channel from two satellites in geosynchronous orbit, pertaining to the Hurricane Frederic.", "outcome": "The authors succeeded in accurately determining both stereo disparities and motion correspondences to sub-pixel accuracy, and applied a versatile visualization tool, the Interactive Image SpreadSheet (IISS), to analyze and visualize these results.", "future_impact": "The approach outlined in this paper can influence more refined and precise methodologies for tracking cloud motion and estimating parameters related to their structure and motion, impacting weather forecasting and meteorological studies.", "venue": "ICCV", "year": 1995, "title": "Structure and semi-fluid motion analysis of stereoscopic satellite images for cloud tracking"}
{"pid": "6528c254939a5f40829a8139", "context": "Pre-existing text-to-image diffusion models lack the capacity to align the visual and textual embedding space, especially for object categories not seen during training.", "key_idea": "The authors introduce a grounding module coupled with the Stable Diffusion model that can train to align the visual and textual embedding space of the diffusion model with a narrow set of object categories.", "method": "The authors devise an automatic pipeline to construct a dataset of {image, segmentation mask, text prompt} triplets for training the grounding module. The performance of the open-vocabulary grounding on images from the text-to-image diffusion model is evaluated and the augmented diffusion model is used to build a synthetic semantic segmentation dataset.", "outcome": "The grounding module successfully segments objects of categories unseen during training, as demonstrated in Fig. 1. A standard segmentation model trained on the created synthetic dataset demonstrated competitive performance on the zero-shot segmentation (ZS3) benchmark.", "future_impact": "The successful performance of the grounding module in object segmentation opens up new possibilities for utilizing the powerful diffusion model in discriminative tasks.", "venue": "ICCV", "year": 2023, "title": "Open-vocabulary Object Segmentation with Diffusion Models."}
{"pid": "0f66e20a-487a-4d80-a1f7-53c8f9e56231", "context": "Scalar functions are often defined over Riemannian manifolds for 3D modeling tasks where 2D surfaces, endowed with various physical properties, are recovered from images. However, creating scale-space representations of these scalar functions on non-Euclidean spaces (like surfaces) is more challenging compared to Euclidean image domains where such representations can be easily obtained through Gaussian kernel convolutions.", "key_idea": "The authors present a new approach for creating scale-space representations of scalar functions on 2D Riemannian manifolds. This approach uses the spectral decomposition associated with the heat-diffusion framework and an intrinsic scale parameter.", "method": "In addition to proposing the concept of a scale-space representation, the authors have developed a feature detector and a region descriptor based on these representations. These concepts are tested on real data sets with various physical properties.", "outcome": "Experiments performed on real datasets with varied physical properties demonstrated the validity and efficacy of the proposed approach.", "future_impact": "The proposed method ensures the structuring of information with respect to its intrinsic scale, opening possibilities for a wide range of low-level computations. The introduction of a feature detector and a region descriptor, which extend previous tools to manifolds, may also contribute to improvements in image processing and 3D modeling.", "venue": "ICCV", "year": 2011, "title": "Scale-space representation of scalar functions on 2D manifolds"}
{"pid": "e569b83e-1464-4546-ac3d-d62bfc8c01db", "context": "Archaeological artifacts play a central role in archaeological research. The ways they are currently processed can be challenging and time-consuming.", "key_idea": "The study proposes a new approach for automatic processing of scanned artifacts, which is based on a new direction field on surfaces, called the prominent field.", "method": "The authors demonstrate the applicability of the prominent field in two different scenarios: surface enhancement of archaeological artifacts to help enhance eroded features and remove scanning noise, and artificial coloring to replace manual artifact illustration in archaeological reports.", "outcome": "The application of the prominent field showed enhanced eroded features and scanning noise removal in artifacts, and provided an alternative to manual illustration.", "future_impact": "The automatic processing approach proposed in this study can streamline the process of archaeological artifacts examination and reduce the need for manual work, including illustrations in archaeological reports.", "venue": "ICCV", "year": 2009, "title": "Prominent field for shape processing of archaeological artifacts"}
{"pid": "6087eb5891e011e25a316ca5", "context": "Invariance and equivariance to the rotation group have been widely discussed in the 3D deep learning community for point clouds. Most proposed methods either use complex mathematical tools which limit their accessibility, or are tied to specific input data types and network architectures.", "key_idea": "This paper introduces a general framework of Vector Neuron-based representations which allows the creation of rotation-equivariant neural networks for pointcloud processing. These Vector Neurons extend typical 1D scalar neurons to 3D vectors, enabling a simple mapping of rotation group actions (SO(3)) to the latent spaces.", "method": "The authors incorporate Vector Neurons into diverse network architecture backbones and evaluate their performance on classification, segmentation, and a rotation equivariant reconstruction tasks.", "outcome": "Despite their simplicity, the framework of Vector Neurons performs comparably well in accuracy and generalization with other more complex and specialized state-of-the-art methods on classification and segmentation tasks.", "future_impact": "The Vector Neuron representation provides a simple and versatile framework for embedding rotation equivariance in common neural operations, with potential broad applications in 3D deep learning and beyond, including the first ever demonstrated rotation-equivariant reconstruction network.", "venue": "ICCV", "year": 2021, "title": "Vector Neurons - A General Framework for SO(3)-Equivariant Networks."}
{"pid": "f5665fd2-9975-4793-bd0c-aa8072fe2de5", "context": "Human activities have been modeled as temporal sequences of actions. However, most of this work focused on tasks where actions are limited and each activity can be performed in a few ways.", "key_idea": "The authors propose a robust framework for analysing prolonged activities that can be achieved in a variety of ways, termed mid-term activities, and introduce an activity classification method called the Key Action Discovery system.", "method": "The proposed Key Action Discovery system is combined with temporal modelling of activities' constituent actions using hierarchical graphical models to analyze and recognize mid-term activities as well as detect potential errors in their execution.", "outcome": "The framework is shown to provide higher classification accuracy compared to current activity identification schemes.", "future_impact": "The proposed framework may be useful in future human activity recognition research and applications, particularly for tasks involving varied and prolonged activities.", "venue": "ICCV", "year": 2011, "title": "Automatic analysis of composite activities in video sequences using Key Action Discovery and hierarchical graphical models"}
{"pid": "609e654791e0113e7e2e021f", "context": "In the field of instance segmentation and semantic correspondence, most methods rely on comprehensive pixel-level annotations for supervision, which are time-consuming and expensive to obtain. Furthermore, these two tasks are often tackled separately.", "key_idea": "The authors propose DiscoBox, a novel framework that jointly learns instance segmentation and semantic correspondence from bounding box supervision, making use of a self-ensembling framework and a structured energy model as a teacher.", "method": "The methodology introduced leverages a structured energy model, which incorporates a pairwise and a cross-image potential to model the pixel relationships both within and across the boxes. This model is then minimized to yield refined object masks and dense correspondences between intra-class objects, which serve as pseudo-labels.", "outcome": "The DiscoBox system achieves 37.9% AP on COCO instance segmentation, surpassing prior weakly supervised methods and is competitive with supervised methods. It also obtains state-of-the-art weakly supervised results on PASCAL VOC12 and PF-PASCAL with real-time inference.", "future_impact": "The joint learning and use of bounding box supervision could lead to advancements in instance segmentation and semantic correspondence tasks, saving effort on annotating and providing state-of-the-art results in weakly supervised conditions.", "venue": "ICCV", "year": 2021, "title": "DiscoBox: Weakly Supervised Instance Segmentation and Semantic Correspondence from Box Supervision"}
{"pid": "1591d56a-8c72-40ad-a90a-fbd40725fb7a", "context": "Diamond color grading is traditionally done manually which can lead to inconsistencies and inaccuracies.", "key_idea": "The authors propose an effective method for diamond color grading based on machine vision that uses a specific light source, and also extracts color features including independent and joint distribution features of Hue and Saturation.", "method": "The authors use a special light source based on an integrating sphere to capture diamond images, then extract the devised color features and train a BP Neural Network to grade diamonds by color.", "outcome": "Experiment results show that the proposed method achieves a satisfactory level of accuracy and can serve as a replacement for manual grading for real diamonds.", "future_impact": "The proposed method could also be used to classify other objects where small color differences matter.", "venue": "ICCV", "year": 2009, "title": "Diamond color grading based on machine vision"}
{"pid": "e8f8af58-edbf-4175-b6cc-6d51b77bf3c8", "context": "Reconstructing 3D shape and 2D texture of surfaces from a single image remains a challenge, especially for general cylindrical surfaces which are frequently found in urban areas and scenarios such as deformed book pages needing scanning for text recognition.", "key_idea": "The authors propose a method for reconstructing both 3D shape and 2D texture of generalized cylindrical surfaces covered with low-rank textures from a single perspective image, leveraging recent techniques for low-rank matrix recovery and sparse error correction.", "method": "The authors validate their method using extensive simulations and experiments to assess its effectiveness in rectifying deformation of textures caused by both perspective projection and surface shape.", "outcome": "Results indicate that the proposed algorithm successfully rectifies deformations caused by both perspective projection and surface shape, proving its robustness to sparse occlusion, noise, and saturation. It proves effective across a wide range of symmetric or regular textures present in images of urban environments, objects, or texts.", "future_impact": "This work broadens the applicability of reconstruction techniques from planar surfaces to a larger class of important 3D surfaces, and may influence future approaches to 3D shape and 2D texture reconstruction from single images, especially for urban settings and text recognition purposes.", "venue": "ICCV", "year": 2011, "title": "Unwrapping low-rank textures on generalized cylindrical surfaces"}
{"pid": "b461ccf7-5dbd-4984-a76f-75f0d49aaba6", "context": "Color appearance of an object is significantly influenced by the color of the illumination which can cause inconsistency in appearance. Achieving color constancy, especially in outdoor scenes, has been a challenge for existing physics-based methods due to changing illumination conditions.", "key_idea": "The authors propose a physics-based method to estimate and remove illumination color, focusing on outdoor scenes and leveraging the differences in illumination between shadowed and non-shadowed regions.", "method": "The method involves estimating illumination colors from shadowed (illuminated by sky light) and non-shadowed regions (illuminated by a combination of sky light and sunlight) in single input images of outdoor scenes. Part of the estimation process includes analyzing noise present in natural images.", "outcome": "The proposed method was found to be more effective and robust in handling outdoor scenes as compared to existing methods.", "future_impact": "The proposed method has usefulness for many applications in computer vision where consistent color representation in varying outdoor lighting conditions is required.", "venue": "ICCV", "year": 2005, "title": "Consistent surface color for texturing large objects in outdoor scenes"}
{"pid": "63b63fd190e50fcafd8f5972", "context": "Deep neural networks are often vulnerable to adversarial attacks, where malicious actors generate adversarial examples using a specific model to undermine others. There is a need for a mechanism to trace the source or origin of these adversarial attacks in cases where a machine learning model is distributed to various buyers, who each receive a slightly different but functionally identical copy.", "key_idea": "The authors introduce a two-stage separate-and-trace framework to address the problem. This framework comprises a model separation stage that generates unique copies of a model for a given classification task, and a tracing stage that identifies the source of adversarial examples based on the distinct features in the models.", "method": "The authors develop a parallel structure to embed a 'tracer' in each differentiated model copy, and use a noise-sensitive training loss to inject unique characteristics into each model version. These characteristics allow the tracing stage to identify the likely source of adversarial examples by evaluating the output logits from each tracer.", "outcome": "Empirical results demonstrate the feasibility of tracing the origin of the adversarial example across a broad range of architectures and datasets.", "future_impact": "The proposed mechanism holds the potential to aid forensic investigation of attack incidents and deter potential adversarial attacks in the context of distributed machine learning models.", "venue": "ICCV", "year": 2022, "title": "Tracing the Origin of Adversarial Attack for Forensic Investigation and   Deterrence"}
{"pid": "6196569d6750f87a92a93d10", "context": "The ever-increasing number of medical imaging studies is placing a burden on radiologists. While deep learning provides a potential solution for automated medical image analysis and clinical decision support, training deep neural networks typically calls for a large-scale manually labelled dataset, which is challenging and costly to acquire for medical images.", "key_idea": "This study developed label-efficient multimodal medical imaging representations by leveraging radiology reports. It proposed an attention-based framework, GLoRIA, to learn global and local representations by contrasting image sub-regions and words in the paired report.", "method": "The researchers proposed methods to leverage the learned representations for different downstream medical image recognition tasks with limited labels, evaluating its performance in image-text retrieval, classification (fine-tuning and zero-shot settings), and segmentation on different datasets.", "outcome": "The proposed framework, GLoRIA, demonstrated strong performance and label-efficiency for image-text retrieval, classification, and segmentation on different datasets.", "future_impact": "The framework could potentially help in automated medical image analysis and clinical decision support, easing the burden on radiologists.", "venue": "ICCV", "year": 2021, "title": "GLoRIA - A Multimodal Global-Local Representation Learning Framework for Label-efficient Medical Image Recognition."}
{"pid": "d79a1159-03e6-4ed7-afd4-d201701d5b96", "context": "Stereo matching in computer vision frequently uses full bit-rate images, which might not be ideal for processing images acquired by mobile cameras due to computational intensity and resource constraints.", "key_idea": "A new stereo matching framework that utilizes bit-plane slicing and operates on low bitrate image pairs to compute rough disparity maps is proposed. This hierarchical approach then iteratively updates low confidence disparities with information provided by additional image bit-planes.", "method": "The method is applied for remote processing of the images acquired by a mobile camera and is also combined with existing stereo matching algorithms for experimentation on Middlebury datasets.", "outcome": "Experimentation and results show that the proposed technique performs well against conventional full bit-rate matching techniques when evaluated on Middlebury datasets.", "future_impact": "The proposed hierarchical matching framework can be combined with existing stereo matching algorithms, implying potential improvements in stereo matching techniques.", "venue": "ICCV", "year": 2012, "title": "Hierarchical stereo matching based on image bit-plane slicing"}
{"pid": "30350bf8-7106-4b12-a0fe-3fecd5419367", "context": "Image registration in rainy weather situations is a challenging task due to the presence of raindrops.", "key_idea": "This paper presents a novel approach for improved image registration in rainy weather situations by performing monocular raindrop detection in single images based on a photometric raindrop model.", "method": "The authors test their approach with experiments on video sequences taken from within a moving vehicle.", "outcome": "The proposed method was shown to precisely detect raindrops even in front of complex backgrounds, demonstrating a significant increase in image registration accuracy and successful image restoration.", "future_impact": "The approach could be feasibly applied to real-world scenarios, leading to improvements in image registration during rainy weather situations.", "venue": "ICCV", "year": 2009, "title": "Video-based raindrop detection for improved image registration"}
{"pid": "0e6a4294-d49c-4a5b-a041-b500b6f1078d", "context": "Despite a decade of usage, retinal laser photocoagulation has seen no significant improvement in results.", "key_idea": "The authors present a simulator, SOPHOCLE, designed to separate actual practice from apprenticeship for retinal laser photocoagulation. It is created to be as close to real operation conditions as possible, and provides a large library of current or rare cases.", "method": "SOPHOCLE uses an actual slit-lamp equipped with sensors that measure all system degrees of freedom. A PC computer calculates the images and displays them on a miniature screen inside the binocular. The user interface is provided through a Computer Assisted Training software.", "outcome": "The simulator allows students to learn how to manipulate the photocoagulation equipment and train themselves for diagnosis and operations. It also allows them to manage the pigmentations and pathologies database, track their skill level, and prepare for critical operations.", "future_impact": "The simulator can potential change the method of teaching and improving the skills of retinal laser photocoagulation, serving as a practical learning tool that can result in tangible improvements in results.", "venue": "ICCV", "year": 1995, "title": "SOPHOCLE: A Retinal Laser Photocoagulation Simulator: Overview"}
{"pid": "c2eeaa89-7289-4cb8-932a-62993d639cfa", "context": "Multiple images of a scene under different illumination conditions are typically used to extract interesting information about the scene in computer vision and graphics. However, these techniques struggle to be applied in dynamic environments due to the need for robust motion compensation algorithms.", "key_idea": "The authors introduce a method to separate multiple illuminants from a single image by encoding each light source with a distinct sinusoidal pattern strategically selected given the relative position of each light in respect to the camera, so that the observed sinusoids become independent from the scene geometry.", "method": "The authors encode each light source with a distinct sinusoidal pattern and demultiplex individual illuminants by analyzing local frequencies. Various applications of the approach are shown in image-based relighting, photometric stereo, and multiflash imaging.", "outcome": "The method generates individual images as if they had been illuminated separately by each of the light sources. It successfully demultiplexes individual illuminants by analyzing local frequencies.", "future_impact": "The proposed method can enhance applications in image-based relighting, photometric stereo, and multiflash imaging.", "venue": "ICCV", "year": 2011, "title": "Illumination demultiplexing from a single image"}
{"pid": "0e55d4e5-9375-4574-93e2-48f25abd7ede", "context": "Model-based methods for recognizing 3-D objects from 2-D data rely on the fundamental principle known as the viewpoint consistency constraint (VCC). However, the performance of existing methods that establish feature correspondences using the VCC is lacking.", "key_idea": "The authors propose a measure of viewpoint consistency error (VCE), which is based on a formal model of image feature errors, and introduce a more reliable method called viewpoint consistency ascent that uses the VCE as a search heuristic.", "method": "The authors present a quantitative analysis of the VCC and its use in the newly proposed viewpoint consistency ascent algorithm. The performance of this new method is compared to existing incremental methods in an experimental study.", "outcome": "Viewpoint consistency ascent, which uses the viewpoint consistency error (VCE) as a heuristic for a state-space search, proved to be more reliable than prior incremental methods, which exhibited poor performance.", "future_impact": "The approach for quantitative analysis of alternative algorithms can potentially be applied to model-based object recognition more broadly, fostering further research and progress in this area.", "venue": "ICCV", "year": 1993, "title": "Quantitative analysis of the viewpoint consistency constraint in model-based vision"}
{"pid": "86910735-d410-4f22-8270-a3d752c4efe4", "context": "Traditional object segmentation based on shape suffers from issues such as the need for point correspondences and the problematic tuning of weighing coefficients for partial differential equations, and it struggles with multidimensional data.", "key_idea": "A novel approach is proposed for shape-based segmentation that uses a specially designed level set function format. This approach takes color into consideration besides shape prior information, and solves the above problems.", "method": "The method depends on a set of training shapes to build a parametric shape model, which is fitted to the image volume through energy minimization. To demonstrate the efficiency, the starfish in 2D and the brain ventricles in 3D were extracted.", "outcome": "The approach was demonstrated to overcome the mentioned problems associated with conventional methods, and works well with multidimensional data. It has been successful in extracting the 2D starfish and the brain ventricles in 3D.", "future_impact": "This improved technique for shape-based segmentation could potentially increase the computational efficiency and accuracy of image segmentation tasks using multidimensional data.", "venue": "ICCV", "year": 2005, "title": "A shape-based segmentation approach: an improved technique using level sets"}
{"pid": "5ed0206c-00c8-40eb-bf80-677b6e8329cf", "context": "Existing design and implementation of object-oriented DBMS have limitations, particularly in the efficient interpretation of SQL statements, dynamic linking of functions, and catalog management.", "key_idea": "The authors designed and implemented an object-oriented DBMS, METU Object-Oriented DBMS (MOOD), which builds upon the Exodus Storage Manager (ESM). MOOD introduces kernel functions for the optimization and interpretation of SQL statements, dynamic linking of functions, and catalog management.", "method": "The authors developed MOOD integrating its functionalities onto the Exodus Storage Manager, using the Volcano Query Optimizer Generator for implementing a query optimizer, and developed a graphical user interface named Mood-View. MOOD was implemented in GNU C++ on Sun Sparc 2 workstations.", "outcome": "With the implemented system, SQL statements are interpreted and functions within SQL statements are dynamically linked and executed efficiently. MOOD's functionalities include graphically displaying schema information and query results, updating database schema, and traversing the references in query results.", "future_impact": "MOOD's approach can improve efficiency in object-oriented DBMS by avoiding the interpretation of functions and allowing for runtime modification of schema and objects.", "venue": "SIGMOD", "year": 1995, "title": "Implementation aspects of an object-oriented DBMS"}
{"pid": "da7559e0-fa69-4d19-8e9d-ef2027fda98c", "context": "The conventional relational algebra, the mathematical basis for relational databases, does not innately support transaction time, which is crucial in keeping a historical record of all events within the database.", "key_idea": "This paper introduces extensions to the conventional relational algebra to incorporate transaction time and, by implication, provide support for valid time, forming a complete temporal algebraic language.", "method": "The authors propose extensions to the relational algebra and formalize them using denotational semantics to verify the support for transaction time.", "outcome": "The proposed extensions maintain the beneficial properties of the conventional relational algebra while effectively capturing transaction time.", "future_impact": "This work could underpin improved capabilities in handling historical and future time data in relational databases, potentially enriching data management and tracking capabilities.", "venue": "SIGMOD", "year": 1987, "title": "Extending the relational algebra to support transaction time"}
{"pid": "23c90aa9-c6bb-42ae-b277-f96b1388c209", "context": "Subsequence similarity matching in time series databases is an essential research area with many applications, but doing this efficiently and accurately over massive data streams remains a challenge", "key_idea": "The paper proposes an automatic, online, approximate approach for subsequence similarity matching over data streams, using an online segmentation and pruning algorithm, and a similarity definition based on a permutation followed by a metric distance function.", "method": "The proposed approach is validated using experiments on real stock data, where the correctness of trend predictions is used to evaluate the performance of the proposed subsequence similarity matching approach.", "outcome": "The paper does not specificly mention the outcome, hence, it's N/A", "future_impact": "The authors mention an application for future data movement prediction based on statistical information, suggesting potential significant impact on fields reliant on accurate data movement predictions.", "venue": "SIGMOD", "year": 2004, "title": "Online event-driven subsequence matching over financial data streams"}
{"pid": "3f020771-e7c4-4d35-b4e4-2e3d1d749f2d", "context": "The R-tree, a popular access method for rectangles, uses heuristic optimization of the area of the enclosing rectangle in each inner node. Other variants, like Guttman's linear and quadratic R-tree and Greene's variant, have been proposed.", "key_idea": "The authors devised the R*-tree, an improved method that incorporates a combined optimization of area, margin, and overlap of each enclosing rectangle in the directory.", "method": "A series of experiments were run in a standardized testbed under various conditions of data, queries, and operations to design the R*-tree. It was then compared to existing R-tree variants using the same testbed.", "outcome": "It was found that the R*-tree outperforms existing R-tree variants for different types of queries and operations, including map overlay, rectangles, and multidimensional points.", "future_impact": "The R*-tree is especially valuable because it supports point and spatial data efficiently and its implementation cost is just slightly higher than that of other R-trees. It could be adopted for varied applications requiring efficient and robust access methods for points and rectangles.", "venue": "SIGMOD", "year": 1990, "title": "The R*-tree: an efficient and robust access method for points and rectangles"}
{"pid": "b02341fb-82fe-4031-a3d9-504cd011cbad", "context": "A recent study proposed a general framework for single-pass approximate quantile finding algorithms, which was more efficient compared to other methods. However, space-efficient algorithms for approximate quantile finding usually require advance knowledge of the input sequence length, and this is not always possible in many important applications employing quantiles.", "key_idea": "The authors propose a novel non-uniform random sampling scheme and an extension of their previous framework which allows for computation of approximate quantiles without prior knowledge of the input sequence length. They also provide a simple algorithm for estimating extreme values, which requires less space than the earlier techniques for computing all quantiles.", "method": "The authors developed a new algorithm based on their novel non-uniform random sampling scheme and framework extension. In addition, they proposed a simple extreme value estimation algorithm.", "outcome": "The authors presented a new algorithm that computes approximate quantiles without knowledge of the input sequence length, and another algorithm that estimates extreme values using less space than was required by earlier methods.", "future_impact": "This work provides an improved solution to compute approximate quantiles in large datasets, particularly in cases where it is not feasible to know the length of the input sequence in advance, which could be highly relevant for many database applications.", "venue": "SIGMOD", "year": 1999, "title": "Random sampling techniques for space efficient online computation of order statistics of large datasets"}
{"pid": "2f307e9c-fc9e-4148-b38f-5a9c0bc658bf", "context": "Query optimization is the most computationally complex task in a database management systems. While memory size continues to scale with Moore's Law, processor speeds are leveling off. It highlights the need for parallelizing query optimizers to continue enjoying the growth trend of Moore's Law.", "key_idea": "In the context of the extensible optimizer architectures found in many commercial database systems, this study identifies the key data dependencies inherent in the dynamic programming at the heart of these optimizers and proposes a flexible parallel query optimization implementation.", "method": "The authors apply their understanding of key data dependencies inherent in the dynamic programming central to optimizers to design a flexible parallel query optimization implementation, and assess opportunities for parallelism in this context.", "outcome": "The created blueprint can be used for retrofitting existing industry-grade optimizers to leverage multicore architectures without necessitating significant rework of the underlying infrastructure.", "future_impact": "The proposed solutions may prompt a shift in how industry-grade optimizers are improved, enabling them to leverage multicore architectures more effectively.", "venue": "SIGMOD", "year": 2009, "title": "Parallelizing extensible query optimizers"}
{"pid": "60d3093491e01182ead65cb5", "context": "There are several popular proximity problems (KNN, clustering, minimum spanning tree) that repeatedly perform expensive distance computations during their execution.", "key_idea": "The authors develop principled solutions to minimize distance computations in such problems, especially in scenarios where resolving unknown distances through an expensive oracle is the main cost for these algorithms.", "method": "The researchers compare their approaches conceptually and empirically with a broad range of existing works and present multiple techniques. They also provide a comprehensive set of experiments using large-scale real-world datasets and proximity algorithms.", "outcome": "The proposed techniques have demonstrated effective results in reducing distance computations, as shown through experiments on multiple large-scale real-world datasets.", "future_impact": "The practitioner's guide they included in the paper can assist the wider community in adopting the solution frameworks to proximity problems, thereby enhancing the performance of algorithms solving these problems.", "venue": "SIGMOD", "year": 2021, "title": "A Generalized Approach for Reducing Expensive Distance Calls for A Broad Class of Proximity Problems"}
{"pid": "a16fbfea-a0e3-46ea-9bfe-043d2c493baa", "context": "Traditionally, exploring the parameter space of rules using different parameter values in association mining requires hours of computation and substantial manual investigation.", "key_idea": "The authors develop a technology, PARAS, which achieves near real-time speeds for interactive association mining by providing technology innovations such as stable region abstractions and rule redundancy management.", "method": "The authors showcase how PARAS technology supports novel parameter space-centric exploratory queries through an interactive demonstration.", "outcome": "PARAS is shown to provide near-real-time speeds for operations, such as comparing rule sets mined using different parameter values, which traditionally require hours of computation, and is able to provide parameter tuning recommendations.", "future_impact": "PARAS can transform the experience for data analysts by significantly reducing the need for trial-and-error interactions and providing a rich experience through parameter tuning recommendations.", "venue": "SIGMOD", "year": 2013, "title": "PARAS: interactive parameter space exploration for association rule mining"}
{"pid": "d1f17ec8-dab0-4262-bb95-9acad8ec297e", "context": "Main-memory database systems, which are essential for modern business applications, primarily use flat relational data representations. The processing of hierarchical data and its versioning is challenge in these systems.", "key_idea": "The authors propose a versioned pendant of the nested intervals (NI) labeling scheme, the DeltaNI index, which is deeply integrated into the relational kernel. The index facilitates complex updates of the tree structure and supports branching histories.", "method": "The performance of the DeltaNI index is evaluated on large inputs consisting of millions of nodes and thousands of versions.", "outcome": "The DeltaNI index shows good scalability and delivers satisfactory performance for large business scenarios. It is also shown to be space- and time-efficient and provides a gapless, fixed-size integer NI labeling for each version.", "future_impact": "As many query processing techniques that work on top of the NI labeling have been proposed, the DeltaNI index could be used as a foundation block for processing various kinds of queries.", "venue": "SIGMOD", "year": 2013, "title": "DeltaNI: an efficient labeling scheme for versioned hierarchical data"}
{"pid": "fb16c96c-dfc9-4952-ac68-d97d6aabe783", "context": "The aspect of temporal evolution has been studied in the field of databases, signifying that web-based information systems mirror, and need to capture, the time-varying nature of the phenomena they model. In recent years, many papers have addressed the representation and management of time and evolution in the Semantic Web, signalling a growing research interest in this area.", "key_idea": "To support this growing research interest, the authors decided to compile an annotated bibliography addressing the handling of time and evolution in Semantic Web research.", "method": "The authors gathered references pertaining to the handling of time and evolution in Semantic Web research, in an effort to compile a comprehensive annotated bibliography.", "outcome": "As a product of their work, the authors successfully compiled an annotated bibliography which is available online.", "future_impact": "This annotated bibliography could serve as a helpful resource for students and young researchers exploring temporal and evolution aspects in Semantic Web research.", "venue": "SIGMOD", "year": 2013, "title": "Introducing an annotated bibliography on temporal and evolution aspects in the semantic web"}
{"pid": "e18e62a1-f185-4aa5-b25b-60e758a2ae51", "context": "The need for a deductive database system that supports a rich declarative language and allows a combination of declarative and imperative programming is evident. Furthermore, the demand for a system with a variety of evaluation methods and the ability to manage data either persistently on disk or in main memory is increasing.", "key_idea": "The CORAL deductive database system has been designed and implemented to meet these needs. A key idea is its architecture which allows integration of different evaluation strategies and gives users the discretion to influence optimization techniques. Additionally, extensibility is ensured by allowing C++ programmers to enhance the system using the class structure of C++.", "method": "The authors manifest the implementation of CORAL through its architecture. This includes structures like the module interface that allows modules with different evaluation techniques to interact, and giving users a wide range of control choices at the level of each module.", "outcome": "CORAL provides a robust and versatile deductive database system that can address a range of evaluation methods, allows users to influence optimization techniques, and allows for programming in a combination of declarative CORAL and C++ extended with CORAL primitives for high extensibility.", "future_impact": "As CORAL gives users the ability to influence optimization techniques and its interface with C++ allows for high extensibility, it may significantly influence the future of deductive database systems and provide a viable solution for various database needs.", "venue": "SIGMOD", "year": 1993, "title": "Implementation of the CORAL deductive database system"}
{"pid": "c4e01945-eb92-4d2f-9fb7-c648fd2f4b83", "context": "Information extraction by text segmentation (IETS) applies to cases where data values of interest are organized in implicit semi-structured records available in textual sources. Despite being an important practical problem widely discussed in the recent literature, its effective execution still constitutes a considerable challenge.", "key_idea": "The authors introduce ONDUX, a new unsupervised probabilistic approach for IETS that deviates from traditional IETS approaches by leveraging a highly effective matching strategy rather than explicit learning strategies.", "method": "The paper employs this new unsupervised strategy, ONDUX, in a number of different data domains to compare it with a state-of-the-art IETS approach.", "outcome": "ONDUX exhibited high flexibility and superior effectiveness in comparison with a contemporary information extraction approach, as demonstrated by experimental evaluations conducted using textual sources from different domains.", "future_impact": "This new method of leveraging ONDUX\u2019s matching strategy offers the potential for further improved performance in the field of information extraction from text.", "venue": "SIGMOD", "year": 2010, "title": "Unsupervised strategies for information extraction by text segmentation"}
{"pid": "f8491420-db38-4c0f-bb88-e4789fdc477c", "context": "Spreadsheets are among the most commonly used applications for data management and analysis, but their potential for use as a relational database engine has not been thoroughly explored.", "key_idea": "The authors propose that a spreadsheet can act as a relational database engine by implementing all operators of relational algebra using spreadsheet formulas, without any use of macros or built-in programming languages.", "method": "The authors implement a database in SQL on a spreadsheet workbook with empty worksheets for data tables and worksheets filled with formulas for queries. Performance tests were conducted using the beta version of Excel 2010.", "outcome": "The spreadsheet successfully served as data storage and executed SQL queries, acting as a relational database engine. The performance tests showed that this method is sufficient for a desktop database with a few thousand rows.", "future_impact": "The findings present a new way of utilizing spreadsheets for data management and analysis, potentially broadening the usability of spreadsheets in various applications, especially where relational databases are required.", "venue": "SIGMOD", "year": 2010, "title": "Spreadsheet as a relational database engine"}
{"pid": "139a86f2-6299-4f39-8569-c72e19b4e53e", "context": "The steady growth of graph data in various applications has resulted in wide-spread research in finding significant sub-structures in a graph. Labels in these structures may be either discrete or continuous and can be multi-dimensional.", "key_idea": "The authors propose a new method for finding statistically significant connected subgraphs. This method involves using the chi-square statistic and the concept of super-graphs created by contracting edges, allowing for a balance between accuracy and time.", "method": "The authors employ chi-square statistics to measure statistical significance. They introduce the idea of contracting edges to form super-graphs and reduce the number of super-vertices. Their method is evaluated by comparing time spent and accuracy of chi-square values against the optimal value.", "outcome": "Their method provides chi-square values that are always within 96% of the optimal value, while significantly reducing the time spent. It was also demonstrated to be scalable.", "future_impact": "This proposed method enhances the ability to analyze real datasets and could impact applications in spatial co-location rule mining and outlier detection.", "venue": "SIGMOD", "year": 2014, "title": "Mining statistically significant connected subgraphs in vertex labeled graphs"}
{"pid": "cba016aa-0ae7-4f49-8d2c-5817f1f6259e", "context": "Scientific computing has been an application of computer science and data management for a long time, with growing interest from the data management community, due to the commoditization of parallelism, diminishing system administration costs, and a search for relevance beyond enterprise applications.", "key_idea": "The authors propose the idea of a newly formed institute at Johns Hopkins University to enhance the interaction between computer science, and science and engineering to address the challenges of scientific computing and data management.", "method": "The authors have implemented the proposal of an institute at Johns Hopkins University and describe ongoing projects at the institute.", "outcome": "The authors have successfully developed a network of collaboration that fosters mutual appreciation of problems and has resulted in concerted software development efforts.", "future_impact": "The formation of this institute is aimed to further the interaction between different fields, potentially leading to breakthroughs in scientific computing, engineering, and data management.", "venue": "SIGMOD", "year": 2011, "title": "Scientific data management at the Johns Hopkins institute for data intensive engineering and science"}
{"pid": "c1fb0fa2-ad7e-4247-ac8d-14e9c0c1cff4", "context": "Dynamic XML documents, which incorporate calls to web services to generate required information, offer inherent forms of distributed computation. The distribution and replication of dynamic XML data poses new challenges, especially in today's web architecture.", "key_idea": "The authors propose to study new issues raised by the distribution and replication of dynamic XML data, providing a framework for distributed and replicated dynamic XML documents, which originated in the context of the Active XML system.", "method": "The authors develop a data model and a query language, along with a comprehensive cost model for query evaluation, applicable to user queries and service calls. They also describe an algorithm to select data and services that should be replicated to improve efficiency.", "outcome": "The authors successfully create a framework for handling distributed and replicated dynamic XML documents, which includes a new cost model for query evaluations and an algorithm to enhance the efficiency of maintaining and querying its dynamic data.", "future_impact": "While the study was conducted in the context of the Active XML system, the results are broadly applicable to many other systems that handle dynamic XML data, contributing to more efficient and effective management of dynamic XML documents.", "venue": "SIGMOD", "year": 2003, "title": "Dynamic XML documents with distribution and replication"}
{"pid": "99d11ca0-d9b4-48f0-b8ac-fd9eed4b1e65", "context": "In practice, XML documents are often dynamically generated by a program, and checking whether all XML documents generated by the program are valid with respect to a given type, is called the typechecking problem. This problem, the XML typechecking problem, has been recently investigated, and different techniques have been adopted, but all have certain limitations.", "key_idea": "The paper identifies and defines the XML typechecking problem and focuses on evaluating current approaches to typechecking.", "method": "The authors review and discuss current approaches to XML typechecking, particularly their limitations.", "outcome": "The paper provides an understanding and discussion of the limitations of current techniques for the XML typechecking problem.", "future_impact": "The study suggests that the limitations found in the study need further exploration and investigation to advance the field of XML typechecking.", "venue": "SIGMOD", "year": 2002, "title": "The XML typechecking problem"}
{"pid": "5ed384dd9fced0a24b656ff9", "context": "Today, as applications often use data from different sources and with different levels of credibility, data repair is a crucial step, and many different approaches to this problem have been proposed.", "key_idea": "T-REx, a system for providing data repair explanations through Shapley values is proposed. T-REx treats the repair algorithm as a black box and helps users understand how specific cell repairs were made based on the significance of each constraint and each table cell.", "method": "T-REx employs Shapley values to explain the impact of each constraint and table cell when repairing a cell of interest, ranking constraints and table cells according to their significance in the repair process.", "outcome": "The explanation provided by T-REx allows users to understand the repair process and, based on this knowledge, make adjustments to the most influential constraints or the original database.", "future_impact": "T-REx, being generic and not specific to a certain repair algorithm, can potentially be used to enhance the transparency and understanding of diverse data repair processes across multiple application contexts.", "venue": "SIGMOD", "year": 2020, "title": "T-REx: Table Repair Explanations"}
{"pid": "3b8bb136-657a-460c-8ffe-1a6dcac0405b", "context": "Data stream management systems (DSMS) process data streams and use networks of interconnected machines to enhance power. Often, these systems use clusters of equal, non-autonomous machines, which can have high costs and difficulty in deployment. Some applications might lack access to such resources.", "key_idea": "This paper presents the author's PhD project for developing and deploying a distributed DSMS that can operate in a Peer-to-Peer (P2P) network of autonomous and heterogeneous peers. This network will involve handling autonomous and heterogeneous machines such as notebooks, personal computers or smartphones instead.", "method": "The study addresses three main challenges which are data source management, continuous query distribution, and distributed query management in the system being developed. The specific design and implementation details are not mentioned, and an evaluation for the system is planned for future study.", "outcome": "A prototypical implementation of the distributed DSMS is already in place, but specific outcomes or results are as yet unknown as evaluations are still planned.", "future_impact": "This system may provide an alternative for data stream processing in situations where infrastructure costs or accessibility are an issue, enabling decentralized and heterogeneous computation.", "venue": "SIGMOD", "year": 2014, "title": "Data stream processing in dynamic and decentralized peer-to-peer networks"}
{"pid": "a86a347e-d53b-4f45-b433-47ca009ed718", "context": "String similarity joins find similar string pairs between two input string collections and are used in data integration and cleaning. However, existing solutions are designed for deterministic strings and are inappropriate for increasing use cases dealing with imprecise or uncertain strings.", "key_idea": "The authors propose the first solution for similarity join queries over uncertain strings that implements possible-world semantics, using the edit distance as the measure of similarity.", "method": "The authors propose various filtering techniques for estimated lower or upper bound on the probability of the edit distance between two strings being less than a threshold without having to instantiate possible worlds for either of the strings. These techniques are then incorporated into an indexing scheme and further improved by using a trie structure. The methods are evaluated through practical experimentation.", "outcome": "The proposed filtering techniques, indexing scheme, and trie structure reduce filtering and verification costs in uncertain string similarity join operations, as tested through practical experimentation.", "future_impact": "The authors establish the foundation for answering similarity join queries over uncertain strings, which is significant for data integration and cleaning in many domains dealing with imprecise or uncertain strings.", "venue": "SIGMOD", "year": 2014, "title": "Similarity joins for uncertain strings"}
{"pid": "8c0f0b9b-f646-4d5a-99d5-f58b917cf676", "context": "Predicting customer churn is a significant challenge in the telecommunications industry, and there is room for improvement in leveraging big data for this task.", "key_idea": "The authors propose to improve churn prediction by leveraging big data from the perspectives of Volume, Variety, and Velocity, utilizing a large volume of training data, a large variety of features from both business support systems (BSS) and operations support systems (OSS), and high-speed processing of new data.", "method": "The proposed approach was tested by deploying a churn prediction system within one of the largest mobile operators in China.", "outcome": "The system was able to identify prepaid customers most likely to churn in the following month with a precision of 0.96 for the top 50000 predicted churners. This significantly boosted recharge rates when matching retention campaigns were implemented with the targeted potential churners.", "future_impact": "The proposed system demonstrates high potential for improving customer retention efforts in the telecommunications industry through more effective use of big data, which could lead to significant business value.", "venue": "SIGMOD", "year": 2015, "title": "Telco Churn Prediction with Big Data"}
{"pid": "1d60f8ce-786c-4bd1-9019-e5eb5f5c4af0", "context": "Query optimization is an important part of relational database management systems, involving selectivity estimation, i.e., estimating the fraction of records in a database that satisfies a particular query. Current commercial database systems use histograms to approximate the frequency distribution of attribute values.", "key_idea": "The study presents a new technique for building histograms on underlying data distributions based on multiresolution wavelet decomposition, aiming at improving accuracy in databases, statistics, and simulation contexts. These histograms are built on cumulative data distributions, aiming for quality approximations with limited space usage.", "method": "The authors provide algorithms for building histograms and using them online for selectivity estimation. They also use the developed histograms to provide quick approximate answers to OLAP queries. The effectiveness of the proposed method in capturing the joint distribution of multiple attributes was tested, even when the attributes are correlated.", "outcome": "The authors have proven through experiments that their histograms offer substantial improvements in accuracy over random sampling and other previous approaches.", "future_impact": "The fast algorithms for constructing and using histograms developed in this study can be potentially useful in improving the efficiency of relational database management systems, especially in the context of selectivity estimation and providing fast answers for OLAP queries.", "venue": "SIGMOD", "year": 1998, "title": "Wavelet-based histograms for selectivity estimation"}
{"pid": "0fcd2202-addb-493a-9e25-76513382357e", "context": "Database query optimizers require query selectivity estimation to find the most efficient access plans. Multi-dimensional selectivity estimation becomes essential when multiple dependent attributes are referenced from the same relation or for multimedia databases. However, traditional histograms are unsuitable for multi-dimensional cases due to high storage overheads and error rates.", "key_idea": "A novel approach to multi-dimensional selectivity estimation is proposed, which uses compressed information from a large number of small-sized histogram buckets, maintained using the discrete cosine transform, allowing for low error rates and storage overheads even in high dimensions.", "method": "The paper presents an approach that is tested through extensive experiments, although the exact methods or datasets are not specified in the abstract.", "outcome": "The experimental results show that the proposed approach for multi-dimensional selectivity estimation has advantages, but the specific results or metrics are not given in the abstract.", "future_impact": "According to the abstract, the proposed approach is expected to have advantages in handling high dimensional data and could shape future practices in multi-dimensional selectivity estimation, particularly because of its capability to handle dynamic data updates without requiring periodical reconstructions of the compressed information.", "venue": "SIGMOD", "year": 1999, "title": "Multi-dimensional selectivity estimation using compressed histogram information"}
{"pid": "69978fb7-bf10-4eae-bd50-33b6e9f94b79", "context": "Hash join algorithms are important for main memory environments on modern multi-core processors, but the most efficient implementation is not well-defined.", "key_idea": "This paper studies each internal phase of a typical hash join algorithm and explores different alternatives for implementing each phase, thereby producing a family of hash join algorithms. A significant observation was that a very simple hash join algorithm that builds a shared hash table and does not partition the input relations, proved to be very competitive.", "method": "The authors implement these main memory algorithms on two different modern multi-processor systems and examine the factors that affect the performance of each method.", "outcome": "The simple shared hash table method showed competitive performance compared to more complex methods, and its performance significantly improved as the skew in the input data increased, outperforming all other algorithms.", "future_impact": "Considering its simplicity and superior performance, this algorithm could be easier for query optimizers and execution engines to use in practice, providing a valuable direction for the development of hash join algorithms on multi-core systems.", "venue": "SIGMOD", "year": 2011, "title": "Design and evaluation of main memory hash join algorithms for multi-core CPUs"}
{"pid": "479abdca-2c42-4a2a-8a70-0f3c5c23e236", "context": "Current scientific workflow systems lack efficient ways to manage and operate on nested data collections concurrently, customize workflow component behavior on-the-fly, improve handling of exceptions and faults, and transparently pass provenance and metadata within token streams.", "key_idea": "The authors propose an approach that logically delimits arbitrarily nested data collections in scientific workflows using special control tokens, and provides components with operations for managing these collections. This approach introduces new capabilities for concurrent operation on collections, on-the-fly customization of workflow component behavior, improved handling of exceptions and faults, and transparent passing of provenance and metadata within token streams.", "method": "The proposed approach is demonstrated using a workflow for inferring phylogenetic trees.", "outcome": "The proposed approach successfully demonstrated the capacity to handle nested data collections in scientific workflows, showing improved efficiency and handling of the specified issues in the demonstration.", "future_impact": "The authors plan on extending this approach to support richer typing mechanisms to facilitate sharing and reuse of workflow components between disciplines. The authors also believe that their approach will help in significantly reducing the complexity of creating and reusing workflows and workflow components, which could shift scientific workflow systems towards a collection-oriented dataflow programming paradigm.", "venue": "SIGMOD", "year": 2005, "title": "An approach for pipelining nested collections in scientific workflows"}
{"pid": "6b59f148-aa15-42c9-b30b-b555fac6551c", "context": "Database-centric systems, found in a variety of applications from e-commerce to scientific projects, often suffer from costly bugs. Traditional verification techniques, including model checking and theorem proving, have limitations when applied to these intricate systems. High-level specification tools have also made an appearance in the field of business process management, shifting from a traditional process-centric approach to data awareness.", "key_idea": "The authors propose an automatic verification approach for database-centered systems that leverages the high-level specification tools trend. This approach seeks to find specific classes of applications and properties for which complete and automatic verification can be performed.", "method": "The proposed approach relies on a mix of database and model checking techniques. Although specific experiments/methodologies are not detailed in the abstract, the authors seem to focus mainly on verification of business artifacts.", "outcome": "The abstract states that the theoretical and practical results achieved concerning the verification of such systems are encouraging. They suggest that unlike arbitrary software systems, key classes of data-driven systems may be amenable to automatic verification.", "future_impact": "While not explicitly stated, the abstract suggests that this novel approach to automatic verification holds potential to improve both development speed and code reliability in database-centric systems in numerous application areas.", "venue": "SIGMOD", "year": 2014, "title": "Automatic Verification of Database-Centric Systems"}
{"pid": "5eda197c9fced0a24b932b73", "context": "Cardinality estimation is a pivotal technique in database management systems and impacts query performance. Traditional approaches such as histogram-based or sampling-based methods have been extensively used for years, and with the advancement of Machine Learning (ML), several methods have been developed to improve the quality of cardinality estimation.", "key_idea": "The authors propose the concept of a hybrid approach for cardinality estimation that combines the strengths of both traditional and ML models. They advocate a better interweaving of ML models and traditional approaches considering their potential, advantages, and disadvantages.", "method": "A classification of different estimation techniques and their applicability to cardinality estimation is proposed and a novel hybrid approach is instigated that uses both ML models and the proven histogram approach. The authors evaluate this hybrid approach on two real-world datasets.", "outcome": "The authors show that their hybrid approach identifies when it's beneficial to use ML models or when to trust the traditional estimators. They provide insights about how to improve the coexistence of traditional and ML approaches in DBMS.", "future_impact": "The authors' proposed hybrid approach for cardinality estimation provides a path towards improving DBMS by leveraging ML, without abandoning decades of valuable research in cardinality estimation. This could potentially lead to a new direction in the development of improved or next-generation DBMS.", "venue": "SIGMOD", "year": 2020, "title": "Best of both worlds: combining traditional and machine learning models for cardinality estimation"}
{"pid": "60d3093491e01182ead65cde", "context": "Data profiling, or extracting technical metadata and profiles, has numerous applications in data understanding, validation, integration, and cleaning. Most data profiling primitives in existing literature are limited to categorical attributes with limited techniques considering numerical attributes. These either focus on simple relationships involving a pair of attributes or convert the continuous semantics of numerical attributes to a discrete semantics, resulting in information loss.", "key_idea": "The authors developed a new data-profiling primitive called Conformance Constraints designed to model linear arithmetic relationships involving multiple numerical attributes and present CoCo, a system for interactive discovery and exploration of these Conformance Constraints.", "method": "The authors leverage CoCo's simple interface to allow users to guide Conformance Constraint discovery based on their preferences. They investigate how well a new dataset satisfies or violates discovered Conformance Constraints, examine the extent of Conformance Constraint violation due to alterations in dirty data tuples, and provide suggestions for cleaning these tuples.", "outcome": "The authors demonstrate that CoCo can help in understanding trends in data and assist users in interactive data cleaning using Conformance Constraints.", "future_impact": "CoCo, with its focus on numerical attributes and interactivity, has the potential to significantly enhance data profiling practices, particularly in the context of data cleaning.", "venue": "SIGMOD", "year": 2021, "title": "CoCo: Interactive Exploration of Conformance Constraints for Data Understanding and Data Cleaning"}
{"pid": "152cc11b-ca92-47f9-88eb-51c6913bfb70", "context": "In outsourced database (ODB) systems, data is published via remote servers with the goal of efficient data access and querying by clients. Servers may be untrusted or compromised, thus query authentication is key. Current solutions focus largely on static scenarios and are based on idealistic properties of certain cryptographic techniques.", "key_idea": "This paper first defines cost metrics associated with ODB systems then evaluates different approaches in terms of these metrics. Additionally, the authors focus on solutions for dynamic scenarios where data at the servers is constantly updated, and introduce 'query freshness', a new dimension in data authentication.", "method": "Various approaches are analytically evaluated based on the defined cost metrics. An extensive experimental evaluation of the proposed and existing approaches is conducted to validate the analytical models.", "outcome": "The findings show that the proposed solutions improve performance significantly over existing approaches in both static and dynamic environments.", "future_impact": "The introduction of 'query freshness' and the focus on dynamic scenarios may open up new horizons in data authentication research for outsourced database systems.", "venue": "SIGMOD", "year": 2006, "title": "Dynamic authenticated index structures for outsourced databases"}
{"pid": "2f89f0cb-0dc8-4078-91dd-620c355d4038", "context": "Multi-user database systems need to provide selective data sharing capabilities while also restricting data access, ensuring appropriate protection and security. In a dynamic environment where tables or views are created or destroyed dynamically, there's a need for a mechanism to control authorization dynamically.", "key_idea": "The paper proposes an authorization mechanism in a relational database system, namely System R, where the creator of a database table is fully authorized to perform actions on it and can optionally grant privileges to others with further granting abilities, forming a directed graph of privileges.", "method": "The proposed mechanism is discussed in the context of its implementation in the relational database management system, System R, with a focus on issues of granting, authentication, revocation of authorization, and measures to minimize the cost of dynamic revalidation.", "outcome": "The authors present an algorithm that can appropriately determine which user privileges should be revoked after revoking a user's granted privileges, considering the possibility of other remaining privilege grants.", "future_impact": "The proposed framework and algorithm for dynamic authorization in relational databases may serve as a fundamental approach to data protection and selective data sharing in multi-user database systems.", "venue": "SIGMOD", "year": 1976, "title": "An authorization mechanism for a relational data base system"}
{"pid": "8955fdf7-5ad2-476c-891f-d42b9644795d", "context": "Concurrent transaction processing is a crucial part of database system performance but studying the effects of parameters such as the granularity of locks and the degree of multiprogramming has typically relied on resource-intensive simulation models.", "key_idea": "The authors propose two queueing network models that mimic different implementations of the lock management algorithm for concurrent transaction processing in a database system, providing a less resource-intensive alternative to simulation models.", "method": "The authors develop their models and present a numerical example using a set of parameters deemed to be realistic.", "outcome": "The numerical example confirms the result, reported in earlier work by Ries and Stonebraker, that a coarse granularity is sufficient for efficient resource utilization, demonstrating the effectiveness of the proposed queueing models.", "future_impact": "The queueing network models proposed in this paper could potentially allow for a more detailed examination of the cause-effect relationships in concurrent transaction processing, at a lower cost.", "venue": "SIGMOD", "year": 1979, "title": "Queueing network models for concurrent transaction processing in a database system"}
{"pid": "3e1a8803-d316-463e-9363-b8c22b0b2675", "context": "The concept of Cartesian product files was not previously explored in computer science literature.", "key_idea": "The authors introduce the concept of Cartesian product files and derive a formula for random files.", "method": "The authors perform a computer simulation experiment to compare the newly conceived Cartesian product files with random files. Moreover, they present a method for finding minimal N-tuples and discuss its properties.", "outcome": "The experimental results suggest that the Cartesian product file concept is effective. Furthermore, the authors demonstrated that the task of designing an optimal Cartesian product file is partially intertwined with the problem of finding a minimal N-tuple.", "future_impact": "The concept of Cartesian product files and the derived formula for random files can potentially guide future studies in designing optimized file systems.", "venue": "SIGMOD", "year": 1980, "title": "Some properties of Cartesian product files"}
{"pid": "e57e263c-510a-43a7-8e65-769ffe56d0cf", "context": "Database applications often require the analysis of rapidly changing data streams, with particular difficulties posed by pseudo-periodical streams, where successive events seem to recur at certain intervals but evolve with small differences over time.", "key_idea": "The authors put forward a new method named Pattern Growth Graph (PGG) for online variation management over pseudo-periodical data streams. This method uses the wave-pattern to capture key information about data evolution and with a wave-pattern matching algorithm, it detects the variations in a single pass over the stream data.", "method": "The proposed Pattern Growth Graph (PGG) technique involves storing only the different segments of the pattern for incoming streams, which greatly compresses the data. Extensive experiments on real datasets containing millions of data items were carried out to test the proposed scheme.", "outcome": "The results demonstrate that the Pattern Growth Graph (PGG) method can distinguish meaningful data changes from noise and reconstruct the stream with acceptable accuracy, effectively managing variations in pseudo periodical streams.", "future_impact": "The introduced method can be applied to various problem domains such as patient vital signal monitoring in medical applications, thus having potential for significant impacts in these fields.", "venue": "SIGMOD", "year": 2007, "title": "Effective variation management for pseudo periodical streams"}
{"pid": "8fea00e5-e521-4885-95bf-435420a67257", "context": "Real-world data, especially data generated by distributed measurement infrastructure such as sensor networks, tends to be incomplete, imprecise and erroneous. Current database systems do not provide adequate support for treating such data using frequent model updates as new data arrives, thus not facilitating scientists and engineers who depend on these models for data management.", "key_idea": "This study proposes a new abstraction called model-based views and presents the architecture of MauveDB, a database system designed to handle and treat real-world data using frequent model updates.", "method": "MauveDB supports a declarative language for defining model-based views, allows declarative querying over such views using SQL, and supports various materialization strategies and techniques for efficient maintenance in the face of frequent updates. A prototype system that currently supports views based on regression and interpolation using the Apache Derby open source DBMS has been implemented.", "outcome": "The authors present results demonstrating the utility and performance benefits of supporting various types of model-based views in a database system using the implemented prototype system.", "future_impact": "The introduction of MauveDB and the concept of 'model-based views' can enhance the way scientists and engineers manage real-world, imprecise data, offering a more robust, efficient, and declarative approach to database management.", "venue": "SIGMOD", "year": 2006, "title": "MauveDB: supporting model-based user views in database systems"}
{"pid": "60f16ad291e011963c8d4164", "context": "Linear regressions are essential for learned index structures, most implementations use Simple Linear Regression which optimizes the squared error. However, learned indexes often use exponential search.", "key_idea": "The authors propose tailoring the regression for learned indexes by optimizing the logarithmic error, without requiring any architectural changes.", "method": "The authors introduce novel algorithms and optimization heuristics to handle the increased optimization complexity introduced by log-error regressions.", "outcome": "Their new method significantly improves learned index's lookup performance and speeds up lookups on data sets with outliers by over a factor of 2.", "future_impact": "The research provides a robust solution for degenerated leaf models and fast look-up times which will likely influence the design of learned indexes in the future.", "venue": "SIGMOD", "year": 2021, "title": "A Tailored Regression for Learned Indexes: Logarithmic Error Regression"}
{"pid": "5ed384dd9fced0a24b657024", "context": "The usage of knowledge graphs, often represented as RDF graphs, in various applications have grown in recent years. However, due to the complexity of the SPARQL language and lack of data schema, users often face difficulty in obtaining desired data from their SPARQL queries, especially when those queries are complex.", "key_idea": "This research proposes methods to fine-tune SPARQL queries through two sub-problems: query-restricting and query-relaxing, in order to make the query results closer to what the user initially intended.", "method": "The authors model the problem of modifying SPARQL queries as two sub-problems and conduct experiments on real-world knowledge graphs to evaluate the effectiveness and efficiency of their proposed solutions.", "outcome": "The research proves that both the query-restricting and query-relaxing problems are NP-hard. There is no Polynomial-Time Approximation Scheme (PTAS) for query-restricting unless P=NP, and there is no polynomial-time constant-factor approximation algorithm for the query-relaxing. The authors propose a (1-1/\u03b5)-approximation method for query-restricting and two heuristics for query-relaxing.", "future_impact": "The introduction of the concept of 'modifiers' and the proposed solutions in this research can potentially improve SPARQL language applications, narrowing the gap between users' desired outcomes and the actual results returned by their queries.", "venue": "SIGMOD", "year": 2020, "title": "SPARQL Rewriting: Towards Desired Results"}
{"pid": "0b449792-9f3c-4a02-9421-6a926cb774d0", "context": "Interactive Data Exploration (IDE) is a critical aspect of various discovery-oriented applications, including scientific computing and evidence-based medicine. These applications involve executing numerous exploration queries with varying predicates, aiming to balance collecting all relevant information while reducing the size of the returned data. There is a need to support these human-in-the-loop applications by assisting their navigation in the data to find interesting objects.", "key_idea": "The paper introduces AIDE, an Automatic Interactive Data Exploration framework that steers the user towards interesting data areas and predicts a query that retrieves his objects of interest. The approach combines relevance feedback on database samples to model user interests and strategically collects more samples to refine the model while minimizing user effort.", "method": "AIDE integrates machine learning and data management techniques to provide data exploration results that match users' interests with high accuracy and high interactive performance. The framework's performance is evaluated based on accuracy of its query predictions and user wait time per iteration.", "outcome": "AIDE delivers highly accurate query predictions for very common conjunctive queries with very small user effort. It provides interactive performance by limiting the user wait time per iteration to less than a few seconds on average. A user study indicates that AIDE significantly reduces the user effort and the total exploration time compared with manual exploration.", "future_impact": "AIDE has the potential to vastly improve the efficiency and ease of IDE operations across diverse domains by significantly reducing user effort and total exploration time compared to current state-of-the-art manual exploration methods.", "venue": "SIGMOD", "year": 2014, "title": "Explore-by-example: an automatic query steering framework for interactive data exploration"}
{"pid": "d1497e06-ef25-42ea-b9ad-368345f29479", "context": "In a document streaming environment, online detection of the first documents that mention previously unseen events is an open challenge. Prior work on online new event detection (ONED) assumes that sufficient resources are available, disregarding efficiency considerations. Moreover, previous studies have not addressed user interface design.", "key_idea": "The authors introduce a resource-adaptive ONED framework that combines indexing and compression methods to accelerate document processing. They also propose mechanisms to handle resource constraints and high event arrival rates, and a technique to identify implicit citation relationships among documents to guide source selection.", "method": "The authors built a prototype of their ONED system on top of IBMu0027s Stream Processing Core middleware and ran tests using the standard TDT5 benchmark.", "outcome": "An ONED system was successfully implemented, showcasing efficient document processing without sacrificing detection accuracy, adaptive computations when resources are limited, and prioritization of new events when their arrival rate surpasses the system's processing ability.", "future_impact": "The proposed ONED framework could pave the way for new practical applications in large-scale stream processing systems, bridging a gap previously existing in the field.", "venue": "SIGMOD", "year": 2007, "title": "Resource-adaptive real-time new event detection"}
{"pid": "634d805990e50fcafd4e0f74", "context": "Tasks in machine learning using relational data often require time-consuming effort of collecting features across multiple relations, which involves solving a data discovery and integration problem.", "key_idea": "The authors propose LEVA, an end-to-end system that builds a relational embedding by representing relational data as a graph and then using embedding methods to translate it into vectors, ultimately boosting the performance of machine learning tasks.", "method": "LEVA's performance is demonstrated on different classification and regression datasets, where it is compared with multiple other baselines.", "outcome": "The study shows that the supervision signal from the downstream task filters out information that is not useful, resulting in the improvement of machine learning task performance while using LEVA.", "future_impact": "LEVA can potentially help analysts avoid the time-consuming effort of collecting features across multiple relations, instead relying on these techniques to train better-performing models.", "venue": "SIGMOD", "year": 2022, "title": "Leva: Boosting Machine Learning Performance with Relational Embedding Data Augmentation"}
{"pid": "d2cb59e8-971a-4655-9fe3-4714326fbd31", "context": "Querying databases normally requires the user's knowledge of query language and underlying data, which can be challenging because human memory is often imprecise, incomplete, and may contain errors.", "key_idea": "The authors present Kaleidoscope, a cooperative query interface that guides users through query creation to reduce errors. It generates valid query constituents step-by-step by interpreting a language grammar, which the user follows for query creation.", "method": "The user's process of creating a query in Kaleidoscope is described, showing how the system interacts with the user and guides them in constructing the query using a context-sensitive menu and updating a partial query status window. A procedural decoration attached to grammar rules is used to implement this intraquery guidance.", "outcome": "The application of Kaleidoscope's approach to two linear-syntax languages in different levels of abstraction is reported, and it's noted that Kaleidoscope runs on a XEROX-1186 LISP machine with a SUN server configured with a relational DBMS.", "future_impact": "The normative system assumption upon which Kaleidoscope is based suggests its potential application even in systems with a small amount of stored knowledge, possibly making it easier for users to interact with databases without extensive prior knowledge.", "venue": "SIGMOD", "year": 1990, "title": "Kaleidoscope: a cooperative menu-guided query interface"}
{"pid": "60d3093491e01182ead65d43", "context": "The integration of multiple GPUs into a single machine and the introduction of higher bandwidth interconnects like NVLink 2.0 has opened up new opportunities for relational query processing on multiple GPUs. Yet, due to unique characteristics of GPUs and the interconnects, existing hash join implementations spend up to 66% of their execution time moving data between GPUs with less than 50% utilization of the bandwidth, which leads to poor scalability.", "key_idea": "The authors propose MG-Join, a scalable partitioned hash join implementation on multiple GPUs of a single machine that employs a novel multi-hop routing for cross-GPU communication that adaptively chooses the efficient route for each data flow to minimize congestion.", "method": "The authors develop and test MG-Join on a DGX-1 machine, measuring its bandwidth utilization, scalability, and overall performance in comparison with state-of-the-art hash join implementations and database systems.", "outcome": "MG-Join is found to significantly reduce communication overhead and attains up to 97% utilization of the bisection bandwidth of the interconnects, outperforming state-of-the-art hash join implementations by up to 2.5x and enhancing the overall performance of TPC-H queries by up to 4.5x over the multi-GPU version of the Omnisci GPU database.", "future_impact": "MG-Join could revolutionize the field of relational query processing on multiple GPUs, offering superior performance, scalability and utilization of bandwidth.", "venue": "SIGMOD", "year": 2021, "title": "MG-Join: A Scalable Join for Massively Parallel Multi-GPU Architectures"}
{"pid": "60d3093491e01182ead65d77", "context": "Most database systems delegate scheduling decisions to the operating system, which simplifies the overall database design but presents challenges for adaptive resource allocation and incorporating domain knowledge to improve query scheduling. Modern systems often use task-based parallelism, breaking a single query into small, independent tasks for fine-grained scheduling. However, little work has investigated the optimization opportunities created by this execution model.", "key_idea": "The authors present a lock-free, self-tuning stride scheduler for database systems that optimizes query latencies for analytical workloads, with the ability to adaptively manage query priorities and task granularity for high scheduling elasticity, and incorporation of domain knowledge into scheduling decisions.", "method": "The paper's authors compare their novel stride scheduler to traditional database systems under various workloads, focusing on query latencies and workload management.", "outcome": "The self-tuning stride scheduler retains near-optimal latencies for short-running queries even at high load, and often improves tail latencies by over 10 times compared to traditional database systems.", "future_impact": "The proposed scheduler may serve as a strong solution for database systems having difficulty with certain workloads, making query processing more efficient in analytical environments.", "venue": "SIGMOD", "year": 2021, "title": "Self-Tuning Query Scheduling for Analytical Workloads"}
{"pid": "988330d0-938b-4e17-b5aa-8c997b2b3cd1", "context": "Before this study, attaching and propagating annotations (or Post-It notes) in relational databases as data is transformed was a challenging task. Tracing the provenance and flow of data systematically was difficult, and inserting new information about data without changing the database schema was not straightforward.", "key_idea": "The researchers propose DBNotes, a Post-It note system for relational databases where annotations can transparently propagate alongside data transformations. The annotation propagation is based on provenance (lineage), allowing the tracing of a data's origins and other related information.", "method": "The authors demonstrate how DBNotes operates, enabling the propagation of annotations based on the principle of data lineage/provenance. Annotations attached to sources can subsequently help to trace the provenance and flow of data.", "outcome": "With DBNotes, it is possible to trace the lineage of data and store additional information about the data. An error report could be attached to erroneous data, and this report will propagate to other databases along transformations, notifying other users of the error. The annotations, therefore, also provide an estimate of the quality of the database.", "future_impact": "This system could transform how data in relational databases is annotated and managed. The transparent propagation of annotations can notify users about errors, and the ability to insert new information about data without changing the schema is a useful feature that can adapt to various scenarios and applications.", "venue": "SIGMOD", "year": 2005, "title": "DBNotes: a post-it system for relational databases based on provenance"}
{"pid": "c406e90f-7b79-4154-b6ac-2912077fd2a4", "context": "Batch processing systems like Hadoop are commonly used for data analytics on large datasets. However, as there is increasing interest in reducing processing latency, this has led to renewed interest in execution engines that can process continuous queries, specifically windowed aggregation queries. These queries arise in a wide range of applications but finding the most suitable execution engine for these queries requires considerable manual effort.", "key_idea": "The authors present Cyclops, a continuous query processing platform that manages and orchestrates windowed aggregation queries in an ecosystem made up of multiple continuous query execution engines. With a cost-based approach, Cyclops determines the most suitable engine and plan for executing any given query.", "method": "The authors demonstrate an interactive visualization of the rich execution plan space of windowed aggregation queries, allowing users to analyze and understand the differences among plans. They also show the cost spectrum of query execution plans across three different execution engines (Esper, Storm, and Hadoop) as estimated by Cyclops.", "outcome": "Cyclops is able to orchestrate windowed aggregation queries by executing them on the most suitable engine, reducing manual effort and optimizing performance. Cost spectrum of query execution plans across different engines demonstrate the capabilities of Cyclops.", "future_impact": "The Cyclops platform could encourage further development and usage of execution engines, optimizing the performance of continuous queries in big data analytics environments, leading to diversified requirements and effective cost-based approach for query execution.", "venue": "SIGMOD", "year": 2013, "title": "Execution and optimization of continuous queries with cyclops"}
{"pid": "273c7a1c-8bb9-4b00-b3cf-3dcb184e59cd", "context": "Creating an Electronic Dictionary System (EDS) that can accommodate dictionaries of various different languages with different structures and enable efficient and complex queries remains a challenge.", "key_idea": "The authors develop an EDS using object-oriented database techniques based on ObjectStore, which is composed of a Database Building Program (DBP) that reads in a dictionary encoded in SGML tags, and a Database Querying Program (DQP) that uses a tree model, Category Lists, and an optimization procedure.", "method": "The authors use the DBP to process SGML-tagged dictionaries and build a database from them, and then perform complicated queries using DQP, comparing its performance against a relational database system.", "outcome": "The results show that DQP achieves much higher speed and flexibility in comparison to traditional relational databases.", "future_impact": "This paper demonstrates a new way of applying Object-Oriented Database Management Systems to systems that handle text information with strong yet varied intrinsic hierarchies.", "venue": "SIGMOD", "year": 1995, "title": "Application of OODB and SGML techniques in text database: an electronic dictionary system"}
{"pid": "d67539fa-c306-4ab6-a281-2ea15c546491", "context": "In current database systems, the optimization of queries embedded in programs occurs during the compilation of the program, requiring the query optimizer to make assumptions about variables, resources and data in the database. The optimality of the resulting query evaluation plan depends on these assumptions which can create efficiency issues when the established evaluation plan is used over an extended period of time.", "key_idea": "The authors propose developing specific criteria for when reoptimization of queries is necessary and propose a new technique called dynamic query evaluation plans to avoid unnecessary reoptimization.", "method": "They plan to identify reoptimization criteria and implement them efficiently while incorporating their technique of dynamic query evaluation plans into the EXODUS optimizer generator.", "outcome": "The authors have just outlined the advantages and the need for dynamic plans but haven't yet shown concrete experimental results.", "future_impact": "The adoption and execution of dynamic query evaluation plans could lead to efficient database systems that significantly reduces the periodical need for reoptimization.", "venue": "SIGMOD", "year": 1989, "title": "Dynamic query evaluation plans"}
{"pid": "9244cc33-cfb4-4713-be25-2563241656bd", "context": "Query optimizers rely on both the statistics of the entire table and the individual partitions to enhance query performance and manage the data. In Oracle 10g, the gathering of these statistics requires two separate scans of the entire table and the individual partitions. When data in some partitions changes, both types of statistics are regathered, resulting in unnecessary scanning of the whole table.", "key_idea": "In Oracle 11g, a new one-pass distinct sampling based method is adopted, which accurately derives the table level statistics from the partition level statistics. On data change, Oracle 11g only regathers the statistics for the changed partitions, omitting the need to re-scan the entire unchanged table.", "method": "The authors conducted comprehensive experiments on both benchmark data and real customer data to validate the efficiency and performance of the new method.", "outcome": "The experimental results showed that the new method used in Oracle 11g significantly outperforms the old method used in Oracle 10g in terms of accuracy and speed.", "future_impact": "The implementation of the one-pass distinct sampling technique, a first in commercial databases like Oracle 11g, signifies a potential shift in how large databases manage and optimize data processing.", "venue": "SIGMOD", "year": 2008, "title": "Efficient and scalable statistics gathering for large databases in Oracle 11g"}
{"pid": "c5867b57-c79b-4c88-970c-fd9c0eb082ac", "context": "Much attention has been given to improving the node fanout of B-tree internal nodes to minimize tree height and the importance of B-tree page size. However, less focus has been given on understanding the architecture of B-tree internal nodes.", "key_idea": "The author seeks to describe the evolution of internal node architecture and techniques in B-trees, considering each problem that was addressed during the various incremental steps that have led to improved node organizations.", "method": "This paper appears to leverage a review and historical analysis of the evolution of B-tree node organizations and the problems tackled during each step of the improvement.", "outcome": "The paper provides a detailed account of the evolution of B-tree internal node architecture, shedding light on problems tackled at each stage of improvement towards better node organizations.", "future_impact": "The understanding garnered from this historical account could guide future optimization efforts related to B-tree architecture and node organization techniques.", "venue": "SIGMOD", "year": 2001, "title": "The evolution of effective B-tree: page organization and techniques: a personal account"}
{"pid": "f7d77893-7bdc-4f21-8ff8-cbde62211f7d", "context": "The paper discusses the challenge of processing relational queries in the domain based database machine DBMAC.", "key_idea": "This paper presents how relational queries can be translated into operations on the objects of D-model in a domain based DBMS.", "method": "The paper first defines the objects of the D-model and a set of operations on these objects, then showing this set S as complete, demonstrating that any relational query can be translated into D-model operations belonging to S. Finally, a method for processing relational queries using D-model operations is provided.", "outcome": "The procedure shows that fast equi-join execution and a compact representation of intermediate results can be obtained through a domain-based physical organization of data.", "future_impact": "The efficient and compact processing of complex queries outlined in the paper requires a powerful parallel physical architecture for implementation, so it provides potential for future research and development in this area.", "venue": "SIGMOD", "year": 1983, "title": "Relational queries in a domain based DBMS"}
{"pid": "4e268597-ae93-4ffe-b860-3bc4af078138", "context": "The status quo lacks a thorough exploration of relations constructed via the union and selection operations from fragment relations. Existing literature does not provide sufficient insights on managing insertions and deletions in such relations, access set determination for a relation, and the interaction of fragmentation with queries on the relation.", "key_idea": "The paper introduces a theory that develops on the understanding of relations constructed from fragment relations through union and selection operations. Key topics include meaningfulness of relation insertions and deletions, finding an access set for a relation, and the effect of relation fragmentation on queries.", "method": "The authors develop algorithms for inserting and deleting from relations composed of physical fragments and demonstrate when such operations are meaningful. They describe a method for finding an access set for a relation, apply it to examine how fragmentation of relations interacts with a query on the relation.", "outcome": "The paper demonstrates that a selection on the relation can be implemented by retrieving a set of physical fragments that forms an access set for another particular relation.", "future_impact": "The presented theory could be foundational for further research into understanding how to better manage relational databases, performing more optimized queries, and ensuring more effective data storage and retrieval.", "venue": "SIGMOD", "year": 1983, "title": "Fragments of relations"}
{"pid": "634d805990e50fcafd4e0ee8", "context": "Traditional content exploration tools have a need to curate extraction pipelines for text collections or the necessity to annotate large amounts of training data.", "key_idea": "ASET, an ad-hoc tool, is presented to explore unstructured text data by automatically organizing relevant portions into tabular form, eliminating the need for pre-established extraction pipelines or extensive training data annotation.", "method": "ASET operates with a two-phased approach. Initially, it extracts a superset of information nuggets using available extractors like named entity recognizers. Following this, it applies embeddings and a new matching strategy to match the extractions to a structured table definition as specified by the user.", "outcome": "The demo of ASET displays a graphical user interface that permits people lacking machine learning or programming expertise to efficiently explore text collections.", "future_impact": "With ASET, exploring text collections can be more self-directed and flexible, and it is anticipated that ASET will help provide users an intuitive impression of result quality.", "venue": "SIGMOD", "year": 2022, "title": "Demonstrating ASET: Ad-hoc Structured Exploration of Text Collections"}
{"pid": "21c96237-0bd2-4f27-8263-756c6c308f5b", "context": "Previously, rebuilding B+-tree indexes online posed a challenge, consuming considerable system resources, impacting performance, and potentially causing deadlocks with other index operations.", "key_idea": "This study proposes an efficient method to perform an online rebuild of a B+-tree index that achieves high concurrency, minimal logging, good performance, no deadlock with other index operations while maintaining good space utilization and clustering.", "method": "The proposed method involves copying the index rows to newly allocated pages in key order and deallocating old pages during the process. It rebuilds multiple leaf pages before propagating changes to higher levels, and when propagating leaf-level changes to higher levels, level 11 pages are reorganized, thus eliminating the need for a separate pass.", "outcome": "The performance study shows that the approach significantly reduces logging and CPU time. Also, the concurrency control mechanism in the proposed approach is the same as that in split and shrink operations.", "future_impact": "The new method's consistency with existing concurrency control mechanisms during split and shrink operations makes it attractive for implementation in database systems, potentially enhancing online B+-tree index rebuilding processes.", "venue": "SIGMOD", "year": 2000, "title": "Online index rebuild"}
{"pid": "8f39c9a5-d14e-4973-bf01-f5fc1cdf7cd4", "context": "Application experts often struggle with executing their applications on a computer, primarily due to their lack of programming expertise.", "key_idea": "The authors propose the System for Business Automation (SBA), within which non-programmers can describe and execute their applications. This system uses a programming language that is a superset of Zloof's Query-by-Example, wherein users program within skeletons of business entities using a series of Query-by-Example operations.", "method": "The proposed system allows users to program within skeletons of business entities such as tables, forms, charts, etc., using a series of Query-by-Example operations.", "outcome": "The System for Business Automation was successful in enabling application experts to manage their applications on a computer even with a limited understanding of programming. The system can run in a partly manual and partly automated manner, facilitating quick initial use of the computer while gradually automating the business process.", "future_impact": "While not explicitly stated by the authors, the SBA system can potentially democratize application development, enabling non-programmers to configure and deploy applications, thereby fostering faster automation of business processes.", "venue": "SIGMOD", "year": 1976, "title": "The System for Business Automation (SBA): Programming language"}
{"pid": "d1c2e9d7-1bbc-4ed1-9cdc-0be57da63f2a", "context": "Traditional join algorithms in a relational database management system (DBMS) are designed to minimize the time to completion of a query, but are not suitable for online processing of multi-table aggregation queries in exploratory decision-support applications.", "key_idea": "The authors present ripple joins, a new class of join algorithms designed to minimize the time until an acceptably precise estimate of the query result is available. Ripple joins are adaptive, taking into account the statistical properties of the data, and allow the user to balance the time between successive updates of the running aggregate and the rate of confidence interval reduction at each update.", "method": "The authors implemented ripple joins within a conventional DBMS using iterators, also detailing the strategies used to compute confidence intervals and to adaptively optimize the ripple join 'aspect-ratio' parameters. The effectiveness of ripple joins was evaluated in experiments within the POSTGRES DBMS.", "outcome": "In the conducted experiments, the time required to produce reasonably precise online estimates using ripple joins was up to two orders of magnitude smaller than the time required for the best offline join algorithms to produce exact answers.", "future_impact": "The ripple join algorithms could facilitate more efficient online processing of multi-table aggregation queries and improve the interactive capabilities of decision-support applications.", "venue": "SIGMOD", "year": 1999, "title": "Ripple joins for online aggregation"}
{"pid": "42aeb4e4-7e72-4c2f-8a0f-30493a837271", "context": "Existing methods for answering all relational calculus queries require the use of auxiliary variables or invented constants or an explicit enumeration of the active domain, which could be a possible limitation for large data values domain.", "key_idea": "The authors propose a method for answering all relational calculus queries under the assumption that the domain of data values is sufficiently large, without the need for auxiliary variables, invented constants or an explicit enumeration of the active domain.", "method": "The method utilizes extended relation representations for answering domain dependent queries. Additionally, the method maps relational algebra operations with relational calculus queries extending relational algebra to a full boolean algebra, where intersection, union, and difference are defined between any two relations.", "outcome": "The proposed method is shown to be logically correct with polynomial data complexity. An example of the method shows effectiveness in the context of distributed query optimization.", "future_impact": "This approach could be significant for distributed query optimization, redefining how relational algebra operations are leveraged, potentially providing a more powerful tool for querying extensive datasets.", "venue": "SIGMOD", "year": 1993, "title": "Interpreting a reconstructed relational calculus (extended abstract)"}
{"pid": "5c7d6624-0a5a-467a-a3ca-c7cfcf8cd64e", "context": "Many applications require the ability to manipulate sequences of data, indicating a need for efficient sequence query processing.", "key_idea": "The authors present a framework for optimizing sequence queries, featuring unique techniques such as query transformations, using metadata-driven optimizations, and caching intermediate results.", "method": "A bottom-up algorithm is developed which creates an efficient query evaluation plan based on cost estimates.", "outcome": "The authors effectively showcase their optimization framework for sequence queries but do not provide a specific measurable outcome.", "future_impact": "The authors identify multiple avenues of future research, implying that the presented framework could guide subsequent studies in sequence query processing.", "venue": "SIGMOD", "year": 1994, "title": "Sequence query processing"}
{"pid": "672e2c3e-1177-456a-a66e-72e700b73393", "context": "Provenance, or records of digital objects' origin, context, and other historical information, is an important topic in areas like databases. Despite its relevance, there has been limited interaction among researchers working on provenance across various computer science disciplines.", "key_idea": "The paper reports about the Principles of Provenance Workshop held in November 2007 that brought together researchers from different domains to discuss and address the problems related to provenance.", "method": "The researchers held a workshop to facilitate interactions among academics and developers working on provenance in a variety of settings, including databases, security, information retrieval, Semantic Web, and software engineering.", "outcome": "The workshop indeed took place, as reported, facilitating interaction among researchers working on provenance in different contexts and those applying it in practical scenarios.", "future_impact": "The workshop is expected to encourage collaborations, cross-disciplinary interactions, and practical applications of provenance concepts, which could potentially lead to innovative solutions in the future.", "venue": "SIGMOD", "year": 2008, "title": "Report on the Principles of Provenance Workshop"}
{"pid": "d398a6e0-31ce-4c20-921b-dbc8c35412a9", "context": "The need exists for a modern object-relational database system to serve as a research vehicle for the database community.", "key_idea": "PREDATOR, a freely available object-relational database system developed at Cornell University, is proposed for use in database research and education.", "method": "Not explicitly mentioned in the abstract, so it is marked as N/A", "outcome": "The authors developed PREDATOR to be a modern code base for database research, but specific outcomes such as evaluations or validations are not mentioned in the abstract.", "future_impact": "The authors anticipate PREDATOR will be an attractive choice for database research and education.", "venue": "SIGMOD", "year": 1998, "title": "PREDATOR: a resource for database research"}
{"pid": "ffd577b0-abff-4428-992c-26abb5997139", "context": "Existing systems for modeling and analyzing data streams representing financial contracts may be inflexible, making it challenging to integrate and analyze data from different sources.", "key_idea": "The Contract Aggregation Framework (CAF) is proposed as a flexible and extensible system for modeling and analyzing data streams that represent a variety of financial contracts such as privately negotiated deals and exchange-traded securities.", "method": "The authors demonstrate the use of CAF through an exemplar representing trading in corporate equities and bonds. Using a measure of Market volume, they deploy several analytical methods to explore the data.", "outcome": "Initial observations suggest that the CAF successfully integrates and analyzes data from different sources, proving its beneficial capabilities.", "future_impact": "Although the authors do not state this explicitly, the future impact could be the transformation of financial data stream analytics through the wider adoption of more flexible and extensible frameworks like the CAF.", "venue": "SIGMOD", "year": 2014, "title": "A Flexible and Extensible Contract Aggregation Framework (CAF) for Financial Data Stream Analytics"}
{"pid": "39b9f06e-c00c-491f-a0ba-569575f114bb", "context": "Existing annotation management techniques in relational databases are all passive engines which manage annotations obtained from external sources. They neither learn from the available annotations nor exploit the annotations-to-data correlations to enhance the quality of the annotated database.", "key_idea": "This paper proposes the Nebula system, a proactive annotation management engine in relational databases, which learns from available annotations, analyzes their content and semantics, and understands their correlations with the data to discover and recommend potentially missing annotation-to-data attachments.", "method": "The researchers propose context-aware ranking and prioritization of the discovered attachments, approximation techniques, and expert-enabled verification mechanisms, and implement Nebula on top of an existing annotation management engine. The system is then experimentally evaluated to illustrate the effectiveness of the proposed techniques.", "outcome": "Nebula system successfully demonstrates an effective way to enhance the quality of annotated databases by learning from existing annotations, analyzing their content, and proactively discovering potential missing attachments.", "future_impact": "The proposed techniques in Nebula system can potentially enhance the quality of future annotation management in large-scale databases, minimizing the need for expert involvement and improving data accuracy.", "venue": "SIGMOD", "year": 2015, "title": "Proactive Annotation Management in Relational Databases"}
{"pid": "b48ac698-ee37-4c30-bb69-44fc7895c4b9", "context": "Database engines are optimized for storing and processing text data based on Latin scripts, and while they support management of multilingual data, no prior studies have quantitatively compared their performance in handling diverse languages. Moreover, some necessary features for multilingual functionality remain unimplemented in popular database systems.", "key_idea": "The authors first quantify the performance of multiple database systems in handling multilingual data and then propose Cuniform, a compressed format that is easily convertible to Unicode, as a solution to improve the processing of multilingual scripts in database systems.", "method": "The authors profile the performance of various databases in handling text data in ISO:8859, the standard database character set, and in Unicode, the multilingual character set. Additionally, they conduct initial experiments with Cuniform to test its performance.", "outcome": "The experiments reveal significant performance degradation in handling multilingual data in current database systems, with further inconsistencies in the query optimizer's accuracy between standard and multilingual data types. Initial tests with Cuniform show it largely eliminates the performance degradation for multilingual scripts with small repertoires.", "future_impact": "The Cuniform format has the potential to support extensions to SQL for more efficient multilexical text processing in future implementations.", "venue": "VLDB", "year": 2003, "title": "On the cost of multilingualism in database systems"}
{"pid": "7d45f7ed-e2d7-4101-a23b-8ca95b734ddd", "context": "The decomposition storage model (DSM) is excellent for I/O performance when the number of attributes accessed by a query is small and has a better cache footprint than the standard storage model (NSM) used by most database systems. However, it incurs a high cost in reconstructing the original tuple from its partitions.", "key_idea": "The authors suggest a simple indexing strategy and compare different reconstruction algorithms. They also propose a new mirroring scheme, termed 'fractured mirrors', that uses both NSM and DSM models.", "method": "The authors built a prototype system using the Shore storage manager and evaluated its performance using queries from the TPC-H workload.", "outcome": "The performance of the proposed 'fractured mirrors' scheme was evaluated, but the abstract does not specify the output of these experiments.", "future_impact": "The 'fractured mirrors' scheme aims to combine the best aspects of NSM and DSM storage models and has the potential to better serve an ad hoc query workload, indicating its potential impact on the field of database systems.", "venue": "VLDB", "year": 2003, "title": "A case for fractured mirrors"}
{"pid": "bbe5afaa-1add-48c2-83c4-5418a50c59d2", "context": "A major problem in relational database systems is finding efficient procedures for database operations, particularly regarding scheduling join operations in a paging environment. The challenge lies in doing so while minimizing page-swapping counts.", "key_idea": "The paper introduces heuristic procedures for obtaining near-optimum solutions to the problem by treating it as a special case of the Hamiltonian path problem, which is NP-complete.", "method": "Two sufficient conditions for the existence of the minimum solutions are proposed. These conditions are based on the Hamiltonian path condition and the Euler path condition.", "outcome": "Using the two proposed conditions, heuristic procedures for near optimum solutions are developed.", "future_impact": "The authors demonstrate a new way to approach scheduling in join operations of relational database systems, offering means to derive near optimal solutions, which could impact future research and improvements in this area.", "venue": "VLDB", "year": 1981, "title": "Scheduling of page-fetches in join operations"}
{"pid": "efcc72a2-346b-424a-9ac1-db3aa7c6cd6b", "context": "Current MapReduce frameworks such as Hadoop lack native support for spatial data, posing a problem when dealing with spatial data.", "key_idea": "The paper presents SpatialHadoop, the first comprehensive MapReduce framework with native support for spatial data. SpatialHadoop pushes spatial data inside the core functionality of Hadoop and has basic spatial components built inside the MapReduce layer.", "method": "The system prototype of SpatialHadoop was demonstrated running on an Amazon EC2 cluster against two sets of real spatial data obtained from Tiger Files and OpenStreetMap with sizes 60GB and 300GB, respectively.", "outcome": "SpatialHadoop runs existing Hadoop programs as is, yet, it achieves order(s) of magnitude better performance than Hadoop when dealing with spatial data.", "future_impact": "The paper suggests that other spatial operations can be similarly deployed in SpatialHadoop, which could open new avenues for more efficient handling of spatial data.", "venue": "VLDB", "year": 2013, "title": "A demonstration of SpatialHadoop: an efficient mapreduce framework for spatial data"}
{"pid": "482cec2e-badb-4346-9319-4468cd188358", "context": "On the Semantic Web, data comes from many different ontologies, and processing information across these ontologies is impossible without understanding the semantic mappings between them. Manual mapping is tedious, error-prone, and not scalable.", "key_idea": "The authors propose GLUE, a system that utilizes machine learning techniques to automatically find mappings between different ontologies. The system works with a variety of well-defined similarity measures and efficiently incorporates multiple types of knowledge.", "method": "The authors test GLUE on several real-world domains, using probabilistic definitions of several practical similarity measures and multiple learning strategies that exploit various types of information in the data instances or the taxonomic structure of the ontologies.", "outcome": "The GLUE system is shown to propose highly accurate semantic mappings in the tested domains, and it can also be extended to find complex mappings between ontologies.", "future_impact": "The successful implementation and results of the GLUE system could accelerate the development of tools needed for efficient and accurate ontology mapping, thus making information processing across different ontologies on the Semantic Web more feasible.", "venue": "VLDB", "year": 2003, "title": "Learning to match ontologies on the Semantic Web"}
{"pid": "bf3b2e4b-c193-441d-b242-1f0d955793b9", "context": "Previous works deal with numeric databases, where instances are vectors in Rn and queries involve their linear transformations with imprecise query answers as intervals.", "key_idea": "The paper introduces a security requirement function \u03c1 for a query, which specifies the maximum probability \u03c1(l) that the precise query answer is within any interval of length l.", "method": "The authors develop random disclosure algorithms that satisfy the proposed security requirement functions.", "outcome": "Under certain conditions, the developed random disclosure algorithms can guarantee maximum data availability.", "future_impact": "The introduction of the security requirement function \u03c1 for queries can potentially increase the robustness and security of numeric database systems.", "venue": "VLDB", "year": 2007, "title": "Answering queries based on imprecision and uncertainty trade-offs in numeric databases"}
{"pid": "6c0208af-7935-433b-9265-f85f38abb85d", "context": "The requirements for a main memory data storage model are both compactness and efficient processing for all database operations.", "key_idea": "The authors propose DBGraph, a storage model that represents the entire database in a graph-based structure, fully exploiting the direct-access capability of main memory systems.", "method": "Operations like Selection, Join and Transitive closure over base or temporary relations are tested by DBGraph traversal without tuple comparison and move. DBGraph's decomposability is also examined by loading only the useful subset of the database from disk without format conversion. Database queries are processed by either set-oriented or pipelined mode depending on the graph's traversal.", "outcome": "Analysis shows DBGraph has good storage occupancy and excellent performance for both update and retrieval operations.", "future_impact": "Complex database queries can be processed effectively by either set-oriented or pipelined mode depending on the way the graph is traversed, which can enhance the efficiency of database management systems in the future.", "venue": "VLDB", "year": 1990, "title": "Efficient main memory data management using the DBgraph storage model"}
{"pid": "30e944c3-0ae4-424d-b4b2-239edcc280d6", "context": "Database programming requires an understanding of database semantics to maintain database integrity and for optimization. There is a need for the automated programming of database transactions, as they often follow simple constructs and algorithms, use available database semantics, and perform small incremental updates.", "key_idea": "The authors propose an approach for the automated synthesis of database transactions that ensure the preservation of integrity constraints using deductive techniques, with a transaction logic developed as a formalism for this synthesis.", "method": "The synthesis process involves generating transactions as a by-product of proving specifications in the proposed transaction logic. The Manna-Waldinger deductive-tableau system is extended with inference rules for extracting transactions from these proofs.", "outcome": "Transactions are successfully generated as a by-product of the proof process in the proposed logic, using the extended Manna-Waldinger deductive-tableau system.", "future_impact": "The approach could pave the way for more effective database programming by enabling automated programming of database transactions that adhere to database integrity and semantic rules.", "venue": "VLDB", "year": 1990, "title": "Synthesizing Database Transactions"}
{"pid": "c7f700ed-4273-4eab-bd51-2289179c42ea", "context": "Selectivities estimation for range and spatial join queries in real spatial databases has been a challenging task because real point sets consistently violate the 'uniformity' and 'independence' assumptions and often display fractal nature with non-integer dimensionalities.", "key_idea": "The paper presents a new approach to solve selectivity estimation problem by identifying that the 'Correlation Dimension' Dz, a specific type of fractal dimension, is the dimension needed to predict the selectivity of spatial join. It also proposes that the average number of neighbours for a given point-set follow a power law, with LIu0026 as the exponent.", "method": "The method involves observing the behavior of real and synthetic point-sets under the proposed approach and modelling of 'biased' range queries. The bias is that queries' centers prefer areas of high point density.", "outcome": "The approach successfully solves the selectivity estimation for spatial joins and 'biased' range queries. It results in very low relative errors (typically about 10%) as compared to the 40%-100% errors of the uniformity assumption, as shown on real and synthetic point sets. ", "future_impact": "The approach has potential to vastly improve the efficiency of selectivity estimation for range and spatial join queries in real spatial databases, and could catalyze further research into the application of fractal dimensions within this domain.", "venue": "VLDB", "year": 1995, "title": "Estimating the Selectivity of Spatial Queries Using the `Correlation' Fractal Dimension"}
{"pid": "6b1110b0-86e4-46f5-a7ab-8208fa7de00c", "context": "Lack of trust between commercial entities and purchasers can restrict the potential of e-commerce. The challenge for researchers is determining the e-commerce model that maximizes the trust relationship.", "key_idea": "The authors address this challenge by creating a measure of trust based on the information distributed to the parties in the transaction and propose four new e-commerce models to maximize trust for the purchaser.", "method": "The authors isolate instances which maximize trust for the purchaser and use this to guide the development of four new models for e-commerce.", "outcome": "The paper proposes four new models for improving consumer trust in e-commerce transactions. It demonstrates that no new technologies are needed to implement these models.", "future_impact": "The proposed models are expected to lead to an increase in online commerce by improving consumer trust.", "venue": "VLDB", "year": 2008, "title": "A Trusted Approach to E-Commerce"}
{"pid": "ca49784d-969b-4402-8309-f2bb6b674b0c", "context": "In Semantic Web databases, explicit data is encoded in RDF triples with additional implicit data implied by the RDF semantics. Optimal view selection for materialization can minimize costs related to query processing, view storage, and maintenance,  but existing relational view selection methods are not ideally suited to the RDF context.", "key_idea": "The authors propose new algorithms for recommending view sets in RDF Semantic Web databases, and introduce a novel RDF query reformulation algorithm to account for implicit triples in query answers without increasing the complexity of the selection process.", "method": "Starting with an existing relational view selection method, the authors adapt it for the RDF context and incorporate their proposed RDF query reformulation algorithm into the view selection process, the effectiveness is demonstrated through a series of experiments.", "outcome": "The techniques proposed in this paper proved to be effective in view selection in Semantic Web databases, as demonstrated through experiments. These new algorithms scale significantly beyond existing ones.", "future_impact": "This paper introduces novel methods that enhance efficiency and scalability in view selection within Semantic Web databases, which could lead to improved contextual retrieval, processing efficiency, and cost savings in maintaining Semantic Web databases.", "venue": "VLDB", "year": 2011, "title": "View selection in Semantic Web databases"}
{"pid": "50b5437f-81d8-43a4-a950-78f125113829", "context": "There are existing concepts for version management in databases but they are neither general nor powerful enough to tailor to specific user requirements.", "key_idea": "The authors introduce a general model for version management, expressed as the concept of version environments, that provide mechanisms for structuring version sets of objects.", "method": "The application tools are embedded into the version environment allowing it to be tailored according to the specific user requirements. They demonstrate how well-known version concepts can be implemented using this version environment.", "outcome": "The proposed version environment concept proved to be more general and powerful than the existing concepts.", "future_impact": "The generation and application of version environments would provide users with specific application environments, consisting of objects, their version structures, and the tools operating on them, tailored to their specific requirements.", "venue": "VLDB", "year": 1986, "title": "A General Model for Version Management in Databases"}
{"pid": "abba58c3-44bc-4d6c-a714-e18e6a5304d9", "context": "Association Rule Mining algorithms operate on a data matrix and derive association rules. These traditional methods often require multiple passes over the data set and/or large memory.", "key_idea": "The authors propose a new paradigm, Ratio Rules, that can measure the 'goodness' of a set of discovered rules. They also propose the 'guessing error' as a measure of the 'goodness'. Ratio Rules, unlike association rules, can perform important tasks such as forecasting, answering 'what-if' scenarios, detecting outliers, and visualizing the data.", "method": "A novel method to guess missing/hidden values from the derived Ratio Rules is introduced. Also, experiments were carried out on several real data sets like basketball and baseball statistics, biological data.", "outcome": "The proposed method results in rules that make sense, finds large itemsets in binary matrices even in presence of noise, and consistently achieves a 'guessing error' up to five times less than using straightforward column averages.", "future_impact": "The Ratio Rules paradigm has the potential to enhance the capabilities of data mining by facilitating tasks such as forecasting and detecting outliers. Moreover, it can process data in a single pass with small memory requirements, an improvement over traditional association rule mining methods.", "venue": "VLDB", "year": 2000, "title": "Quantifiable data mining using ratio rules"}
{"pid": "1bbc1cfa-6ead-4c4c-81af-00cd0d9c1fd0", "context": "Table addressing and file handling traditionally face issues with changing record count, leading to deteriorations in access or memory load performance.", "key_idea": "The paper introduces Linear Hashing, a novel method where the address space can dynamically grow or shrink, which allows for any number of insertions or deletions without performance degradation.", "method": "The authors used Linear Hashing on files and tables to examine the method's efficiency in handling changes in record size while maintaining performance.", "outcome": "With Linear Hashing, a record in a file can be located in a single access while maintaining a nearly constant load of up to 90%. Similarly, a record in a table can be found with a mean of 1.7 accesses with an unchanging load of 80%.", "future_impact": "The potential for future research lies in exploring other applications of Linear Hashing and improving it further, considering no other algorithms with similar performance have been identified so far.", "venue": "VLDB", "year": 1980, "title": "Linear hashing: a new tool for file and table addressing"}
{"pid": "9c23be6b-9ad5-40e5-bd20-9d6c5cce40b2", "context": "Previous solutions for continuous and on-line evaluation of concurrent continuous spatio-temporal queries over data streams suffered from inefficient use of scarce memory resources.", "key_idea": "The authors present a Scalable On-Line Execution (SOLE) algorithm, which optimizes memory use by maintaining only significant objects and expiring insignificant ones. SOLE is scalable, allowing all queries to share the same buffer pool, and is presented as a spatio-temporal join between two input streams.", "method": "SOLE is implemented as a pipelined query operator in a prototype of a data stream management system. Its performance and efficiency are tested in highly dynamic environments.", "outcome": "Performance experiments show that the SOLE algorithm is scalable and efficient in highly dynamic environments.", "future_impact": "The authors suggest that SOLE can be combined with traditional query operators in a query execution plan, indicating its potential to support a wide variety of continuous queries in the future.", "venue": "VLDB", "year": 2008, "title": "SOLE: scalable on-line execution of continuous queries on spatio-temporal data streams"}
{"pid": "c972347b-cad8-4795-b0d6-21b3689e01ee", "context": "Currently, there's a growing need for non-expert users to access databases, and information systems are becoming characterized by several heterogeneous component systems rather than a single centralized architecture.", "key_idea": "The authors have designed a new query system with both user-oriented and multidatabase features, featuring an adaptive visual interface, interchangeable interaction modalities, and a 'translation layer' to create the illusion of a single homogeneous schema from several heterogeneous components.", "method": "The system's components are constructed on a formally defined and semantically rich data model, the Graph Model, and a set of Graphical Primitives for visually expressing general query operations. The paper describes how schemata in different data models can be translated into the Graph Model and how mappings can be established between known query languages and the Graphical Primitives.", "outcome": "The authors detail how queries expressed using the Graphical Primitives can be translated into relational expressions to be processed by actual DBMSs.", "future_impact": "The introduced system has the potential to facilitate the interaction of non-expert users with databases and heterogeneous information systems, although specific future applications or improvements are not explicitly outlined in the abstract.", "venue": "VLDB", "year": 1997, "title": "Graphical interaction with heterogeneous databases"}
{"pid": "fedd85a7-e026-443e-bf7e-32d5f99c227d", "context": "In spatial database outsourcing, data management tasks are delegated to a location-based service (LBS) that indexes the data with an authenticated data structure (ADS). Most ADSs must be constructed and maintained by the data owner, which is a computationally intensive task.", "key_idea": "The key idea proposed by the authors includes the development of two novel ADSs, the MR-tree and the MR*-tree. The latter is a modified version of the MR-tree that significantly reduces the size of the verification object through a novel embedding technique.", "method": "The authors propose outsourcing the MR-tree and MR*-tree construction and maintenance tasks to the LBS, which is a deviation from existing approaches where the data owner performs these tasks.", "outcome": "Two new ADSs, the MR-tree and MR*-tree, were introduced. The MR*-tree utilizes a novel embedding technique to significantly reduce the size of the Verification Object.", "future_impact": "The new approach of outsourcing the construction and maintenance of the MR-tree and MR*-tree to the LBS could alleviate the computational burden on data owners, which could transform the way spatial database outsourcing is managed.", "venue": "VLDB", "year": 2009, "title": "Authenticated indexing for outsourced spatial databases"}
{"pid": "e946c3ee-550f-457e-a50b-954fc522414a", "context": "Conventional approaches to execution of database queries on general-purpose multiprocessors maximize system throughput using inter-query parallelism with a fixed number of processors and standard uniprocessor optimization techniques.", "key_idea": "The paper proposes a method to increase performance by using intra-query parallelism and minimizing overall resource requirements, specifically through coordination of the order in which data pages are read into memory and page joins are assigned to available processors.", "method": "The paper presents a scheduling strategy based on join indices, along with a heuristic for estimating the required number of processors to complete join execution in minimal time. The approaches' resource requirements are validated through lower and upper bound proofs and simulated performance.", "outcome": "Simulation results indicate that the proposed techniques effectively utilize processors and buffer requirements.", "future_impact": "The methodology and techniques proposed in this paper, especially the heuristic for estimating the number of processors required, could lead to significant performance improvements and resource optimizations in the execution of database queries on multiprocessor systems.", "venue": "VLDB", "year": 1989, "title": "Effective resource utilization for multiprocessor join execution"}
{"pid": "6391890890e50fcafd2b4835", "context": "A significant fraction of data in cloud storage is rarely accessed, this cold data is a challenge for cloud providers to balance between reducing cost and improving system performance. Current methodology with LSM-tree default process does not fully utilize the access information of data records, leading to a suboptimal data layout that negatively impacts the system performance.", "key_idea": "The authors propose SA-LSM, a method that uses Survival Analysis for Log-Structured Merge Tree (LSM-tree) key-value stores. This method optimizes the data layout based on a statistical learning algorithm used in biostatistics, thereby improving the prediction of cold data using historical semantic information and access traces.", "method": "The authors implemented SA-LSM in X-Engine, a commercial-strength open-source LSM-tree storage engine, and offloaded CPU-intensive work, such as model training and inference, to an external service. They performed extensive experiments on real-world workloads.", "outcome": "The implementation of SA-LSM can decrease the tail latency by up to 78.9% compared to the state-of-the-art techniques according to experiments on real-world workloads.", "future_impact": "The generality of this approach and the significant performance improvement show great potentials in a variety of related applications.", "venue": "VLDB", "year": 2022, "title": "SA-LSM : Optimize Data Layout for LSM-tree Based Storage using Survival Analysis."}
{"pid": "9f378c60-c957-405c-b403-95b8672ebb6e", "context": "Modern computer workstations have thousands of applications that store data in over 100,000 files on the file system of the underlying operating systems. This results in a complex environment of data processing solutions and various data and file formats, which is challenging for users to manage.", "key_idea": "The authors have created a software system called iMeMex, which aims to act as a unified solution for personal information management and integration across different file formats.", "method": "iMeMex is designed to seamlessly integrate into existing operating systems, including Windows, Linux and Mac OS X, and allows existing applications to gradually dispose of file-based storage.", "outcome": "With the help of iMeMex, modern operating systems are able to make use of sophisticated database management systems, information retrieval and data integration technologies.", "future_impact": "The seamless integration of iMeMex into existing operating systems can enable new applications that provide unprecedented concepts of data storage and analysis.", "venue": "VLDB", "year": 2005, "title": "iMeMex: escapes from the personal information jungle"}
{"pid": "fa0f40c5-b2a8-4999-9005-187fc5fefb9b", "context": "The SQL language allows users to express queries with nested subqueries. Optimization of these nested queries has been a topic of interest recently. However, the existing solution for JA type queries, Kim\u2019s algorithm, has been identified to have the COUNT bug and a more generalized strategy is being used to circumvent it.", "key_idea": "In this paper, the authors propose an improved version of Kim's algorithm that avoids the COUNT bug, and may be more efficient than the general strategy in some situations.", "method": "The authors modify Kim's algorithm to circumvent the COUNT bug and also present a couple of enhancements that precompute aggregates and evaluate joins and outer joins in a top-down order.", "outcome": "The modifications and enhancements to Kim\u2019s algorithm proposed by the authors eliminate Cartesian products when certain correlation predicates are absent and enable the use of Kim's method for more blocks.", "future_impact": "The presented improvements will be incorporated into a new unnesting algorithm, which could lead to better optimization of SQL nested queries in the future.", "venue": "VLDB", "year": 1992, "title": "Improved Unnesting Algorithms for Join Aggregate SQL Queries"}
{"pid": "cd2a09cd-1ce3-4116-a17c-be8dc0dee701", "context": "Existing data cleaning tools have limitations in handling various types of data quality rules beyond the well known CFDs (FDs), MDs and ETL rules and providing easy customization features.", "key_idea": "The authors present NADEEF, a generic, extensible, and easy-to-deploy data cleaning system that distinguishes between a programming interface and core for generality and extensibility. The programming interface allows users to define data quality rules, while the core supports various algorithms for detecting and resolving data errors.", "method": "Users are allowed to test NADEEF's generic programming interface to define new types of rules and extend the core. The paper also demonstrates the use of a live data quality dashboard.", "outcome": "The authors demonstrate the system's heterogeneity, interdependency, deployment/extensibility, and metadata management, features provided by NADEEF, proving its extensibility, generality, and ease of deployment.", "future_impact": "NADEEF can significantly enhance the user's involvement in the data cleaning process by providing a live data quality dashboard, suggesting it could become a valuable tool in data management field.", "venue": "VLDB", "year": 2013, "title": "NADEEF: a generalized data cleaning system"}
{"pid": "f87f1a5a-934a-4861-8ddd-10898a223db5", "context": "The Teradata Database was originally on TOS, a proprietary ldbit Operating System and faced challenges in addressing the main Very Large Databases (VLDB) problems of performance and reliability.", "key_idea": "This study presents the parallel enhancements necessary to port the Teradata Database from TOS to an SVR4 Unix system and how the Teradata Database solves the main VLDB problems by transitioning from DBC/lOlZ nodes to virtual processors (vprocs).", "method": "The authors implemented the transition from Database Computer DBC/lOlZ nodes to the virtual processors (vprocs) which run concurrently in a collection of SMP nodes. They also introduced the Parallel Database Environment (PDE) add-on package to Unix.", "outcome": "The authors discussed the results of their performance enhancement work but did not provide specific quantitative outcomes in the abstract.", "future_impact": "The findings from this study will guide future enhancement work on Massive Databases in Unix systems, though specific further research is not explicitly identified in the abstract.", "venue": "VLDB", "year": 1995, "title": "OS Support for VLDBs: Unix Enhancements for the Teradata Data Base"}
{"pid": "115f082b-9790-4f97-8e58-8b847587cf88", "context": "Interacting with data management systems often requires specialized knowledge and can be hard for end-users, and there's a need for preventing unauthorized access to particular fields in a database.", "key_idea": "The study proposes EUFID, a man-machine interface system that allows users to communicate with data management systems in natural language and acts as a security screen for unauthorized access.", "method": "The approach taken is to model the restricted set of linguistic structures and functions required for each application, as opposed to trying to understand all properties of natural language.", "outcome": "Though explicit results are not mentioned, it is implied that this methodology enables efficient processing of English queries against specific databases.", "future_impact": "EUFID aims to be applicable in real-world scenarios, indicating a potential for wide-scale practical adoption.", "venue": "VLDB", "year": 1978, "title": "EUFID: the end user friendly interface to data management systems"}
{"pid": "93987f80-195a-43c3-94e2-3dd880768ef3", "context": "A decade ago, in database replication, achieving performance meant relying on lazy replication at the expense of transactional guarantees. The strong consistency of eager approaches brought high costs in performance and limited scalability.", "key_idea": "The authors invoke the early design of Postgres-R, a database replication solution system that fused distributed systems and databases to deliver both scalability and strong consistency through the use of group communication primitives with strong ordering and delivery guarantees, combined with optimized transaction handling.", "method": "The authors review the original motivation for Postgres-R, it's design and implementation, and trace the evolution of the ideas that underpinned its creation.", "outcome": "Ten years after its inception, the techniques introduced in Postgres-R\u2019s design are now commonly used in various contexts, especially in cloud computing scenarios.", "future_impact": "The narrative of Postgres-R provides a platform to continue evolving and optimizing database replication methods for emerging computing scenarios.", "venue": "VLDB", "year": 2010, "title": "Database replication: a tale of research across communities"}
{"pid": "1938f42f-a34f-435f-be80-a00e17fcdb6f", "context": "The Multiple Time Bucket Join (MTB-join) algorithm is the current best approach for processing continuous intersection join (CI-join) queries over moving objects, but it does not meet real-time application performance requirements for large sets of moving objects.", "key_idea": "This paper proposes a new algorithm called the multi-layered grid join (MLG-join) that leverages the computational power of GPUs and realizes certain key features, such as memory locality friendly indexing, no dynamic memory allocation, in-place object updates, lock-free concurrent updates, and massive parallelism.", "method": "The authors conduct a theoretical analysis which can predict the pruning power of the new MLG-join algorithm with certain parameters, and then validate the theoretical implications through extensive experiments.", "outcome": "The MLG-join algorithm outperforms the MTB-join algorithm and a GPU-based nested-loops join algorithm by up to two orders of magnitude, achieving real-time performance for CI-join queries on large sets of moving objects.", "future_impact": "The approach in the paper can be leveraged to further enhance the real-time application performance of CI-join queries over moving objects based on GPUs.", "venue": "VLDB", "year": 2014, "title": "Real-time continuous intersection joins over large sets of moving objects using graphic processing units"}
{"pid": "d86dad72-30a7-427f-a00f-655481a0dddd", "context": "Conventional access methods cannot be effectively used in large Scientific/Statistical Database (SSDB) applications, necessitating more appropriate solutions.", "key_idea": "A file structure known as the bit transposed file, which stores data by vertical bit partitions using various data encoding methods and can also apply a version of the run length encoding scheme for compression, is proposed as a suitable solution for handling large SSDBs.", "method": "The file structure is tested through experiments, and its efficiency was evaluated using developed operators on compressed bit vectors which form the basis of a query language.", "outcome": "The experiments suggest that the bit transposed file structure can be a reasonable alternative for storing and accessing large SSDBs.", "future_impact": "The bit transposed file structure exhibits not only a selective power with low overhead for SSDBs but also amicability to special parallel hardware, indicating potential for more efficient data handling in future SSDB applications.", "venue": "VLDB", "year": 1985, "title": "Bit transposed files"}
{"pid": "f00859b6-0938-46be-963b-7571b43011a6", "context": "Understanding the relationship, or links, among graph nodes is crucial for applications in areas such as social networks, bibliographic networks, and biological databases. However, traditional approaches have limitations in recognizing highly similar nodes.", "key_idea": "This paper proposes an extension to the similarity join operator, called link-based similarity join (LS-join), which uses link-based measures. The LS-join returns all pairs of nodes that are highly similar to each other, based on an e-function that generalizes common measures like Personalized PageRank and SimRank.", "method": "An efficient LS-join algorithm is studied on a large graph and further improvements are made for Personalized PageRank and SimRank, which involve expensive random walk operations.", "outcome": "The solutions were validated through extensive experiments conducted on three real graph datasets, demonstrating efficient results.", "future_impact": "The proposed LS-join can be used to enhance the understanding of relationships in graph-based applications and improve services like link prediction, recommendation, and spam detection.", "venue": "VLDB", "year": 2011, "title": "On link-based similarity join"}
{"pid": "a04fc1fa-d711-4296-9876-283875bad5c8", "context": "Declustering is a well-known strategy for achieving maximum I/O parallelism in multi-disk systems. Many declustering methods have been proposed for symmetrical disk systems, where all disks have the same speed and capacity. However, adapting these methods for heterogeneous environments, where there are many types of disks and servers with a wide range of speeds and capacities, is still a challenge.", "key_idea": "The paper addresses adapting declustering methods for heterogeneous environments with disks of varying speeds and capacities. It deals with the case of perfectly declustered queries and considers the fraction of the dataset allocated to each disk affected by both the relative speed and capacity of the disk. An algorithm is also proposed to determine this fraction of the dataset on each disk.", "method": "The authors propose an algorithm which calculates the fraction of the dataset that should be loaded on each disk. The algorithm can be adapted to find disk loading for minimal response time given a database size or compute a system profile showing optimal disk loading for varying database sizes.", "outcome": "The authors found that, surprisingly, to achieve optimality when retrieving data, the fraction of data loaded on each disk should not be directly proportional to its speed. Instead, a bias needs to be assigned towards the faster disks.", "future_impact": "The methods suggested in the paper are general and can be combined with most known symmetric declustering methods, potentially aiding in the optimization of data management on heterogeneous disk systems.", "venue": "VLDB", "year": 1995, "title": "Declustering Databases on Heterogeneous Disk Systems"}
{"pid": "891479bf-9d58-4427-b33c-4a5a2e6e1fcf", "context": "The author has implemented an integrated sort package as a part of an experimental relational database system called System R.", "key_idea": "The sort facility is designed and implemented specifically for variable length sort keys and tuples, aiming to support complex relational operations like join and projection, dynamic creation of access paths, and loading and reorganizing of data clustered by field values.", "method": "The input loop of the sort can be driven by various scans which allow the filtering of qualified tuples according to disjunctive normal forms of simple search arguments. Design decisions concerning sorting, peerage, and merging techniques in the sort facility are explored. The integration with storage and transaction management, locking, and logging components is also examined.", "outcome": "The paper presents a detailed structural design and implementation aspects of the sort facility with anticipated potential use in relational database systems.", "future_impact": "The sorting facility described in the paper could provide a powerful tool for implementing complex relational operations and supporting the dynamic creation of access paths and data reorganization in future relational database systems.", "venue": "VLDB", "year": 1977, "title": "A scan-driven sort facility for a relational database system"}
{"pid": "6391890890e50fcafd2b4650", "context": "Anomalous trajectory detection, which aims to extract abnormal movements of vehicles on the roads, is challenging due to varying traffic conditions at different times and locations.", "key_idea": "The paper proposes a deep-probabilistic-based time-dependent anomaly detection algorithm (DeepTEA) that employs deep-learning methods to obtain time-dependent outliers from a large volume of trajectories.", "method": "A more efficient version of DeepTEA is developed to capture abnormal behaviors in real-time.", "outcome": "Compared with state-of-the-art solutions, DeepTEA is 17.52% more accurate than seven competitors on average, and can handle millions of trajectories.", "future_impact": "Given its ability to handle complex traffic conditions and detect outliers more accurately, DeepTEA may influence future trajectory outlier detection methods, and improve taxi fraud detection and traffic behavior understanding.", "venue": "VLDB", "year": 2022, "title": "DeepTEA: Effective and Efficient Online Time-dependent Trajectory Outlier Detection."}
{"pid": "c344daae-d27a-463a-b172-d99657e92286", "context": "The conventional database approach to integrity constraint enforcement has been found to be unsuccessful.", "key_idea": "The paper proposes a transformational mechanism which uses knowledge about the application domain and database organization to reformulate integrity constraints into semantically equivalent ones from which efficient code can be derived.", "method": "The validation of the reformulated constraints is performed using theorem proving techniques, and is tested whenever a state transition occurs in the database.", "outcome": "The authors have demonstrated the feasibility and power of a knowledge-based approach to the efficiency problem of constraint validation.", "future_impact": "The findings of the paper may foster the optimization of the validation of constraints in databases and provide methods for handling invalid requests for state changes.", "venue": "VLDB", "year": 1986, "title": "Knowledge-based Integrity Constraint Validation"}
{"pid": "6757b76e-7140-48bc-8cd7-0e829f9b023e", "context": "Traditionally, database management functions are performed using general purpose host computers, and they have limitations in handling relational data model directly in hardware. Also, their ability to run a number of programs concurrently with a relationally complete instruction set is limited.", "key_idea": "The authors present the organization of an autonomous processor, DataBase Concurrent Processor (DBCP), that can support database management functions, directly supports relational data model in hardware, and is able to run concurrently a number of programs written with a relationally complete instruction set.", "method": "The DBCP is composed of a parallel organization of cells and a Coordination Unit (CU). Each cell processes tuples of a unique relation and consists of a special purpose microprocessor and a circulating serial memory. The CU organizes different concurrency control strategies.", "outcome": "The authors propose a new processor architecture that could better utilize the processing capability due to its cellular organization and independent microprocessor functionalities. They claim that this concurrent processing capability at the backend level fits better to the database system's multiuser nature (shared resources).", "future_impact": "It is expected that the DataBase Concurrent Processor could facilitate higher capabilities and performance rates due to its support for concurrent program execution and direct handling of relational data model in hardware.", "venue": "VLDB", "year": 1979, "title": "Database Concurrent Processor"}
{"pid": "ce5c9b9a-b49d-41a5-ae39-2b5664e6b9e1", "context": "The integration of heterogeneous database environments is a complex task due to the difficulties of making autonomous systems interoperate correctly in a distributed setting.", "key_idea": "The paper presents the A la carte Framework, a reusable and extensible architecture supporting incremental integration of existing database facilities into heterogeneous systems, addressing problems of integration, identifying key interfaces, and providing an approach to combine these interfaces in an incremental way.", "method": "The A la carte Framework implements reusable components integrating major functional domains such as transaction management and provides a mechanism for capturing key characteristics of the components and constraints. The framework is validated through the implementation of an experimental, heterogeneous configuration as part of the object management work in the software engineering research consortium, Arcadia.", "outcome": "The A la carte Framework successfully reduces the complexity of heterogeneous systems integration process by providing reusable, integrating components for major functional domains and mechanisms for capturing key characteristics and constraints.", "future_impact": "The A la carte Framework's approach to incremental integration, if adopted widely, could simplify the process of integrating existing database facilities into heterogeneous systems, thereby advancing the field of distributed database management.", "venue": "VLDB", "year": 1992, "title": "A toolkit for the incremental implementation of heterogeneous database management systems"}
{"pid": "0c5b9c4d-6435-46ae-974c-116a12fc66e8", "context": "In the current digital advertising ecosystem, a need for effective data management exists.", "key_idea": "The paper presents an overview of Turn Data Management Platform (DMP), a system designed to serve the digital advertising ecosystem by managing data.", "method": "The authors detail the key components of Turn DMP, including data ingestion and integration, data warehousing and analytics, and real-time data activation, discussing the technical and research challenges and design choices for each.", "outcome": "Turn DMP was designed and detailed with the functions of data ingestion and integration, data warehousing and analytics, and real-time data activation. Different design challenges were discussed.", "future_impact": "Turn DMP, with its focus on data management, has the potential to shape the fast-growing multi-billion dollar digital advertising industry.", "venue": "VLDB", "year": 2013, "title": "Overview of turn data management platform for digital advertising"}
{"pid": "1d22983f-befa-48bf-b7d0-bf75b170bd86", "context": "In the scientific data management domain, specifically within geographical information systems (GIS) and global change research, metadata management is important. Thus far, attention has been paid to the spatial and temporal extents of scientific objects, but derivation semantics have been overlooked.", "key_idea": "This paper presents a framework for managing the data derivation information of scientific objects. The Gaea scientific database management system is introduced, in which special constructs are proposed to capture and manage metadata: concepts, processes, and tasks.", "method": "The authors present and discuss how the Gaea system handles metadata by using the proposed constructs: concepts, processes, and tasks, focusing on capturing the derivation procedure of scientific objects.", "outcome": "The paper details the implementation of a framework for capturing and managing scientific data derivation histories within the Gaea scientific database management system. A proposed extension to the current semantic modeling and object-oriented technology is conceptualized.", "future_impact": "The authors believe that this framework, beneficial for GIS and global change studies, could be generalized to other scientific fields.", "venue": "VLDB", "year": 1993, "title": "Managing Derived Data in the Gaea Scientific DBMS"}
{"pid": "64b8e23b3fda6d7f06accb00", "context": "Query rewriting is an important technique to optimize SQL performance in databases. Existing rewriting capabilities inside databases are, however, insufficient to optimize machine-generated queries, especially with the prevalent use of business intelligence systems and object-relational mapping frameworks.", "key_idea": "The authors propose a novel system, QueryBooster, to support SQL query rewriting as a cloud service. It allows users to formulate rewriting rules via a language or express rewriting intentions by providing example query pairs, share rewriting knowledge among multiple users, and requires no modifications to applications or databases.", "method": "The method of validating this system is through demonstration, using real-world applications and datasets to show QueryBooster's user experience and its ability to rewrite queries and share rewriting knowledge.", "outcome": "The authors successfully demonstrated the capability of QueryBooster using real-world applications and datasets, although specific metrics of success are not provided in abstract.", "future_impact": "The QueryBooster's unique approach of handling SQL query rewriting as a cloud service and its application-agnostic design could potentially impact how SQL query optimization operates in the future.", "venue": "VLDB", "year": 2023, "title": "Demo of QueryBooster: Supporting Middleware-based SQL Query Rewriting as a Service"}
{"pid": "c764314e-3a6b-41c2-887f-35f0ac064876", "context": "The difficulties associated with using query languages for large, complex databases such as statistical databases like Census data and energy data are being examined in the current literature.", "key_idea": "The authors propose a system that offers a graphical interface for complex databases, using graphics devices as interface tools. The system allows database schemas to be viewed as a network of entity and relationship types, upon which traversal paths can be used to express specific queries.", "method": "The system contains features such as subject directories, help messages, zooming facilities to the relevant part of the database schema, and partial query formulation with intermediate results. It allows for the formulation and graphical representation of local queries, with retrieval results available at any time. Parts of the schema can be made selectively visible or invisible to manage level of detail.", "outcome": "The system lets users build queries in a piecemeal fashion by linking local queries together to form larger ones, providing an interactive and intuitive way to explore complex databases.", "future_impact": "This approach to database interaction could revolutionize how users navigate and use complex databases, making it easier for users to formulate and execute partial and larger queries.", "venue": "VLDB", "year": 1982, "title": "GUIDE: Graphical User Interface for Database Exploration"}
{"pid": "83e977ac-221d-4aec-826b-e2e62a2cdb53", "context": "Linear discriminant analysis (LDA) is a popular method for dimensionality reduction that preserves class separability. Kernel discriminant analysis (KDA), performed in the reproducing kernel Hilbert space (RKHS), is used when data are highly non-linear in their distribution and performs better than LDA. However, traditional KDA is computationally expensive involving the eigen-decomposition of the kernel matrix, which is a problem when dealing with a large number of training samples.", "key_idea": "The authors present a new algorithm for kernel discriminant analysis, Spectral Regression Kernel Discriminant Analysis (SRKDA). It reframes discriminant analysis into a regression framework using spectral graph analysis, allowing more efficient computation and use of regularization techniques. Furthermore, the SRKDA only requires solving regularized regression problems, avoiding the need for eigenvector computation.", "method": "SRKDA is validated through extensive experiments on spoken letter, handwritten digit image and face image data. Additionally, the authors evaluate the development of an incremental version of the algorithm and the ability to produce sparse projections (Sparse KDA) using a L1-norm regularizer.", "outcome": "Results from the experiments on spoken letter, handwritten digit image and face image data confirm the effectiveness and efficiency of the proposed SRKDA algorithm.", "future_impact": "The new formulation in SRKDA can lead to the development of an incremental version of the algorithm that can fully utilize existing training sample computations. Furthermore, it simplifies the production of sparse projections with the addition of a L1-norm regularizer.", "venue": "VLDB", "year": 2011, "title": "Speed up kernel discriminant analysis"}
{"pid": "9a8eb44c-9a56-4491-b8ac-25bdf0af921d", "context": "Virtual views are a mechanism that facilitates re-use and makes queries easier to express in query evaluation and analysis, but the use of iterative view definitions complicates the process.", "key_idea": "This study investigates containment and equivalence problems for queries built up through simple unions of conjunctive queries and view definitions, utilizing non-recursive Datalog.", "method": "To examine the complexity of containment and equivalence for non-recursive Datalog, several computations were performed, including some with restrictions on the schema and queries.", "outcome": "The researchers find that the problem is much harder than its classical counterpart \u2014 it's complete for co-NEXPTIME. Even with restrictions on the schema and queries, this remains true.", "future_impact": "The study identifies more tractable subcases, ranging from NP to PSPACE, which could potentially serve as a basis for future research in this area.", "venue": "VLDB", "year": 2010, "title": "The impact of virtual views on containment"}
{"pid": "6391890690e50fcafd2b442d", "context": "In uncertain data management, often a relational probabilistic database is given where each tuple is correct with some probability. However, determining the correctness of results obtained from querying such databases remains challenging, especially when verification can be costly.", "key_idea": "The authors propose ActivePDB, a novel framework for managing uncertainty in databases, which uses an oracle (such as a domain expert) to verify as few tuples as possible and thus determine the correct outputs of the query.", "method": "ActivePDB incorporates two main steps - tracking provenance to identify which input tuples contribute to each output tuple and their contributions, and designing an active learning solution to iteratively choose tuples for verification based on the provenance structure and an evolving estimation of the tuple's correctness probability.", "outcome": "ActivePDB provides an end-to-end solution to the problem of correct output determination from querying probabilistic databases while minimizing the need for tuple verification.", "future_impact": "The authors aim to demonstrate ActivePDB in the context of the NELL database of extracted facts, which will allow participants to both pose queries and play as oracles, potentially leading to broader applications and improvements in uncertain data management.", "venue": "VLDB", "year": 2022, "title": "ActivePDB: Active Probabilistic Databases."}
{"pid": "c34fcb1f-58f0-4a32-9e63-45beb23c4b96", "context": "Despite the widespread usage of unstructured mesh in several application domains such as computer aided design and climate modelling, a database specifically designed to support storing and querying such data structures doesn't exist. Current mesh libraries work with file-based APIs, which fail to support declarative querying and are burdensome to maintain.", "key_idea": "This thesis proposes a general model, the Incidence multi-Graph Complex (ImG-Complex) data model, for storing the combinatorial aspect of meshes in a database. With the use of optional and application-specific constraints, this model can be specialized to represent specific object classes or geometric representations.", "method": "The authors use incidence graph (IG) representation with multi-incidence information (ImG) to represent a class of objects known as ImG-Complexes. They introduce optional and application-specific constraints to check the validity of meshes based on the properties of the object class being modeled, and demonstrate how graph databases can be employed to query combinatorial mesh queries based on the (possibly constrained) ImG model.", "outcome": "The paper illustrates the strengths and limitations of a graph-only query language in expressing combinatorial mesh queries.", "future_impact": "A specialized mesh database that supports declarative query language, easier maintenance, and query optimization, can significantly benefit domains employing unstructured meshes.", "venue": "VLDB", "year": 2013, "title": "Database support for unstructured meshes"}
{"pid": "8278bc52-4d0c-4b46-8d53-ce684c064ae5", "context": "Queries over XML data require accurate selectivity estimation of path expressions to optimize query execution plans. Previous methods for selectivity estimation of XML path expression require an off-line scan of the XML repository to collect the statistics, which is difficult when the underlying XML repository is very large or inaccessible.", "key_idea": "XPathLearner is proposed as a method for estimating selectivity of the most commonly used types of path expressions without looking at the XML data. It gathers and refines the statistics using query feedback in an on-line manner and can adjust the statistics when the underlying XML data change.", "method": "XPathLearner is validated by empirically assessing the estimation accuracy using several real data sets.", "outcome": "Estimation accuracy of XPathLearner is demonstrated empirically using real data sets, but specific outcomes or metrics are not mentioned.", "future_impact": "With its capability to adapt to changing XML data and to provide more accurate results under tight memory constraints, XPathLearner could be particularly useful in Internet scales applications where underlying XML repository may be either inaccessible or too large to be scanned in its entirety.", "venue": "VLDB", "year": 2002, "title": "XPathLearner: an on-line self-tuning Markov histogram for XML path selectivity estimation"}
{"pid": "4e6b16cf-72f4-4f43-be88-3d4b48a5549c", "context": "Extensible database systems allow for the addition of new indexes or data types, but they face challenges efficiently supporting the new index reference pattern with existing buffer replacement strategies.", "key_idea": "The authors propose a mechanism that allows an index method to communicate replacement hints to the buffer manager by assigning priority values to buffer pages to reflect desirable replacement criteria. This provides more flexible control over replacement criteria and facilitates strategizing the buffer replacement process.", "method": "The authors illustrate their approach using a hierarchical index example and conduct experiments testing its performance against the commonly used LRU strategy.", "outcome": "Experimental results show that a custom priority-based replacement strategy outperforms the commonly used LRU strategy.", "future_impact": "This study makes buffer replacement extensible and facilitates the design and fine-tuning of improved replacement strategies, promising enhanced performance for extensible database systems.", "venue": "VLDB", "year": 1992, "title": "Extensible Buffer Management of Indexes"}
{"pid": "5f1807d891e011c28ff02cd8", "context": "The most common goal of query scheduling techniques is to increase query performance, often without considering disk reads.", "key_idea": "The authors propose a new technique for query scheduling with the explicit goal of reducing disk reads and thus implicitly increasing query performance. For this, they introduce a learned scheduler that leverages overlapping data reads among incoming queries and learns a scheduling strategy that improves cache hits.", "method": "The authors utilize deep reinforcement learning for their scheduler to produce workload-specific strategies, being adaptive to previously unseen data access patterns.", "outcome": "The authors present results from a proof-of-concept prototype, demonstrating that learned schedulers can offer significant performance improvements over hand-crafted scheduling heuristics.", "future_impact": "The authors anticipate that the intersection of machine learning and databases, specifically through techniques like learned scheduling, represents a promising research direction.", "venue": "VLDB", "year": 2020, "title": "Buffer Pool Aware Query Scheduling via Deep Reinforcement Learning"}
{"pid": "d279460e-4fd6-4d78-961c-5a3ac5b87489", "context": "Storing and retrieving strings in main memory is a fundamental problem in computer science, with efficiency being crucial for many applications. The burst trie, a common choice for these tasks, uses linked lists as substructures which can result in poor use of CPU cache and main memory.", "key_idea": "This paper introduces a novel solution that carefully combines a trie with a hash table, creating a variant of burst trie called HAT-trie.", "method": "A thorough experimental analysis is conducted to test the performance ofthe HAT-trie and two of its novel variants engineered for greater space-efficiency across large sets of strings and on different computing architectures.", "outcome": "The HAT-trie and its two variants exhibit rapid, compact, and scalable storage and retrieval of variable-length strings, currently making them the leading in-memory trie-based data structures.", "future_impact": "The proposed solution might be beneficial for several applications such as in-memory databases, text-based search engines, and dictionaries where efficient string storage and retrieval is crucial.", "venue": "VLDB", "year": 2010, "title": "Engineering scalable, cache and space efficient tries for strings"}
{"pid": "97682794-4d63-48fe-b7f4-4e0b682ce2d2", "context": "SQL lacks support for array and spreadsheet-like calculations, causing difficulties in OLAP and business modeling applications. Commonly, these calculations are emulated using complex joins, UNION operations, window functions, and CASE expressions. The result is often cumbersome SQL code that is arduous to develop and maintain, even though alternatives such as spreadsheets and specialized MOLAP engines present their limitations.", "key_idea": "The authors propose SQL Spreadsheet, a new extension for SQL to address its limitations. This extension provides a more efficient means to perform business modelling computations and offers a more mathematically rigorous and scalable solution compared to traditional relational databases and MOLAP engines.", "method": "The authors use typical business modeling computations to compare the SQL Spreadsheet method with standard SQL approaches, evaluating both performance and programming ease. They also accompany a scalability example where data is processed in parallel.", "outcome": "The SQL Spreadsheet approach proves advantageous over typical SQL for Business Modeling computations in terms of performance and ease of programming. Additionally, it demonstrates capability to execute parallel processing of data.", "future_impact": "The paper also presents a new class of query optimizations applicable to SQL Spreadsheet, suggesting scope of further improvements in query optimizations using this new approach.", "venue": "VLDB", "year": 2003, "title": "Business modeling using SQL spreadsheets"}
{"pid": "6cda2a48-4a9b-45a3-ad36-c14cd1aa04a5", "context": "Advancements in database technology have led to a demand for new optimization techniques for join expressions; traditional dynamic programming techniques do not suit complex problems.", "key_idea": "This paper studies multiple algorithms that compute approximate solutions for optimizing join orders. It compares two solution spaces - the space of left-deep and bushy processing trees. It also scrutinizes optimizers across three classes: heuristic, randomized, and genetic algorithms.", "method": "The study statistically evaluates the space of left-deep and bushy processing trees and analyzes heuristic, randomized, and genetic algorithms for their working principle and fitness for optimizing join expressions.", "outcome": "The study found that randomized and genetic algorithms are well-suited for optimizing join expressions, as they generate high-quality solutions within a reasonable running time. However, while heuristic optimizers have a short running time, they often exhibit only moderate optimization performance.", "future_impact": "The insights from this study provide a new perspective that might lead to improved database optimization techniques, with an emphasis on the potential effectiveness of randomized and genetic algorithms in particular.", "venue": "VLDB", "year": 1997, "title": "Heuristic and randomized optimization for the join ordering problem"}
{"pid": "86a4322d-cf0e-472b-9348-0923f6e255bb", "context": "Main memory cache performance is a key determinant in the performance of object-oriented, object-relational and XML databases. Current methods to improve this involve prefetching or pre-loading pages to anticipate cache misses.", "key_idea": "In this study, a new framework for creating prefetching algorithms with path and cache consciousness is proposed. The path consciousness means the use of short sequences of object references in the reference trace to identify navigation paths. The cache consciousness involves using historical page access knowledge to guess which pages are likely to be main memory cache resident most of the time and this information is used in the context of prefetching.", "method": "The authors conducted a number of experiments comparing their approach against four highly competitive prefetching algorithms.", "outcome": "The results showed that their approach outperforms existing prefetching techniques in some situations while underperforming in others.", "future_impact": "The authors provide guidelines as to when their algorithm should be used and when other algorithms may be more desirable, suggesting their work may influence the choice of prefetching algorithms in future studies or development.", "venue": "VLDB", "year": 2007, "title": "Path and cache conscious prefetching (PCCP)"}
{"pid": "6391890690e50fcafd2b43b3", "context": "Data analytics often make sense of large data sets by generalization, which could sometimes draw misleading generalizations from a cherry-picked level of aggregation to obscure substantial subgroups that oppose the generalization.", "key_idea": "The authors propose OREO, a system to detect and explain cherry-picked generalizations by refining the corresponding aggregate queries and computing a support score of the given statement to quantify the quality of the generalization.", "method": "The authors demonstrate the utility of OREO for investigating generalizations by interacting with the VLDB'22 participants who use the OREO interface for statement validation and explanation.", "outcome": "OREO can compute a support score of the given statement to quantify the quality of the generalization, identify significant counterexamples, and find alternative statements that better represent the dataset.", "future_impact": "OREO might be further used in data analytics to verify the accuracy of generalized statements and to help avoid misleading conclusions drawn from cherry-picked aggregations.", "venue": "VLDB", "year": 2022, "title": "OREO: Detection of Cherry-picked Generalizations."}
{"pid": "6391890790e50fcafd2b44d6", "context": "Array DBMSs operate on big N-d arrays and Cellular Automata (CA) work on a discrete lattice of cells, essentially N-d arrays. However, it is not straightforward to make an Array DBMS support CA simulation workloads.", "key_idea": "The authors propose SimDB, a solution that enables end-to-end cellular automata (CA) simulations directly inside the CHRONOSDB array DBMS through the use of new components.", "method": "SimDB is implemented inside the CHRONOSDB array DBMS and a desktop application is developed to showcase SimDB. The application features interactive components to graphically reveal the insights of SimDB internals.", "outcome": "A successful implementation of SimDB running CA simulations entirely inside an Array DBMS was achieved, a convenient GUI was provided to investigate how end-to-end road traffic simulations run entirely inside an Array DBMS.", "future_impact": "SimDB expands the applications of Array DBMS and opens a wide range of research and development opportunities.", "venue": "VLDB", "year": 2022, "title": "SimDB in Action: Road Traffic Simulations Completely Inside Array DBMS"}
{"pid": "dedcf324-414d-4902-b1e6-e9d9a89e77df", "context": "One known challenge in data warehousing is the efficient incremental maintenance of warehouse data in the presence of source data updates.", "key_idea": "The authors identify several critical data representation and algorithmic choices when developing the machinery of an incrementally maintained data warehouse. They evaluate various alternatives for each decision area.", "method": "Through extensive experiments, the authors evaluate the various alternatives that can be made in relation to the data representation and algorithm choices in an incrementally maintained data warehouse.", "outcome": "The authors find that the right choice of data representation and algorithm options can lead to dramatic performance gains.", "future_impact": "The authors propose guidelines for making the right decisions under different scenarios, which may inform future development of efficient incremental data warehouse maintenance systems.", "venue": "VLDB", "year": 2000, "title": "Performance Issues in Incremental Warehouse Maintenance"}
{"pid": "5a493605-3b96-4701-ae55-2433c29a5387", "context": "Previous algorithms for garbage collecting object-oriented databases in a client-server environment require locks on data and callbacks to clients, which can impact performance and useability. Most of these algorithms lack fault tolerance and extensive logging.", "key_idea": "The authors propose an efficient server-based algorithm for garbage collection that is incremental, can run concurrently with client transactions, does not hold any locks on data, does not require callbacks to clients, and is fault tolerant with minimal logging.", "method": "The algorithm has been designed to be integrated into existing Object-Oriented Database (OODB) and it was implemented in the EXODUS storage manager for evaluation.", "outcome": "The abstract does not provide specific results or outcomes of the implementation.", "future_impact": "Potential integration into existing OODB systems, which could lead to better client-server performance optimizations such as client caching and flexible management of client buffers in the field of Object-Oriented Databases.", "venue": "VLDB", "year": 1995, "title": "Efficient Incremental Garbage Collection for Client-Server Object Database Systems"}
{"pid": "38400eef-b9fb-43de-b870-b3dc08256660", "context": "Workflow scheduling, which is a problem of finding a correct execution sequence for workflow tasks, has largely concentrated on temporal constraints. However, resource allocation constraints, which are also critical, have received relatively little attention in workflow modeling.", "key_idea": "The authors present a new framework for workflows, whose correctness is influenced by a set of resource allocation constraints, and they develop new techniques for scheduling such systems.", "method": "The authors integrate Concurrent Transaction Logic (CTR) with constraint logic programming (CLP) to create a new logical formalism, which they call Concurrent Constraint Transaction Logic, or CCTR.", "outcome": "The abstract does not provide precise outcomes of implementing the proposed CCTR.", "future_impact": "The abstract does not explicitly state the anticipated future impacts or potential further research based on this study.", "venue": "VLDB", "year": 2002, "title": "A logical framework for scheduling workflows under resource allocation constraints"}
{"pid": "bcdaac3a-4042-4b1f-ba11-3216a21a3a7a", "context": "Creating efficient index structures for data-oriented applications like peer-to-peer databases or peer-to-peer information retrieval using structured overlay networks often involves frequent re-indexing of data and resulting construction of overlay networks. So far, there are no efficient approaches in literature for the construction of such networks from scratch in a self-organized manner.", "key_idea": "This paper introduces a proposal for an efficient, completely decentralized and parallel approach for the construction of data-oriented, structured overlay networks from scratch that also ensures good load-balancing for skewed data key distributions.", "method": "The authors provide a theoretical analysis of the proposed decentralized algorithm and present a practical system implementation which has been tested on PlanetLab and used to support peer-to-peer information retrieval and database applications.", "outcome": "Details regarding the outcome of this study are not mentioned in the paper's abstract.", "future_impact": "The abstract does not provide explicit anticipations about the future impact of this study.", "venue": "VLDB", "year": 2005, "title": "Indexing data-oriented overlay networks"}
{"pid": "86f36f34-2b8d-436a-98aa-65b2b06c75ee", "context": "Numerous algorithms have been proposed for concurrent access to B+-trees, but their performance and characteristics are not well understood.", "key_idea": "The authors examine the performance of different B+-tree concurrency control algorithms, which includes a new algorithm, under a variety of data contention situations and resource conditions by using a detailed simulation model of B+-tree operations in a centralized DBMS.", "method": "Various B+-tree concurrency control algorithms are analysed through detailed simulations in various scenarios, including a broad range of data contention situations and resource conditions.", "outcome": "The study suggests that algorithms with updaters that use lock-coupling with exclusive locks perform worse than those allowing more optimistic index descents. Particularly, B-link algorithms provide the most concurrency and the best overall performance.", "future_impact": "The findings highlight the need for a highly concurrent long-term lock-holding strategy to leverage the full benefits of a highly concurrent mechanism for index operations.", "venue": "VLDB", "year": 1993, "title": "Performance of B + tree concurrency control algorithms"}
{"pid": "6d317ee2-a662-469c-84ec-98a81a01c3eb", "context": "Searching for relevant visual information based on content features in large databases is a challenging topic that has gained lots of attention from both the research community and industry.", "key_idea": "The paper presents investigations on effective and efficient video similarity search, with novel techniques developed for video retrieval in a large collection of segmented video clips, and video subsequence identification from a long unsegmented stream.", "method": "The proposed methods for processing two types of similarity queries - video retrieval in large collections of segmented clips and video subsequence identification in unsegmented streams, are tested and incorporated into a prototype system named UQLIPS.", "outcome": "The proposed methods have shown encouraging performance and are being incorporated into the prototype system, UQLIPS, which has demonstrated some marketing potentials for commercialisation.", "future_impact": "The solutions proposed in this paper, already operational in the UQLIPS system, show potential for commercialisation, indicating a possible future impact in the market of video search systems.", "venue": "VLDB", "year": 2008, "title": "Challenges and techniques for effective and efficient similarity search in large video databases"}
{"pid": "cde55ff7-a51b-4d01-a2d8-6813f468e07c", "context": "With rising energy costs and increasing power use due to the ever-growing demand for computing power (servers, storage, networks), electricity bills have become a significant expense for today's data centers. While performance organizations like SPEC have developed power benchmarks for single servers, there's no benchmark that measures power consumption of transaction processing systems.", "key_idea": "The authors propose a power consumption model based on data readily available in the TPC-C full disclosure report of published benchmarks. The model identifies the most power-intensive components and demonstrates power consumption trends over time.", "method": "The authors verify their model with measurements taken from three fully scaled and optimized TPC-C configurations including client systems, database server, and storage subsystem. They then apply this model to a subset of 7 years of TPC-C results.", "outcome": "The analysis shows that, given the current trends, hardware enhancements alone will not be able to satisfy the demand for energy efficiency in the future.", "future_impact": "This paper anticipates hardware and software enhancements to meet energy efficiency demands of future systems. It supports the initiative of the Transaction Processing Performance Council (TPC) to add energy efficiency metrics to all its benchmarks.", "venue": "VLDB", "year": 2008, "title": "Energy cost, the key challenge of today's data centers: a power consumption analysis of TPC-C results"}
{"pid": "fb9bc8d1-e2e2-44ee-b363-8fa960f8b31b", "context": "A major challenge in the design and implementation of database programming languages (DBPLs) is query optimisation. Traditional approaches have not fully addressed issues like non-termination of expressions and construction of infinite data structures.", "key_idea": "The authors propose to investigate algebraic query optimisation techniques for DBPLs in the context of a purely declarative functional language that supports sets as first-class objects. Their language has a well-defined semantics and a set bulk data type, allowing reasoning about the properties of expressions and utilization of prior work on the optimisation of relational languages.", "method": "Starting with the syntax of their representative DBPL and its semantics, the authors define an algebra of operators over the set data type, provide key equivalences for expressions, and list transformation principles for optimising expressions. They then extend their language with two higher constructs commonly found in functional DBPLs and investigate extending the set operator equivalences to analogous operators over bags.", "outcome": "The authors identified key equivalences for their proposed constructs and provided transformation principles for expressions in them. They also managed to extend their equivalences for the set operators to those over bags and identified caveats to well-known equivalences for non-deductive database languages.", "future_impact": "Although developed in the context of a functional language, the authors claim that their findings could be directly applicable to other DBPLs of similar expressiveness, suggesting potential broader applications of the work.", "venue": "VLDB", "year": 1996, "title": "Algebraic query optimisation for database programming languages"}
{"pid": "1f775406-2587-4617-b1ad-ffdbdc8603aa", "context": "Improvement in the efficiency of tree pattern matching involves quick identification and elimination of redundant nodes in the pattern. This is used to query tree-structured data such as XML and LDAP.", "key_idea": "The paper presents a polynomial-time query minimization algorithm called CIM, which eliminates redundant nodes, and ACIM, an algorithm that augments the tree pattern using integrity constraints (ICs) before applying CIM.", "method": "The authors develop the CIM algorithm based on the principles that a node cannot be redundant unless its children are and the order of elimination of redundant nodes is not critical. They then develop and apply ACIM, which augments the tree pattern using ICs and applies CIM to find the unique minimal equivalent query. A faster algorithm, CDM, is also proposed which identifies and eliminates local redundancies by propagating 'information labels' up the tree pattern.", "outcome": "The authors demonstrate that ACIM always finds the unique minimal equivalent query. An experimental study shows the effectiveness of their tree pattern minimization techniques.", "future_impact": "The ACIM and CDM methods can be used to improve efficiencies in identifying and eliminating redundancies in tree patterns, thereby potentially impacting query handling in tree-structured data systems.", "venue": "VLDB", "year": 2002, "title": "Tree pattern query minimization"}
{"pid": "1d096d36-4bd6-44df-bacd-c9ccaf9bb313", "context": "The use of stroke gestures in interfaces lacks a way to estimate user-perceived scale or articulation of gestures, and makes it challenging to simplify gesture set design, improve gesture-to-function mappings, and reduce the need for users to learn and for recognizers to discriminate unnecessary symbols.", "key_idea": "The authors present a simple rule that estimates the user-intended scale of input stroke gestures, leveraging scale as a natural parameter for gesture input, reflective of user perception.", "method": "They use the established consensus among users in how they articulate gestures at various scales (i.e., small, medium, and large) to formulate their estimation rule.", "outcome": "The proposed simple rule estimates the user-intended scale of input gestures with 87% accuracy.", "future_impact": "This gesture scale estimator can enhance current gestural interfaces by simplifying gesture set design, improving gesture-to-function mappings, and reducing the need for users to learn and for recognizers to discriminate unnecessary symbols.", "venue": "CHI", "year": 2013, "title": "Small, medium, or large?: estimating the user-perceived scale of stroke gestures"}
{"pid": "e526751c-93e9-406b-8d31-4aefdb4ff41f", "context": "Previous studies on computer-based multitasking behavior lacked robust metrics to investigate the phenomenon comprehensively taking user, task, and technology considerations into account.", "key_idea": "The authors propose new metrics to investigate computer-based multitasking behavior, ranging from a lean dichotomous variable to a rich measure based on task switches.", "method": "The authors demonstrate the use of these proposed measures with an exploratory study based on self-reported user logs.", "outcome": "The authors successfully calculated and demonstrated these new measures for investigating multitasking behavior, using data from self-reported user logs.", "future_impact": "The proposed measures lay the foundation for incorporating the variable of multitasking behaviour in future studies of human-computer interaction, which could potentially improve the understanding of this field.", "venue": "CHI", "year": 2009, "title": "Towards new metrics for multitasking behavior"}
{"pid": "9ef85150-b4de-4fc3-9421-e405855f5586", "context": "Existing display techniques for navigating large-scale virtual environments integrate information from different frames of reference. One such method is frequency separation which resembles a mass-spring-damper system.", "key_idea": "This study introduces Dynamic viewpoint tethering, a new display technique to support effective navigation in large-scale virtual environments, building on the principles from older techniques like frequency separation.", "method": "The researchers examined the effect of dynamic viewpoint tethering on human user's performance by assigning them with local guidance and global awareness tasks.", "outcome": "The research results support the design of display systems that use dynamic viewpoint tethering for enhancing human-computer interaction in teleoperation tasks.", "future_impact": "The study supports the application of dynamic viewpoint tethering to design better display systems, improving human-computer interaction in teleoperations tasks in the future.", "venue": "CHI", "year": 2001, "title": "Dynamic viewpoint tethering: controlling a virtual camera for effective navigation in virtual environments"}
{"pid": "6287042a5aee126c0f5b6dae", "context": "Effective data literacy instruction requires that learners have the capability to humanize data through a contextual understanding of argumentation and reasoning in the real-world.", "key_idea": "In the study, a co-designed data comic unit about adolescent friendships is implemented. This unit involves 7th-grade students analyzing data graphs about these friendships and conveying perspectives on that data through comic narratives.", "method": "The study implements the curriculum on a 7th-grade unit which analyzes 33 student comics, and conducts interviews with two teachers and four students.", "outcome": "The analysis of student comics and interviews showed that students engaged in data reasoning and social-emotional reasoning when making sense of data about personal, everyday experiences.", "future_impact": "This research may impact the design of arts-integrated curricula that support students' mutual engagement in data and social-emotional reasoning.", "venue": "CHI", "year": 2022, "title": "\u201dI happen to be one of 47.8%\u201d: Social-Emotional and Data Reasoning in Middle School Students\u2019 Comics about Friendship"}
{"pid": "9c998a8a-b285-48ab-953e-eb378d4625a9", "context": "Existing tools for the application of the Semiotics Inspection Method (SIM) are presumably lacking in terms of breadth and communicability.", "key_idea": "This study proposes to build a system based on the Semiotics Engineering Theory that enables a broader application of the SIM.", "method": "Research is carried out to develop a collaborative system for implementing the Semiotics Inspection Method.", "outcome": "The abstract does not provide measurable results or outcomes of the system development.", "future_impact": "The expected impact is to provide a tool that supports evaluators and researchers during inspection of semiotics to interactive systems, potentially increasing the efficiency or effectiveness of such inspections.", "venue": "CHI", "year": 2012, "title": "Sistema de apoio \u00e0 aplica\u00e7\u00e3o do MIS"}
{"pid": "63f5e056-afbe-4582-8b22-e5df66a71e7f", "context": "One of the main principles of gamification is the use of social comparison, with leaderboards being a common tool that allows players to compare their performance against others.", "key_idea": "The study investigates how the position on a leaderboard can affect a player's satisfaction and their desire to replay a game.", "method": "The study was conducted with participants placed in the second, fourth, or seventh positions on a leaderboard, and their reported satisfaction levels were measured and compared.", "outcome": "The study found that players in the second, fourth, or seventh positions on the leaderboard reported higher levels of satisfaction than players in other leaderboard positions.", "future_impact": "The results indicate potential mechanisms that could influence game satisfaction from leaderboard positions, and invites future work and implications for the design of leaderboards.", "venue": "CHI", "year": 2015, "title": "Leaderboard Position Psychology: Counterfactual Thinking"}
{"pid": "6162cd1c91e01128aa26095c", "context": "Personal Health Record (PHR) is a technology designed to supplement medical care with health monitoring outside traditional care environments in hospitals. However, the widespread adoption and use of PHRs will not occur unless it provides good usability for users. Autoimmune conditions, which exhibit variability in daily symptoms, increase the need for PHRs.", "key_idea": "Thymun, a mobile application made for individuals with autoimmune diseases, incorporates PHR as its main feature. The authors aim to improve the usability of Thymun, particularly in its symptom recording feature.", "method": "The authors conduct a usability evaluation on Thymun's initial design iteration, consider the needs and challenges faced by patients in traditional health monitoring, and redesign the product for a second iteration. They then perform another usability evaluation on the newly revised version.", "outcome": "The authors found that the lowest scored feature in terms of usability was symptom recording. After redesign, the second iteration of Thymun had a better satisfaction rate, a higher usability score (74 according to the SUS test instrument), and more positive comments.", "future_impact": "While not expressly stated, the study implicitly suggests potential future work in continuing to refine and improve the usability of PHR applications like Thymun, ideally leading to greater adoption and effectiveness in managing autoimmune conditions.", "venue": "CHI", "year": 2021, "title": "Improving The Usability of Personal Health Record in Mobile Health Application for People with Autoimmune Disease"}
{"pid": "5ea2c2ea9fced0a24b1ddcab", "context": "Interacting with non-touchscreens such as TV or public displays can be difficult and inefficient.", "key_idea": "The authors propose WATouCH, a novel method that localizes a smartwatch on a display and allows direct input by turning the smartwatch into a tangible controller by leveraging sensor fusion of the built-in inertial measurement unit (IMU) and photoplethysmogram (PPG).", "method": "WATouCH tracks the smartwatch movement using IMU data and corrects its location error caused by drift using the PPG responses to a dynamic visual pattern on the display. The authors tested WATouCH with a user study on a point and click and line tracing task to evaluate the system usability and user performance.", "outcome": "Evaluation results suggest that the sensor fusion mechanism effectively confined IMU-based localization error, achieved good targeting and tracing precision, and was positively received by the participants.", "future_impact": "The effectiveness and positive reception of WATouCH open up new opportunities for wider and more efficient interaction with non-touchscreen displays.", "venue": "CHI", "year": 2020, "title": "WATouCH: Enabling Direct Input on Non-touchscreen Using Smartwatch's Photoplethysmogram and IMU Sensor Fusion"}
{"pid": "6287041e5aee126c0f5b13d0", "context": "Movement-based video games can provide engaging play experiences and encourage physical activity, but current design guidelines for such games mainly focus on non-disabled players.", "key_idea": "The authors are exploring the perspectives of wheelchair users on movement-based games, aiming to adapt and expand game design guidelines to include physically disabled players.", "method": "They created eight game concepts which served as discussion points in semi-structured interviews with wheelchair users (N=6), which were analyzed with Interpretative Phenomenological Analysis. They also ran an online survey (N=21) based on the same game concepts and performed Thematic analysis on the results.", "outcome": "Key themes around independent access, challenges in social settings, the need for comprehensive adaptation, the importance of adequate challenge, and considerations for multiplayer experiences emerge from the interviews and online survey.", "future_impact": "The findings will be used to re-contextualize and expand game design guidelines established by Mueller and Isbister to be inclusive of disabled players, showing potential to improve the game experience for physically disabled users.", "venue": "CHI", "year": 2022, "title": "Including the Experiences of Physically Disabled Players in Mainstream Guidelines for Movement-Based Games"}
{"pid": "532eff3e-94ef-4265-8ae7-80cb1e19eb0d", "context": "Traditional media monitoring tasks and text analysis tools for improving government services through social media monitoring were not effectively addressing specific information needs of users.", "key_idea": "The authors explore how text analysis tools can support a social media monitoring task in the government context while also examining how government monitors take specific actions such as checking and vetting information contributed by the online community.", "method": "The authors conduct a preliminary analysis of tasks and information needs of users performing social media monitoring in order to improve government services.", "outcome": "The study finds that social media monitoring in the governmental context is a complex task which not only involves monitoring traditional media but also requires taking actions to improve services based on information from the wider online community.", "future_impact": "The results of their analysis could help inform the development of more effective ways of responding to social media posts and ultimately lead to improved government services.", "venue": "CHI", "year": 2011, "title": "Listening to the community: social media monitoring tasks for improving government services"}
{"pid": "34480e12-7947-4702-b0cc-b148b1660941", "context": "Current interfaces used for simple problem solving tasks often have a structured interaction style which may limit flexibility in the interaction with the problem space.", "key_idea": "The authors developed DataBoard, a freeform spatial interface, to give users more flexibility for simple problem solving tasks.", "method": "The authors conducted a controlled user study where they compared the DataBoard with a traditional spreadsheet and analyzed video data in detail.", "outcome": "The freeform interface improved task performance and memory recall, and it supported users in areas such as incremental strategy execution, problem state tracking, reducing mental computation, and perceptual solution verification. However, the traditional spreadsheet also had advantages.", "future_impact": "The findings about the benefits of a freeform interface and their detailed comparison with a structured one could potentially shape how future interfaces for problem solving are designed, integrating the advantages of both styles.", "venue": "CHI", "year": 2011, "title": "How a freeform spatial interface supports simple problem solving tasks"}
{"pid": "6ee2e466-4785-445c-8ca6-50ca08c97d5f", "context": "In 1991, Bulgaria separated from the USSR and installed a democratic government. This was around the same time when the University of Arizona installed GroupSystems, a group decision support system (GDSS), in a new facility in Sofia.", "key_idea": "The GroupSystems software at the new facility in Sofia offers various modules for brainstorming, stakeholder identification, voting, questionnaire design and administration, group editing, and topic discussion, with the option to run in either Latin or Cyrillic alphabets and allowing subgroups of participants and anonymity.", "method": "The Authors measure the receptiveness of Bulgarians to the GDSS technology through initial group experiences in the facility.", "outcome": "Initial experiences show that Bulgarians are receptive to GDSS technology, especially the modules allowing anonymous discussion.", "future_impact": "The study proposes to compare the implementation of GDSS technology for Bulgarian business people and government officials to the implementation of the same technology for American foreign service officers serving in Bulgaria, this could impact the future usage and approach to user-centric design of the system in different socio-political environments.", "venue": "CHI", "year": 1992, "title": "The introduction of GDSS in Bulgaria"}
{"pid": "38947211-9578-4147-b097-6714f6635ac3", "context": "Previous research in 2D zooming environment navigation primarily focused on unconstrained movement.", "key_idea": "This paper introduces the idea of constraining movement in a 2D zooming environment to potentially reduce both mechanical and cognitive demands of navigation.", "method": "An experiment comparing constrained and unconstrained movement in a 2D zooming environment is conducted, with detailed analysis focusing on time on task, mouse activity, user calmness, confidence, and spatial disorientation.", "outcome": "Results showed a significant reduction in time on task and mouse movement activity when movement was constrained, suggesting subjects were calmer, more confident in their actions and experienced less spatial disorientation.", "future_impact": "The paper suggests that judiciously constraining movement can enhance the efficiency and user experience of navigation in 2D zooming environments.", "venue": "CHI", "year": 2003, "title": "\"This is a lot easier!\": constrained movement speeds navigation"}
{"pid": "c412c834-bf3c-49ac-b3d8-37107e36f2b7", "context": "Budgeting is an essential aspect of controlling finances and reducing debt. However, there is a misalignment between people's actual budgeting practices and those supported by off-the-shelf budgeting aids.", "key_idea": "The authors propose a more user-centric design for individual and household budgeting technology, guided by three tenets to bridge the gap between actual practices and those supported by existing budgeting technology.", "method": "The authors conduct an ethnographically informed study with 15 participants to understand the misalignment between actual budgeting practices and those supported by off-the-shelf budgeting tools.", "outcome": "The authors highlighted the misalignment between actual budgeting practices and off-the-shelf budgeting aids and outlined three tenets for designing more user-centric budgeting technology.", "future_impact": "The proposed tenets might be incorporated into future work in this area to design better technology for individual and household budgeting.", "venue": "CHI", "year": 2015, "title": "Fixing the Alignment: An Exploration of Budgeting Practices in the Home"}
{"pid": "615d13fe5244ab9dcb637a44", "context": "Although large language models (LLMs) have demonstrated impressive potential on simple tasks, their breadth of scope, lack of transparency, and insufficient controllability can make them less effective when assisting humans on more complex tasks.", "key_idea": "The authors introduce the concept of Chaining LLM steps together, where the output of one step becomes the input for the next. In addition, an interactive system is introduced where users can modify these Chains, along with their intermediate results, in a modular way.", "method": "A set of LLM primitive operations useful for Chain construction is defined and an interactive system is presented where these Chains can be modified by users. A 20-person user study is conducted to evaluate this approach.", "outcome": "Chaining not only improved the quality of task outcomes but significantly enhanced system transparency, controllability, and sense of collaboration. Users have developed new ways of interacting with LLMs through Chains by leveraging sub-tasks to calibrate model expectations, comparing and contrasting alternative strategies by observing parallel downstream effects, and debugging unexpected model outputs by 'unit-testing' sub-components of a Chain.", "future_impact": "In two case studies, the authors explore how LLM Chains may be used in future applications and suggest that they may bring new ways of human-AI interaction.", "venue": "CHI", "year": 2022, "title": "AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts"}
{"pid": "60a4e58991e011f4291ce2c5", "context": "While women in online labor marketplaces earn about as much overall as men, women set lower bill rates suggesting gender differences in pricing strategies.", "key_idea": "The authors aim to understand strategies used to set hourly bill rates on online labor marketplaces, specifically Upwork, with a focus on gender differences.", "method": "The authors surveyed 392 freelancers in the United States (US) on Upwork to gather data on their pricing strategies.", "outcome": "The survey did not find significant gender differences in pricing strategies that were related to bill rate. Other factors such as full-time freelancer status and level of self-esteem were identified as factors that explain gender differences in bill rates.", "future_impact": "The findings of this study may contribute to better equity and fairness in the growing gig economy by guiding CHI researchers to identify, assess, and address the complex interaction between societal conditions in online labor markets.", "venue": "CHI", "year": 2021, "title": "Understanding Gender Differences in Pricing Strategies in Online Labor Marketplaces"}
{"pid": "07b21c18-bd01-48f5-bdd9-0fc2b463c2dc", "context": "With the advent of new technology in vehicles, drivers can access information in many different forms and from many information sources, increasing concern about the potential adverse effects resulting from drivers' interactions with such multi-function devices.", "key_idea": "The paper aims to examine the disruptive impact of complex, interactive, hands-free cell phone communications upon the driver's visual awareness while proceeding through high volume intersections.", "method": "The study documents changes in driver visual behavior, resulting from cognitive distraction of speech-based interactions.", "outcome": "The study finds that cognitive distraction from speech-based interactions can contribute to intersection crashes due to changes in driver visual behavior.", "future_impact": "The results have significant HCI implications for the design of interactive Intelligent Transportation Systems (ITS) within the automotive sector.", "venue": "CHI", "year": 2003, "title": "Cell phone communication and driver visual behavior: the impact of cognitive distraction"}
{"pid": "60a4e58991e011f4291ce43f", "context": "Designers of machine-cut objects often need to consider if their designs can be fabricated with the available materials. Traditional tools mainly focus on preparing finished designs for fabrication, with a long feedback loop between design creation and fabrication preparation.", "key_idea": "This paper introduces Fabricaide, a new tool that interleaves processes of design creation and preparation for fabrication, providing live feedback on how parts should be placed onto material sheets, analyzing material consumption, and alerting users when designs are infeasible.", "method": "Fabricaide uses a custom packing algorithm for arranging parts on material sheets achieving interactive speeds. The authors validate the tool through a qualitative user study exploring different workflows.", "outcome": "The qualitative user study shows that Fabricaide supports different workflows, encourages material-conscious design practices, and gives valuable insights for improving similar interfaces in the future.", "future_impact": "With its ability to shorten the feedback loop between design and fabrication, Fabricaide has the potential to encourage more material-conscious design practices and to lead improvements in the design interfaces of the future.", "venue": "CHI", "year": 2021, "title": "Fabricaide: Fabrication-Aware Design for 2D Cutting Machines"}
{"pid": "5ea2c2ea9fced0a24b1ddb8c", "context": "Existing tools for Geometric and Signomial Programming are complex and lack explainability.", "key_idea": "The authors propose GPkit, a Python toolkit for Geometric and Signomial Programming that emphasizes explainability and incremental complexity. It's designed through an ethnographic approach and influences daily engineering workflows in various settings from firms to classrooms.", "method": "The design process of GPkit involved incorporation of it into the daily workflow of engineering work in firms, classrooms, and research labs. Novel algorithms and design methods were presented and used based on insights gained from the application of GPkit.", "outcome": "GPkit has been integrated into daily engineering work within firms, classrooms, and research labs, and this integration inspired new toolkit features. Insights from GPkit implementation led to novel contributions in the formulation and interpretation of convex programs.", "future_impact": "Suggested applications and use-cases of GPkit could lead to a better understanding of and further advancements in early-stage engineering design.", "venue": "CHI", "year": 2020, "title": "GPkit: A Human-Centered Approach to Convex Optimization in Engineering Design"}
{"pid": "f6e3fca3-5b00-4c16-9a42-df158c935f81", "context": "Eye tracking on mobile platforms is a challenging task due to constraints such as device mobility, variable lighting conditions, and user movement. Calibration is a fundamental component of eye tracking that often involves usability and performance tradeoffs.", "key_idea": "The authors designed and implemented a neural network-based eye tracking system on an unmodified common tablet and evaluated its usability.", "method": "The usability and performance of the neural network-based eye tracking system were evaluated subjectively and objectively, focusing on the calibration component.", "outcome": "The developed system achieved an average spatial accuracy of 3.95\u00b0 and an average temporal resolution of 0.65 Hz during trials. It was found that increasing the neural network training set could improve spatial accuracy, but at the cost of greater physical effort and fatigue.", "future_impact": "The paper suggests that further improvement in spatial accuracy may be achievable by utilizing a larger neural network training set, even though it could potentially lead to increased user effort and fatigue.", "venue": "CHI", "year": 2013, "title": "Usability evaluation of eye tracking on an unmodified common tablet"}
{"pid": "2d325109-1659-4838-bb24-894fd827d058", "context": "Minorities are the fastest growing demographic in the U.S. and the poverty level in the U.S. is the highest it has been in 50 years. Current understanding of technology use in homes is missing nuances of socioeconomic differences.", "key_idea": "The study explores how middle to upper class, suburban, white American parents and low-income, urban, African-American parents incorporate technology into their lives, with a specific focus on how socioeconomic differences both reflect and reinforce technology use at home.", "method": "The authors interviewed parents from different socioeconomic backgrounds, all of whom had teens in their homes with access to technological devices like computers and cell phones.", "outcome": "The study found that low socioeconomic status families share devices more often and low socioeconomic status teens have more responsibility and independence in their technology use.", "future_impact": "The authors anticipate that understanding technology use in low socioeconomic status families, a growing demographic, would inform better design strategies for the CHI community.", "venue": "CHI", "year": 2012, "title": "Income, race, and class: exploring socioeconomic differences in family technology use"}
{"pid": "664e5e6d-c131-4deb-b815-0331b8844a7d", "context": "Traditional music is linear and does not interact with the listener's behavior or environment in real-time.", "key_idea": "The authors introduce a concept called 'reactive music' which is a non-linear format that responds in real-time to the listener and her environment. They also create Giant Steps, an iPhone application that implements this 'reactive music' in correlation with a jogger's movements and environmental sounds.", "method": "The authors implement their idea of 'reactive music' in an iPhone application, Giant Steps, that interacts with a jogger's movements and environmental sounds.", "outcome": "The study results in the creation of the Giant Steps application, which exemplifies the concept of 'reactive music' interacting with user behavior in real time.", "future_impact": "The authors hope that their approach will improve understanding of 'machine to user' adaptation, and particularly in the context of mobile sports applications.", "venue": "CHI", "year": 2013, "title": "Reactive music: when user behavior affects sounds in real-time"}
{"pid": "40dd6d07-bd39-4c4e-9613-6e10d1bec372", "context": "Historical textual cadasters, which are official registers that record land properties, are an invaluable resource for understanding the social/economic background of changes in land uses or ownership. However, there's a gap in mapping old and new cadasters effectively.", "key_idea": "The authors introduce JigsawMap, an interactive visualization tool designed to visualize and map historical textual cadasters.", "method": "The authors evaluated JigsawMap through usability studies and long term case studies with historians.", "outcome": "The authors received positive responses from the usability studies and long term case studies conducted to evaluate JigsawMap. The authors also presented design guidelines for participatory design projects with historians.", "future_impact": "With JigsawMap, historians will be able to continue mapping older or newer cadasters thereby connecting past land survey results to today and to the future.", "venue": "CHI", "year": 2012, "title": "JigsawMap: connecting the past to the future by mapping historical textual cadasters"}
{"pid": "7506085a-bfdb-4410-94c7-3819c97665d2", "context": "Human mobility analysis currently lacks an effective analytic unit, which could provide insightful understanding of spatial patterns and can be utilized in practical applications.", "key_idea": "The authors propose a new analytic unit for human mobility analysis, named Regularly Visited Patches (RVP), along with a process for identifying these patches and metrics to characterize and measure their spatial patterns.", "method": "The authors develop a method for identifying and measuring RVPs and apply this methodology using a large Foursquare check-in dataset to test the effectiveness of their proposed approach.", "outcome": "The application of RVP analysis on the dataset revealed fundamental patterns of human mobility.", "future_impact": "This novel approach to human mobility analysis will lead to promising research with strong implications for businesses.", "venue": "CHI", "year": 2013, "title": "Regularly visited patches in human mobility"}
{"pid": "3501c335-3f7f-4006-8c17-d57f8d9597ef", "context": "Current chat systems lack the means to efficiently show the affective state or emotions of the user in the online environment.", "key_idea": "A chat system is proposed that uses animated dynamic text associated with emotional information, with the user's affective state being detected via a physiological sensor attached to the user.", "method": "The authors conducted preliminary experiments comparing their proposed animated chat system with a conventional one.", "outcome": "Initial observations suggest that an online interface conveying emotional information, such as the one proposed, helps users interact with each other more efficiently.", "future_impact": "The authors hint at potential applications of their chat system, though the specific nature of these applications is not discussed in the abstract.", "venue": "CHI", "year": 2004, "title": "Communicating emotions in online chat using physiological sensors and animated text"}
{"pid": "42d347f6-bf22-4a53-94ab-49a30fedff5d", "context": "Children's storytelling can be enhanced with the help of technology and there is a potential to involve robotics in this process.", "key_idea": "The development of a new robotic pet called PETS, constructed from modular parts, that can act out stories inputted through the 'My Pets' software.", "method": "The design process was carried out by an intergenerational team, working to create the first PETS prototypes and align the functionalities with the requirements of children.", "outcome": "The paper describes the development and design of initial PETS prototypes.", "future_impact": "The authors anticipate focusing on further refining the design and functionality of the PETS technology.", "venue": "CHI", "year": 1999, "title": "Designing PETS: a personal electronic teller of stories"}
{"pid": "219ad678-7823-4770-a9c0-27a54bdf4ca0", "context": "As societal norms influence behaviour in the physical world, it remains unclear how they impact interactions in virtual environments, specifically the concept of personal space.", "key_idea": "This study investigates the influence of the societal norm of personal space on behaviour during interaction and communication in an online virtual environment.", "method": "An online virtual world was explored using a participatory-observer approach for a duration of 3 months.", "outcome": "Findings indicate that personal space norms exist in virtual environments and play a role in influencing behaviors; violation of personal space was found to induce discomfort and possible flight.", "future_impact": "Future research could probe whether this observed influence of personal space is due to identification with one\u2019s avatar or some other factors.", "venue": "CHI", "year": 1998, "title": "Personal space in a virtual community"}
{"pid": "60a7892691e0110affd71cfe", "context": "Co-creation with artificial intelligence (AI) is an emerging trend, however, less attention has been given to the development of systems for Japanese novelists.", "key_idea": "The authors created BunCho, an AI-supported story co-creation system in Japanese that uses GPT-2 trained on Japanese web texts and novels, and can generate titles and synopses from keywords. They also propose an interactive story co-creation AI system as a tabletop role-playing game.", "method": "The authors conducted summative studies by using BunCho with a group of writers (N=16) and readers (N=32) to evaluate its effectiveness and impact on creativity in writing.", "outcome": "According to the study, 69% of the writers enjoyed writing synopses with BunCho more than by themselves. At least one of the five common metrics, including creativity, improved in the objective evaluation. Moreover, 63% of writers indicated that BunCho broadened their stories.", "future_impact": "BunCho demonstrates a new path to support Japanese novelists in creating high-level and creative writing, potentially changing the approach to writing in Japanese.", "venue": "CHI", "year": 2021, "title": "BunCho: AI Supported Story Co-Creation via Unsupervised Multitask Learning to Increase Writers\u2019 Creativity in Japanese"}
{"pid": "ca0b2b97-d64d-4cd6-8aaf-d1a6d4883728", "context": "Designing, developing, and deploying technologies with local African communities requires rapport and trust, which is often hindered by time constraints, limited resources, and differing protocols.", "key_idea": "The authors recognize the central role of community members as co-designers and co-researchers, thus advocating for a more community-driven development approach.", "method": "The authors collected input through an international workshop and panel discussions to identify key factors for effective collaboration with local African communities.", "outcome": "The paper collates advice on successful collaboration strategies from local researchers, community members, and experienced designers.", "future_impact": "The accumulated knowledge described in this paper could provide a basis for improving future collaborative efforts with local communities in Africa and potentially extend to other regions.", "venue": "CHI", "year": 2014, "title": "Collaborating with communities in Africa: a hitchhikers guide"}
{"pid": "150679f1-5c85-4e85-9958-9da95a32f0e2", "context": "Location-based reminders (LBRs) which use people's physical location to trigger reminders have become commonplace due to advanced mobile technology. However, it is understood that current LBR software may not fully support the complexity of such tasks.", "key_idea": "This study conducts an evaluation of location specification in a commercial LBR and, based on the findings, proposes a new classification of the different uses of location in to-do tasks.", "method": "The authors carried out a short study to evaluate the specification of location in a commercially available LBR, which was followed by a survey to collect typical to-do tasks that included location information.", "outcome": "The findings suggest that location-based reminders are more complex than what current LBR software supports. A new classification of different uses of location in to-do tasks is proposed based on the research results.", "future_impact": "The newly proposed classification of location uses in tasks has implications for the design of future location-based reminders.", "venue": "CHI", "year": 2015, "title": "Beyond \"Geofencing\": Specifying Location in Location-Based Reminder Applications"}
{"pid": "609cfbbb91e01118a99b9370", "context": "With the global pandemic pushing musicians online, traditional folk clubs, which had little previous interest in digital platforms, were forced to move their performances online.", "key_idea": "The study analyzes two traditional folk clubs, each of which transitioned their in-person experiences to online platforms, using different approaches.", "method": "An ethnographic account of the transition process of the two folk clubs was provided, with one embracing video conferencing for their singaround format while the other evolved a community-produced, pre-recorded show.", "outcome": "Both approaches were somewhat successful, but participants were unable to 'sing in chorus' due to network constraints. The research also showed how their practices were shaped in unforeseen ways due to the adaptation of these online platforms.", "future_impact": "The findings of the study, which discusses the appropriations of participants and implications, can guide the design and deployment of future live performance platforms, promoting online liveness through rich participatory structures.", "venue": "CHI", "year": 2021, "title": "Producing Liveness: The Trials of Moving Folk Clubs Online During the Global Pandemic"}
{"pid": "234bb81a-9bed-4af1-a8bc-f1d3cff8d740", "context": "Decision-making behavior and performance during the search process among sighted and blind users are not well-understood, particularly in relation to search result relevance, search result presentation, and effort required to process the corresponding web page.", "key_idea": "The authors conducted a study to examine how users evaluate effort needed to explore search results pages and make decisions accordingly, noting variations depending on visual ability and result relevance.", "method": "The authors conducted a study where they manipulated the search result's relevance to a task, the search result's presentation, and the effort required to process the corresponding web page, to observe users' decision making behavior and performance during the search process.", "outcome": "The study found that users utilized page features to gauge the amount of effort required to explore search pages, and their desire for additional page details varied based on their visual ability and the results' relevance.", "future_impact": "The findings suggest that understanding the cost/benefit tradeoff of additional page features could lead to better support for diverse web searchers.", "venue": "CHI", "year": 2004, "title": "Search result exploration: a preliminary study of blind and sighted users' decision making and performance"}
{"pid": "5ea411e39fced0a24bae0d32", "context": "There is a gap between what online platforms like Google and Facebook can infer about users from their collected data and the inferences users expect or believe are possible. This creates surprises when users discover these inferences.", "key_idea": "The authors aim to study users' reactions, particularly surprises, to the inferences made about them by these platforms in order to better understand this gap.", "method": "The authors conducted interviews with users of Google and Facebook to learn about their beliefs and expectations regarding how these platforms use their data for making inferences.", "outcome": "Through these interviews, the authors identified four common sources of surprise for users: irrelevant inferences, outdated inferences, inferences unconnected to online activity, and inferences related to friends or family.", "future_impact": "The findings have implications for designing inference-generating systems, suggesting the need to consider user reactions and expectations in their design.", "venue": "CHI", "year": 2020, "title": "'That's Not Me': Surprising Algorithmic Inferences"}
{"pid": "eb52e32d-2865-47dd-8a83-4e118f78db98", "context": "In real-world scenarios, instructions are typically given through words and body orientations such as head movements, which helps in coordinating actions among participants. There is a need for the similar principle to be applied in the design of interactive robots.", "key_idea": "The study introduces the concept of 'projectability' in the context of robot-human interaction, suggesting the need to design a robot's head so a local participant can project the robot's (and remote person's) actions.", "method": "The authors use GestureMan, a robot designed to support projectability properties, to investigate systems for supporting remote instruction via a mobile robot.", "outcome": "The authors argue that a remote-controlled mobile robot, designed as a communication medium, makes relevant dual ecologies: ecology at a remote (robot operator's) site and at a local participant's (robot's) site.", "future_impact": "To design a robot as a viable communication medium, it is suggested that consideration of how these dual ecologies can be mediated and supported is essential.", "venue": "CHI", "year": 2004, "title": "Dual ecologies of robot as communication media: thoughts on coordinating orientations and projectability"}
{"pid": "60a7892691e0110affd71bf0", "context": "The COVID-19 pandemic has led to a health crisis, and mobile apps for tracing people\u2019s contacts seem effective at preventing overloading of medical capacities. However, these apps have raised concerns about privacy and are contested in public discourse.", "key_idea": "The authors carry out an NLP-supported analysis of comments about the German contact-tracing app on news websites, social media and app stores to understand prevalent topics, stances, and development over time.", "method": "The authors used natural language processing (NLP) techniques to analyze comments about the German contact-tracing app from various online sources such as news websites, social media and app stores, and identified prevalent topics and stances.", "outcome": "The investigation revealed privacy to be one of the most hotly debated topics, which was discussed from various perspectives. The authors found that public commentary got peaked when the discussion was centered on tracing protocols and privacy protection.", "future_impact": "The authors encourage further research on the connection between public discussions and actual adoption rates of the app.", "venue": "CHI", "year": 2021, "title": "Tracing Contacts With Mobile Phones to Curb the Pandemic:Topics and Stances in People\u2019s Online Comments About the Official German Contact-Tracing App"}
{"pid": "4b086e95-26e3-4288-ada8-62eb748ca666", "context": "There is a need for effective systems that can teach ASL vocabulary to young children.", "key_idea": "The authors introduce a concept of PlayWare, a system of augmented dress-up clothes, toys, and a digital environment designed to teach simple ASL vocabulary to young children.", "method": "The authors provide a preliminary evaluation of the PlayWare system in a school setting.", "outcome": "The authors discuss their preliminary evaluation but do not present specific results in the abstract.", "future_impact": "The authors plan to improve the PlayWare system for future deployment, implying potential impact in educational settings, particularly for teaching sign language to young children.", "venue": "CHI", "year": 2008, "title": "Playware: augmenting natural play to teach sign language"}
{"pid": "97f50bde-057b-4e66-9388-ec1e05a63b3d", "context": "A user task often spans multiple heterogeneous devices, like working on a PC and then continuing the same task on a mobile phone. However, existing technology has limitations and does not efficiently support the migration of tasks across different devices.", "key_idea": "The authors propose Deep Shot, a framework for capturing the user's work state required for a task (such as a specific part of a webpage) and resuming it on a different device. It introduces two novel interaction techniques, deep shooting and deep posting, for pulling and pushing work states, respectively, using a mobile phone camera.", "method": "The authors demonstrated that Deep Shot can be used to support a range of everyday tasks migrating across devices through a series of experiments.", "outcome": "A series of experiments demonstrated the feasibility of the proposed framework and techniques.", "future_impact": "Deep Shot provides a concise API for developers to make their application states migratable, which could potentially make task migration across devices a seamless experience in future.", "venue": "CHI", "year": 2011, "title": "Deep shot: a framework for migrating tasks across devices using mobile phone cameras"}
{"pid": "962b5eda-42e6-4cdc-803f-364903c4ff37", "context": "The ability for early readers to learn about story structures and experience the relationship between pictures and text, as well as to experiment with causal effects is a concern in progressive learing environments.", "key_idea": "The authors introduce the Graphic StoryWriter (GSW), an interactive system that allows users to create complete stories by manipulating graphic objects in a simulated storybook. The GSW utilizes a rule-based story engine that manages characters and prop interaction, guides story development, and generates text.", "method": "The authors conducted an empirical comparison of children's stories created both orally and using the GSW.", "outcome": "The paper describes the design and motivation for GSW but does not provide specific outcomes from the empirical comparison of children's stories.", "future_impact": "GSW has the potential to be a useful tool to help early readers learn about story structures, the relationship between pictures and text, and experiment with causal effects.", "venue": "CHI", "year": 1992, "title": "Graphic StoryWriter: an interactive environment for emergent storytelling"}
{"pid": "3dd1125f-8677-4893-9186-fa1ef5613798", "context": "The use of software reuse in object-oriented programming environments is a topic that requires more insight and study.", "key_idea": "The paper facilitates an in-depth study of a single software developer's work, displaying a development style characterized by robust software reuse, strategic template selection, and coding, along with the avoidance of techniques that require deep understanding of code details.", "method": "The research study examines the programming methodology of a single subject: a software developer functioning in an object-oriented programming environment.", "outcome": "From the study, it was found that the subject showed a preference for software reuse and strategic coding, while avoiding techniques that required intensive understanding of code details.", "future_impact": "The study's findings could inspire more investigation into programming strategies and the development of a mature mental model for dealing with object-oriented programming tasks.", "venue": "CHI", "year": 1989, "title": "Some strategies of reuse in an object-oriented programming environment"}
{"pid": "60094a0e91e011721878d7e4", "context": "In Japanese idol culture, meet-and-greet, especially handshaking events, were a key constituent until COVID-19 disrupted such practices. Idol groups are striving to shift these face-to-face events to a computer-mediated communication setup due to pandemic restrictions.", "key_idea": "The author proposes to investigate the ongoing transition in Japanese idol culture events from in-person to computer-mediated communication due to the unique characteristics present in their manner of communication.", "method": "The author conducts a quantitative survey to understand the transition, and then conducts semi-structured interviews with idol fans about their perceptions of the shift. This includes examining distinctive approaches to computer-mediated communication in the idol events.", "outcome": "The survey and interviews reveal distinct approaches in the transition and uncover a large gap in perceptions between traditional offline events and emerging online events. One notable approach involves fans gathering at a venue but communicating with the idol member via a video call, separated by an acrylic plate.", "future_impact": "The study discusses how to develop interaction techniques to aid this transition and suggests potential application of these techniques to other domains, such as computer-mediated performing arts.", "venue": "CHI", "year": 2021, "title": "No More Handshaking: How have COVID-19 pushed the expansion of computer-mediated communication in Japanese idol culture?"}
{"pid": "350129c0-e710-4755-af3c-661ab70e4a65", "context": "Estimation of complexity within computer software source texts is a challenging task in computer science. Traditional methods for characterizing complexity and identifying anomalies and potential errors in language usage requires enhancement.", "key_idea": "The paper introduces an approach that estimates the information content of individual program tokens, based on which tokens are ordered by their 'uncertainty' or 'peculiarity' within the context of the program they are part of.", "method": "The authors refine methods of software science to develop their analysis technique for estimating information content of program tokens.", "outcome": "Applying this analysis method aids in highlighting language usage anomalies and potential errors.", "future_impact": "The information obtained from the proposed analysis can be useful for guiding software review activities. Further theoretical work and experimental validation could potentially allow the technique to be used in a practical environment.", "venue": "CHI", "year": 1985, "title": "Estimating the distribution of software complexity within a program"}
{"pid": "d5b284a8-1ebb-411e-af0e-e7f37799e870", "context": "Data structure algorithms, which are fundamental for teaching and software development, are often difficult to understand, making debugging and development challenging.", "key_idea": "The authors propose a new interactive approach for understanding, debugging, and developing heap manipulating data structures that combines deep parametric abstraction techniques with interactive abstraction manipulation, bridging program analysis with Human-Computer Interaction.", "method": "The authors implement their approach in a Java-based system called FluiEdt and it is evaluated with 27 developers.", "outcome": "Based on their evaluation with developers, the authors found that FluiEdt is more effective in helping developers find data structure errors than existing IDEs such as Eclipse or purely visualization-based approaches.", "future_impact": "As the proposed system effectively assists in finding and addressing data structure errors, it has the potential to improve the development and teaching of data structure algorithms in the future.", "venue": "CHI", "year": 2015, "title": "An Interactive System for Data Structure Development"}
{"pid": "ea4db772-b635-4939-a3eb-65163b539100", "context": "Existing scrolling techniques for notebook computers, such as linear virtual scrolling, may not be optimal or preferred by users.", "key_idea": "The authors propose a new circular touch gesture for scrolling, referred to as ChiralMotion.", "method": "A study was undertaken where performance of ChiralMotion was compared to linear virtual scrolling on a notebook computer TouchPad using a document scrolling task, and participant preferences were surveyed in a follow-up questionnaire.", "outcome": "ChiralMotion outperformed linear Virtual Scrolling in the experiment, and participants in the study indicated a preference for ChiralMotion over linear scrolling in the questionnaire.", "future_impact": "The results indicate potential for further studies incorporating different devices to leverage and validate the ChiralMotion scrolling technique.", "venue": "CHI", "year": 2008, "title": "Evaluating touch gestures for scrolling on notebook computers"}
{"pid": "6287042a5aee126c0f5b6d37", "context": "Textile interfaces provide a way to integrate unobtrusive media and smart home controls into furniture. However, the physical form factor of these controls, such as overall slider shape, raised vs. recessed sliders, and number and layout of tick marks, has received few careful studies.", "key_idea": "The authors investigate how the overall slider shape, the raised vs. recessed nature of the slider and the number and layout of tick marks, all influence user preferences and performance with textile interfaces.", "method": "The authors conducted two user studies: the first one identified a preference for certain design aspects like recessed, closed-shaped sliders; the second study looked into performance measurements on variations of these preferred designs and provided a closer look at tick marks.", "outcome": "The studies showed that users had a preference for certain design combinations, like recessed, closed-shaped sliders. Tick marks supported orientation better than slider shape and sliders with at least three tick marks were preferred. Non-uniform, equally distributed tick marks reduced the movements users needed for orientation on the slider.", "future_impact": "The findings about user preferences for textile interface design can be used to improve the design of textile interfaces in the future.", "venue": "CHI", "year": 2022, "title": "Shaping Textile Sliders: An Evaluation of Form Factors and Tick Marks for Textile Sliders"}
{"pid": "d8a5ec15-4276-45b5-811c-5c3c448874c4", "context": "The construction of cognitive tutors is often focused on limited domains due to the time-intensive process involved.", "key_idea": "The authors propose the use of pseudo-tutors, which are tools to model a small number of problems in a short time, eliminating the need to program a general cognitive model.", "method": "They demonstrated the use of pseudo-tutors through the LSAT Analytic Logic Tutor, which was designed for teaching strategies for solving analytic logic games using only three problems.", "outcome": "The use of three rich problems in the LSAT Analytic Logic Tutor was sufficient to significantly improve student performance.", "future_impact": "The paper suggests that well-designed pseudo-tutors could be more useful than a full cognitive tutor, potentially changing the approach towards the creation and use of cognitive tutors.", "venue": "CHI", "year": 2005, "title": "Simple tutors for hard problems: understanding the role of pseudo-tutors"}
{"pid": "6350f8c7-9e6f-4902-bc19-664b07187b27", "context": "Mobile games have predominantly focussed on touch-based interaction or device tilt for game mechanics, but there is a research gap in exploring the use of the physical position and movement of the handheld device in relation to the physical-digital game world.", "key_idea": "The researchers introduce NerdHerder, a mobile game with an augmented reality (AR) interface that uses the handheld device's physical position and movement as the core game mechanic, merging puzzle-solving and motion-based action.", "method": "The authors present an overview of the system implementation, design process, and game design rationales for the AR-based mobile game NerdHerder.", "outcome": "The authors have successfully implemented the AR-based game NerdHerder, demonstrating the game's integration of puzzle-solving and motion-based action through the physical position and movement of a handheld device.", "future_impact": "While not explicitly stated in the abstract, the exploration and demonstration of physical-device movement based gameplay in NerdHerder could influence future AR game designs, and encourage more research into alternative game mechanics in mobile AR gaming.", "venue": "CHI", "year": 2012, "title": "Herding nerds on your table: NerdHerder, a mobile augmented reality game"}
{"pid": "864ae061-ec76-455e-a412-7a4b272e3659", "context": "Organizations are increasingly interested in facilitating collaboration in distributed groups, and real-time text chat tools are being integrated into work environments.", "key_idea": "The author studies how effective use of real-time chat tools interacts with group norms and group structure among technical support engineers, in terms of response rates to questions and the adaptive use of the tool based on roles and problem range in the group.", "method": "The author examines three distributed groups of technical support engineers at a large high technology company who have integrated a real-time text chat tool into their work practice.", "outcome": "Findings suggest that highly collaborative group norms increase the likelihood of receiving responses to questions in the chat tool, reducing the need to specifically target questions at the right person. Members also use the chat tool in ways that reflect the group's structure (roles and problem range), with active expert participation increasing the chances for a useful answer.", "future_impact": "Understanding these dynamics could inform more effective integration of chat tools into distributed work environments.", "venue": "CHI", "year": 2000, "title": "Tech support engineers' communication in a chat tool"}
{"pid": "60a4e58991e011f4291ce254", "context": "The rise of artificial intelligence (AI) applications has brought about concerns regarding the fairness and transparency of AI behavior. As a result, the computer science community is advocating for the involvement of the general public in the design and evaluation of these systems.", "key_idea": "The study evaluates the effect of two common visualization techniques (text-based and scatterplot) and the display of outcome information (i.e., ground-truth) on the perceived fairness of AI predictors.", "method": "An online crowdsourcing study with 80 participants was used to evaluate the effect of visualization techniques and the display of outcome information on perceived fairness.", "outcome": "The study found that the chosen visualization technique significantly alters people\u2019s fairness perception. Also, the presented scenario, as well as the participant\u2019s gender and past education, were found to influence perceived fairness.", "future_impact": "The findings of this study provide recommendations for future work that seeks to involve non-experts in AI fairness evaluations.", "venue": "CHI", "year": 2021, "title": "Effect of Information Presentation on Fairness Perceptions of Machine Learning Predictors"}
{"pid": "5e5e199893d709897ce78bbd", "context": "In Human Computer Interaction (HCI) research, a major ongoing challenge is how to adequately design quantitative empirical evaluations for users who have visual impairments.", "key_idea": "The authors conducted a review of 178 papers published since 1988 that focused on technologies for visually impaired users and included at least one quantitative empirical evaluation. From this review, the authors propose a set of guidelines and unified terminology for designing and reporting such evaluations.", "method": "They analyzed a corpus of 178 papers on technologies designed for people with visual impairments that included quantitative empirical evaluations.", "outcome": "The authors provide an overview, historic trends, a unified terminology for designing and reporting quantitative empirical evaluations, and identified open issues in this area.", "future_impact": "The results from this analysis aim to facilitate and stimulate future research on designing technology for visually impaired users and conducting efficient empirical evaluations.", "venue": "CHI", "year": 2020, "title": "Review of Quantitative Empirical Evaluations of Technology for People with Visual Impairments"}
{"pid": "a6d4854d-8939-4ab3-a753-bc9b8f8a4dc1", "context": "Privacy is frequently a key concern related to technology and HCI research. However, it is very difficult to study it in a naturalistic way.", "key_idea": "The authors propose a dictionary of privacy designed for content analysis, which is derived using prototype theory and informed by traditional theoretical approaches to privacy.", "method": "The privacy dictionary is evaluated alongside privacy-related categories from an existing content analysis tool, LIWC, using verbal discussions of privacy issues from a variety of technology and non-technology contexts.", "outcome": "The authors find that their privacy dictionary can better distinguish between privacy and non-privacy language and is less context-dependent than LIWC. However, the more general LIWC categories can describe a greater amount of variation in the data.", "future_impact": "The authors suggest improvements to the privacy dictionary and identify areas for future research.", "venue": "CHI", "year": 2011, "title": "Privacy dictionary: a linguistic taxonomy of privacy for content analysis"}
{"pid": "4f351fdc-0c9b-43f9-91b0-33c65b8cc252", "context": "Previous work indicates potential advantages of physical navigation (moving eyes, head, body) over virtual navigation (zooming, panning, flying) in navigating large information spaces. However, users tend to prefer or settle into the less efficient virtual navigation.", "key_idea": "The authors set out to identify specific relationships between display size, amount of physical and virtual navigation, and user task performance in the context of large, high resolution displays.", "method": "The study examines these issues and collects empirical data regarding physical and virtual navigation on different display sizes and how they affect user task performance.", "outcome": "The study found that increased physical navigation on larger displays correlates with reduced virtual navigation and improved user performance.", "future_impact": "The results can be used to identify design factors that afford and promote the use of physical navigation in the user interface.", "venue": "CHI", "year": 2007, "title": "Move to improve: promoting physical navigation to increase user performance with large displays"}
{"pid": "60a7892691e0110affd71c42", "context": "Commercial videogames are increasingly recognized to be able to facilitate meaningful experiences, but little research has been done on their potential as a medium to help players cope with the loss of a loved one.", "key_idea": "The study aims to investigate how the commercial death-themed game Spiritfarer can help players in their bereavement process.", "method": "The authors conducted a thematic analysis of qualitative in-depth interviews with 6 participants who have played Spiritfarer.", "outcome": "Findings revealed that players' grieving experiences closely resembled the Dual Process Model of Coping with Bereavement. The players' engagement and bereavement experiences largely varied depending on factors such as prior loss experience, gaming environment, and focus.", "future_impact": "The study concludes with insights that can be used in future game designs for bereavement support.", "venue": "CHI", "year": 2021, "title": "How the Death-themed Game Spiritfarer Can Help Players Cope with the Loss of a Loved One"}
{"pid": "d0337227-d2bc-4de4-8c74-64fee500d420", "context": "The relationship between industrial design and interaction design in product development activities is somewhat unclear and has not been thoroughly examined.", "key_idea": "The authors propose to understand the relationship between industrial design and interaction design in product development activities based on a case study, focusing on the early phases of the development activity and the differences in approach between the two types of designers.", "method": "A case study was conducted, focusing on a specific product design and development activity to understand the differences in approach and collaboration between industrial designers and interaction designers.", "outcome": "Most intense collaboration occurs in initial phases of product development such as concept generation and design alternative creation. The study also uncovered differences in methods, techniques and design languages in approaching the design problem between industrial designers and interaction designers.", "future_impact": "The results of the study could aid future case studies and contribute to the development of more effective techniques, design, and representation languages.", "venue": "CHI", "year": 2012, "title": "The relationship between industrial design and interaction design in product development activities"}
{"pid": "5ea2c2ea9fced0a24b1ddab8", "context": "People with visual impairments (PVI) have to interact with a world they cannot see and Remote Sighted Assistance (RSA) has emerged as a conversational assistive technology to aid them.", "key_idea": "The study explores interactions between RSA assistants (agents) and PVIs via a conversational prosthetic called Aira, with the goal of improving understanding of their professional practices.", "method": "The researchers interviewed RSA agents who provide assistance to PVI via the Aira system, studying and identifying patterns in how agents provide assistance and how they interact with PVI as well as the challenges and strategies associated with each context.", "outcome": "The study identified four types of support provided: scene description, navigation, task performance, and social engagement. It found that RSA provides an opportunity for PVI to appropriate the system as a richer conversational/social support tool and that conversational interaction is highly context-dependent.", "future_impact": "The insights gained into the conversational interactions between PVIs and RSA agents point toward design implications for improving assistive technology.", "venue": "CHI", "year": 2020, "title": "The Emerging Professional Practice of Remote Sighted Assistance for People with Visual Impairments"}
{"pid": "ee74b626-ee63-4b70-8db0-22fe08802ce2", "context": "The think aloud method is widely used in usability research to collect user reports of the experience of interacting with a design so that usability evaluators can find the underlying usability problems, but concerns exist about its validity and usefulness.", "key_idea": "The panel aims to present current studies of the think aloud method, examine and question its usage in the field, discuss possible pitfalls that threaten its validity, and provide comments and suggestions on improving its application.", "method": "The method involves conducting a panel discussion presenting current studies on the think aloud method, examining its use, discussing possible pitfalls, and providing suggestions for its application.", "outcome": "The panel generated results and discussion points drawn from both applied research and basic research about think aloud method.", "future_impact": "The panel discussion will give HCI designers and usability practitioners suggestions for improved use of the think aloud method and stress the importance of investigating currently used or newly designed usability methods for HCI or usability researchers.", "venue": "CHI", "year": 2006, "title": "Does think aloud work?: how do we know?"}
{"pid": "64564a29d68f896efae7b3c2", "context": "Cultural heritage plays an important role in realizing the Sustainable Development Goals. Currently, there is a need for enhanced public understanding of cultural values in historical contexts.", "key_idea": "The authors use emerging technologies such as Augmented Reality and gamified learning to design HeritageSite AR, an exploration game for onsite cultural heritage learning and visits, applied to Relics of Arhat Monastery and Twin Pagoda.", "method": "The authors based their design on research investigation of technical means, expert semi-structured interviews and online surveys to distill and incorporate four design goals. The design is then evaluated with respect to three design components (reality, meaning, play) and four stages (trigger, engage, consolidate, relate) in cultural heritage visits.", "outcome": "The authors successfully develop and implement HeritageSite AR, an exploration game for onsite cultural heritage learning, but no measurable outcomes of the game's impact are provided in the abstract.", "future_impact": "The authors conclude with a discussion of the game's contributions to Sustainable Development Goals, suggesting the potential for using augmented reality and gamified learning in cultural heritage education.", "venue": "CHI", "year": 2023, "title": "HeritageSite AR: An Exploration Game for Quality Education and Sustainable Cultural Heritage\u2731"}
{"pid": "6287042a5aee126c0f5b6e37", "context": "Human-Computer Interaction (HCI) research on menstrual tracking has emphasized the need for more inclusive design of mechanisms for tracking and sharing information on menstruation. Existing mechanisms for tracking and sharing data on menstruation are not adequately responsive to the needs of those who seek relevant menstrual education.", "key_idea": "The authors investigate menstrual tracking and data-sharing attitudes and practices in young, educated menstruating individuals with self-identified minimal menstrual education backgrounds in the United States.", "method": "The authors conduct interviews (N=18), a survey (N=62), and participatory design (N=7) to understand the users' needs and desires regarding menstrual tracking and data sharing.", "outcome": "The study identifies a design gap for participants with minimal sexual education backgrounds who wish to better understand their cycles. The analysis also highlights the understanding of structural health inequities that impact menstrual tracking and sharing practices.", "future_impact": "The study lays groundwork for recommendations for technology-mediated menstrual care that can be more inclusive and responsive to diverse needs.", "venue": "CHI", "year": 2022, "title": "Investigating Culturally Responsive Design for Menstrual Tracking and Sharing Practices Among Individuals with Minimal Sexual Education"}
{"pid": "e2cea0ef-1141-4dfd-8536-d86ce9c0c518", "context": "Previous works on password usage focused mainly on specific computers, websites, or organizations, but little research has been carried out on examining overall password usage in daily life.", "key_idea": "The authors propose a diary study method to examine all aspects of password use in daily life, from how often people log in, where they log in, to how frequently people use foreign computers.", "method": "The authors collected password usage data through a diary study method, allowing participants to record their password usage patterns.", "outcome": "The study reveals new findings based on quantitative analyses about how often people log in, where they log, and how often they use foreign computers. The study also confirms or updates existing statistics about password usage.", "future_impact": "The findings of the study have implications for design and security education, potentially influencing how passwords are designed and implemented, and how users are educated about security best practices.", "venue": "CHI", "year": 2011, "title": "A diary study of password usage in daily life"}
{"pid": "36120d1f-78ae-47c1-8ad3-62612f05c363", "context": "The widespread use of flexible software applications that can be enhanced by adding components (also known as plugins or add-ons) is accompanied by difficulties in searching, installing and configuring new plugins, which is only weakly handled by existing support mechanisms.", "key_idea": "The authors developed an understanding of software appropriation as a social and collaborative activity, based on an empirical study in small software enterprises.", "method": "The authors conducted an empirical study in small software enterprises to understand how software appropriation happens within these organizations.", "outcome": "They've built design principles based on practices they've seen in the software industry and presented a prototype implementation that improves existing tool sharing and knowledge management mechanisms.", "future_impact": "The research might lead to better support mechanisms for software tool appropriation, making it more efficient for developers to locate, install, and configure helpful plugins for their needs. It can impact how software tools are shared and knowledge is managed in enterprises.", "venue": "CHI", "year": 2012, "title": "Supporting the social context of technology appropriation: on a synthesis of sharing tools and tool knowledge"}
{"pid": "60a7892691e0110affd71cf9", "context": "Consumer electronics are increasingly using traditional materials to blend better with everyday environments. Specifically, transmissive materials enable displays to disappear when turned off, and appear when turned on. However, the use of materials such as textile meshes, veneer, one-way mirrors, or translucent plastics greatly limit the display brightness of typical graphical displays.", "key_idea": "The authors propose to use a parallel rendering technique to enable ultrabright graphics that can pass through transmissive materials, developing interactive prototypes with touch-sensing that can blend into traditional aesthetics.", "method": "A set of interactive prototypes with touch-sensing were developed, unlocking expressive interfaces with practical end-to-end software and low-cost hardware implementation on mass-produced passive OLED displays.", "outcome": "The produced prototypes successfully can provide user interfaces through various materials such as wood, textile, plastic and mirrored surfaces.", "future_impact": "This work can impact the design of consumer electronic devices, creating more expressive and blended interfaces for ambient computing.", "venue": "CHI", "year": 2021, "title": "Hidden Interfaces for Ambient Computing: Interacting with High-brightness Visuals through Everyday Materials"}
{"pid": "4879d672-9dd0-4982-986f-e63070eec1b3", "context": "Searching for historical word-forms in a database of 17th-century English text using modern English queries presents challenges due to changes in spelling and language structure over time.", "key_idea": "The authors propose an approach to identify words in a 17th century English text database that are similar to a query word in modern English using spelling correction techniques including n-gram matching, non-phonetic coding, and dynamic programming.", "method": "The authors conducted experiments using n-gram matching, non-phonetic coding, and dynamic programming methods for spelling correction in a historical English text database.", "outcome": "The experiments demonstrate that high-recall searches can be executed, but some are computationally demanding.", "future_impact": "The proposed method, in principle, could be applied to historical texts in a variety of languages and time periods.", "venue": "SIGIR", "year": 1992, "title": "Searching for historical word-forms in a database of 17th-century English text using spelling-correction methods"}
{"pid": "d51efc8c-947c-4384-9850-f7c3e53817de", "context": "In cross-language information retrieval (CLIR), the impact of the quality and relevance of translation resources on CLIR performance, particularly in specific domains, is under-explored. Whether systematic analysis and optimal matching of training resources to target collections can improve CLIR performance is also under-explored.", "key_idea": "The study probes into these questions by evaluating several CLIR methods - with different training corpora - on test documents in the medical domain, and proposing a simple criterion for automatically matching training resources to target corpora based on cosine similarity.", "method": "Various CLIR methods are evaluated using different training corpora applied to medical domain test documents. A criterion for automatically matching training resources to target corpora is also tested - this uses cosine similarity between training and target corpora as resource weights.", "outcome": "Using a general-purpose training corpus or a commercial machine translation system results in severe performance degradation as opposed to a domain-specific training corpus. Using the proposed method of cosine similarity between training and target corpora as resource weights, a 5.6% performance improvement was achieved over unweighted resources, nearly matching the performance (99.4%) when an oracle chooses the optimal resource.", "future_impact": "The study could potentially guide further research into optimizing CLIR performance by matching training resources based on domain-relevance, and provide insights into improving resource selection for domain-specific cross-lingual information retrieval.", "venue": "SIGIR", "year": 2004, "title": "Resource selection for domain-specific cross-lingual IR"}
{"pid": "d26fe285-3d9c-498d-8ac5-c6041cfeebad", "context": "Research approaches in Information Retrieval (IR) can differ greatly depending on the goal, such as describing search behavior, predicting a second query input, or evaluating the effectiveness of IR systems.", "key_idea": "This tutorial aims to provide a comprehensive overview of various research goals in IR, the evaluation approaches suitable for each goal, and the constraints of each approach.", "method": "The tutorial is structured in two independent parts, each focused on different research approaches. The authors achieve this through a detailed examination and analysis of their own published research papers, supplemented by broader literature.", "outcome": "Participants are expected to gain a broad understanding of research goals and approaches in IR, as well as the benefits and limitations of these research approaches.", "future_impact": "The tutorial's insights on the research process and the difficult choices and trade-offs made while designing and conducting IR studies could guide future endeavours in IR research methodology.", "venue": "SIGIR", "year": 2014, "title": "Choices and constraints: research goals and approaches in information retrieval (part 1)"}
{"pid": "76308594-d161-4acc-90f5-2aba264a9130", "context": "Existing methods for information retrieval of documents represented as a vector typically use (generalized) p-norms as a matching function between the query and the document. The cosine-matching function has been used for this purpose, for example by Salton and others.", "key_idea": "The authors propose a new algorithm for information retrieval that uses a function measurement of the relative dispersion of the terms between a document and a query, rather than relying on p-norms.", "method": "The properties of this new algorithm are analyzed and compared to the specifications of the new Cater-Kraft wish list and the original cosine-matching function of Salton.", "outcome": "The new information retrieval algorithm is shown to possess desirable properties as per the Cater-Kraft wish list, including those of the original cosine-matching function. The algorithm also refines the property of the cosine-matching function that, if one only uses weights 0 to 1, one is reduced to Boolean IR by taking into account the specialization of a document and a query.", "future_impact": "It is not specifically mentioned in the abstract.", "venue": "SIGIR", "year": 1989, "title": "A new method for information retrieval, based on the theory of relative concentration"}
{"pid": "4b7ae713-12bf-4e38-a20d-3e92f1fb0c27", "context": "Conditional Markov chain models (CMM) have been used to extract information from semi-structured text, applied to tasks such as identifying the author and title in research papers, or finding phone numbers and street addresses on web pages.", "key_idea": "The paper suggests a new technique of information extraction by learning a discriminative context free grammar from training data. This approach is seen to provide several advantages, such as the use of long range and even global constraints, more efficient use of training data, and introduction of more powerful features.", "method": "The study deploys this new approach in the specific problem of extracting personal contact or address information from unstructured sources like documents and emails, comparing it with the linear-chain CMMs.", "outcome": "The grammar-based system, described as interactive and able to correct multiple errors automatically, results in a 50% reduction in error rate compared to linear-chain CMMs. Their system labels 93.71% of all tokens correctly (compared to 88.43% for the CMM) and 72.87% of records have all tokens labeled correctly (compared to 45.29% for the CMM).", "future_impact": "This grammar-based approach results in semantic information that could be beneficial for Information Retrieval applications such as question answering.", "venue": "SIGIR", "year": 2005, "title": "Learning to extract information from semi-structured text using a discriminative context free grammar"}
{"pid": "64c78b993fda6d7f06db59fe", "context": "Current methods for Next Point-of-Interest (POI) recommendation rely on Graph Neural Networks with pre-defined POI graphs to capture user preferences and geographical dependencies among POIs. However, these pre-defined graph structures are not optimal due to issues like noise and limited adaptability, thus reducing the quality of learned POI representations and user preference modeling.", "key_idea": "To deal with these issues, the authors propose an Adaptive Graph Representation-enhanced Attention Network (AGRAN) for next POI recommendation, which leverages graph structure learning to replace pre-defined static graphs, with the aim of learning more expressive POI representations.", "method": "In AGRAN, an adaptive POI graph matrix is developed and is learned via similarity learning with POI embeddings, which automatically captures the underlying geographical dependencies for representation learning. Additionally, the learned POI representations and personalized spatial-temporal information are combined using an extension to the self-attention mechanism. The proposed method is validated using two real-world datasets.", "outcome": "Extensive experiments conducted on two real-world datasets show that the proposed method improves upon state-of-the-art baselines in terms of performance.", "future_impact": "The proposed adaptive approach for graph structure learning has the potential to greatly improve future POI recommendation systems and other applications that can benefit from expressive representations of geographical points of interest.", "venue": "SIGIR", "year": 2023, "title": "Adaptive Graph Representation Learning for Next POI Recommendation."}
{"pid": "62de85745aee126c0f9750d0", "context": "The 'standard' community-wide evaluations, like TREC, are simultaneous games where leaderboard submissions leak information about the held-out evaluation set. This contradicts the key principle in machine learning about separation of training and test data, leading to accumulating 'leaks' over time that threaten the validity of the insights that can be drawn from the leaderboards.", "key_idea": "The authors describe their experiences in managing this issue through the design and implementation of the MS MARCO document ranking and passage ranking leaderboards, which operate as sequential games where every move is immediately visible to all.", "method": "Based on their experiences over the years, authors have operationalized considerations into a coherent submission policy to combat the aforementioned challenges.", "outcome": "A coherent submission policy is made, serving as a solution to combat the leakage of information about the held-out evaluation set from leaderboard submissions.", "future_impact": "Lessons learned from the design choices of the MS MARCO leaderboards can help guide designers of future leaderboards.", "venue": "SIGIR", "year": 2022, "title": "Fostering Coopetition While Plugging Leaks: The Design and Implementation of the MS MARCO Leaderboards"}
{"pid": "62de859a5aee126c0f975f08", "context": "The existing neural sequence-to-sequence model, doc2query, predicts natural language queries from a given input text to better serve retrieval models, such as BM25 or uniCOIL. These methods have shown effectiveness on the MS MARCO datasets and have become widely used baselines.", "key_idea": "With the release of the MS MARCO V2 passage and document ranking test collections, the authors update their doc2query and uniCOIL models to adapt to new changes.", "method": "The authors use the Anserini and Pyserini IR toolkits to update their doc2query and uniCOIL models for the refreshed MS MARCO V1 and V2 test collections.", "outcome": "The authors successfully provide resources that support competitive, reproducible baselines for both the MS MARCO V1 and V2 test collections.", "future_impact": "The updated models and resources aim to provide a solid foundation for future research on neural retrieval models using the MS MARCO datasets and beyond.", "venue": "SIGIR", "year": 2022, "title": "Document Expansion Baselines and Learned Sparse Lexical Representations for MS MARCO V1 and V2"}
{"pid": "3ea5520d-62ab-442b-bfdc-102947b3ac91", "context": "The task of recognizing places-of-interest in smartphone photos presents challenges due to the uncertainty in camera sensor data and the issue of scalability.", "key_idea": "The authors propose a framework called Knowing Camera that uses a probabilistic field-of-view model to capture uncertainty in camera sensor data, relies on sparse coding for visual similarity computation of candidate images, and employs an ANN filtering technique for speedup.", "method": "The authors conduct preliminary experiments in an urban area of a large city to validate the framework.", "outcome": "The experiment results show that the knowing Camera framework performs well in a real-world online image database and doesn't incur any complex data structure, making it scalable.", "future_impact": "The Knowing Camera framework could improve recognition of places-of-interest in smartphone photos, even in cases with contaminated, real-world online image databases.", "venue": "SIGIR", "year": 2013, "title": "The knowing camera: recognizing places-of-interest in smartphone photos"}
{"pid": "52c64da2-d6db-4c07-ac22-63665cb0bee7", "context": "Search engines and information retrieval systems struggle with how to effectively present search results when a single query retrieves many documents. Currently, the common separate post-processing techniques are ranking and clustering, which help to organize retrieved documents.", "key_idea": "The authors propose a spectral analysis method that integrates clustering and ranking techniques based on content similarity networks, with the goal of improving literature search.", "method": "A variety of theoretical and empirical studies were carried out to evaluate the presented method, especially its performance in biomedical literature retrieval.", "outcome": "The studies demonstrated that the presented spectral analysis method performs well in real applications, particularly in biomedical literature retrieval.", "future_impact": "The proposed approach could potentially be applied to a wide range of information systems, beyond just literature search services, including web search engines.", "venue": "SIGIR", "year": 2008, "title": "Spectral geometry for simultaneously clustering and ranking query search results"}
{"pid": "263a9379-9c2c-41bb-9147-2929c4356e66", "context": "The existing evaluation methods in information retrieval (IR) experiments typically rely on dichotomous relevance judgments, which do not distinguish highly relevant documents from merely relevant ones.", "key_idea": "This paper proposes new IR evaluation techniques that take into account non-dichotomous relevance judgments to credit retrieval methods, focusing on their ability to retrieve highly relevant documents.", "method": "The paper proposes (1) a different application of Precision-Recall (P-R) curves and average precision computations based on separate recall for documents of varying relevancy, and (2) two novel measures to compute the cumulative gain a user obtains by examining the retrieval result up to a given ranking. These methods are demonstrated in a case study testing the effectiveness of different query types in retrieving relevant documents, featuring a best match retrieval system (In-Query I) tested on a newspaper article database.", "outcome": "The results reveal that certain strong query structures are most effective in retrieving highly relevant documents. The observed differences among query types were statistically significant. Furthermore, the study confirmed that non-dichotomous relevance assessments are practical and useful in IR experiments.", "future_impact": "These novel evaluation methods could pave the way for a better understanding of retrieval behaviors by highlighting non-dichotomous relevance assessments, which might reveal unique phenomena and allow for more rigorous testing of IR techniques.", "venue": "SIGIR", "year": 2000, "title": "IR evaluation methods for retrieving highly relevant documents"}
{"pid": "9a4351ee-143f-4000-9d2c-2a4415d3af18", "context": "The rapid increase in the amount of medical information available has made search techniques increasingly important in the medical domain.", "key_idea": "This tutorial discusses recent results related to search techniques in the medical domain including end user requirements, relevant research, and current applications.", "method": "The tutorial reviews surveys on end user requirements, various studies and researches, as well as current health and medical search applications.", "outcome": "The tutorial reveals the extent to which current techniques meet user requirements and discusses open challenges in the field.", "future_impact": "Based on the identified challenges, forthcoming research could focus on improving search techniques in order to better meet user needs in the medical domain.", "venue": "SIGIR", "year": 2012, "title": "Medical information retrieval: an instance of domain-specific search"}
{"pid": "00b3d390-cf1c-409a-95da-a34d3b0d3d8b", "context": "Currently, there is a lack of methods that can accurately quantify and diagnose the structure of topics in documents.", "key_idea": "The paper introduces a method based on document probes for quantifying and diagnosing topic structure, therefore categorizing topics as either monolithic, structured, or diffuse.", "method": "The developed method is applied to the TREC/Reuters-96 topics to verify its effectiveness in assessing topic structures.", "outcome": "Preliminary results indicate that the proposed method has predictive value when applied to TREC/Reuters-96 topics.", "future_impact": "The structure analysis generated by this method can be utilized to optimize filter creation in future classifier developments.", "venue": "SIGIR", "year": 2002, "title": "Topic structure modeling"}
{"pid": "626b49615aee126c0fffce85", "context": "In recommendation systems, the choice of loss function is crucial for model performance. Manual design of effective loss functions is a challenging task given the complexity, and large fraction of work relies on handcrafted functions that require significant expertise and human effort.", "key_idea": "The authors propose AutoLossGen, an automatic loss function generation framework that constructs loss functions from basic mathematical operators, without requiring prior knowledge on the loss structure. They use a controller model driven by reinforcement learning for loss function generation, and tackle the extreme sparsity of recommendation datasets through a reward filtering mechanism.", "method": "The authors develop iterative and alternating optimization schedules to update parameters of both the controller model and the recommender model, and employ a reward filtering mechanism to address the sparse reward problem in loss function genreation and search within recommender systems.", "outcome": "Experimental results show that AutoLossGen can create tailored loss functions for different recommendation models and datasets, and these generated losses give better recommendation performance than commonly used baseline losses. Additionally, most of the generated losses are transferable across models and datasets.", "future_impact": "This work could streamline the development of recommendation models by providing an automated means of generating tailored, transferable loss functions, reducing the need for manual loss function design.", "venue": "SIGIR", "year": 2022, "title": "AutoLossGen: Automatic Loss Function Generation for Recommender Systems"}
{"pid": "60b9a540e4510cd7c8fcc8bc", "context": "In sponsored search ads, relevance modeling is key but presents significant research challenges. Existing methods mostly rely solely on the semantic information in the input query-ad pair, yet this pure semantic information is not adequate to fully capture user's search intents.", "key_idea": "The authors aim to enhance relevance modelling by incorporating unsupervised user behavior data from historical search logs as a complementary graph, and propose three novel AdsGNN models to aggregate topological neighborhood from the perspectives of nodes, edges and tokens.", "method": "The authors focus on two critical but rarely investigated problems, domain-specific pre-training and long-tail ads matching, and evaluate the AdsGNN models on a large industry dataset with online/offline tests.", "outcome": "The experimental results consistently demonstrate the superior performance of the proposed AdsGNN models.", "future_impact": "The proposed approach has potential to enhance the effectiveness of sponsored search ads by improving the relevance modeling.", "venue": "SIGIR", "year": 2021, "title": "AdsGNN: Behavior-Graph Augmented Relevance Modeling in Sponsored Search"}
{"pid": "5c8222ab-6bd2-4eff-bf66-d41775c78f69", "context": "Previous studies involving information retrieval have not fully considered the cognitive abilities of end-users.", "key_idea": "The authors studied the effects of various cognitive abilities on the performance of university students searching for references using a standard computerized index.", "method": "The cognitive abilities of fifty university students were assessed using eight tests from the Kit of Factor-Referenced Cognitive Tests, and then they were asked to search for references using a standard computerized index. The performance in the searches was analysed using various measures, and effects for demographic characteristics and knowledge were also considered.", "outcome": "It was found that perceptual speed affected the quality of searches, and logical reasoning, verbal comprehension, and spatial scanning abilities influenced search tactics.", "future_impact": "This finding suggests that information retrieval systems could be improved to accommodate users with different levels of cognitive abilities, which can assist users to scan lists of terms, choose appropriate vocabulary for searching, and select useful references.", "venue": "SIGIR", "year": 1992, "title": "Cognitive differences in end user searching of a CD-ROM index"}
{"pid": "60b9a180e4510cd7c8f6bce1", "context": "Current models for personalized search are built predominantly on user profiles derived from historical behavior data. For users without historical data, existing models incorporate profiles of similar users for re-ranking results. However, identification of similar users has been largely based on basic lexical or topical similarity in search behaviors.", "key_idea": "In this paper, the authors propose a neural network enhanced method for identifying similar users in semantic space, and incorporate friendship networks into personalized search to determine user closeness. They propose a 'friend network enhanced personalized search model' that groups users into multiple friend circles based on search behaviors and friend relations.", "method": "The authors propose and develop a new model for personalized search that factors in both search behaviors and friend relations to build friend circles and refine personalization.", "outcome": "Experimental results show significant improvement of the proposed model over existing personalized search models.", "future_impact": "This new model for integrating behavioural data and friendship networks could improve personalized search quality, especially for users without extensive historical data.", "venue": "SIGIR", "year": 2021, "title": "Group based Personalized Search by Integrating Search Behaviour and Friend Network"}
{"pid": "20b77836-3178-4f75-891c-20fb5024ec13", "context": "Indexing is a crucial Information Retrieval (IR) operation that needs parallelization to support large-scale document corpora.", "key_idea": "The authors propose a novel adaptation of the single-pass indexing algorithm utilizing the MapReduce programming model.", "method": "The authors experiment with the proposed adaptation in the context of the Hadoop MapReduce implementation, assessing improvements achieved with more processing hardware and larger corpora.", "outcome": "The results demonstrate a close-to-linear increase in indexing speed when scaling corpus size or number of processing machines.", "future_impact": "The proposed indexing implementation is potentially suitable to support the expanding scale of future document corpora.", "venue": "SIGIR", "year": 2009, "title": "On single-pass indexing with MapReduce"}
{"pid": "cf7d6696-460c-4836-b816-9de59bd8483a", "context": "Automatic classification of German business letters into corresponding message types is a challenging task in document analysis.", "key_idea": "The paper introduces the INFOCLAS system which applies statistical methods of information retrieval for the classification of German business letters. The system has two main modules: the central indexer (for extraction and weighting of indexing terms) and the classifier (for classifying business letters into given types).", "method": "INFOCLAS utilizes several knowledge sources, including a letter database, word frequency statistics for German, lists of message type specific words, morphological knowledge, and the underlying document structure.", "outcome": "INFOCLAS evaluates a set of weighted hypotheses about the type of the actual letter, which can assist with automatic distribution or archiving of letters.", "future_impact": "The classification of documents provided by INFOCLAS is an excellent starting point for higher-level document analysis.", "venue": "SIGIR", "year": 1994, "title": "Using IR techniques for text classification in document analysis"}
{"pid": "621c3d205aee126c0fe7dfe9", "context": "In deep learning, the process of model checkpoint validation is crucial for avoiding overfitting and determining when the model has converged. A commonly used strategy involves adding validation loops during training. However, for dense retrievers (DR), this is inefficient as the entire document corpus needs to be encoded into vectors using the current checkpoint before any retrieval operation for checkpoint validation can be carried out. This becomes especially time-consuming for corpora containing millions of documents.", "key_idea": "The authors propose the Asyncval toolkit, a Python-based solution for efficiently validating DR checkpoints during training. Asyncval fundamentally decouples the validation loop from the training loop and uses an additional GPU to validate new DR checkpoints asynchronously from training.", "method": "Asyncval implements various corpus subset sampling strategies for validating DR checkpoints to further speed up the validation process. The authors conducted an investigation to evaluate the impact of these strategies on validation time and validation fidelity.", "outcome": "The authors have not provided specific quantitative results in the abstract, although they suggest that the proposed approach can speed up the validation process.", "future_impact": "Asyncval being available as an open-source project promises to facilitate more efficient and time-saving validation processes in dense retriever training, potentially advancing the field of deep learning research.", "venue": "SIGIR", "year": 2022, "title": "Asyncval: A Toolkit for Asynchronously Validating Dense Retriever Checkpoints During Training"}
{"pid": "60b9a348e4510cd7c8f8c753", "context": "Current models for code retrieval and code summarization tasks require labeled data, which might be resource intensive to produce.", "key_idea": "The authors introduce Corder, a self-supervised contrastive learning framework for source code models. Corder uses a set of semantic-preserving transformation operators to generate syntactically diverse but semantically equivalent code snippets for training.", "method": "Corder is trained to recognize similar and dissimilar code snippets through a contrastive learning objective. The pre-trained model's efficacy is evaluated against several code retrieval and code summarization tasks.", "outcome": "Through extensive experiments, it is shown that Corder substantially outperforms other baselines for code-to-code retrieval, text-to-code retrieval, and code-to-text summarization tasks.", "future_impact": "Corder's design can potentially reduce the need for labeled data in code retrieval and code summarization tasks. The pre-trained model could be particularly useful in tasks lacking labeled data or in cases where label data is still required, for instance, during the fine-tuning process for code summarization.", "venue": "SIGIR", "year": 2021, "title": "Self-Supervised Contrastive Learning for Code Retrieval and Summarization via Semantic-Preserving Transformations"}
{"pid": "5eb78919da5629cf244303ba", "context": "Graph-based models, particularly Graph Neural Networks (GNNs), have been employed for fraud detection tasks. Current approaches aggregate the neighborhood information into node embeddings based on the assumption that neighboring nodes share similar context, features, and relations, which may not always be true due to the inconsistency problem.", "key_idea": "The authors identify the presence of inconsistencies, specifically context, feature, and relation inconsistencies, in the fraud detection process, and counter these issues with a new GNN framework, GraphConsis.", "method": "To tackle the identified inconsistencies: (1) context inconsistency is addressed by combining context embeddings with node features; (2) feature inconsistency is tackled through a consistency score that filters inconsistent neighbors and generates corresponding sampling probabilities; (3) relation inconsistency is managed by learning relation attention weights associated with sampled nodes. The framework's effectiveness was tested through empirical analysis on four datasets.", "outcome": "The empirical analysis showed that the inconsistency problem is significant in fraud detection tasks and that GraphConsis, the proposed framework, is effective in addressing these issues. Additionally, the authors released a GNN-based fraud detection toolbox with implementations of state-of-the-art models.", "future_impact": "The GraphConsis framework could be a valuable tool in further development and application of GNN-based models in fraud detection, potentially improving accuracy and performance. The shared fraud detection toolbox and code could serve as a resource for future research and model development.", "venue": "SIGIR", "year": 2020, "title": "Alleviating the Inconsistency Problem of Applying Graph Neural Network  to Fraud Detection"}
{"pid": "9a1135bc-bad7-43e4-b0b5-71eef6180aa9", "context": "Machine learning techniques have been successfully applied to a wide range of information retrieval problems, including web search engines, recommendation systems, online advertising, among others. However, a need arises for researchers in the information retrieval community to understand the core machine learning techniques.", "key_idea": "The authors propose a tutorial divided into two sessions: one covering basic machine learning concepts and tools, and the other introducing more advanced topics in machine learning with recent developments in its application to information retrieval.", "method": "The tutorial covers two key aspects. The first session discusses core concepts in machine learning, optimization techniques, and their application to information retrieval problems including text classification etc. The second session covers advanced optimization techniques and emerging learning techniques. Both sessions are self-contained.", "outcome": "The aim of the tutorial is to benefit a wide audience in the information retrieval community, from students new to machine learning to seasoned researchers who want to understand recent advances.", "future_impact": "This tutorial can also potentially benefit practitioners who apply learning techniques to real-world information retrieval systems.", "venue": "SIGIR", "year": 2011, "title": "Machine learning for information retrieval"}
{"pid": "890810cc-04a7-4701-9e35-4f7d1819cc49", "context": "Various behavioural signals have been employed for implicit relevance feedback models in real-time information retrieval systems. However, these signals are often noisy and unreliable. Prior work has shown dwell time and task information to be effective in relevance judgement prediction, but task information is not always available.", "key_idea": "The paper proposes using affective and physiological signals in combination with dwell time as a reliable signal for relevance judgement prediction in a video retrieval system.", "method": "The study investigates the effectiveness of the affective and physiological signals both independently and in conjunction with behavioural signals for relevance judgement prediction across four different search intentions: seeking information, refinding information, and two different entertainment intentions.", "outcome": "Experimental results reveal that the effectiveness of the studied signals varies across different search intentions. Combining affective and physiological signals with dwell time indicates a significant improvement.", "future_impact": "These findings will aid in the creation of superior search engines in the future.", "venue": "SIGIR", "year": 2013, "title": "An effective implicit relevance feedback technique using affective, physiological and behavioural features"}
{"pid": "09067708-052a-4184-919a-7fb05d0d2fdf", "context": "The nature of web comments concerning their similarity in topic to the commented object is not established, which hinders their potential usage in cross-media retrieval tasks.", "key_idea": "The paper contends that web comments are of a descriptive nature, and posits that they could be used in place of the object they describe for various cross-media retrieval tasks.", "method": "Experiments were conducted to determine the similarity between web comments and the topics they comment on. Specifically, measures were taken to gauge the number of comments needed to expect a high similarity, and the number of comments required to replace the object in a ranking task.", "outcome": "Experiments revealed that 10 comments suffice to expect a high similarity between the comments and the commented text; 100-500 comments are enough to replace the text in a ranking task, and the contribution of commenters could be measured beyond the commented text.", "future_impact": "The findings could be applied in cross-media retrieval tasks, potentially using web comments in place of the respective online objects being commented on for various tasks.", "venue": "SIGIR", "year": 2009, "title": "Measuring the descriptiveness of web comments"}
{"pid": "5f0277e911dc830562231d8a", "context": "The key challenge of next-Point-of-Interest (POI) recommendation is learning users' sequential movements from sparse check-in data. Existing embedding methods learn representations of check-in data in the Euclidean space, their ability to learn complex patterns, especially hierarchical structures, is limited by the dimensionality of Euclidean space.", "key_idea": "The authors propose a new research direction that aims to learn the representations of check-in activities in a hyperbolic space. They introduce a novel hyperbolic metric embedding (HME) model for next-POI recommendation, which projects the check-in data into a hyperbolic space to capture hierarchical structures implied by the power-law distributions of user movements more effectively.", "method": "To evaluate the HME model, the authors conduct experiments on three check-in datasets and four online transaction datasets for next-item recommendation comparing with state-of-the-art next-POI recommendation algorithms.", "outcome": "The authors state that their hyperbolic embedding approach is superior to state-of-the-art next-POI recommendation algorithms.", "future_impact": "This research opened a new direction of using non-euclidean models for next-POI recommendation and their approach could potentially be generalized for next-item recommendation tasks.", "venue": "SIGIR", "year": 2020, "title": "HME: A Hyperbolic Metric Embedding Approach for Next-POI Recommendation"}
{"pid": "946cdbf7-13e7-4e24-8338-267c1d54cf3f", "context": "Existing text summarization methods often struggle to cover the entirety of a document's main content or to exclude redundant information.", "key_idea": "The authors propose two generic text summarization methods which rank and extract sentences from original documents. The first method uses standard IR methods for ranking, while the second uses latent semantic analysis for identifying semantically important sentences. Both methods aim at selecting sentences that are highly ranked and diverse, therefore covering a wider range of content with less redundancy.", "method": "Performance evaluations of the two summarization methods were conducted by comparing their output with the manual summaries created by three independent human evaluators. The evaluations also explored the impact of different Vector Space Model (VSM) weighting schemes on the performance of text summarization.", "outcome": "The findings of the evaluations and the effects of the VSM weighting schemes are not explicitly mentioned in the abstract.", "future_impact": "Furthermore, the authors investigate the causes of large disparities in the manual summarization results by involving the evaluators, which may yield insights into human text summarization patterns and influence future research in this field.", "venue": "SIGIR", "year": 2001, "title": "Generic text summarization using relevance measure and latent semantic analysis"}
{"pid": "c7554112-84d9-437a-a246-995065afba9d", "context": "Many existing tools used for information extraction and document annotation require extensive knowledge of the extraction process and involve a slow and time-consuming annotation process.", "key_idea": "Amilcare is an Adaptive Information Extraction tool designed to actively support the manual annotation of documents for the Semantic Web. Its key aspect is that it learns to reproduce user-inserted annotations and auto-fills new texts with preliminary annotations, easing the user's task.", "method": "To demonstrate the capabilities of Amilcare, a simulation of a small corpus annotation is performed where the tool's ability to support users in the annotation process, its proactivity and intrusivity is tested. Also, the correctness of suggestions provided by Amilcare, when the corpus size is increased, is evaluated.", "outcome": "Amilcare is found to effectively support users during the annotation process, contribute valuable suggestions, and offer easy control over its proactivity and intrusivity allowing user's to focus on validating the extracted information.", "future_impact": "Tools like MnM and Ontomat annotizer adopting Amilcare's learning strategy may change the landscape of information extraction and document annotation, making it considerably faster and more efficient.", "venue": "SIGIR", "year": 2002, "title": "Adaptive information extraction for document annotation in amilcare"}
{"pid": "b1f0b110-be2f-4a88-a72e-852fb890616f", "context": "There are many studies examining ambiguity in Information Retrieval, but a particular class of ambiguous words that is commonly used in queries has not been extensively explored.", "key_idea": "The authors highlight the lack of test collections carrying ambiguous queries and propose a method for creating these collections using existing resources.", "method": "They create a new collection using their method and conduct tests to evaluate the impact of query ambiguity on an Information Retrieval (IR) system.", "outcome": "The tests have shown that conventional IR systems cannot effectively handle queries with the prevalent type of ambiguity, and current assumptions about boosting search effectiveness do not work when such queries are employed.", "future_impact": "This finding challenges the assumptions about search effectiveness, which may inspire future research to improve ambiguity handling in Information Retrieval systems.", "venue": "SIGIR", "year": 2008, "title": "Ambiguous queries: test collections need more sense"}
{"pid": "6294359f5aee126c0f2fe2a2", "context": "Modern large-scale recommendation systems use Embedding & MLP as a paradigm, but this approach struggles with the item cold-start problem, compromising the ecological health of these systems.", "key_idea": "The authors propose a model-agnostic Conditional Variational Autoencoder (CVAR) based recommendation framework that generates enhanced warmed-up ID embeddings for cold items using historical data and limited interaction records. Their focus lies in: cold-start deployment in online recommendation scenarios without additional data requirements, leveraging both historical records and constantly emerging interaction data of new items, and modelling the relationship between item ID and side information stably from interaction data.", "method": "CVAR uses latent variables to learn a distribution over item side information and generates item ID embeddings using a conditional decoder. The proposed method is evaluated through offline experiments on public datasets and online A/B tests on the Tencent News recommendation platform.", "outcome": "The offline experiments on public datasets and online A/B tests on the Tencent News recommendation platform demonstrated the compatibility of CVAR on various backbones, the elimination of extra requirements for data, and the utilization of both historical and recent interaction data.", "future_impact": "The approach could improve the effectiveness and robustness of recommendation systems, especially in handling the item cold-start problem, which could make it a promising solution for real-world applications.", "venue": "SIGIR", "year": 2022, "title": "Improving Item Cold-start Recommendation via Model-agnostic Conditional Variational Autoencoder"}
{"pid": "0bb12c8f-4e86-4a0e-a548-0880bae6c343", "context": "Query suggestion is a valuable tool for helping users express their information demands by delivering alternative queries. Previous studies' effectiveness assessments of query suggestion algorithms have primarily concentrated on whether a suggested query is relevant to the input query.", "key_idea": "This paper introduces two new scenarios of query suggestion: one where the search result of the input query is unsatisfactory and the other where the search result is satisfactory but the user may be seeking alternative solutions. It then proposes two new assessment criteria based on these scenarios.", "method": "The authors test their proposed assessment criteria by implementing and labeling results based on their new criteria.", "outcome": "The labeling results indicate that the new evaluation criteria provide more detailed distinctions amongst query suggestions compared to the traditional criterion based on relevance.", "future_impact": "The new assessment criteria have potential to provide improved evaluation abilities for query suggestion algorithms, enabling better performance and user satisfaction.", "venue": "SIGIR", "year": 2012, "title": "New assessment criteria for query suggestion"}
{"pid": "47a2543a-a88a-4101-b212-3a9c40e37e81", "context": "Current collaborative filtering systems operate in a centralized manner which may lead to issues with scalability and efficiency.", "key_idea": "The authors propose a fully decentralized and self-organizing collaborative filtering technique that operates via an item-based buddy table system, which gets updated every time an item is downloaded.", "method": "The authors have compared their distributed collaborative filtering approach to the traditional centralized collaborative filtering system.", "outcome": "The decentralized collaborative filtering system demonstrated similar performance to the centralized approach, thus indicating its feasibility.", "future_impact": "Use of this methodology can facilitate recommendations in peer-to-peer networks thereby enhancing efficiency and scalability.", "venue": "SIGIR", "year": 2005, "title": "Self-organizing distributed collaborative filtering"}
{"pid": "62de891b5aee126c0f9938db", "context": "GNNs have shown superior performance in various applications and have been used for session-based recommendations. Due to the diverse types of potential information in sessions, existing GNN-based methods perform differently on different session datasets, leading to the need for efficient design of neural networks adapted to session recommendation scenarios.", "key_idea": "The authors propose AutoGSR, an automated neural architecture search framework specifically tailored for graph-based session recommendations. It is designed to find the optimal GNN-based session recommendation model.", "method": "The authors propose two novel GNN operations to build an expressive and compact search space in AutoGSR and employ a differentiable search algorithm to find the optimal graph neural architecture. They also propose a method to learn the item meta knowledge that guides the optimization of final session representations. AutoGSR is evaluated on three real-world datasets.", "outcome": "The experiments show that AutoGSR is able to find effective neural architectures and achieve state-of-the-art results on the tested datasets.", "future_impact": "As the first work to study the neural architecture search for session-based recommendation, it has the potential to be a foundational piece for future work in the area of session recommendation systems.", "venue": "SIGIR", "year": 2022, "title": "AutoGSR: Neural Architecture Search for Graph-based Session Recommendation"}
{"pid": "60b9a22ae4510cd7c8f764e3", "context": "Visual search has become popular, particularly in the domain of electronic commerce, allowing users to search for items to purchase by using an image from their mobile device or photo library.", "key_idea": "The study presents a comprehensive analysis of visual e-commerce search, focusing on the comparison between visual and textual search in terms of retrieved results and user interaction.", "method": "The authors perform a query log analysis of one of the largest e-commerce platforms' mobile search application, examining aspects like image query characteristics, refinement by attributes, and performance prediction for visual search queries.", "outcome": "The analysis reveals a variety of differences between visual and textual e-commerce search, especially regarding the retrieved results and user interaction.", "future_impact": "The implications of the differences found between visual and textual e-commerce search could influence the design of future e-commerce search systems.", "venue": "SIGIR", "year": 2021, "title": "An Image is Worth a Thousand Terms? Analysis of Visual E-Commerce Search"}
{"pid": "6a2dd00c-1d0c-41a7-9592-1c0e73f7bb81", "context": "Google entered the Chinese market late in 2005, facing challenges such as having no local employees, an inadequate product line, and small market share.", "key_idea": "Google China focused on building a local team, understanding local user needs, and applied its global innovation model to offer redesigned and improved products to Chinese users.", "method": "The company conducted user studies to understand local user needs and preferences. The key findings were used to improve their products, and innovation was encouraged via Google's global 20% project approach.", "outcome": "Google China made progress in Chinese search relevance, user experience, and key technology areas, leading to successful product innovations such as the weather map, the input method editor, and SMS greetings search.", "future_impact": "Google China's successful local adaptation has dispelled the myth that multinational Internet companies cannot succeed in China. It has demonstrated the importance of focusing on the customer, embracing the corporate culture, empowering local flexibility, and consistent innovation in achieving success.", "venue": "SIGIR", "year": 2008, "title": "Delighting Chinese users: the Google China experience"}
{"pid": "29045c98-3517-4ccd-b3e6-3bcc5aed0360", "context": "There was a need for a new type of information retrieval service in Beijing and other cities in China.", "key_idea": "This paper presented the conception and development of the Beijing Document Service (BDS), a new type of online information retrieval service system mainly for Beijing and other cities.", "method": "The system was designed with specific considerations and goals, and the steps towards achieving the goal of loading the NTIS Bibliographic Data Base into the BDS system and making its services publicly available online are recounted.", "outcome": "The BDS system was successfully developed and made available for public use. An appraisal of the system was conducted and issues experienced by BDS were identified.", "future_impact": "The identified problems and potential solutions could inform the development of future modernized information retrieval systems in China.", "venue": "SIGIR", "year": 1984, "title": "Development of the BDS online information retrieval system"}
{"pid": "5ee30ddd9e795e897aa956c8", "context": "Conversion Rate (CVR) prediction is integral to recommender systems in modern e-commerce. However, CVR prediction poses challenges due to Sample Selection Bias (SSB) and Data Sparsity (DS) issues. Existing methods built on the user sequential behavior path 'impression->click->purchase' address the SSB issue but struggle with DS due to scarce purchase training samples.", "key_idea": "The authors propose to enhance CVR prediction by decomposing post-click behavior. This involves inserting disjoint Deterministic Action (DAction) and Other Action (OAction) between click and purchase in parallel, thereby forming a unique user sequential behavior graph 'impression->click->D(O)Action->purchase'. This approach allows leveraging all impression samples across the entire space and an abundance of supervised signals from D(O)Action, effectively tackling both SSB and DS issues.", "method": "The authors devise a novel deep recommendation model named Elaborated Entire Space Supervised Multi-task Model (ESM2). This model employs multi-task learning, predicting decomposed sub-targets in parallel, and sequentially composes them to formulate the final CVR. The authors validate the proposed approach via experiments in both offline and online settings.", "outcome": "Extensive experiments demonstrate the superiority of the proposed ESM2 model over state-of-the-art models in both offline and online scenarios.", "future_impact": "The source code and dataset will be released, which could facilitate future research and development in CVR prediction and recommender system improvement.", "venue": "SIGIR", "year": 2020, "title": "Entire Space Multi-Task Modeling via Post-Click Behavior Decomposition for Conversion Rate Prediction"}
{"pid": "11b171d0-dcc8-4fc6-9402-d06db2635ff1", "context": "Although there has been considerable work on expertise retrieval, little attention has been paid to the evolution and dynamics of personal expertise over time.", "key_idea": "The authors propose a probabilistic model that characterizes how individuals change or retain their areas of expertise, taking into account three factors: the personality of the expert in exploring new areas, the similarity between the new area and the expert's current areas, and the popularity of the new area.", "method": "The factors are incorporated into a unified generative process, and a predictive language model is derived to estimate the distribution of an expert's words in future publications. The KL divergence is defined on this predictive language model to quantify and predict expertise changes. The model is tested using an academic publication dataset.", "outcome": "Initial results from experiments conducted on a testbed of academic publications indicate that the proposed approach is effective.", "future_impact": "This model could potentially be used to predict an expert's areas of research and interest in the future, although this impact is not explicitly stated.", "venue": "SIGIR", "year": 2014, "title": "Modeling the dynamics of personal expertise"}
{"pid": "673698f8-706f-4216-b86d-1236dc259ca3", "context": "Traditionally, Information Retrieval (IR) systems have been evaluated using simulation based on the Cranfield paradigm. However, these evaluations often ignore user interaction, which is crucial in all real-world searches.", "key_idea": "The authors propose that simulations can provide a way to evaluate interactive IR systems by making user interaction and interfaces explicit, whilst maintaining the advantages of the Cranfield Paradigm.", "method": "In the SimInt 2010 workshop, around 40 participants presented and discussed their views on the simulation of interaction in evaluating IR systems.", "outcome": "The general consensus and main conclusion drawn from the workshop is that simulation offers great potential for the field of IR because it can make explicit the user and the user interface while maintaining the Cranfield paradigm.", "future_impact": "Simulations of user interactions are expected to advance the methodology in the field of information retrieval by including the important aspect of user interaction in system evaluations.", "venue": "SIGIR", "year": 2011, "title": "Report on the SIGIR 2010 workshop on the simulation of interaction"}
{"pid": "b260f52e-4fe8-49d0-93a6-c988199bc613", "context": "Prior search result diversification work focuses on achieving topical variety in a ranked list, usually equally across all aspects. However, it does not consider sentiment diversification with bias towards a specific sentiment.", "key_idea": "The paper proposes diversifying search results with sentiments according to an explicit bias. It introduces three different ways to diversify results, namely equal diversification, diversification towards the Topic Sentiment, and diversification against the Topic Sentiment.", "method": "The sentiment of a controversial topic is first inferred and then this information is utilized in three different ways for sentiment diversification. The effects of different approaches are studied by gradually degrading the accuracy of a perfect sentiment classifier down to 40%.", "outcome": "The results reveal that the proportionality-based methods and the authors' SCSF model, which considers sentiment strength and frequency in the diversified list, yield the highest gains. If the Topic Sentiment cannot be reliably estimated, performance is affected by equal diversification, with an average of loss between 6.48% and 16.23% across all evaluation measures, depending on whether an emphasis either towards or against the Topic Sentiment is desired.", "future_impact": "The method proposed allows users to switch the result perspective to better grasp the polarity of opinionated content, such as during a literature review, thus having potential implications for improving user experience in search and information retrieval systems.", "venue": "SIGIR", "year": 2013, "title": "Sentiment diversification with different biases"}
{"pid": "a01401ae-a88b-4902-b4f8-0087c0f556d5", "context": "Internet search engines calculate a relevance score for webpages given the query terms, and rank these pages according to these scores. However, these relevance scores are not typically presented to the user.", "key_idea": "This study proposes that displaying the computed relevance scores to users can help them in making informed decisions.", "method": "The authors conducted a user study to evaluate the users' reaction to the display of relevance scores.", "outcome": "The results of the user study indicated that users understand graphical displays of relevance, and make decisions based on these scores.", "future_impact": "The study suggests that in the context of exploratory search, displaying relevance scores may encourage users to explore more search results.", "venue": "SIGIR", "year": 2013, "title": "Displaying relevance scores for search results"}
{"pid": "3d60aac4-05aa-4096-9218-cb9b0c9906d3", "context": "Securing information in indexed, random access files using privacy transformations presents unique challenges distinct from sequential files. Issues include processing overhead due to encrypting, threats to encipherment from updates, and the file structure itself.", "key_idea": "The paper proposes a general encipherment scheme for files maintained in a paged structure on secondary storage. The scheme is then applied to the encipherment of indexes organized as B-trees, a specific type of multiway search tree.", "method": "Threats to the encipherment of B-trees, especially related to updating, are examined and respective countermeasures are proposed. The effect of encipherment on file access and update, on paging mechanisms, and on files related to the enciphered index are also discussed.", "outcome": "The paper successfully proposes countermeasures for each identified threat to the encipherment of B-trees. It also discusses the effects of encipherment on various aspects of file maintenance.", "future_impact": "Many of the concepts presented here may be readily transferred to other forms of multiway index trees and to binary search trees, potentially influencing encryption methods for these data structures.", "venue": "SIGIR", "year": 1975, "title": "On the encipherment of search trees and random access files"}
{"pid": "a3078ddd-d0f6-4d8d-ac86-c2384b73ac87", "context": "Graph-ranking based algorithms like TextRank have been used for multi-document summarization, yet these algorithms miss the temporal dimension which is crucial when summarizing evolving topics.", "key_idea": "The authors propose the TimedTextRank algorithm that incorporates the temporal dimension into the document summarization process while operating on the basis of existing graph-ranking based algorithms.", "method": "The authors conduct a preliminary study to investigate the effectiveness of the proposed TimedTextRank algorithm for dynamic multi-document summarization.", "outcome": "The abstract does not provide specific outcomes, so this aspect is N/A", "future_impact": "The abstract does not provide information on anticipated future impacts, so this aspect is N/A", "venue": "SIGIR", "year": 2007, "title": "TimedTextRank: adding the temporal dimension to multi-document summarization"}
{"pid": "7b7fc004-9ff9-4485-b8be-695ae1d7c82d", "context": "High precision Information Retrieval (IR) is often challenging due to the large number of morphological variants for any given term. To address mismatches between different word forms used in queries and the relevant documents, existing research proposed the use of various stemming algorithms to reduce terms to a common base form.", "key_idea": "The paper proposes that stemming can assist in specific contexts and suggests an empirical investigation into the relationship between stemming performance and retrieval performance. The study extends previous work with a novel, dictionary-based perfect stemmer that can be parametrized for different accuracy and coverage levels.", "method": "The study conducts an empirical evaluation of the stemming accuracy for three stemming algorithms, including the widely used Porter algorithm, and discusses their use in IR. The researchers measure changes in IR performance corresponding to changes in stemming performance on a given dataset.", "outcome": "The authors present experimental evidence of their stemming algorithms' relative coverage and accuracy, and findings from the usage of these stemmers for IR.\n", "future_impact": "The study's results could open the door to future research on improving stemming and IR algorithms, and their interconnection, especially in specific contexts where stemming may be beneficial.", "venue": "SIGIR", "year": 2000, "title": "Stemming and its effects on TFIDF ranking."}
{"pid": "60a7959191e011f90a51de12", "context": "Reinforcement learning (RL) is widely used to learn conversational recommendation policies that decide what attributes to ask, which items to recommend, and when to ask or recommend. However, existing methods typically aim to solve only one or two of these decision-making problems and have separate conversation and recommendation components. This approach restricts the scalability and generality of conversational recommender systems (CRS) and does not preserve a stable training procedure.", "key_idea": "The authors propose a unified policy learning task that combines the three decision-making problems in CRS. They develop a dynamic weighted graph-based RL method to systematically integrate conversation and recommendation components and select the action at each conversation turn.", "method": "The authors propose two action selection strategies to deal with the sample efficiency issue by reducing the candidate action space based on preference and entropy information. The proposed method is validated through experiments on two benchmark CRS datasets and a real-world E-Commerce application.", "outcome": "The experimental results demonstrate that the proposed method not only significantly outperforms existing methods but also enhances the scalability and stability of CRS.", "future_impact": "The paper suggests a scalable, unified policy learning task for Conversational Recommender Systems that could provide a basis for future studies on enhancing Conversational Recommender Systems' stability and scalability.", "venue": "SIGIR", "year": 2021, "title": "Unified Conversational Recommendation Policy Learning via Graph-based Reinforcement Learning"}
{"pid": "f6ba95a4-c660-4252-899b-914f67c8c1ac", "context": "Open source tools and techniques are fundamental to the advancement of information retrieval community, but there's a need for organized discussion and sharing of ideas amongst researchers and practitioners of the field.", "key_idea": "The SIGIR 2012 Workshop was organized as a platform for researchers in academia and experts from the industry to discuss open source tools in information retrieval, with invited talks, paper presentations, and demonstrations.", "method": "The workshop involved 2 invited talks, one from industry and one from academia, 6 full papers and 6 short papers presentations, as well as demonstrations of 4 open source tools. A discussion on future directions was also part of the workshop.", "outcome": "The workshop was successfully organized with various events including invited talks, paper presentations, and demonstrations of open source tools in information retrieval.", "future_impact": "The workshop has outlined future directions for the open source information retrieval community, which are expected to guide further advancements and collaborations in the field.", "venue": "SIGIR", "year": 2012, "title": "Open source information retrieval: a report on the SIGIR 2012 workshop"}
{"pid": "866db906-bc7a-4b8e-8e09-2d1168be2175", "context": "Web search engines face challenges such as a rapidly increasing amount of information, high query loads, and tight performance constraints, with speed and accuracy being key determinants of user satisfaction. Within this framework, multiple problems arise within partitioned query processing, pruning, and caching.", "key_idea": "The thesis discusses query processing efficiency and proposes several novel techniques: a hybrid approach combining pipelined and traditional query processing, a document-at-a-time processing of sub-queries, skipping extensions to pipelined query processing, a efficient self-skipping inverted index, and optimizations related to caching in Web search engines.", "method": "The thesis tests the proposed techniques through simulations using real-world text collections and query logs, as well as real implementation.", "outcome": "Most of the proposed techniques are found to improve the state-of-the-art in the conducted empirical studies.", "future_impact": "While the proposed improvements show promise in research settings, their applicability in practice requires further evaluation in real-life settings.", "venue": "SIGIR", "year": 2013, "title": "Efficient query processing in distributed search engines"}
{"pid": "dee3e5d0-fe0e-44b3-9fe5-f3e4acaceb0d", "context": "Search engine logfiles are currently used to determine the relevance relationship between URLs and query terms, but there has been no exploration into using associated queries as metadata.", "key_idea": "The authors propose using queries associated with a URL as useful URL metadata, potentially assisting in determining a URL's semantic category.", "method": "The authors validated their hypothesis by conducting a classification experiment using the DMOZ dataset.", "outcome": "The authors found that their method can annotate URLs even if they have no associated queries.", "future_impact": "The authors' method could change URL metadata collection processes to include more semantic categorization information by implementing associated queries as metadata.", "venue": "SIGIR", "year": 2009, "title": "Annotation of URLs: more than the sum of parts"}
{"pid": "5ea9503e91e0118eb1e19ea9", "context": "Question answering (QA) over text passages is a longstanding problem in information retrieval. Specifically, the conversational setting, where a user asks a sequence of questions revolving around a topic, presents the issue of understanding context implicitly left by the user in follow-up questions.", "key_idea": "The authors introduce CROWN, an unsupervised system for conversational QA with passage responses, that supports context propagation over multiple turns by building a word proximity network (WPN) from extensive corpora to store significant term co-occurrences.", "method": "The passages are ranked by a combination of their similarity to the question, and coherence of query terms within. These factors are measured by reading off node and edge weights from the WPN. The system was evaluated using TREC CAsT data.", "outcome": "CROWN achieves above-median performance in a pool of neural methods on TREC CAsT data.", "future_impact": "CROWN provides an interface that is both intuitive for end-users, and can provide insights for experts to reconfigure it according to individual setups, suggesting its potential application in real-world scenarios.", "venue": "SIGIR", "year": 2020, "title": "Conversational Question Answering over Passages by Leveraging Word  Proximity Networks"}
{"pid": "60b9a484e4510cd7c8fbbc3d", "context": "Existing chat services often provide a way to search through previously sent messages, but many of these services have limited search functionalities, typically supporting only exact matching on individual messages.", "key_idea": "The authors introduce a new task, called searching for conversations, which aims to retrieve and rank groups of related chat messages given a search query, and promote this task by providing a platform called PECAN for research and development.", "method": "The authors provide a platform, PECAN, which gives researchers the tools they need to conduct experiments on searching for conversations. The system is designed to be generic, supporting organizations and individuals who wish to search their chat message archives.", "outcome": "The authors have released PECAN as an Open Source project available for download.", "future_impact": "PECAN is expected to assist researchers in future experiments on conversation search tasks, and help organizations and individuals in improving their chat message search capabilities.", "venue": "SIGIR", "year": 2021, "title": "PECAN: A Platform for Searching Chat Conversations"}
{"pid": "ffbdb568-1654-42e0-94a7-8de3c8b95893", "context": "The problem of linking information between different idiomatic usages of the same language, such as colloquial and formal language, has not been adequately addressed in the existing literature.", "key_idea": "The authors propose a novel probabilistic topic model called multi-idiomatic LDA (MiLDA) which is based on the intuitive assumption that certain words are shared between two idioms of the same language, while other words are non-shared, i.e., idiomatic specific.", "method": "The authors apply the proposed model to a dataset containing product descriptions and reviews and evaluate it using the perplexity measure. Moreover, they also use the model in a recently proposed IR task of linking Pinterest pins (colloquial English) to online webshops (formal English).", "outcome": "The multi-idiomatic model outperforms both the standard monolingual LDA model and the pure bilingual LDA model in terms of perplexity and MAP scores in the IR task.", "future_impact": "The MiLDA model could enable more effective linking and searching of e-commerce data across different levels of formality in language, leading to improved e-commerce user experiences.", "venue": "SIGIR", "year": 2014, "title": "Learning to bridge colloquial and formal language applied to linking and search of E-Commerce data"}
{"pid": "5f0277e911dc830562231e26", "context": "In cross-lingual text classification, it is common to use labeled data from one language to train a model that is then applied to a different language. However this approach can neglect subtle language differences.", "key_idea": "The authors propose a semi-supervised adversarial training process that minimizes the maximal loss for label-preserving input perturbations, and uses the resultant model as a teacher to induce labels for unlabeled target language samples for further adversarial training and model adaptation to the target language.", "method": "The proposed adversarial training process is compared against a number of strong baselines in document and intent classification tasks across a diverse set of languages.", "outcome": "The adversarial training process yields significant effectiveness gains in document and intent classification across a diverse set of languages compared to the baselines.", "future_impact": "This adversarial training process potentially paves way for improved cross-lingual text classification power, taking into consideration subtle differences in languages.", "venue": "SIGIR", "year": 2020, "title": "Leveraging Adversarial Training in Self-Learning for Cross-Lingual Text Classification"}
{"pid": "7c59e61c-ae14-4d0f-87e7-dba1269420fc", "context": "In commercial search engines, ranking functions are selected for deployment mainly by comparing the relevance measurements over candidates. This can lead to relevance degradation over time due to changes.", "key_idea": "The paper suggests selecting Web ranking functions based on both their relevance and robustness to changes that may affect their performance over time. It proposes that ranking robustness can be effectively measured by considering the ranking score distribution across Web pages.", "method": "The authors improve Normalized Discounted Cumulative Gain (NDCG) with two new metrics to measure their proposed criteria of ranking function selection.", "outcome": "The suggested two new metrics display superiority in terms of stability to ranking score turbulence and stability in function selection.", "future_impact": "Selection of Web ranking functions with the proposed approach of considering both relevance and robustness can improve the performance and longevity of search engine ranking functions.", "venue": "SIGIR", "year": 2009, "title": "Comparing both relevance and robustness in selection of web ranking functions"}
{"pid": "94d794ad-b998-4c26-8b9f-ae049e94e3bf", "context": "The understanding that in natural language text, knowledge of a short substring can be used to guess the next character, and that this technique can be applied to predictive text compression.", "key_idea": "This paper presents a family of predictive text compression methods that utilize a hash table to store prediction information.", "method": "Experiments were carried out to evaluate the proposed methods in terms of compression gains and speed.", "outcome": "Results from the experiments show that the proposed methods produce good compression gains and are very fast, with the one-pass versions being especially apt for 'on-the-fly' compression of transmitted data.", "future_impact": "The one-pass versions of the proposed methods could serve as a foundation for developing specialized hardware.", "venue": "SIGIR", "year": 1987, "title": "Predictive test compression by hashing"}
{"pid": "19b8065a-824d-48d6-805a-382f42a2691d", "context": "The field of information retrieval is aware of the relevance of artificial intelligence, but there remain untapped applications.", "key_idea": "This paper explores ways in which artificial intelligence can influence information retrieval, examining one particular application in detail.", "method": "The authors detail and analyze a specific application of artificial intelligence within the realm of information retrieval to uncover the technical difficulties involved in its successful utilization.", "outcome": "Findings indicate that while the potential of AI is bright, the complete fulfillment of its promise is still far in the future due to complexities and subtle aspects of intelligent behavior, contradicting naivety and over-optimism in previous research.", "future_impact": "The paper suggests that addressing these technical challenges and continuing to explore the application of AI in information retrieval will require more basic research and may lead to eventual solutions for more difficult problems.", "venue": "SIGIR", "year": 1983, "title": "Artificial intelligence implications for information retrieval"}
{"pid": "31b6b7f7-52d3-435c-b20c-50e02f3fd6d9", "context": "Current multidimensional models of relevance suffers from methodological limitations preventing empirical testing of model fit to observed data, which calls into question their validity. A psychometric framework for multidimensional relevance modelling was proposed by Xu and Chen [77], but it has shown several limitations.", "key_idea": "The authors aim to overcome the limitations of the existing psychometric framework for multidimensional relevance modelling by revising the methodology and incorporating elements like crowdsourcing and quality control methods from psychometrics.", "method": "The authors propose to scale the original psychometric framework via crowdsourcing and incorporate quality control methods from psychometrics.", "outcome": "Not explicitly mentioned in the abstract.", "future_impact": "It is anticipated that the improved methodology for relevance judging will benefit both human-centered and systems-centered Information Retrieval (IR).", "venue": "SIGIR", "year": 2014, "title": "Multidimensional relevance modeling via psychometrics and crowdsourcing"}
{"pid": "fe9c63ea-c31a-4300-8948-14104a140c21", "context": "The empirical investigation of information retrieval (IR) systems requires a collection of various elements including a set of relevance judgments made by human assessors for each query. Previous experiments show that differences in human relevance assessments do not affect the relative performance of IR systems.", "key_idea": "The authors propose a new approach to replace human relevance judgments with an automatic method. This proposal is made based on the observation that differences in human relevance assessments do not affect the relative performance of retrieval systems.", "method": "The new approach is evaluated by correlating the ranking of retrieval systems with human-based evaluations. The study uses an assumption of a Web-like imperfect environment where all documents' indexing information is available for ranking, but some documents may not be available for retrieval due to document deletions or network problems.", "outcome": "The proposed methodology resulted in positive and significant correlations with human-based evaluations of IR system rankings.", "future_impact": "The proposed method can be used for Web search engine assessment and in estimating the effects of network conditions, such as network unreliability, on IR system performance.", "venue": "SIGIR", "year": 2003, "title": "Automatic ranking of retrieval systems in imperfect environments"}
{"pid": "e5d3dc86-2f76-4cde-bf32-97001b82507c", "context": "In an information retrieval system, the index can be split into multiple shards and replicated across query servers to improve efficiency. Typically, the replica with the least queued queries is chosen for each new query. However, this presents the problem of inaccurate workload representation, as the queue length doesn't consider differing execution times for different types of queries.", "key_idea": "This paper proposes the use of query efficiency prediction to measure the expected workload of a replica, as a way to improve the selection of replicas.", "method": "Experiments are conducted using 2.2k queries, over various numbers of shards and replicas for the large GOV2 collection.", "outcome": "The results show that the proposed approach can significantly reduce query waiting and completion times, and improve scheduling accuracy.", "future_impact": "This work suggests that the accurate prediction of response times could further enhance the efficiency of scheduling algorithms in information retrieval systems.", "venue": "SIGIR", "year": 2012, "title": "Scheduling queries across replicas"}
{"pid": "5f0277e911dc830562231e6a", "context": "In professional search tasks like precision medicine literature search, queries often involve multiple aspects and to assess the relevance of a document, a searcher validates each aspect in the query and follows a task-specific logic to make a relevance decision. Hence, the relevance judgment is structured and not univariate. However, current search engines may not support this kind of workflow.", "key_idea": "The authors propose novel retrieval models that emulate how medical experts make structured relevance judgments using structured relevance judgment data.", "method": "The authors utilized structured relevance judgment data from the TREC Precision Medicine track to design their retrieval models.", "outcome": "Experiments showed that these simple, explainable models can outperform complex, black-box learning-to-rank models.", "future_impact": "This approach of building retrieval models opens up opportunities for the model to explain its decision in the same 'lingo' as the searcher, meaning that it could greatly enhance research methods in domains where structured relevance judgments are important.", "venue": "SIGIR", "year": 2020, "title": "Towards Explainable Retrieval Models for Precision Medicine Literature Search"}
{"pid": "14d688d0-bfa3-4932-b198-aa6273eb669f", "context": "Web users present queries that only partially describe their complex information needs due to the imbalance in the richness of information on the web and the succinctness and poverty of search requests.", "key_idea": "The authors propose to leverage contextual information to make search experiences context-aware, aiming for a drastic improvement in user's searching and browsing behavior on the web.", "method": "The authors conducted a series of studies to discover, model, and utilize contextual information in order to understand and improve users' searching and browsing behavior.", "outcome": "The studies have led to results that capture important aspects of context under the realistic conditions of different online search services.", "future_impact": "The findings have the potential to transfer to the operational settings of real-world applications, enhancing the effectiveness of web search services.", "venue": "SIGIR", "year": 2015, "title": "Using Contextual Information to Understand Searching and Browsing Behavior"}
{"pid": "1942e886-72fc-42e5-8735-ccae697b08c7", "context": "The predecessor of Microsoft Academic Service (MAS) is based on publisher feeds for populating the entity graph, which consists of field of study, author, institution, paper, venue, and event.", "key_idea": "The new MAS version includes not only data from publisher feeds, but also data mining results from the Web index and an in-house knowledge base from Bing, a commercial search engine, resulting in a significant increase in size and richness of the entity graph.", "method": "The authors validate and enrich the entities within and beyond the academic domain in the MAS graph by integrating Bing's knowledge base. They also demonstrate two scenarios: a knowledge-driven, interactive dialog that combines search and proactive suggestion, and a proactive heterogeneous entity recommendation.", "outcome": "The number of papers indexed by MAS grew from tens of millions to 83 million while maintaining an accuracy above 95% based on test data sets derived from Microsoft Research's academic activities.", "future_impact": "MAS allows for a variety of applications in the academic research field, including a knowledge-driven, highly interactive dialog that combines search with proactive suggestions and proactive heterogeneous entity recommendation.", "venue": "WWW", "year": 2015, "title": "An Overview of Microsoft Academic Service (MAS) and Applications"}
{"pid": "4d2610ee-1154-435e-9313-bc55e830cd82", "context": "Currently, there is a need for automatically identifying bursty events from multiple text streams, particularly during natural or economic disasters.", "key_idea": "The authors propose an approach that investigates the characteristics of bursty terms that appear in the documents generated from text streams and incorporates those characteristics into a term weighting scheme that distinguishes bursty terms from other non-bursty terms.", "method": "The effectiveness of the proposed approach is evaluated based on a news corpus.", "outcome": "The proposed approach outperforms the existing alternatives in extracting bursty terms from multiple text streams, as shown by experimental results.", "future_impact": "The proposed research is expected to contribute to increasing the situational awareness of ongoing events especially when a natural or economic disaster occurs.", "venue": "WWW", "year": 2012, "title": "Bursty event detection from text streams for disaster management"}
{"pid": "5e9ef9b69fced0a24b1b6634", "context": "For e-commerce companies, identifying a family of product variants is crucial for customer experiences and brand image. Current approaches, such as using basic classification models, fall short in dealing with unstructured product information and delivering satisfactory results.", "key_idea": "This study introduces a new method for identifying product variants that combines constrained clustering and tailored Natural Language Processing techniques. The method is designed to meet business criteria, including high accuracy demands across a wide range of categories and the interpretability to make it comprehensible to all business partners.", "method": "The novelty of the method resides in using constrained clustering and tailored NLP techniques to process unstructured product title and identify similar model numbers.", "outcome": "This new method provides superior performance in comparison to the existing baseline which uses a vanilla classification approach.", "future_impact": "This new method for identifying product variants could be crucial for improving customer experiences and cultivating the authoritative brand image of e-commerce companies. It meets high accuracy requirements across a wide range of categories and prioritizes interpretability of the model, making it accessible and understandable to all business partners.", "venue": "WWW", "year": 2020, "title": "Interpretable Methods for Identifying Product Variants"}
{"pid": "6e48c652-800e-4ecd-83f9-66ea18ec61fd", "context": "Finding specific information on the World-Wide Web (WWW) is becoming increasingly difficult due to the rapid growth of the Web and the diversity of the information offered. Hypertext systems often provide simple searching tools that mostly ignore the 'hyper-structure' formed by the links. Current searching tools in the WWW are divided into gateways and client-based search tools.", "key_idea": "The paper presents the 'fish-search' algorithm, a client-based search tool with an open-ended selection of search criteria, implemented on top of Mosaic for X.", "method": "The authors explore the usage of the 'fish-search' algorithm to locate data in the Web, and the implementation of a client-based tool on top of Mosaic for X. The algorithm's impact on network speed and resource consumption and its improvement with the combination of a cache is also assessed.", "outcome": "The study shows the performance of the 'fish-search' algorithm and how it could be supplemented by a cache called 'Lagoon' to address its challenges of slow speed and high network resource consumption.", "future_impact": "The paper suggests potential for further optimization by distributing the calculation of a search request's answer among caching servers, reducing network traffic.", "venue": "WWW", "year": 1994, "title": "Information retrieval in the World-Wide Web: making client-based searching feasible"}
{"pid": "60641ca19e795e72406b65f1", "context": "Multivariate Hawkes Processes (MHPs) have been critical in understanding and predicting social information systems; though due to their complex modeling of temporal dependencies, they've proven hard to scale, limiting their applications to fairly small domains.", "key_idea": "The authors propose a new model and computational approach that overcomes scalability limitations of Multivariate Hawkes Processes (MHPs) by exploiting a characteristic sparsity pattern found in real-world diffusion processes.", "method": "The authors validate their approach using synthetic and real-world datasets, calculating the exact likelihood and gradients of an MHP, regardless of the ambient dimensions of the underlying network.", "outcome": "The proposed approach not only achieves state-of-the-art modeling results, but also improves runtime performance by multiple orders of magnitude on sparse event sequences.", "future_impact": "With easily interpretable latent variables and influence structures, the proposed model will allow researchers to analyse diffusion processes in networks at a scale previously unachievable.", "venue": "WWW", "year": 2021, "title": "Modeling Sparse Information Diffusion at Scale via Lazy Multivariate Hawkes Processes"}
{"pid": "5e9ef9b69fced0a24b1b660c", "context": "Web sites disseminating fake news are increasingly problematic and while the issue of identifying whether a web page contains fake news has been tackled, the discovery of new sources of fake news has largely been unexplored.", "key_idea": "The authors propose an automatic discovery system that proactively discovers fake news domains before they are flagged by humans. The system uses Twitter feeds to uncover user co-sharing structures to discover political websites and then uses a topic-agnostic classifier to score and rank newly discovered domains.", "method": "The authors conduct an experimental evaluation of their system by collecting tweets related to the 2020 presidential impeachment process in the United States.", "outcome": "The experimental evaluation shows that the system can effectively discover new fake news sites, and a large percentage of these discovered sites are indeed publishing fake news.", "future_impact": "The authors mention that their proactive discovery system could expedite the fact-checking process and be a valuable tool in the fight against misinformation.", "venue": "WWW", "year": 2020, "title": "Proactive Discovery of Fake News Domains from Real-Time Social Media Feeds"}
{"pid": "ec55ab08-50ae-437a-b228-8289b3e292e2", "context": "Providing diverse groups of people access to a collection of sites, containing disparate information provided by a decentralized organization can be challenging.", "key_idea": "The authors suggest the concept of a 'home site', an evolution from a traditional home page, designed to facilitate user access to a diverse collection of resources.", "method": "The authors present their experience and process in developing a home site for The Australian National University (ANU) to simplify resource discovery.", "outcome": "The authors successfully developed a 'home site' for the Australian National University, making resource discovery simpler for readers.", "future_impact": "The 'home site' design ideology explored in this paper could impact how organizations facilitate access to diverse and decentralized information resources in the future.", "venue": "WWW", "year": 1998, "title": "From home page to home site: effective Web resource discovery at the ANU"}
{"pid": "99adaee3-97ba-4ecf-a92b-4959478db9eb", "context": "The task of generating coherent multilingual natural language descriptions about museum objects from Semantic Web Ontologies presents a unique case study opportunity.", "key_idea": "The researchers are creating an ontology-based multilingual application for museum information using a Reason-able View of the Web of linked data applied to the realm of cultural heritage.", "method": "An experimental web application was developed utilizing Semantic Web Ontologies for generating coherent multilingual natural language descriptions about museum objects, with data derived from actual museums.", "outcome": "Initial experimental results suggest that the approach effectively performs well for the languages examined.", "future_impact": "The success of this approach could have significant implications for the development of similar applications in other industries or areas requiring multilingual natural language descriptions.", "venue": "WWW", "year": 2012, "title": "Multilingual online generation from semantic web ontologies"}
{"pid": "e6a80260-8631-42dd-86cd-972095a1e8b5", "context": "A number of websites use friend-finding features to bootstrap social networks on their platforms by copying connections from established networks like Facebook or Twitter. However, the extent to which this practice, known as social bootstrapping, effectively enhances a user's social experience on these websites is not clearly understood.", "key_idea": "The researchers developed a stylised analytical model that investigates how successfully 'borrowing' connections from an established platform can facilitate the growth of a connected community in a new platform while preserving certain properties such as reciprocity and clustering.", "method": "Using data from Pinterest and Last.fm, they compared the subgraph of links copied from Facebook to those created natively on these platforms, while also exploring changes in these networks as users become more active and influential.", "outcome": "The researchers found that the subgraph of copied links had a giant component, higher reciprocity and clustering, and saw higher social interactions compared to native connections. Additionally, they observed that the need for copying connections declined as users became more active and influential, as these users began to create more native links with users more similar to them than their Facebook friends.", "future_impact": "The findings provide insights into how bootstrapping from established social networks can help engage new users by enhancing social interactivity on a new site.", "venue": "WWW", "year": 2014, "title": "Social bootstrapping: how pinterest and last.fm social communities benefit by borrowing links from facebook"}
{"pid": "6274c7875aee126c0f7071e1", "context": "Machine learning is becoming vital for many web applications, and edge computing is becoming an essential part of 5G networks. In particular, edge artificial intelligence (AI) performs machine learning model training and inference at the network edge on edge servers. Although edge AI enables low-latency machine learning inference, which is critical for delay-sensitive applications, previous work has not fully explored its unique ability to process data with context-awareness.", "key_idea": "The authors propose a novel framework called Pyramid that leverages edge AI to facilitate both homogeneous and heterogeneous hierarchical machine learning inferences, enabling enhanced context-awareness.", "method": "Pyramid's proof of concept is demonstrated via a traffic prediction use case. The proposed framework's performance is evaluated through numerous experiments conducted on two real-world datasets.", "outcome": "The results show that Pyramid neural networks outperform in the realm of hierarchical traffic prediction and weather analysis, signifying the efficient role of edge AI.", "future_impact": "The novel use of edge AI for context-aware processing as shown in Pyramid could be highly beneficial for the Web-of-Things (WoT) initiative and contribute to the advancement of smart city applications.", "venue": "WWW", "year": 2022, "title": "Pyramid: Enabling Hierarchical Neural Networks with Edge Computing"}
{"pid": "62620f1d5aee126c0f686dcd", "context": "Current research largely assumes that a user's engagement with internet content (such as retweeting, liking, or sharing) is driven primarily by factors like the content itself, publication date, user's network position, and platform used, giving limited attention to the role of information interaction - the idea that a user's choice is partly influenced by their prior exposure to other information.", "key_idea": "The authors highlight the need for close examination of information interaction in understanding user engagement with online content, and propose a dedicated interaction model built on a new approach that they believe is well-suited to addressing the complexities of studying these interactions.", "method": "The authors draw on literature reviews to underscore the complexities inherent in studying information interactions, and they briefly detail their own approach to creating a dedicated interaction model.", "outcome": "The work demonstrates that their new approach and interaction model offer superior fit to the problem compared to existing methods.", "future_impact": "The authors anticipate that acknowledging and incorporating interactions into information spread studies can enrich our understanding of information interaction processes in real-world datasets and should not be neglected in the modeling of spreading processes, indicating a promising direction for future research.", "venue": "WWW", "year": 2022, "title": "Interactions in Information Spread"}
{"pid": "61e8d3175244ab9dcb58414c", "context": "Unsupervised graph representation learning, particularly graph contrastive learning, has garnered attention for its promising performance in various tasks. However, current methods largely focus on augmenting or perturbing graph structures to generate contrasting pairs, but this can introduce noise and limit the application scope of graph contrastive learning.", "key_idea": "The authors propose a novel graph contrastive learning method called Dual Space Graph Contrastive (DSGC) Learning, which conducts graph contrastive learning among views generated in different spaces - the hyperbolic space and the Euclidean space.", "method": "The authors carried out comparative experiments to evaluate DSGC's performance across various datasets and conducted extensive experiments to analyze the impact of different graph encoders on DSGC.", "outcome": "The experimental results demonstrate that DSGC achieves competitive or better performance compared to existing methods across all evaluated datasets.", "future_impact": "The analysis of how different graph encoders impact DSGC provides insights into how to better leverage the advantages of contrastive learning between different spaces, which could guide future enhancements and applications of graph contrastive learning.", "venue": "WWW", "year": 2022, "title": "Dual Space Graph Contrastive Learning"}
{"pid": "de125d41-a608-4763-a8dd-48019025ab59", "context": "Social media websites promote diverse user interaction on media objects as well as user actions with respect to other users. Extracting community structure in these networks is important, especially for the enterprise domain, where it can inform new team formations, discovery of expertise, and organizational restructuring.", "key_idea": "The authors propose a three-fold approach to extract community structures in social networks: a relational hypergraph model to model various social contexts and interactions; a novel hypergraph factorization method for community extraction; and an on-line method for handling temporal evolution through incremental hypergraph factorization.", "method": "The authors conducted extensive experiments on real-world enterprise data, and evaluated the quality of their mining results by using their method to predict users' future interests", "outcome": "The findings suggest that the proposed technique is scalable and can extract meaningful communities. In addition, the method's predictions of users' future interests outperformed baseline methods (frequency counts, pLSA) by 36-250% on average.", "future_impact": "The ability to extract community structures in social networks could aid in forming collaborative teams, facilitate expertise discovery, and guide enterprise reorganization.", "venue": "WWW", "year": 2009, "title": "Extracting community structure through relational hypergraphs"}
{"pid": "9f535543-49f1-4fbf-ab11-cdd9b0a4f994", "context": "Distributed database and other distributed data processing systems like Pregel and GraphLab divide large datasets using data partitioning technology. By default, these systems use hash partitioning to randomly assign data to partitions, resulting in significant network traffic between partitions.", "key_idea": "The paper introduces Lute, a novel prototype system that provides an efficient fine-grained partitioning scheme for distributed systems, which minimizes the number of nodes involved within a transaction or job while balancing the workload across data nodes.", "method": "A prototype distributed Database Management System (DBMS) was implemented on Postgresql using Lute as a middleware to provide fine-grained partitioning support. Extensive experiments, including the TPC-C benchmark, were conducted to assess the effectiveness of this approach.", "outcome": "The results of the evaluation show that compared to other state-of-the-art lookup table solutions, the proposed approach can significantly improve throughput by about 20% to 70% on the TPC-C benchmark.", "future_impact": "The study presents a novel fine-grained partitioning system, Lute, that could potentially improve the efficiency of distributed data processing systems by better managing and balancing data nodes.", "venue": "WWW", "year": 2014, "title": "Fine-grained data partitioning framework for distributed database systems"}
{"pid": "c81073ca-5025-44a9-8cd7-451142a2add1", "context": "While schools in the developing world are increasingly gaining access to computers and the internet, their full utilization is hindered by intermittent connectivity and limited bandwidth.", "key_idea": "The authors make two contributions to this problem: First, they characterize six weeks of HTTP traffic from a primary school in India to understand performance issues and improvement opportunities. Second, they develop an aggressive caching and prefetching engine to accelerate users' overall browsing experience, excluding video content.", "method": "The authors collected and analysed six weeks' worth of HTTP traffic data from a primary school in Bangalore, India. They then developed and deployed an aggressive caching and prefetching engine, testing its performance in this school setting.", "outcome": "The aggressive caching and prefetching engine accelerated the users' overall browsing experience (excluding video content) by 2.8x. It leverages innovative techniques, including serving stale pages, cached page highlighting, and client-side prefetching.", "future_impact": "The solution - provided as an open-source Firefox plugin that runs directly on client machines - can provide easy installation and configuration for end-users in developing regions where lack of permissions or technical expertise often prevents modification of internal network settings.", "venue": "WWW", "year": 2011, "title": "Analyzing and accelerating web access in a school in peri-urban India"}
{"pid": "60c093fc91e0116059b15a36", "context": "In the context of social media interactions during the 2020 U.S. Presidential Election, understanding online sentiment for political candidates was a relevant issue but often diverged from traditional poll results.", "key_idea": "The study uses Multi-Layer Perceptron classifier for conducting tweet sentiment analysis of the 2020 U.S. Presidential Election, with the goal of evaluating political opinions in a low-cost, easy alternative way to traditional polling methods.", "method": "The authors collected over 260,000 tweets related to the 2020 U.S. Presidential Election via Twitter API, performed feature extraction on this data, and applied the Multi-Layer Perceptron classifier to classify these tweets with either a positive or negative sentiment.", "outcome": "Based on the tweet sentiment analysis, it is concluded that the negativity to positivity ratio for the candidates was very close, contrary to popular poll results. Negative sentiments were found to be more common and prominent within social media. Some key events can be detected through trending sentiment on social media.", "future_impact": "The findings suggest that sentiment analysis can serve as a low-cost and easier alternative to gather political opinion, indicating a potential for widespread application in future political and social studies.", "venue": "WWW", "year": 2021, "title": "Tweet Sentiment Analysis of the 2020 U.S. Presidential Election"}
{"pid": "6274c5785aee126c0f6f402b", "context": "Current ranking algorithms in recommender systems, which aim to maximize user utility by capturing preferences over items, tend to cause fairness issues on online platforms. Previous approaches to fairness have not properly considered the lack of negative feedback in implicit feedback data.", "key_idea": "FairGAN is a proposed Generative Adversarial Networks (GANs) based learning algorithm that addresses the exposure fairness issue by mapping it to the problem of negative preferences in implicit feedback data. It uses a novel fairness-aware learning strategy to dynamically generate fairness signals.", "method": "FairGAN optimizes the search direction to find the optimal rankings that can fairly allocate exposure to individual items, whilst preserving users\u2019 utilities.", "outcome": "The abstract does not provide specific outcomes or results for the approach proposed.", "future_impact": "By helping to balance fairness and utility in recommender systems, FairGAN may lead to more equitable online platforms.", "venue": "WWW", "year": 2022, "title": "FairGAN: GANs-based Fairness-aware Learning for Recommendations with Implicit Feedback"}
{"pid": "88599849-64ef-48d4-9479-abafdddabca1", "context": "With emerging technologies for 3D graphics generation, such as VRML (the Virtual Reality Modeling Language), now coming to the consumer market, new challenges in the area of databases visualization within a 3D environment are initiated.", "key_idea": "The authors introduce a prototype that generates on-the-fly 3D VRML virtual worlds depending on the retrieved information, applicable across interactive education courses to virtual shops for Electronic Commerce.", "method": "The authors discuss their component-based model in terms of flexibility, re-use, and performance, though specific experiments or proofs to validate this model are not mentioned in the abstract.", "outcome": "The prototype successfully generates on-the-fly 3D VRML virtual worlds based on the retrieved information. However, specific measurements or benchmarks are not provided in the abstract.", "future_impact": "The authors anticipate that this approach will be of benefit in numerous applications, ranging from interactive education courses to virtual shops for Electronic Commerce.", "venue": "WWW", "year": 1998, "title": "3D visualization of multimedia content on the World Wide Web"}
{"pid": "3d294e62-d368-45f4-b7d8-9632eaf70e5b", "context": "Personalized recommendation systems have been extensively used in various applications, with collaborative filtering assuming that the rating matrix, such as viewers' movie ratings, is low-rank.", "key_idea": "The study proposes a novel approach, suggesting that the rating matrix is locally low-rank - it is low-rank within specific neighborhoods of the metric space defined by user-item pairs.", "method": "The researchers incorporate a local low-rank approximation approach based on the Frobenius norm with empirical risk minimization for ranking losses.", "outcome": "The study's experiments show that the combination of multiple local low-rank matrices, each trained to reduce a ranking loss, surpasses many existing state-of-the-art recommendation systems.", "future_impact": "The method proposed in the study is straightforward to parallelize, suggesting it could be applied to large scale, real-world rank-based recommendation systems.", "venue": "WWW", "year": 2014, "title": "Local collaborative ranking"}
{"pid": "60641d8c9e795e72406b665e", "context": "Recent mobile app technology allows people to encourage their friends to vote by sending them messages. However, quantifying the effect of these messages on voter turnout is a challenge due to several statistical issues, including attenuation bias from incorrect measurement of the subjects\u2019 outcomes and low precision due to non-compliance with the subjects\u2019 assignments.", "key_idea": "The authors address these challenges by using additional data about users and subjects. Using the meta-data of users\u2019 in-app behavior, the authors reconstruct the subjects\u2019 positions in users' queues. Then, this information is utilized to refine the study population to subjects who were more compliant and higher in the queues.", "method": "The authors performed an unobtrusive assessment using the mobile app Outvote, which randomized an aspect of its system. Ancillary data of subjects\u2019 matches to the voter rolls was used to further refine the study population, thereby minimizing outcome mismeasurement.", "outcome": "The analysis reveals statistically significant effects of friend-to-friend mobilization efforts on voter turnout, with a result of 8.3, CI = (1.2, 15.3), among the largest reported in the get-out-the-vote literature.", "future_impact": "The study provides a valuable insight to the role of friend-to-friend interactions in effective get-out-the-vote campaign which can be factored into the design of future initiatives aimed at understanding and increasing voter mobilization.", "venue": "WWW", "year": 2021, "title": "Assessing the Effects of Friend-to-Friend Texting on Turnout in the 2018 US Midterm Elections"}
{"pid": "6274c7645aee126c0f705e64", "context": "Open source software (OSS) projects often support code maintenance for old versions through maintaining multiple stable branches as users may not always use the latest version. The growing number of OSS vulnerabilities, however, has strained this patch deployment model.", "key_idea": "To address the need in the security community for a better understanding of security patch management across stable branches in OSS projects, the authors conduct a large-scale empirical study of stable branches in OSS projects and the security patches deployed on them.", "method": "The authors investigate 608 stable branches from 26 popular open source software projects and over 2000 security fixes for 806 CVEs deployed on stable branches.", "outcome": "The study reveals that more than 80% affected CVE-Branch pairs are unpatched, and the unpatched vulnerabilities could pose a serious security risk, with 47.39% of them achieving a CVSS score over 7. It is also found that the patch porting process requires significant manual effort and takes an average of 40.46 days.", "future_impact": "The authors hope that this study can improve the practice of patch management in OSS projects.", "venue": "WWW", "year": 2022, "title": "Understanding the Practice of Security Patch Management across Multiple Branches in OSS Projects"}
{"pid": "77934344-f927-4558-a32e-029107556c4e", "context": "Before this study, it has been an issue to seamlessly and meaningfully integrate the World-Wide Web (WWW) with applications.", "key_idea": "The paper proposes a solution to integrate the WWW with applications using the 'web widget' which is part of Hush, allowing Tcl/Tk/Hush programmers to mutually embed scripts into a webpage and use WWW as part of an application.", "method": "The authors develop and utilize a 'web widget' to demonstrate the integration of applications and the WWW, including the embedding of scripts in a web page.", "outcome": "The integration of applications and the WWW was achieved, demonstrating new possibilities such as inline MPEG, interactive games, and navigation facilities.", "future_impact": "The described method may lead to a more mutual integration of applications and the WWW, potentially opening up opportunities for a myriad of new online features and advances.", "venue": "WWW", "year": 1995, "title": "Integrating applications and the World-Wide Web"}
{"pid": "5e5644103a55ac122e36c49c", "context": "Abstractive snippets are original summaries of web pages on a search engine results page, offering advantages such as circumventing copyright issues and potential for personalization. However, the question of whether abstractive snippets can be automatically generated with sufficient quality remains open.", "key_idea": "This paper introduces a novel approach to abstractive snippet generation, which leverages large-scale sources for distant supervision: anchor contexts and web directories. It further proposes a bidirectional abstractive snippet generation model.", "method": "The authors mine the entire ClueWeb09 and ClueWeb12 for anchor contexts and utilize the DMOZ Open Directory Project to compile the Webis Abstractive Snippet Corpus 2020. The quality of both the corpus and the generated abstractive snippets is assessed using standard measures, crowdsourcing and comparison to the state-of-the-art.", "outcome": "The evaluation results show that the novel data sources along with the proposed model allow for producing usable query-biased abstractive snippets while minimizing text reuse.", "future_impact": "The novel data sources and the proposed model could pave the way for more effective automated generation of abstractive snippets, significantly enhancing search engine functionality and possibly opening up more possibilities for personalization.", "venue": "WWW", "year": 2020, "title": "Abstractive Snippet Generation"}
{"pid": "41f27eb8-7fd1-4ab2-87d6-e060aed0621c", "context": "Traditional methods of extracting class attributes from unstructured web text require handcrafted extraction patterns and domain-specific knowledge, which is achieved through supervised means. The task of class attribute extraction from inherently noisy search queries is relatively unexplored.", "key_idea": "The authors propose a seed-based framework for weakly supervised extraction of class attributes such as side effects and generic equivalents for drugs from anonymized query logs. The extraction process does not require any handcrafted extraction patterns or additional domain-specific knowledge.", "method": "The authors' method involves a setting where the extraction is guided by a small set of seed attributes from various domains of interest to web search users.", "outcome": "The accuracy levels of the attributes of classes extracted by the proposed method significantly exceed the current state of the art.", "future_impact": "This work demonstrates the potential value of noisy search queries, an underused resource, for web-based information extraction, in particular for the task of class attribute extraction.", "venue": "WWW", "year": 2007, "title": "Organizing and searching the world wide web of facts -- step two: harnessing the wisdom of the crowds"}
{"pid": "17075488-7c70-4dd2-bd30-d6cc8e07a084", "context": "The Internet along with new devices and technologies are altering the habits of end users in terms of media consumption. Traditionally, users search for related information to the currently watched TV show manually.", "key_idea": "The authors propose an enhanced user experience by automatically enriching media using semantic extraction. They suggest handling multi-screen, multi-user scenarios through sessions and introducing techniques for interaction and customization along with keyword extraction for discovering related web content.", "method": "The authors utilize methods like statistical algorithms, natural language processing technologies, and several transport protocols for real-time cross-platform synchronization. In addition, the work involves building a prototype to manifest these improvements.", "outcome": "The prototype effectively reflects the enhancements to the media enrichment system described, with significant improvements in user experience.", "future_impact": "Future research steps are planned for better refining the proposed enhancements and dealing with identified challenges, which could further improve the quality and effectiveness of media enrichment.", "venue": "WWW", "year": 2014, "title": "Enhancing media enrichment by semantic extraction"}
{"pid": "399a2ef6-2f60-4bdd-8596-3322ee48dc82", "context": "Minwise hashing and b-bit minwise hashing are standard techniques for efficient set similarity estimation. However, they require an expensive preprocessing step where k permutations (with, e.g., k=500) are applied to the whole dataset, slowing down operations such as duplicate web page detection.", "key_idea": "The authors introduce a GPU-based approach to minwise hashing, aiming to accelerate the preprocessing step and hence improve speed.", "method": "The authors developed a parallelization scheme using GPUs and measure their approach by looking at reduction in processing time.", "outcome": "With their GPU-based approach, the authors managed to reduce the processing time of minwise hashing by a factor of 20-80.", "future_impact": "The high processing speed could be beneficial for use cases such as duplicate web page detection and increasing the testing speed of online classifiers when the test data are not preprocessed.", "venue": "WWW", "year": 2012, "title": "GPU-based minwise hashing: GPU-based minwise hashing"}
{"pid": "5f1ffbac91e011d50a621b21", "context": "Sponsored search auctions are a billion-dollar industry and optimizing such marketplaces requires understanding how bidders will react to changes in the auction design.", "key_idea": "The authors propose the use of no-regret-based econometrics for bid prediction, modeling players as no-regret learners with respect to an unknown utility function, and the incorporation of a visibility bias component in the utility function.", "method": "They propose econometric methods to simultaneously learn the parameters of a player\u2019s utility and their learning rule, and apply these methods to a dataset from the BingAds sponsored search auction marketplace.", "outcome": "No-regret econometric methods perform comparably to state-of-the-art time-series machine-learning methods without co-variate shift and outperform machine-learning methods when there is a co-variate shift. No-regret learning outperforms more traditional equilibrium-based econometric methods. Prediction performance can be further improved by considering bidders with a utility function that includes a visibility bias component.", "future_impact": "The study indicates that using structural econometric approaches could improve the prediction of how players will respond to changes in the market, which could further optimize sponsored search auctions.", "venue": "WWW", "year": 2021, "title": "Bid Prediction in Repeated Auctions with Learning"}
{"pid": "320c33f8-0ac5-4da8-8617-a15b9f00b0df", "context": "Currently, the Australian Government is collecting emergency incident data from web feeds for emergency management. The ERIC (Emergency Response Intelligence Capability) tool has been used for this process.", "key_idea": "This paper presents a comparative study of information obtained via the ERIC tool from web feeds and information available on Twitter utilizing the Emergency Situation Awareness (ESA) platform.", "method": "They compared the intelligence obtained using ERIC for a specific fire event with the information that was available on Twitter using the Emergency Situation Awareness (ESA) platform.", "outcome": "The findings show that Twitter data was reported faster, contained more specific event information, was updated more frequently, included information from the public, and remained available longer than the web feed information.", "future_impact": "This suggests that Twitter can be a highly beneficial supplementary source of information for emergency management, providing real-time details about emergency events including impact to the community.", "venue": "WWW", "year": 2013, "title": "Comparing web feeds and tweets for emergency management"}
{"pid": "5e2eb5213a55ace6202f4860", "context": "The increasing availability and usage of Knowledge Graphs (KGs) on the Web prompts the need for scalable and general-purpose solutions to store these data structures.", "key_idea": "The authors propose Trident, a novel storage architecture for very large Knowledge Graphs on centralized systems, which uses interlinked data structures to provide fast access to nodes and edges and adapts its physical storage based on the graph's topology to reduce memory footprint.", "method": "The performance of Trident is evaluated on multiple workloads, with focus on its capacity to handle graphs with 10^11 edges using inexpensive hardware.", "outcome": "Results indicate that Trident is capable of efficiently handling graphs with 10^11 edges using inexpensive hardware and delivering competitive performance on multiple workloads.", "future_impact": "Though not explicitly stated, Trident's general-purpose interface design suggests potential for wide applicability in tasks like SPARQL query answering, reasoning, and graph analytics.", "venue": "WWW", "year": 2020, "title": "Adaptive Low-level Storage of Very Large Knowledge Graphs"}
{"pid": "5e9ef9b69fced0a24b1b6585", "context": "Approximating Jaccard's index in big data problems such as K-Nearest-Neighbor (KNN) graph construction is expensive in terms of computation time, and there is a need to speed up existing KNN algorithms.", "key_idea": "The authors propose a binary representation of datasets, GoldFinger, to approximate Jaccard's index that can accelerate existing KNN algorithms with little to no overhead.", "method": "The authors tested GoldFinger in the context of KNN graph construction, comparing its performance against raw data. They also applied this scheme in the context of item recommendation.", "outcome": "GoldFinger delivered a speedup of up to 78.9% compared to the use of raw data, with negligible to moderate loss in KNN quality. In the context of item recommendation, the loss in recommendation quality was negligible.", "future_impact": "By providing k-anonymity and l-diversity, the compact representation of data with GoldFinger can protect users' privacy, which might open up new applications in privacy-sensitive data processing.", "venue": "WWW", "year": 2020, "title": "Smaller, Faster & Lighter KNN Graph Constructions"}
{"pid": "bbd3378f-e299-432b-b164-a434832990f0", "context": "Modern search engines distribute crawled web documents among thousands of servers in a local index-partitioning scheme. To expedite the time documents become searchable, documents may simply be appended to the index partitions but this results in larger index sizes since document reordering for index compactness is no longer performed, which degrades the search query processing performance.", "key_idea": "The work considers the effects of several online document routing strategies on the aggregated partitioned index size and suggests that there exists a tradeoff between compression of a partitioned index and host distribution.", "method": "The authors suggest and evaluate several online routing strategies in terms of their compression, host distribution, and complexity. A term-based routing algorithm is presented and evaluated, with results compared to the industry standard random routing scheme.", "outcome": "It is analytically shown that the term-based routing algorithm provides better compression results than the random routing scheme, and experimental evaluation on a large benchmark collection of web pages validates the findings.", "future_impact": "The findings could lead to a re-thinking of document distribution strategies for search engines, with potential improvements in search engine performance.", "venue": "WWW", "year": 2011, "title": "Inverted index compression via online document routing"}
{"pid": "6274c6545aee126c0f6fb689", "context": "The COVID-19 pandemic has significantly impacted people's psychological states globally, leading to an increase in depression and domestic violence, but how people's emotional states have changed in response to the pandemic on social media has not been well-studied.", "key_idea": "The paper introduces the concept of \u2018emotion bubbles\u2019. It proposes that people maintain their emotional consistency by selectively focusing on emotion-reinforcing topics on social media during a global crisis, in this case, the COVID-19 pandemic.", "method": "The authors analyzed more than 9 million tweets posted by 9,493 users before and after the outbreak of the pandemic to trace how their overall emotional states changed.", "outcome": "The study found that, in early 2020, although COVID-related tweets filled with negative emotions increased significantly, this outburst was short-lived. Users who expressed positive emotions in the pre-COVID period remained positive after the initial outbreak and vice versa.", "future_impact": "The findings suggest a phenomenon of an emotionally motivated confirmation bias, which can aid in understanding public resilience to global health risks, potentially guiding strategies for communication and mental health support in future crises.", "venue": "WWW", "year": 2022, "title": "Emotion Bubbles: Emotional Composition of Online Discourse Before and After the COVID-19 Outbreak"}
{"pid": "7f045266-069a-416a-a0e2-a85a31792196", "context": "EduSource Canada is a project dedicated to building an open network of interoperable digital repositories, but there are technical challenges in achieving flexible, easy-to-use, and platform-independent communication among these repositories.", "key_idea": "The authors designed and implemented the eduSource Communication Layer (ECL) protocol, which aims to be a highly flexible, easy-to-use, and platform-independent communication protocol that allows new and existing repositories to communicate and share resources across a network.", "method": "The ECL protocol is created following IMS Digital Repository Interoperability (DRI) specifications and supports four main functions: search/expose, submit/store, gather/expose and request/deliver. To facilitate the adoption of the protocol, middleware components for connecting existing systems are also provided.", "outcome": "The ECL protocol has been successfully adopted within the eduSource network and has demonstrated flexibility and usability.", "future_impact": "Potential future work involves integrating ECL with other interoperable initiatives such as Open Knowledge Initiative (OKI), which could further boost the utility and adoption of ECL.", "venue": "WWW", "year": 2004, "title": "Digital repository interoperability: design, implementation and deployment of the ecl protocol and connecting middleware"}
{"pid": "8b6c1a4c-b14b-4309-92ec-2977b6233947", "context": "Web travel is challenging for visually impaired users due to the varying ease of travel from page to page and from site to site, and the inaccessibility or absence of objects that support travel.", "key_idea": "The authors propose a framework for identifying and classifying travel objects within Web pages with the goal of improving mobility for visually impaired users.", "method": "An evaluation was carried out to test the proposed frameworks ability to provide a systematic and consistent method for assessing travel on the Web.", "outcome": "The evaluation demonstrated that the proposed framework supports a systematic and consistent method for assessing mobility on the Web.", "future_impact": "The authors propose that the developed framework could serve as a foundation for a semi-automated tool to facilitate web travel for visually impaired users.", "venue": "WWW", "year": 2003, "title": "A foundation for tool based mobility support for visually impaired web users"}
{"pid": "9a182121-7b9b-4013-a1aa-6cfa3f78eb95", "context": "The process of address book enrichment through information extraction in e-mail signature blocks is a manual process, and issues like signature block detection, named entities tagging, mapping, standardizing details, and auto-updating of the address book are not yet fully automated or handled appropriately.", "key_idea": "The paper proposes a fully automated process that tackles the issues of signature block detection, named entities tagging, mapping with a specific person, standardizing the details, and auto-updating from e-mail signature blocks via a symbolic approach for NLP modules.", "method": "The authors designed the process to handle different types of errors (both human or computer-driven), aiming for 100% precision rate.", "outcome": "While no explicit outcomes are mentioned in the abstract, the paper discusses the design, its precision aims, and the challenges associated with the question of automatic updating and user data rights.", "future_impact": "The paper suggests addressing the issue of automatic updating in relation to users\u2019 data rights, hinting at potential future research on preserving users' rights while enhancing automation in data extraction and usage.", "venue": "WWW", "year": 2012, "title": "Interpreting contact details out of e-mail signature blocks"}
{"pid": "6661b4c2-5d81-4813-81c0-55a95125991b", "context": "At the point of this study, web dissemination of information was gaining recognition but there were limitations due to the lack of advanced authoring tools, primitive server technology from CERN HTTPD, and increasing workloads related to putting information on the server.", "key_idea": "The authors strove for a process to both identify the root causes of the challenges experienced and to develop solutions to these problems. The primary solution proposed entails shifting the responsibility of information upkeep to the author itself using a tool they named 'Deceit'.", "method": "The authors created their own server and embarked on a project to solve the problems encountered by using the flexibility provided by their tool 'Deceit' to shift responsibility for information onto its author and increased the range of information available.", "outcome": "Implementation of 'Deceit' has resulted in decreased workloads for the maintainers and an increase in the range of information available.", "future_impact": "This work could lead to the development of new effective web servers and tools that make the web a more reliable source of information by putting more responsibility on the authors of the information.", "venue": "WWW", "year": 1994, "title": "A tangled web of deceit"}
{"pid": "baa5b5d2-8144-4df2-9fb1-cac8697cfc92", "context": "Creating and populating specialized domain ontologies requires manual effort and domain expertise, which is often not scalable for large volumes of data from different domains.", "key_idea": "The paper presents automated techniques for bootstrapping and populating specialized domain ontologies utilizing relevant overlapping Web sites. This is done through algorithms that detect HTML regularities, transform them into hierarchical semantic structures encoded as XML, and apply tree-mining algorithms to identify key domain concepts and their taxonomic relationships.", "method": "The proposed algorithms were evaluated using data from News, Travel, and Shopping domains, where they were used to bootstrap and populate domain-specific ontologies.", "outcome": "The experimental evaluation indicates that the proposed algorithms are capable of bootstrapping and populating domain specific ontologies with high precision and recall for the considered domains.", "future_impact": "The approach can potentially automate the generation and population of domain-specific ontologies from various web sources thereby reducing manual effort and expert human intervention.", "venue": "WWW", "year": 2004, "title": "OntoMiner: bootstrapping ontologies from overlapping domain specific web sites"}
{"pid": "c491b625-cc95-407b-8d8e-319f360aaa45", "context": "Numerous browser extensions process sensitive information from user inputs and webpages. However, it is unclear whether these extensions may accidentally leak such sensitive information out of the browsers without protection.", "key_idea": "The authors present a framework, LvDetector, that combines static and dynamic program analysis techniques to automatically detect information leakage vulnerabilities in browser extensions.", "method": "The design of LvDetector is tested on 28 popular Firefox and Google Chrome extensions using the implementations derived from the framework.", "outcome": "LvDetector identified 18 previously unknown information leakage vulnerabilities in 13 extensions with an accuracy rate of 87%. Feedback suggested that LvDetector is useful and effective.", "future_impact": "Extension developers can use LvDetector to locate and fix vulnerabilities; browser vendors can use LvDetector to decide whether to host extensions in their online stores; and advanced users can use LvDetector to determine if certain extensions are safe to use.", "venue": "WWW", "year": 2015, "title": "Automatic Detection of Information Leakage Vulnerabilities in Browser Extensions"}
{"pid": "c78f5f7c-2001-46ca-aaf2-75041e0e9db4", "context": "The Internet is a significant source of media content, including video and audio, but currently, this audiovisual media does not integrate the substantial amount of related information available on the Web.", "key_idea": "The paper proposes the Chrooma+ approach to enhance the user experience of media consumption by enriching media content with additional information from various Web sources, focusing on the aggregation and combination of this related information.", "method": "The proposed method involves using new HTML5 technologies and a new annotation format, WebVTT, to display pertinent information at specific times.", "outcome": "The benefits of this approach include the usage of a rich annotation format and the ability to extend to include diverse information sources.", "future_impact": "The Chrooma+ approach could set a new standard for media consumption on the internet, offering a richer experience by associating relevant additional information to media content.", "venue": "WWW", "year": 2013, "title": "The chrooma+ approach to enrich video content using HTML5"}
{"pid": "5e9ef9b69fced0a24b1b6663", "context": "Tagging a friend in a comment is a well-known mechanism that advances user interaction on social media, such as Instagram. However, the specific motivations behind this practice have yet to be investigated thoroughly.", "key_idea": "This study identifies three motivations behind Instagram users tagging friends in comments: (i) information-oriented, (ii) relationship-oriented, and (iii) discussion-oriented, and develops a learning-based model to classify these motivations.", "method": "The researchers collected a large-scale data set consisting of 9K posts and their 4M comments shared by 3M Instagram users. They then applied their model to the comments with user tagging to understand the motivations behind the practice.", "outcome": "The research finds that 54.8% of the comments contain user tagging, signifying it's widely used in Instagram. The model revealed that user tagging is often used for interpersonal communication with friends.", "future_impact": "An understanding of the motivations behind user tagging on Instagram can provide insights into user interaction and engagement, potentially informing the design of features to increase user engagement in social media.", "venue": "WWW", "year": 2020, "title": "Why do Instagram Users Tag Friends in Comments?"}
{"pid": "39e19b19-462f-4d64-b73f-f90a4172f9b7", "context": "Web-based interactive and collaborative applications often have programmers dealing with issues related to collaboration, access control, and networking management. There is a need for a solution that lets programmers focus on the particular logic of their applications.", "key_idea": "The paper proposes a layered component model to support Web-based interactive and collaborative applications, allowing programmers to focus on specific application logic.", "method": "The authors validate their concept by developing a Web-based educational application over the proposed framework.", "outcome": "A tele-education system following the recommendations by the main institutions involved in the learning technology standardization process has been developed using the proposed layered component model.", "future_impact": "This layered component model can standardize and streamline the development of future web-based education and collaborative applications, allowing developers to focus more on application specifics.", "venue": "WWW", "year": 2001, "title": "A component model for stardardized web-based education"}
{"pid": "60c093fc91e0116059b159be", "context": "Finding suitable citations for scientific publications is a time-consuming and challenging issue. Context-aware citation recommendation approaches have been developed, but many lack explanation components to help users understand why certain papers were recommended.", "key_idea": "The paper presents C-Rex, a web-based demonstration system for context-aware citation recommendation that integrates a deep learning recommendation approach with explanation components based on the Neural Citation Network.", "method": "The authors use millions of publications from the Microsoft Academic Graph to train the Neural Citation Network. They evaluate the system's performance both offline, comparing it to the model in the original paper, and online, assessing users' satisfaction with the explanation components.", "outcome": "C-Rex performs comparably to the model presented in the original paper in the offline evaluation, and the explanations of recommendations are shown to increase users' satisfaction in the online evaluation.", "future_impact": "This system can serve as a foundation for future implementations in the field of citation recommendation systems.", "venue": "WWW", "year": 2021, "title": "C-Rex: A Comprehensive System for Recommending In-Text Citations with Explanations"}
{"pid": "dd3d62e7-1a15-441c-a11a-2fbc90c68631", "context": "Prior to this study, the implementation of Web services lacked a dedicated language that would allow developers to focus primarily on the application's logic, while also handling routine actions and performance tuning efficiently.", "key_idea": "The authors propose a new XML-based programming language, XL, specifically designed for the implementation of Web services, which lets programmers focus on application logic by providing high-level, declarative constructs for typical Web service operations.", "method": "The authors designed XL language to be W3C compliant, offering features for actions such as logging, error handling, retrying actions, workload management, events, among others and also for automatic performance tuning measures like caching, horizontal partitioning, etc.", "outcome": "The creation of the XL, an XML programming language was successful. Developers using XL are expected to realize increased productivity, easier program evolution, and potential performance improvements, although these results are not stated explicitly in the abstract.", "future_impact": "The introduction of XL may enhance the productivity of programmers, foster the evolution of programs, and increase the likelihood of achieving good performance in the implementation of Web services.", "venue": "WWW", "year": 2002, "title": "XL: an XML programming language for web service specification and composition"}
{"pid": "60641cb59e795e72406b65fb", "context": "Learning effective feature crosses is crucial for recommender systems, but it requires exhaustive search due to sparse and large feature spaces. Although the Deep & Cross Network (DCN) was proposed to learn bounded-degree predictive feature interactions efficiently, it exhibited limited expressiveness in learning more predictive feature interactions in web-scale applications with billions of examples.", "key_idea": "To address the limitations of DCN, an improved framework, DCN-V2, is proposed. This new framework is designed to be more practical in large-scale industrial settings and is more expressive yet cost-efficient at feature interaction learning.", "method": "A comprehensive experimental study was carried out with extensive hyper-parameter search and model tuning, and the performance of DCN-V2 was compared with other state-of-the-art algorithms on popular benchmark datasets.", "outcome": "The DCN-V2 approaches outperform all the state-of-the-art algorithms on popular benchmark datasets. Furthermore, DCN-V2 has delivered significant offline accuracy and online business metrics gains across many web-scale learning to rank systems at Google.", "future_impact": "The simplicity and effectiveness of DCN-V2 can enable easy adoption as building blocks in various domains. It's anticipated to continue improving accuracy and business metrics in large-scale learning to rank systems. The open-sourcing of the code and tutorial can encourage further development and application of this approach.", "venue": "WWW", "year": 2021, "title": "DCN V2: Improved Deep & Cross Network and Practical Lessons for Web-scale Learning to Rank Systems"}
{"pid": "fe4965ed-87f9-4fea-99f1-c43ae8edc718", "context": "The World Wide Web's reach extends due to its open assimilation of document formats. The global hypermedia system favors certain document formats adapted for the web.", "key_idea": "This paper discusses the evolutionary record leading to the prevalence of eXtensible Markup Language (XML), presenting a taxonomy of document species on the web based on their syntax, style, structure, and semantics.", "method": "The paper discusses and analyzes the preferential adoption of document formats like SGML, CSS, HTML, and XML.", "outcome": "It is observed that document formats like SGML, CSS, HTML, and XML have been adopted favorably due to their declarative encodings, separable styles, declarative markup, and well-defined semantics over operational behavior.", "future_impact": "The paper suggests that XML, combined with the self-referential ability of the web to document itself, could potentially transform the web from a global information space into a universal knowledge network.", "venue": "WWW", "year": 1998, "title": "The origin of (document) species"}
{"pid": "d690a246-dfda-4653-9e5f-03fc303b9ef9", "context": "Consumer reviews are often unstructured and cover various aspects of a product, which can make it difficult for people to quickly grasp an overall opinion or to find reviews related to a specific aspect.", "key_idea": "The authors introduce a method to organize unstructured consumer reviews into a hierarchy, taking advantage of both domain structure knowledge and the content of the reviews themselves. This hierarchical organization then facilitates view aggregation and easy navigation through opinions on different aspects of a product.", "method": "The proposed method was tested on two product review datasets; one containing 314 reviews for five products and another sourced from forum websites comprising 60,786 reviews for five popular products.", "outcome": "Experimental results from two datasets demonstrate the effectiveness of the proposed approach, but specific measurable outcomes are not provided in the abstract.", "future_impact": "By structuring unstructured consumer reviews into a hierarchical organization, consumer's overview of reviews and opinions on various aspects of a product could be facilitated as well as the search for reviews and opinions on any specific aspect.", "venue": "WWW", "year": 2011, "title": "Hierarchical organization of unstructured consumer reviews"}
{"pid": "6274c8835aee126c0f70e58f", "context": "Localizing the source of graph diffusion phenomena is an important yet extremely challenging real world task. Hand-crafted rule-based source localization models are often domain-specific and lack cross-domain performance. At present, the understanding of graph diffusion processes for many applications is incomplete. Source localization is the inverse of graph diffusion, which is known to be ill-posed and presents challenges that are different from traditional (semi-)supervised learning scenarios.", "key_idea": "The authors propose Invertible Validity-aware Graph Diffusion (IVGD), a generic framework for source localization on graphs that can model the inverse processes in an end-to-end fashion, ensures the validity of the inferred sources, and is efficient and scalable.", "method": "The authors develop the IVGD model with three components: a graph residual scenario to inversely infer sources of graph diffusion, an error compensation mechanism to offset the errors of the inferred sources, and a set of validity-aware layers to project inferred sources to feasible regions by encoding constraints with unrolled optimization techniques. The model's efficiency is strengthened through a linearization technique. Its convergence is theoretically proven. Extensive experiments are conducted on nine real-world datasets to validate the performance of IVGD.", "outcome": "Theoretical proofs validate the convergence of the proposed IVGD model, and empirical experiments on nine real-world datasets demonstrate that IVGD significantly outperforms the state-of-the-art comparison methods in source localization tasks.", "future_impact": "The authors' work on a generic source localization framework could enable more accurate and efficient modeling and localizing of graph diffusion phenomena across various domains.", "venue": "WWW", "year": 2022, "title": "An Invertible Graph Diffusion Neural Network for Source Localization"}
{"pid": "6c9b1fa9-34e3-454e-a8be-d43f20619bf0", "context": "The inefficiencies associated with multiple concurrent connections in Web content delivery has been addressed by persistent connections coupled with pipelining. However, the inconsistent support for these techniques across servers, user agents and intermediaries, results in multiple concurrent TCP connections being opened by web browsers.", "key_idea": "This paper proposes a new solution of packaging all objects embedded in a Web page into a single bundled object, which can be fetched by the clients. This approach aims to reduce the response time and lessen the load on servers and the network.", "method": "The authors validate their idea through an analytical examination of their bundling approach, comparing the response time and load on servers and network with those offered by traditional concurrent connection methods.", "outcome": "The bundle approach shows equal or better response times compared to currently used methods, while also reducing load on servers and networks. The approach also gives Web servers better control over the number and duration of supported TCP connections.", "future_impact": "This technique does not require changes to the HTTP protocol, indicating its potential for practical implementation and wide adoption in improving web content delivery efficiency.", "venue": "WWW", "year": 2001, "title": "N for the price of 1: bundling web objects for more efficient content delivery"}
{"pid": "1663b57f-1ae1-47f1-8a27-7fb41d2c825c", "context": "The Web of Data is producing large RDF datasets from diverse fields, but the traditional RDF representations, which were inspired by a document-centric view, results in verbose and redundant data, which are costly to exchange and post-process.", "key_idea": "The ongoing doctoral thesis proposes a binary serialization format for RDF, called HDT, to make the publication, exchange, and consumption of RDF more efficient.", "method": "The study is centered around the concept of HDT and its implementation. Additionally, it delves into the design of compressed rich-functional structures that contribute to the efficiency of HDT and are fundamental for operations on extensive RDF datasets.", "outcome": "The thesis presents HDT, a new binary serialization format for RDF that enhances efficiency in the context of large scale data publication, exchange, and consumption.", "future_impact": "The work can potentially give rise to more efficient formats and solutions in manipulating and exchanging large RDF datasets, thus improving data operations in the web of data.", "venue": "WWW", "year": 2012, "title": "Binary RDF for scalable publishing, exchanging and consumption in the web of data"}
{"pid": "30197620-5b9c-4d4b-81f3-c22db5bc2283", "context": "The problem of budget feasible mechanism design was proposed by Singer, where a principal has a public value for hiring a subset of the agents and a budget, while the agents have private costs for being hired. However, optimal mechanisms were budget balanced only in expectation.", "key_idea": "The authors carry the problem into a Bayesian setting and propose simple, practical, ex post budget balanced posted pricing mechanisms that approximate the value obtained by the Bayesian optimal mechanism.", "method": "The authors analyse their proposed mechanisms using methods related to contention resolution schemes in submodular optimization and the correlation gap analysis.", "outcome": "It's shown that there are simple posted pricing mechanisms that could be used as a feasible solution for budget-balanced mechanism design problems.", "future_impact": "The work is motivated by applications in crowdsourcing, such as on Mechanical Turk, where workers are drawn from a large population and posted pricing is standard, and can influence future mechanisms designed for such platforms.", "venue": "WWW", "year": 2016, "title": "Bayesian Budget Feasibility with Posted Pricing"}
{"pid": "5e5794b791e011545375114a", "context": "Correlation clustering is a common formulation of clustering that faces a major drawback of needing to compute and store an infeasible amount of pairwise similarities.", "key_idea": "The authors propose a query-efficient algorithm for correlation clustering which operates within a set query budget and aims to minimize the number of disagreements with respect to the optimal cost of the instance.", "method": "The authors devise a correlation clustering algorithm and test its performance through an experimental study on both synthetic and real data.", "outcome": "The proposed algorithm offers a provably optimal trade-off between the number of queries and the worst-case error attained, even for adaptive algorithms, showcasing its scalability and accuracy in experimental tests.", "future_impact": "The query-efficient algorithm might influence the development of future clustering algorithms by inspiring the use of a similar query budget-based design to manage computational and storage needs.", "venue": "WWW", "year": 2020, "title": "Query-Efficient Correlation Clustering"}
{"pid": "602ba6d591e0113d72356d38", "context": "Email search engines use a uniform ranking system which may not cater to users' varied preferences and tasks. Previous personalization attempts have focused on characterizing user behavior but have largely ignored search history as a possible source of information. The utilization of search history in Web search has been proven beneficial, but its effectiveness in email search is unstudied.", "key_idea": "A context-dependent neural ranking model (CNRM) is proposed, which uses search history as a query context to provide personalized rankings for email search. The model also takes privacy concerns into account by using ranking features rather than raw text.", "method": "The proposed CNRM model was tested against the baseline neutral model without using context, and its vectors were also clustered and incorporated into the LambdaMart learning-to-rank model to analyze improvements.", "outcome": "The proposed CNRM model outperformed the baseline neural model and also significantly improved results when applied to the state-of-the-art learning-to-rank model LambdaMart, demonstrating the beneficial use of search history for personalizing email search.", "future_impact": "The proposed CNRM model has potential to lead for better customization in email search tasks, leading to improved communication efficiency for users, and the approach might generalize well to unseen users.", "venue": "WWW", "year": 2021, "title": "Leveraging User Behavior History for Personalized Email Search"}
{"pid": "6540062e-88a0-48fd-b82e-94a0432c8762", "context": "Selective disclosure of verifiable content, privacy for blinded content, and control over content extraction or blinding, all of which contribute to Content Extraction Signature (CES) functionality, is a challenging problem not addressed by standard XML Signature.", "key_idea": "The paper proposes custom transform algorithms to expand the functionality of an XML Signature to include CES functionality in XML Signature Core Validation, along with a custom revocation mechanism for non-XML content.", "method": "The paper demonstrates the use of dynamically loaded custom transforms for signing and verification, aiming to show that it enables the verification of an XML Signature-compliant signature even when a custom signature is produced.", "outcome": "The authors show that with dynamic loading, a verifier can still verify an XML Signature-compliant signature even though a custom signature was produced.", "future_impact": "The proposed method could facilitate more secure and flexible content verification and privacy protection, although it's not explicitly mentioned in the abstract.", "venue": "WWW", "year": 2003, "title": "Content extraction signatures using XML digital signatures and custom transforms on-demand"}
{"pid": "635bcaaf90e50fcafd33c354", "context": "Control theory is an interdisciplinary domain that contains complex elements from various sub-domains of maths and engineering, making knowledge transfer a challenging issue such as between researchers focusing on different niches and into potential application domains.", "key_idea": "The paper investigates the Open Research Knowledge Graph (ORKG) as a medium to facilitate knowledge transfer in control theory, examining the current state of control theoretic knowledge presented in the ORKG and describing the process of extending that knowledge.", "method": "The process of extending the control theory knowledge in ORKG is assessed, challenges are noted, and the results are backed by SPARQL queries and further evaluation code which is publicly available for reproducibility.", "outcome": "This results in a list of best practice suggestions for the ORKG contributions and a list of improvement suggestions for the further development of the ORKG and similar platforms.", "future_impact": "The suggestion lists provided for enhancing ORKG contributions and the development of the ORKG and similar platforms could help in the improvement of these platforms and further facilitate the transfer of intricate knowledge across interdisciplinary domains such as control theory.", "venue": "WWW", "year": 2022, "title": "Examining the ORKG towards Representation of Control Theoretic Knowledge \u2013 Preliminary Experiences and Conclusions"}
{"pid": "5e9ef9b69fced0a24b1b65f3", "context": "The extraction of main content from web pages is essential for several applications, including usability aspects and information retrieval. Current techniques rely heavily on hand-crafted features for classification, limiting their generalizability and adaptability to dynamic changes in the structure of web pages.", "key_idea": "The authors propose a novel neural sequence labeling model for web content extraction that solely relies on HTML tags and words from a web page, eliminating the need for hand-crafted features.", "method": "The authors validate their proposal through the development of a browser extension that highlights the content of arbitrary web pages using their model. They also create a new and more current dataset to test the model.", "outcome": "Results demonstrate that the proposed model can adapt to changes in the structure of web pages and outperform the state-of-the-art model in main content extraction from web pages.", "future_impact": "The proposed model, embodied as a browser extension for real-time content highlight, can significantly contribute to web usability, information retrieval, and natural language processing tasks.", "venue": "WWW", "year": 2020, "title": "Boilerplate Removal using a Neural Sequence Labeling Model"}
{"pid": "602bbc6591e0113d72356f10", "context": "Previous techniques for leveraging data from multiple modalities, such as X-ray images taken at different poses or different types of user data on social media, generally suffer from inability to utilize complimentary information from each view and provide interpretable predictions.", "key_idea": "The authors propose a deep co-attention network for multi-view subspace learning, aiming to extract both the common and complementary information in an adversarial setting. This model can provide robust interpretations behind predictions via the co-attention mechanism, enhancing transparency and understandability.", "method": "The authors use a novel cross-reconstruction loss and incorporate classifier information into a new model. This improves the quality of latent representation, accelerates convergence speed, and culminates in an efficient iterative algorithm to find optimal encoders and discriminators. The authors evaluate the model on synthetic and real-world datasets.", "outcome": "The study does not provide a specific measurable outcome in the abstract.", "future_impact": "From the abstract it can be concluded that the developed model can bring improvements to real-world applications where data from multiple modalities is used. However, the exact future impact is not explicitly stated in the abstract.", "venue": "WWW", "year": 2021, "title": "Deep Co-Attention Network for Multi-View Subspace Learning"}
{"pid": "0e7f9e01-f646-4d13-af00-65cc7c66ba08", "context": "The use of social media like YouTube and Twitter displays varying socio-cultural behaviors. However, there has been limited study comparing these behaviors across different social media platforms.", "key_idea": "This research investigates and compares socio-cultural behavior of users in two different social media channels, YouTube and Twitter, specifically in terms of their engagement with K-pop culture.", "method": "The study conducted a comparative analysis of networks generated from both YouTube and Twitter, focusing on relatedness in YouTube and co-links on Twitter.", "outcome": "The study found that Twitter networks more accurately represent actual content consumption in the K-pop culture compared to YouTube networks.", "future_impact": "The research offers a new approach for exploring socio-cultural behavior of users on social media, which may stimulate further research in this field.", "venue": "WWW", "year": 2014, "title": "Investigating socio-cultural behavior of users reflected in different social channels on K-pop"}
{"pid": "fdf8fefb-6fe9-48c3-b3da-0b38a5bc109b", "context": "As GPS-enabled mobile devices have advanced, location-based services (LBS) have become one of the most active subjects in Web-based services, resulting in a large number of geotagged documents. Recently, there have been studies on spatial keyword search which aims to find a set of documents in the Web-based services by evaluating the spatial relevance and keyword relevance.", "key_idea": "The paper introduces the concept of spatial semantic search, which is to find top k relevant sets of documents with spatial constraints and semantic constraints.", "method": "For the spatial semantic search problem, the authors propose a hybrid index strategy, a ranking model, and an efficient search algorithm.", "outcome": "The authors present the current status of research progress but do not specifically mention measurable outcomes.", "future_impact": "The paper discusses remaining challenges and future works in the domain of spatial semantic search, implying potential impacts on future research.", "venue": "WWW", "year": 2014, "title": "Spatial semantic search in location-based web services"}
{"pid": "3f67fa67-0e31-4efd-811e-81cd23423720", "context": "Web application usability evaluation often relies on less detailed, coarse-grained information, such as that provided by classical log files. Current methods to track user interaction can alter the user's experience or may require changes to existing server and browser setups.", "key_idea": "The authors propose a method for detailed tracking of user actions on web pages using standard web technologies, which would allow for usability evaluation of web applications and enable implicit interaction. This method aims to classify the user with regard to computer usage proficiency and make a detailed assessment of how long users take to fill in form fields.", "method": "An implementation is presented where an HTTP proxy modifies HTML pages by adding JavaScript code before delivering them to the client. This JavaScript code tracks data about mouse movements, keyboard input, and more.", "outcome": "The authors demonstrated the efficacy of the proposed method in a case study. It is, however, not mentioned in the abstract what the precise results of this case study were.", "future_impact": "The detailed user activity tracking proposed in this paper could transform the evaluation of website usability and enable more nuanced implicit interaction. Though not explicitly stated, the study suggests directions for future research in detailed web tracking and user profiling.", "venue": "WWW", "year": 2006, "title": "Knowing the user's every move: user activity tracking for website usability evaluation and implicit interaction"}
{"pid": "5e9ef9b69fced0a24b1b6624", "context": "Machine learning systems learn bias from input data, including gender and political bias. Techniques have been proposed to quantify gender bias in a corpus of text by computing a gender subspace for word vectors, but a method for quantifying political bias is less clear.", "key_idea": "This paper applies a method similar to the one used for quantifying gender bias to political bias. It introduces a methodology for defining a set of word pairs to compute a political bias subspace, using a corpus of tweets from Republican and Democratic politicians in the United States.", "method": "The authors collect and analyze a 26 GB corpus of tweets from US Republican and Democratic candidates and members of Congress, using the proposed methodology for calculating a political bias subspace. They examine the trends and examine bias scores on multiple axes.", "outcome": "The paper shows that tweets from both Republican and Democratic presidential candidates have more political bias than tweets from other politicians of the same party. It also highlights the complexity of political, racial, and gender bias, suggesting that they may require modeling along multiple axes or a range of points along a single axis.", "future_impact": "This work extends to other types of bias, proposing examining bias along multiple axes (e.g. liberal/conservative and authoritarian/libertarian for political bias) or as a range of points along a single axis (e.g. a gender spectrum).", "venue": "WWW", "year": 2020, "title": "Studying Political Bias via Word Embeddings"}
{"pid": "eb436963-d807-4626-af33-eefc712991c5", "context": "The original exponentiated gradient algorithm and its performance in the learning from experts setting has been studied by several researchers, including Hazan & Kale and Chiang et al. However, there's a scope for improvement in term of regret bounds.", "key_idea": "The authors present an adaptive variant of the exponentiated gradient algorithm which leverages the optimistic learning framework. They also generalize the Follow-the-Regularized-Leader algorithm to vector-valued payoffs.", "method": "The authors demonstrate the adaptive exponentiated gradient algorithm in the learning from experts setting and extend it to matrix-valued loss functions.", "outcome": "The proposed algorithm improves the regret bounds by depending on the variance and path length of the best expert, resolving an open problem posed by previous research.", "future_impact": "The generalized Follow-the-Regularized-Leader algorithm to vector-valued payoffs could be interesting for future research.", "venue": "ICML", "year": 2014, "title": "Adaptivity and Optimism: An Improved Exponentiated Gradient Algorithm"}
{"pid": "62c28ae65aee126c0f8a2289", "context": "Graph convolutional networks (GCNs) have recently achieved great empirical success in learning graph-structured data, but they have scalability issues due to recursive embedding of neighbouring features. To address it, graph topology sampling has been proposed which has achieved comparable test performance to those without topology sampling.", "key_idea": "This paper provides the first theoretical justification of graph topology sampling in training (up to) three-layer GCNs for semi-supervised node classification, characterizing some sufficient conditions on graph topology sampling such that GCN training leads to diminishing generalization error.", "method": "The authors formally characterize the conditions on graph topology sampling to analyze the generalization performance and sample complexity in the training of GCNs. The paper handles the non-convex interaction of weights across layers, and the findings are validated through numerical experiments.", "outcome": "The paper provides theoretical justifications for the use of graph topology sampling in three-layer GCNs for semi-supervised node classification, demonstrating under certain conditions, this leads to a diminishing generalization error.", "future_impact": "This study provides a theoretical foundation for graph topology sampling in GCN training, which can guide further research in this field on how to improve the generalization performance and sample complexity of GCNs.", "venue": "ICML", "year": 2022, "title": "Generalization Guarantee of Training Graph Convolutional Networks with Graph Topology Sampling."}
{"pid": "8c91551a-5065-4d62-861f-81561ac4bcfb", "context": "Online optimization problems on compact subsets of Rn, where a decision maker chooses at each iteration a probability distribution over the subset, are being studied. Previous work has mainly focused on spaces that are convex and where loss functions are Lipschitz.", "key_idea": "A generalized Hedge algorithm is proposed for handling online optimization problems within spaces that are uniformly fat, a weaker condition than convexity, and with uniformly Lipschitz loss functions.", "method": "To validate their proposed generalization of the Hedge algorithm, the authors examine the regret of the algorithm over time, specifically they show a O(\u221atlogt) bound on the regret.", "outcome": "The study establishes a O(\u221atlogt) bound on the regret when the losses are uniformly Lipschitz and the set is uniformly fat.", "future_impact": "The authors also introduce a generalization of the dual averaging method on the set of Lebesgue-continuous distributions over S, suggesting potential application to a broader range of optimization problems.", "venue": "ICML", "year": 2015, "title": "The Hedge Algorithm on a Continuum"}
{"pid": "c57279f6-04f6-46da-a894-44448c2b4eb9", "context": "Riffled independence is a generalized concept of probabilistic independence suitable for ranked data. However, due to the interleaving phase, it's challenging to recognize riffled independence compared to ordinary independence.", "key_idea": "This paper introduces the first automatic method for finding sets of items that are riffle independent from a training dataset of rankings.", "method": "The authors describe clustering-like algorithms and apply them to real preference ranking datasets to observe their functionality and discover meaningful latent coalitions.", "outcome": "The proposed algorithms were successfully used to discover meaningful latent coalitions from real preference ranking datasets and to learn the structure of hierarchically decomposable models based on riffled independence.", "future_impact": "This new approach to finding riffle independent sets can enhance the understanding and utilization of ranked data, potentially leading to advancements in related fields.", "venue": "ICML", "year": 2010, "title": "Learning Hierarchical Riffle Independent Groupings from Rankings"}
{"pid": "6047615391e0116b67c791dc", "context": "Nondeterminism in neural network optimization produces performance uncertainty, making small improvements hard to discern from run-to-run variability. Focusing solely on training multiple model copies to reduce uncertainty is time-consuming, costly, and affects reproducibility.", "key_idea": "This work proposes an experimental protocol for understanding the effect of optimization nondeterminism on model diversity and identifies instability in model training as the key determinant of run-to-run variability. The authors suggest that even one-bit changes in initial parameters can lead to models converging to vastly different values.", "method": "The authors establish an experimental protocol to isolate and understand the effects of various sources of nondeterminism on model diversity. The authors examine the effect of even one-bit changes in initial parameters on the models' convergence.", "outcome": "The authors find that all sources of nondeterminism have similar effects on measures of model diversity and that even one-bit changes in initial parameters result in models converging to vastly different values.", "future_impact": "The authors propose two approaches for reducing the effects of instability on run-to-run variability, potentially guiding future efforts to improve reproducibility and stability in neural network optimization.", "venue": "ICML", "year": 2021, "title": "Nondeterminism and Instability in Neural Network Optimization"}
{"pid": "5fa1490e91e011f3c6657664", "context": "Generalized linear models (GLMs) such as logistic regression are often used on sensitive datasets. Prior works that investigate GLMs under differential privacy (DP) constraints only provide private point estimates of the regression coefficients, failing to quantify parameter uncertainty.", "key_idea": "The authors introduce a noise-aware DP Bayesian inference method for a GLM, which allows the determination of which of the regression coefficients are statistically significantly different from zero.", "method": "The authors use logistic and Poisson regression examples to introduce their noise-aware DP Bayesian inference method, specifically analyzing it with respect to a noisy sum of summary statistics.", "outcome": "The authors have experimentally demonstrated that the posteriors obtained from their model are close to the non-private posteriors, whilst adhering to strong privacy guarantees.", "future_impact": "This work provides a method to determine which of the regression coefficients are statistically significantly different from zero, which could influence future works that seek to balance privacy concerns with analytical richness in data sets.", "venue": "ICML", "year": 2021, "title": "Differentially Private Bayesian Inference For Generalized Linear Models"}
{"pid": "62c28ae45aee126c0f8a148f", "context": "In cross-device Federated Learning (FL), the communication cost of transmitting full-precision models between edge devices and a central server is a bottleneck because of expensive, unreliable, and low-bandwidth wireless connections.", "key_idea": "The authors propose a novel FL framework named QSFL, aimed at optimizing FL uplink communication at both the client and model levels, using the Qualification Judgment (QJ) algorithm for client-level optimization and Sparse Cyclic Sliding Segment (SCSS) algorithm for model-level optimization.", "method": "The authors performed experimental testing of the QSFL framework, and developed an optimal hyperparameter searching algorithm based on theoretical analysis to enable QSFL to balance model accuracy and communication cost.", "outcome": "QSFL has been shown experimentally to achieve state-of-the-art compression ratios with only marginal model accuracy degradation.", "future_impact": "The QSFL framework could significantly improve the efficiency of uplink communication in Federated Learning by reducing communication costs, therefore possibly becoming a new standard for such operations.", "venue": "ICML", "year": 2022, "title": "QSFL: A Two-Level Uplink Communication Optimization Framework for Federated Learning."}
{"pid": "60f22b025244ab9dcb5c48a8", "context": "Gaussian Processes (GPs) offer accurate uncertainty estimates but have a cubic cost in the number of data instances. Typically, sparse GP approximations with learned inducing points and stochastic variational inference are used to reduce this cost. However, the inducing points determine the flexibility of the model, and a large number may be required for optimal results in some tasks.", "key_idea": "The authors propose to amortize the computation of the inducing point locations and the parameters of the approximate posterior distribution using a neural network, which takes a data instance as input and outputs the inducing point locations and parameters.", "method": "The proposed method is evaluated in several experiments against other state-of-the-art sparse variational GPs.", "outcome": "Their method performs similar to or better than other sparse variational GPs strategies. However, their method drastically reduces the number of inducing points as they depend on input data, thus making the model scale better to larger datasets and have faster training and prediction times.", "future_impact": "This change in approach to compute inducing points can lead to better scalability and faster execution times for sparsely approximated Gaussian Processes on larger datasets.", "venue": "ICML", "year": 2022, "title": "Input Dependent Sparse Gaussian Processes."}
{"pid": "a7cd1e9e-45e0-4a1f-b457-1522c9685149", "context": "The problem of cost-sensitive classification with example-dependent costs, also known as regression level set estimation, is considered. Previous studies proposed surrogate-based algorithms without theoretical justification.", "key_idea": "The authors introduce sufficient conditions on the surrogate loss for the existence of a surrogate regret bound. This includes example-dependent versions of the hinge, exponential, and other common losses.", "method": "The paper provides theoretical arguments for the existence of a surrogate regret bound under certain conditions on surrogate loss.", "outcome": "The proposed conditions on the surrogate loss imply that as the surrogate risk tends towards its optimal value, so does the expected misclassification cost.", "future_impact": "The study provides theoretical justification for some previously proposed surrogate-based algorithms and suggests others that have yet to be developed, which can guide future research in cost-sensitive classification.", "venue": "ICML", "year": 2011, "title": "Surrogate losses and regret bounds for cost-sensitive classification with example-dependent costs"}
{"pid": "5fae52e091e01157e1f024e1", "context": "Current attribution methods, which identify key features leading to model predictions, hinge on a so-called baseline input for feature perturbations. However, limited research has been conducted on the issue of baseline selection, and poor choices limit the ability of these methods to provide one-vs-one explanations for classifiers, particularly when some classes are more similar than others.", "key_idea": "This paper introduces GANMEX, a novel approach utilizing Generative Adversarial Networks (GANs) and incorporating the classifier to be explained as part of the adversarial networks. This method improves upon existing techniques by effectively selecting the baseline as the closest realistic sample which belongs to the target class.", "method": "The authors demonstrate how the GANMEX approach leads to better outcomes under the cascading randomization of the model and how it improves the saliency maps.", "outcome": "It was found that GANMEX baselines resulted in better performance on multiple evaluation metrics compared to existing baselines and led to superior results under cascading randomization of the model.", "future_impact": "The work contributes to improved model explanations by allowing attribution methods to provide true one-vs-one explanations, which can benefit classifiers dealing with similar classes. This is especially vital when it's necessary to focus on key differentiating characteristics rather than shared features across classes.", "venue": "ICML", "year": 2021, "title": "GANMEX: One-vs-One Attributions using GAN-based Model Explainability"}
{"pid": "628464625aee126c0faca2b4", "context": "Self-Supervised Learning (SSL) is an increasingly popular Machine Learning paradigm that trains models to transform complex inputs into representations without relying on explicit labels. Unfortunately, these models are often expensive to train and their exposure over inference APIs has introduced a new security threat of black-box extraction.", "key_idea": "The authors decide to explore model stealing attacks against SSL. Unlike traditional model extraction on classifiers that output labels, the models in SSL output higher dimensional representations, which introduces new challenges and opportunities for attacks.", "method": "The authors construct several novel attacks that train directly on a victim\u2019s stolen representations to study their efficiency and the quality of downstream models they enable.", "outcome": "The attacks constructed by the authors demonstrate that they are query efficient and enable high accuracy for downstream models, revealing the vulnerability of the current SSL model to extraction attacks.", "future_impact": "The authors highlight that existing defenses against model extraction are insufficient and not easily adapted to SSL, indicating the need for further research into defending against such extraction attacks on SSL models.", "venue": "ICML", "year": 2022, "title": "On the Difficulty of Defending Self-Supervised Learning against Model Extraction."}
{"pid": "60bdde338585e32c38af500e", "context": "The need to approximate the sum of distances of a given set of points to any 'shape' in a subspace presents a need for dimensionality reduction. It is an important area of exploration due to its relevance to problems including $k$-median, $k$-subspace approximation, and subspace clustering.", "key_idea": "The manuscript introduces a dimensionality reduction procedure that outputs a subspace of dimension $O(k^{3}/\\epsilon^6)$ where the projections and distances of each point to the subspace are enough to generate an $\\epsilon$-approximation to the sum of distances to any arbitrary shape that lies in a $k$-dimensional subspace.", "method": "The procedure accepts an $n \times d$ matrix, where each row denotes a data point, and it provides an output subspace and corresponding metric approximations.", "outcome": "The procedure reduces the data storage requirement to $(n+d)k^{3}/\\epsilon^6$ from nnz$(A)$, which potentially could be as large as $nd$. It also provides faster processing times for dense matrices and produces poly$(k/\\epsilon)$ size coresets for $k$-median and $(k,1)$-subspace approximation problems in polynomial time.", "future_impact": "The dimensionality reduction algorithm can be used further to obtain poly$(k/\\epsilon)$ size coresets for $k$-median and $(k,1)$-subspace approximation problems efficiently, potentially influencing future techniques in these fields.", "venue": "ICML", "year": 2021, "title": "Dimensionality Reduction for the Sum-of-Distances Metric"}
{"pid": "60bdde338585e32c38af4e17", "context": "Existing noise-robust semi-supervised deep generative models face challenges in tackling noisy labels and outliers simultaneously.", "key_idea": "The authors propose a novel noise-robust semi-supervised deep generative model called Unified Robust Semi-Supervised Variational Autoencoder (URSVAE). The model integrates a noise transition model and employs a robust divergence measure to ensure robustness towards outliers and alleviate the detrimental effects of noisy labels.", "method": "The effectiveness and the robustness of the URSVAE is evaluated on image classification tasks and is compared with the state-of-the-art approaches.", "outcome": "The experimental results show the superiority of the proposed framework in the presence of compound noise, demonstrating its enormous potential in the classification.", "future_impact": "The robustness demonstrated by the proposed model can inspire further research in the field of noise-robust semi-supervised learning techniques, particularly in dealing with noisy labels and outliers.", "venue": "ICML", "year": 2021, "title": "Unified Robust Semi-Supervised Variational Autoencoder"}
{"pid": "30ad7fc5-532c-4de3-a6a8-de436b4dd381", "context": "Predicting the probability distribution of a variable rather than its most likely value can be more useful in many applications, such as meteorology and finance. However, prediction becomes complex when the distribution of the phenomenon is significantly different from a normal distribution, as in the case of surf height data.", "key_idea": "The study proposes an ensemble of mixture density networks to predict the probability density function of surf height, with the objective of predicting if it will fall within a 'surfable' range.", "method": "The authors employed an ensemble of mixture density networks to examine surf data and predict the probability density function.", "outcome": "The evaluation proved the effectiveness of using an ensemble of mixture density networks for predicting the probability density function of surf height data.", "future_impact": "Although not directly stated, the successful implementation of the proposed method implies that it can be potentially used to improve predictions in areas where predicting the probability distribution of a variable is important, beyond just predicting most likely values.", "venue": "ICML", "year": 2005, "title": "Predicting probability distributions for surf height using an ensemble of mixture density networks"}
{"pid": "5f0d963491e011047aff9a89", "context": "Neural networks are often represented as graphs of connections between neurons, but there is currently little understanding of the relationship between the graph structure of the neural network and its predictive performance.", "key_idea": "The authors develop a novel graph-based representation of neural networks called 'relational graph', wherein layers of computation correspond to rounds of message exchange along the graph structure. They also explore how the graph structure of these networks impacts their performance.", "method": "To investigate the impact of the graph structure on the predictive performance of neural networks, the authors evaluated several models across various tasks and datasets.", "outcome": "The study findings include: a 'sweet spot' of relational graphs leading to significantly improved predictive performance; neural network's performance being a smooth function of the clustering coefficient and average path length of its relational graph; these findings being consistent across many different tasks and datasets; this 'sweet spot' can being identified efficiently; and top-performing neural networks having graph structures surprisingly similar to those of real biological neural networks.", "future_impact": "The work opens new directions for the design of neural architectures and improving the understanding of neural networks in general.", "venue": "ICML", "year": 2020, "title": "Graph Structure of Neural Networks"}
{"pid": "629435a05aee126c0f2fe396", "context": "Artificial neural nets can represent and classify many types of high-dimensional data but are often tailored to particular applications such as fair or hierarchical classification, which makes them difficult to adjust for new tasks.", "key_idea": "The authors propose a new neural network architecture, the concept subspace network (CSN), which can generalize existing specialized classifiers to learn a spectrum of multi-concept relationships.", "method": "To validate the proposed architecture, the authors benchmark the performance of CSN against state-of-the-art results in fair classification. Additionally, they evaluate its transformation capability into hierarchical classifiers and its potential to reconcile fairness and hierarchy within a single classifier.", "outcome": "The CSN is capable of reproducing state-of-the-art results in fair classification when enforcing concept independence, can be transformed into hierarchical classifiers, and can reconcile fairness and hierarchy within a single classifier. It also matches the performance of existing prototype-based classifiers that promote interpretability.", "future_impact": "The CSN could facilitate more flexible and adaptable machine learning models capable of handling diverse tasks and promote the interpretability within AI systems.", "venue": "ICML", "year": 2022, "title": "Prototype Based Classification from Hierarchy to Fairness."}
{"pid": "621849025aee126c0f552101", "context": "Normalized Discounted Cumulative Gain (NDCG) is a commonly used ranking metric in the fields of information retrieval and machine learning. However, efficient and proven methods for maximizing NDCG, specifically for deep models, are lacking.", "key_idea": "The authors propose a principled approach to optimize NDCG and its top-$K$ variant through the formulation of a new compositional optimization problem for optimizing the NDCG surrogate, and a novel bilevel compositional optimization problem for the top-$K$ NDCG surrogate.", "method": "Efficient stochastic algorithms with provable convergence guarantees for the non-convex objectives are developed. The methodologies also differentiate themselves from existing NDCG optimization methods, as the per-iteration complexity of the proposed algorithms scales with the mini-batch size instead of the total number of items.", "outcome": "Experimental results reveal that the proposed methods outperform prior ranking approaches in terms of NDCG. The work marks the first time that stochastic algorithms have been proposed to optimize NDCG with a provable convergence guarantee.", "future_impact": "The proposed methods are implemented in the LibAUC library and potentially others may utilize the method from there.", "venue": "ICML", "year": 2022, "title": "Large-scale Stochastic Optimization of NDCG Surrogates for Deep Learning with Provable Convergence."}
{"pid": "60bdde338585e32c38af5295", "context": "The problem of learning binary decision trees that partition data for downstream tasks has traditionally been tackled by separate learning paths for discrete parameters such as tree traversals and node pruning, and continuous parameters like tree split functions and prediction functions.", "key_idea": "This paper proposes learning these discrete and continuous parameters simultaneously using a method called argmin differentiation. This involves sparsely relaxing a mixed-integer program during the learning process to allow gradients to pass through the program to continuous parameters in the network.", "method": "The authors derive customized algorithms to efficiently compute the forward and backward passes, enabling the tree learning procedure to be used as an (implicit) layer in arbitrary deep networks, and to be optimized with arbitrary loss functions.", "outcome": "The proposed method is demonstrated to produce binary trees that are competitive with traditional single tree and ensemble approaches, across supervised and unsupervised settings. It is reportedly faster to train than all other tree-learning baselines, beyond greedy approaches that do not deliver competitive accuracies.", "future_impact": "This new approach to decision tree learning could potentially modify the way decision trees are integrated into deep networks and other machine learning models, potentially improving both the effectiveness and efficiency of these models.", "venue": "ICML", "year": 2021, "title": "Learning Binary Decision Trees by Argmin Differentiation"}
{"pid": "166c9508-e118-4c06-b439-cb9b6ccee085", "context": "During induction of decision trees in ensembles of classification and regression models, predicates that are maximally informative about the prediction target are sought. Common practices use information-theoretic scoring function, the information gain, to select good predicates for both classification and regression problems. However, these common estimation procedures are found to be biased.", "key_idea": "The authors propose to use improved estimators of the discrete and the differential entropy to replace common estimation procedures, arguing this would lead to the construction of better decision trees.", "method": "The information gain estimation procedures were replaced with improved estimators, and then used in decision tree code to ascertain whether these improved estimators can indeed obtain better decision trees.", "outcome": "As per the authors, the proposed modification yields improved predictive performance in decision trees.", "future_impact": "The authors suggest that the improved estimators are simple to implement in any decision tree code, indirectly implying potential widespread application and improved performance of decision tree models.", "venue": "ICML", "year": 2012, "title": "Improved Information Gain Estimates for Decision Tree Induction"}
{"pid": "5f7af0fe91e011983cc81f07", "context": "The adversarial robustness literature primarily considers two main attack models: black-box and white-box. The complexity of designing malicious attacks within these models has not been thoroughly investigated.", "key_idea": "The authors suggest considering black-box and white-box threat models not as distinct categories but as a fine-grained spectrum indexed by the number of queries an adversary can make. They aim to investigate how many queries an adversary needs to design an attack as effective as the best possible white-box attack.", "method": "The authors analyze two classical learning algorithms on two synthetic tasks. They propose a lower bound on the number of queries in terms of the entropy of decision boundaries of the classifier.", "outcome": "Using their approach, they demonstrate that some learning algorithms have more inherent robustness against query-bounded adversaries than others.", "future_impact": "The authors' findings encourage the design of learning algorithms that are inherently robust against query-bounded adversaries, building a pathway for further research on the topic.", "venue": "ICML", "year": 2021, "title": "Query Complexity Of Adversarial Attacks"}
{"pid": "23959e0f-dbfa-4675-bef6-7d64d54dae03", "context": "The speaker diarization system submitted for the NIST Rich Transcription evaluation (RT06s), known as the RT05s system, uses agglomerative clustering with a modified Bayesian Information Criterion (BIC) measure. However, it still required training data for operation.", "key_idea": "The authors present an upgraded version of the ICSI speaker diarization system that adds improvements such as a training-free speech/non-speech detection algorithm, a new system initialization algorithm, a frame purification algorithm, and the use of inter-channel delays as features, thereby eliminating the need for training data.", "method": "The authors use the official evaluation data from the RT06s, and test the system's performance using hand-aligned references and forced-alignments.", "outcome": "The authors demonstrate and explain the effectiveness of their system improvements using official evaluation data, but do not provide specific measureable results.", "future_impact": "Although not explicitly stated, the improvements proposed and tested in this paper could potentially lead to advancements in the field of speaker diarization and in applications involving multi-speaker environments in the future.", "venue": "ICML", "year": 2006, "title": "Robust speaker diarization for meetings: ICSI RT06S meetings evaluation system"}
{"pid": "6c14e7f3-eb92-4151-9e94-049b819453c0", "context": "Current research on multiple-instance learning, a problem of classifying a bag of instances given bags labeled by a teacher as being overall positive or negative, mainly focuses on adapting traditional concept learning.", "key_idea": "This paper proposes the use of lazy learning and Hausdorff distance to address the multiple-instance problem and presents two variants of the K-nearest neighbor algorithm, Bayesian-KNN and Citation-KNN, tailored for this problem.", "method": "The authors conducted experiments on the Drug discovery benchmark data, utilizing Bayesian-KNN and Citation-KNN to solve the multiple-instance problem.", "outcome": "The experiments found that both Bayesian-KNN and Citation-KNN are competitive with the best algorithms conceived in the traditional concept learning framework for multiple-instance problem solving.", "future_impact": "Further work suggested by the authors includes exploring the combination of lazy and eager multiple-instance problem classifiers, which could potentially enhance the performance of these types of problems.", "venue": "ICML", "year": 2000, "title": "Solving the Multiple-Instance Problem: A Lazy Learning Approach"}
{"pid": "35db74a6-cedb-402e-9272-84116fca2c31", "context": "Tree Augmented Naive Bayes (TAN), a classifier based on Bayesian networks, has been proven to outperform naive Bayes and compete with C4.5 and other state-of-the-art methods. However, its limitation is that it only applies to discrete attributes, requiring continuous attributes to be prediscretized.", "key_idea": "This paper proposes an extension to the TAN classifier to handle continuous attributes directly via parametric (e.g., Gaussians) and semiparametric (e.g., mixture of Gaussians) conditional probabilities, therefore amalgamating both discrete and continuous attributes. Moreover, the authors propose a method to use both discrete and continuous forms of an attribute simultaneously in classification.", "method": "The authors empirically test their method by comparing the classification performance achieved using their approach, with purely discrete or purely continuous TAN models.", "outcome": "Emerging empirical results suggest that the proposed method typically achieves classification performance that is as good as or better than either the purely discrete or the purely continuous TAN models.", "future_impact": "This work automates the process of deciding which form of an attribute is most suitable for a classification task and offers the flexibility to choose between a discretized or a (semi)parametric form depending on which correlates better with specific attributes.", "venue": "ICML", "year": 1998, "title": "Bayesian Network Classification with Continuous Attributes: Getting the Best of Both Discretization and Parametric Fitting"}
{"pid": "5ede0553e06a4c1b26a8420a", "context": "There is ongoing research into deriving optimal bounds on sample complexity of latent variable models. Although such bounds have been obtained for Mixture of Gaussian models, they are unknown for Ad-mixtures, a generalization of Mixture distributions.", "key_idea": "This paper presents the first sample complexity upper bound for the problem of learning the vertices of a Latent k-Polytope in R^d, given perturbed points from it. The result is a corollary of the research showing it is sufficient to learn each of k-topic vectors of LDA (a popular Ad-mixture model) with O^*(dk/m) samples.", "method": "The authors specialize the setting to Mixed Membership Stochastic Block Models (MMSB) and validate the generality of the approach.", "outcome": "The provided bound, O^*(dk/\u03b2), is shown to be optimal and linear in the number of parameters. It applies to many stochastic models including a broad class Ad-mixtures.", "future_impact": "The derived sample complexity bounds can serve as a stepping stone for further research, especially around ad-mixtures, LDA models, and Mixed Membership Stochastic Block Models.", "venue": "ICML", "year": 2020, "title": "Near-optimal sample complexity bounds for learning Latent $k-$polytopes and applications to Ad-Mixtures"}
{"pid": "62c28ae55aee126c0f8a1996", "context": "Cooperative multi-agent reinforcement learning (MARL) is being used to solve tasks in grid world and real-world scenarios. In these scenarios, agents have different attributes and goals, leading to different behaviors during the task execution.", "key_idea": "The study proposes 'Role Diversity', a metric designed to measure and quantify the behavioral difference of agents in MARL tasks. Role Diversity is defined from three perspectives: action-based, trajectory-based, and contribution-based.", "method": "Role Diversity's impact on policy optimization is theoretically analyzed, particularly in relation to parameter sharing, communication mechanism, and credit assignment. Experimental validation is conducted on two platforms: Multiagent Particle Environment (MPE) and The StarCraft Multi-Agent Challenge (SMAC).", "outcome": "Theoretical analysis shows that the error bound in MARL can be decomposed into three parts strongly related to Role Diversity. Experimental results demonstrate that Role Diversity can be a robust measurement for diagnosing whether the policy fits the current multi-agent system for better policy performance.", "future_impact": "Role Diversity might be used as a diagnostic tool to help improve policy performance in multi-agent reinforcement learning scenarios in the future.", "venue": "ICML", "year": 2022, "title": "Policy Diagnosis via Measuring Role Diversity in Cooperative Multi-agent RL."}
{"pid": "51f244a0-19e3-40c4-8cf3-f3051a9473cc", "context": "Valiant's formal model of concept learning is highly regarded due to strong performance guarantees, however its application is limited as it considers a narrow range of learnable concept classes.", "key_idea": "The author suggests two strategies to extend Valiant's model: allowing a learner to experiment with the environment and considering a measure of proximity between two concept classes, called density, to extend the learning model.", "method": "The author explores the power gained by including learning by experimentation in the model. Additionally, density, the proposed measure of proximity between two concept classes, is used as a novel extension of the model.", "outcome": "It was demonstrated that in a specific case, no additional power is added by allowing learning by experimentation within the standard model. However, a different model demonstrated significant differences. Density showed that a concept close to the concept under learning can be determined through only polynomial examples.", "future_impact": "The research leaves open the question of whether learning by experimentation is equivalent to learning from examples in the general case. Its findings would stimulate further examination of the Valiant model's appropriate use in functions of experiments in science and the wider use of density as a measure of bias suitability.", "venue": "ICML", "year": 1988, "title": "Extending the Valiant Learning Model"}
{"pid": "609a6c4ae4510cd7c88cad58", "context": "The concept of Big Data has become popular in various fields, including military field, after the emergence of cloud computing.", "key_idea": "This paper undertakes an analysis of the features of equipment support data and the demands of equipment support capacity building in the context of Big Data, and proposes ways to build equipment support capacity.", "method": "The methodology of this paper involves an analysis of equipment support data and the requirements of equipment support capacity construction within the context of Big Data.", "outcome": "This paper proposes ways for equipment support capacity building based on the analysis.", "future_impact": "The findings provide references for building equipment support capacity for the army in the new era.", "venue": "ICML", "year": 2020, "title": "Thinking of Equipment Support Capacity Building based on Big Data"}
{"pid": "6163ab255244ab9dcbf95dbe", "context": "Standard training datasets for deep learning often lack objects in uncommon and rare settings, causing models to inaccurately predict objects based on the image's context rather than the objects present.", "key_idea": "The authors introduce FOCUS (Familiar Objects in Common and Uncommon Settings), a dataset designed to test the generalizability of deep image classifiers. The dataset includes objects in a variety of settings, including different locations, weather conditions, and times of day.", "method": "The authors collected data via modern search engines and evaluated the performance of various popular image classifiers on the dataset. They also fine-tuned a model on the FOCUS dataset to study the improvement in its ability to focus on the object of interest.", "outcome": "The classifiers demonstrated a significant drop in accuracy when tasked with classifying images in uncommon settings. After fine-tuning a model on the FOCUS dataset, it showed improved generalization, especially focusing on the object of interest.", "future_impact": "The authors anticipate their dataset will assist researchers in understanding the inability of deep models to generalize well to uncommon settings and could lead to future work to improve the distributional robustness of these models.", "venue": "ICML", "year": 2022, "title": "FOCUS: Familiar Objects in Common and Uncommon Settings."}
{"pid": "5ede0553e06a4c1b26a84125", "context": "In multilayer networks, where entities interact via multiple types of relations, the networks often share common structures, while each layer can exhibit distinct node connecting behaviors.", "key_idea": "The paper proposes a new flexible latent space model for multilayer networks, which embeds each node with a latent vector shared among layers and a layer-specific effect for each layer.", "method": "To fit the model, a projected gradient descent algorithm is developed for efficient parameter estimation. Theoretical properties of maximum likelihood estimators are also established, showing the upper bound of the common latent structure's estimation error is inversely proportional to the number of layers under some conditions.", "outcome": "Through simulation studies and applications to two real-world data examples, it is shown that the proposed model offers superior performance.", "future_impact": "The proposed latent space model is flexible and efficient for dealing with multilayer networks, and could be influential in further network analysis.", "venue": "ICML", "year": 2020, "title": "A Flexible Latent Space Model for Multilayer Networks"}
{"pid": "6037667cd3485cfff1da4517", "context": "Intangible Cultural Heritage (ICH) currently relies on traditional communication methods, which may not be sufficient in capturing the attention of fast-paced information consumer audiences.", "key_idea": "The paper proposes the use of intelligent media technology to create a new pseudo-environment for ICH communication which can capture audience attention and achieve accurate push.", "method": "The authors suggest improving the ICH brand communication system by improving branded communication accuracy, refining core brand symbols and values, strengthening brand creativity and development communication, and protecting the intellectual property rights of communication brands.", "outcome": "By utilizing intelligent media technology, the paper posits that it's possible to expand the ICH communication groups and consumer subjects, and build a new modern communication network for ICH.", "future_impact": "The implementation of this method can contribute significantly to building the national cultural soft power and improving the national image. Moreover, following the rules of modern information communication can strengthen community protection of ICH and achieve orderly and harmonious development.", "venue": "ICML", "year": 2020, "title": "Intelligent Media Technology Empowered Brand Communication of Chinese Intangible Cultural Heritage"}
{"pid": "5f0d8faa91e011047aff99b4", "context": "Current self-supervised representation learning (SSL) methods are based on the contrastive loss and the instance-discrimination task, relying on many negatives to compare with a positive pair, which is computationally demanding.", "key_idea": "The authors propose a new loss function for SSL, which is based on the whitening of the latent-space features, having a scattering effect on the batch samples to avoid degenerate solutions. This new approach enables the extraction of multiple positive pairs from the same image instance without the need for negatives.", "method": "The authors presented their method by applying their proposed loss function on latent-space features in self-supervised learning, but specific experimental setups are not detailed in the abstract.", "outcome": "The abstract does not provide specific outcomes or results derived from the application of the proposed method.", "future_impact": "The source code for the methods and the experiments has been made publicly available, suggesting potential impact in terms of use by others in the field for self-supervised learning tasks.", "venue": "ICML", "year": 2021, "title": "Whitening For Self-Supervised Representation Learning"}
{"pid": "5db9b0b7-8594-41bd-99c4-27bc4f0a1616", "context": "Given the challenge of constructing maximally general terms covering positive examples while rejecting negative examples in first-order logic (FOL), Version Spaces are often used.", "key_idea": "The authors propose a bottom-up generalization algorithm in FOL that reframes negative examples as constraints on the generalization of the positive example at hand.", "method": "In this algorithm, the constraints space, which orders the negative examples, is used to formally conceptualize Winston\u2019s definition of near-misses in FOL as negative examples minimal with respect to this partial order.", "outcome": "The developed algorithm demonstrates that only near-misses are needed to construct the set G, and that constraints can be directly applied to classify future examples.", "future_impact": "The algorithm has the potential to improve FOL by offering a cogent method for formulating near-misses and thereby minimizing necessary data for the creation of the set G, while also efficiently classifying further examples.", "venue": "ICML", "year": 1994, "title": "A constraint-based induction algorithm in FOL"}
{"pid": "5ede0553e06a4c1b26a83fcd", "context": "Discrete choice models with unobserved heterogeneity are commonly used in Econometric models and require the calculation of a functional fixed point for optimal policy prediction. These models are often used in dynamic economic behaviour prediction including strategic decisions. However, these models often assume fully rational optimizing agents, which may not always hold true in real-world scenarios.", "key_idea": "The authors propose that in a certain class of discrete choice models, the value function is globally concave in the policy, which allows to use simpler algorithms, such as the policy gradient algorithm, to converge to the optimal policy.", "method": "The authors use policy gradient algorithm, a simple optimization approach that doesn't require fixed point computation, to validate their theoretical findings. They compare this method to existing 'nested fixed point' algorithms used in Econometrics.", "outcome": "The policy gradient algorithm demonstrated significant computational advantages over existing 'nested fixed point' algorithms, establishing its effectiveness in converging to the optimal policy without assuming fully rational agents.", "future_impact": "This finding could be used to relax behavioral assumptions regarding optimizing agents and to facilitate Econometric analysis of dynamic behavior.", "venue": "ICML", "year": 2020, "title": "Global Concavity and Optimization in a Class of Dynamic Discrete Choice Models"}
{"pid": "13356d13-5f58-40ed-bdeb-ec7310cbc384", "context": "Submodular maximization is a crucial task in dealing with large-scale machine learning problems, however, existing methods require significant memory and are complex to evaluate.", "key_idea": "The authors propose a new multi-stage algorithmic framework (MULTGREED) that applies an approximate greedy procedure to maximize surrogate submodular functions that act as proxies for a target submodular function, requiring less memory and being simpler to evaluate.", "method": "The authors perform a theoretical analysis of the multi-stage framework\u2019s performance and explain the design instances of MULTGREED for a variety of natural submodular functions. They also carry out empirical evaluation on several real-world problems, including data subset selection on millions of speech samples.", "outcome": "MULTGREED performs closely to the standard greedy algorithm given appropriate surrogate functions and yields at least a thousand times speedup and superior results over the state-of-the-art selection methods in data subset selection on millions of speech samples.", "future_impact": "The paper hints at the potential for the proposed MULTGREED framework to be easily integrated with distributive algorithms for further optimization, suggesting its future impact on improving large-scale machine learning tasks.", "venue": "ICML", "year": 2014, "title": "Fast Multi-stage Submodular Maximization"}
{"pid": "60bdde338585e32c38af4ee4", "context": "Livestreaming ecommerce, promotions and recommendations have presented a new challenge in multi-armed bandit problems due to two distinct features: the ability to pull rewards from a limited number of arms per time period, and the non-parametric recovery of expected rewards of an arm after it is pulled.", "key_idea": "A new type of 'Purely Periodic Policies' is proposed in order to maximize the expected cumulative rewards over a period of time in the new class of multi-armed bandit problems.", "method": "The performance of the proposed policy is evaluated in both offline (known model parameters) and online (unknown model parameters, requiring learning) scenarios.", "outcome": "For the offline problem, the proposed policy achieved an approximation ratio of 1 - O(1/root K), which is asymptotically optimal as K grows to infinity. For the online problem, an Upper Confidence Bound (UCB) based policy design reported an approximate O(N root T) regret against the offline benchmark.", "future_impact": "The design of the proposed policies could be adapted for other offline planning and online learning applications dealing with non-stationary and recovering rewards.", "venue": "ICML", "year": 2021, "title": "Dynamic Planning and Learning under Recovering Rewards"}
{"pid": "d47aead4-26ca-4b36-b331-69685fab5eb0", "context": "The coverage of a learning algorithm is the number of concepts that can be learned by that algorithm from samples of a given size. It's an ongoing question whether good learning algorithms can be designed by maximizing their coverage.", "key_idea": "This paper extends a previous upper bound on the coverage of any Boolean concept learning algorithm and describes two algorithms\u2014Multi-Balls and Large-Ball\u2014whose coverage approaches this upper bound. It also introduces a novel concept of coverage within a bias, suggesting a way that coverage maximization could be applied to strengthen weak preference biases.", "method": "The researchers conduct an experimental measurement of the coverage of the ID3 and FRINGE algorithms and carry out an analysis of the Large-Ball algorithm.", "outcome": "The researchers show that the coverage of the ID3 and FRINGE algorithms is far below the upper bound. They also find that the Large-Ball algorithm learns many concepts, but these do not seem to be very interesting.", "future_impact": "Although maximizing coverage alone does not yield practically-useful learning algorithms, the study introduces the concept of coverage within a bias, suggesting a potential path for improving and strengthening weak preference biases in learning algorithms.", "venue": "ICML", "year": 1992, "title": "On Learning More Concepts"}
{"pid": "f2abadd3-1464-422c-9418-be149ce6b534", "context": "Traditional methods for automatically detecting anatomic structures in medical images require off-line learning, which requires collecting all representative samples before training begins.", "key_idea": "The paper proposes a new online learning method that eliminates the need for storing historical training samples and can continuously enhance its performance with new samples.", "method": "The authors evaluate their approach using three distinct thoracic structures and compare its performance to the offline approach.", "outcome": "The results show that the proposed online learning method achieves competitive performance compared to the offline approach.", "future_impact": "This method of online learning in medical images could provide a way to continually enhance performance as new samples become available, providing an alternative to conventional offline learning methods.", "venue": "ICML", "year": 2011, "title": "Automated detection of major thoracic structures with a novel online learning method"}
{"pid": "60bdde338585e32c38af4ef9", "context": "Goodfellow et al., 2014, observed that linear interpolation between initial neural network parameters and those converged after training with SGD typically leads to a Monotonic Linear Interpolation (MLI) property, despite non-convex objectives and highly non-linear training dynamics.", "key_idea": "The authors extend previous work on the MLI property by evaluating hypotheses that have not yet been explored, and draw connections between the interpolated paths in function space and the monotonicity of the network by using tools from differential geometry.", "method": "The study uses differential geometry to analyze the interpolated paths in the function space and the monotonicity of the network under mean squared error. Additionally, they systematically create networks that violate the MLI property by encouraging the weights to move far from initialization.", "outcome": "The authors establish sufficient conditions for the MLI property and demonstrate that networks violating the MLI property can be produced systematically, by encouraging the weights to move far from initialization.", "future_impact": "The MLI property raises important questions about the loss landscape geometry of neural networks and highlights the need to further study their global properties.", "venue": "ICML", "year": 2021, "title": "On Monotonic Linear Interpolation of Neural Network Parameters"}
{"pid": "61ea24975244ab9dcbabc4ec", "context": "Unconstrained Online Linear Optimization (OLO) is a practical problem setting to study the training of machine learning models, and potential-based algorithms have been proposed to tackle this problem. However, the design of these potential functions typically heavily relies on guessing.", "key_idea": "The authors propose a framework that generates new potential functions by solving a Partial Differential Equation (PDE) to optimize the Unconstrained Online Linear Optimization problem setting.", "method": "The proposed framework produces a novel algorithm that attains an optimal loss-regret trade-off without needing the impractical doubling trick. This is done particularly when losses are 1-Lipschitz.", "outcome": "The novel algorithm achieves a regret bound of $C\\sqrt{T}+||u||\\sqrt{2T}[\\sqrt{\\log(1+||u||/C)}+2]$, where $C$ is a user-specified constant, and $u$ is any comparator unknown and unbounded a priori. It also provides a lower bound that demonstrates the leading order term, including the constant multiplier $\\sqrt{2}$, is tight.", "future_impact": "The proposed algorithm is the first to achieve such optimalities, indicating a promising direction and framework for generating potential functions and achieving optimality in online learning scenarios.", "venue": "ICML", "year": 2022, "title": "PDE-Based Optimal Strategy for Unconstrained Online Learning."}
{"pid": "51d1c257-054c-4556-98f9-a32fad35c6db", "context": "The status quo involves Explanation-Based Learning techniques that are typically used to learn plans or macro-operators in specific orientations, i.e., goal oriented, and are used by nonlinear planners.", "key_idea": "A new Explanation-Based Learning technique is presented that deviates from the norm by learning invariant patterns in the application domain that are not plans, not macro-operators, not goal oriented, and can be utilized by nonlinear planners.", "method": "The LIFE system is described as being used for the automatic discovery, learning, and usage of invariants and makes use of a new kind of explanation structure called a blocking graph which doesn't rely on a problem-solving trace. A theoretical analysis is conducted based on temporal generalization using mathematical induction for reasoning about impossibility.", "outcome": "The new learning method is established as distinct from standard Explanation-Based Learning, particularly in the area of planning, with experimental results to demonstrate its potential.", "future_impact": "The development and application of this new Explanation-Based Learning technique could potentially affect more intractable domains due to the use of mathematical induction for reasoning about impossibility.", "venue": "ICML", "year": 1989, "title": "Learning invariants from explanations"}
{"pid": "2da2c7da-aff2-4c92-b50b-2eb6c87773eb", "context": "Many applications can be formalized as constrained non-linear optimization tasks. However, current numerical methods for solving such problems are brittle and lack scalability.", "key_idea": "This paper proposes a method to improve the efficiency and reliability of numerical optimization by optimizing the computation of the objective function and splitting it into special cases with differentiable closed forms.", "method": "The authors replace a single inefficient non-gradient-based optimization with a set of efficient numerical gradient-directed optimizations that can be performed in parallel. This method was tested in the domain of 2-dimensional structural design.", "outcome": "The proposed method led to a 95% speedup over traditional optimization methods and reduced the reliance of numerical methods on having an optimal starting point.", "future_impact": "The suggested method could provide an optimized approach for tackling constrained non-linear optimization problems in various applications, contributing to efficiency and throughput improvement.", "venue": "ICML", "year": 1991, "title": "Knowledge compilation to speed up numerical optimization"}
{"pid": "1465bbf1-8257-41ae-8f5d-59175f10448e", "context": "In a scenario with no noise in data, learning algorithms are linked to \u03b3(Alg), the set of prior probability distributions for which they are regarded as optimal, where X and Y are finite.", "key_idea": "The paper introduces a method to construct \u03b3(Alg) from Alg and explores the relationship between the various \u03b3(Alg). It identifies and investigates improper algorithms, ones that have a \u03b3(Alg) with zero volume, using linear algebra.", "method": "To illustrate the upshots of \u03b3(Alg) with zero volume, characteristics of improper algorithms are investigated. Two examples of such algorithms are given. The mathematical structure and application of this framework are used to address questions about selecting between competing algorithms.", "outcome": "The paper characterizes 'leave-one-out' cross-validation as a basic method of ML-II prior selection. It examines how mathematical findings apply to practical problems.", "future_impact": "The author points to possible future work but does not explicitly identify what it could involve or how it could extend this study.", "venue": "ICML", "year": 1995, "title": "A Bayesian Analysis of Algorithms for Learning Finite Functions"}
{"pid": "58fbf42d-52c5-49d8-aaf3-1469af8e84f8", "context": "Cell cycle study using time-lapse fluorescent microscopy images is crucial for understanding cell division mechanisms and screening of anti-cancer drugs. However, tracking individual cells in a dense population is challenging due to their complex behaviors and similarity.", "key_idea": "A novel tracking algorithm is proposed to overcome these challenges. This features the use of local neighboring information to distinguish nearby cells with similar morphology, and the Interacting Multiple Model (IMM) filter to account for cell migrations.", "method": "The algorithm employs integer programming to achieve the most stable association between cells in two consecutive frames based on a similarity metric integrating local neighboring information, migration prediction, shape, and intensity. It was evaluated on high content screening assays of HeLa cancer cell populations.", "outcome": "The proposed method achieved an average tracking accuracy of 92%.", "future_impact": "This method could improve the study of cell cycles by enabling accurate tracking of individual cells in high content screening assays of cancer cell populations, potentially leading to advances in understanding of cell division and the screening of anti-cancer drugs.", "venue": "ICML", "year": 2010, "title": "Optimal live cell tracking for cell cycle study using time-lapse fluorescent microscopy images"}
{"pid": "5e7b2bf091e011a9394ab430", "context": "Sitting improperly can have a negative impact on the health of the spine, causing early degradation. There is a need to encourage and remind people to sit correctly.", "key_idea": "This study proposed a method of computing sitting angles and developed a mobile application to alert users when they are not sitting properly.", "method": "The authors used a digital protractor and an accelerometer-equipped smartphone to collect data and derive regression equations. These equations were used to calculate the angles between the upper and lower body and the angles on the left and right sides of the upper body while sitting. The study also created a mobile application and used an Android sensor fusion application to stream the accelerometer data over a local network to a PC-based program for testing the setup.", "outcome": "The results showed that the proposed method and application could accurately calculate sitting angles and successfully alert users when they were sitting improperly.", "future_impact": "The mobile application developed in this study could potentially help reduce spine health issues caused by improper sitting by alerting users to correct their posture.", "venue": "ICML", "year": 2020, "title": "Developing A Mobile Application To Detect Improper Sitting Using Regression Analysis And An Accelerometer"}
{"pid": "5e0c6dcc3a55acc9707f3818", "context": "Gaussian processes (GPs) offer flexible function distributions, but their performance suffers in high-dimension applications due to the curse of dimensionality. This difficulty can be alleviated with low-dimensional projections, but these add numerous trainable hyperparameters, posing challenges in small data scenarios.", "key_idea": "The authors propose using additive sums of kernels, with each kernel targeting a different random projection of the inputs for GP regression. They also propose a deterministic alternative to random projections that converges more readily.", "method": "The authors investigate the predictive performance of their approach as the number of random projections increases. Through this, they compare its performance with that of a kernel operating on full-dimensional inputs across a range of data sets.", "outcome": "The results demonstrate that as the number of random projections increases, the performance quickly matches that of a kernel operating on full-dimensional inputs. The approach enables many problems to be reduced to one-dimensional input spaces without requiring a transformation.", "future_impact": "This approach promises faster inference and improved predictive accuracy for high-dimensional inputs compared to kernels in the original input space. This could potentially reshape future work on high-dimensional data in Gaussian Process Regression.", "venue": "ICML", "year": 2020, "title": "Randomly Projected Additive Gaussian Processes for Regression"}
{"pid": "60bdde338585e32c38af51c8", "context": "Prior work in reinforcement learning (RL) has investigated the use of natural language in controlling policies but has assumed prior knowledge connecting text and state observations.", "key_idea": "The authors introduce a new multi-task environment, MESSENGER, with free-form text manuals describing the environment dynamics, and present a new model called EMMA (Entity Mapper with Multi-modal Attention), which grounds the game manual without assuming prior text-state links and selectively focuses on entities in the environment.", "method": "EMMA uses an entity-conditioned attention module and learns a latent grounding of entities and dynamics from text to observations using solely the rewards from the environment. They tested its capability to generalize to unseen games.", "outcome": "EMMA showed successful zero-shot generalization capabilities to unseen games, obtained a 40% higher win rate compared to multiple baselines, although the win rate on the hardest stage of MESSENGER remains low at 10%.", "future_impact": "The study's results have shown that there is a need for further exploration and investment in developing techniques that improve the capabilities of models to generalize from text to RL tasks.", "venue": "ICML", "year": 2021, "title": "Grounding Language To Entities And Dynamics For Generalization In Reinforcement Learning"}
{"pid": "0fe7c313-6d7a-4e19-b7dd-a0412e520dc4", "context": "In speaker diarization, determining where each participant speaks, the commonly used technique is agglomerative clustering. The choice of complexity, topology, and the number of initial models is vital for the final outcome. In prior systems, these parameters were directly assigned based on development data and were the same for all recordings.", "key_idea": "This paper presents three techniques to select the parameters individually for each case, aiming for more robustness against changes in the data.", "method": "The authors present and test the three novel techniques for parameter selection on development sets and test sets.", "outcome": "The authors achieve an improvement up to 8% relative in the development set and 19% relative in the test set over prior systems.", "future_impact": "The methods presented in this paper allow for developing individualized parameters in speaker diarization, making systems more robust to changes in data thus improving the quality and reliability of speaker diarization technologies.", "venue": "ICML", "year": 2006, "title": "Automatic cluster complexity and quantity selection: towards robust speaker diarization"}
{"pid": "62b288a45aee126c0fbd7cbb", "context": "Efficient algorithms for solving high-dimensional partial differential equations have been developed recently through the combination of Monte Carlo methods and deep learning. These learning problems are often formulated as variational methodologies based on stochastic differential equations (SDEs), which are optimized using gradient-based methods. However, achieving accurate and swift convergence in numerical implementations requires low-variance gradient estimators.", "key_idea": "The paper proposes a rigorous examination of the numerical aspects that appear in the context of linear Kolmogorov PDEs and suggests novel methods which can be more robust.", "method": "After a detailed analysis of existing deep learning approaches for solving PDEs, the authors have proposed and evaluated new methods using both a theoretical approach and numerical techniques.", "outcome": "The proposed methods were found to be more robust both theoretically and numerically, offering significant performance improvements over existing techniques.", "future_impact": "The novel methods proposed in this study can enhance the accuracy and efficiency of solving linear Kolmogorov partial differential equations. This could potentially impact many fields where such equations are encountered.", "venue": "ICML", "year": 2022, "title": "Robust SDE-Based Variational Formulations for Solving Linear PDEs via Deep Learning."}
{"pid": "603f524191e011cacfbda1ba", "context": "In most strategic learning settings, such as loan approvals or college admissions, it is typically assumed that individuals have full knowledge of the decision-making protocols. However, in reality, these decision rules are frequently inaccessible.", "key_idea": "The researchers examine scenarios in which decision-making rules are unknown to individuals who then rely on learning from peers, which leads to the formation of groups with different levels and types of information about the decision rules. The authors propose an 'information overlap proxy' to evaluate the disparity in improvement across sub-populations.", "method": "Theoretical analysis based on the study of welfare optimization across sub-populations is conducted, followed by empirical evaluation conducted on real-world datasets.", "outcome": "The study shows that optimizing the principal\u2019s decision rule for welfare across sub-populations could cause a negative externality as the true quality of some of the groups may deteriorate. However, in many cases, optimal improvement can be guaranteed for all sub-populations simultaneously.", "future_impact": "The study identifies conditions that allow for improvement across all sub-populations while maintaining high predictive accuracy. This could prompt reconsideration and potential improvements in practice across domains where strategic learning and decision-making are key.", "venue": "ICML", "year": 2022, "title": "Information Discrepancy in Strategic Learning."}
{"pid": "b5e42fa0-a709-4eef-80e9-15a5a116b425", "context": "Existing models that analyze joint distributions of groups of observations that co-occur with ordinal response variables often rely on improper statistical assumptions for ordinal variables, leading to less effective predictive ability and knowledge extraction.", "key_idea": "The authors propose a new class of mixed membership models for analyzing joint distributions of observation groups co-occurring with ordinal response variables, designed to improve statistical associations between the ordinal response variables and the observation groups.", "method": "To validate their models, the authors apply them to a collection of consumer data consisting of unstructured text reviews of mobile software applications, each accompanied with an ordinal rating. These models were also compared to existing works to determine improvements.", "outcome": "The proposed models demonstrated the ability to infer useful and meaningful recurring patterns of consumer feedback and showed significant improvements over existing models in both predictive ability and knowledge extraction.", "future_impact": "The proposed class of models addresses a requirement for improved predictive and diagnostic methods in wide-ranging practical contemporary applications.", "venue": "ICML", "year": 2015, "title": "Ordinal Mixed Membership Models"}
{"pid": "9c0a9a09-5acc-4fdd-b40e-45d22e1e38ff", "context": "Many computational problems can be solved by multiple algorithms, with different algorithms fastest for different problem sizes, input distributions, and hardware characteristics. Traditionally, the problem of algorithm selection involves dynamic choice of an algorithm to minimize the overall execution time.", "key_idea": "The authors formulate the problem of algorithm selection as a kind of Markov decision process (MDP) and use ideas from reinforcement learning to solve it. They also introduce a unique type of MDP that models the algorithm selection problem by allowing multiple state transitions.", "method": "The authors adapt the well-known Q-learning algorithm for their MDP in a way that combines both Monte-Carlo and Temporal Difference methods. They also extend the Least-Squares Temporal Difference algorithm (LSTD(0)) to control problems. The methodology is tested on classic problems of order statistic selection and sorting.", "outcome": "The experimental results show the potential of applying learning methods to traditional computational problems, suggesting that the proposed approach is promising but, as stated by the authors, require further confirmation through broader studies.", "future_impact": "The proposed approach potentially opens a new avenue for dynamic algorithm selection methods and could influence the development of new learning methods applicable to traditional computational problems.", "venue": "ICML", "year": 2000, "title": "Algorithm Selection using Reinforcement Learning"}
{"pid": "62a7fc625aee126c0ff5dbfe", "context": "Traditional feature selection methods in supervised learning usually require fitting and evaluating a large number of models, specifically 2^p models for a p-dimensional feature space.", "key_idea": "The authors introduce a new concept, e-value, a scalar quantity representing the proximity of the sampling distribution of parameter estimates in a model trained on a subset of features to that of the model trained on all features, aiming to provide a more efficient method for feature selection.", "method": "The concept of e-values is implemented using data depths and a fast resampling-based algorithm in a feature selection procedure. This approach was tested through experiments across several model settings and on both synthetic and real datasets.", "outcome": "The experiment results suggest that e-values can separate models that contain all essential features from those that do not, and only require evaluating p+1 models for a p-dimensional feature space, offering a potentially more efficient alternative to existing model-specific methods of feature selection.", "future_impact": "The e-values framework is applicable to a wide range of parametric models, suggesting its potential as a general alternative to existing model-specific methods of feature selection.", "venue": "ICML", "year": 2022, "title": "Feature selection using e-values."}
{"pid": "e90f8810-a9cf-4ac9-98b6-4f89f78cb360", "context": "Relational reinforcement learning (RRL) uses models of the world to enhance learning. However, learning perfect models is often not possible, necessitating probabilistic methods for handling uncertainty.", "key_idea": "The authors propose an algorithm that takes a middle ground between model-free and model-based RRL. A model of world dynamics is learned incrementally using a relational Dynamic Bayesian Network (DBN). ", "method": "The authors test the competence of their proposed algorithm by comparing its performance with traditional RRL Q-learners.", "outcome": "Findings show that sampling from the partially learned model performs better than traditional RRL Q-learners.", "future_impact": "The authors highlight open problems like the potential utility of other SRL techniques in RRL context, and the need to efficiently combine, evaluate and utilize partial knowledge chunks, which could be interesting propositions for future research.", "venue": "ICML", "year": 2006, "title": "Model-assisted approaches for relational reinforcement learning: Some challenges for the SRL community"}
{"pid": "5ede0553e06a4c1b26a83ea2", "context": "The study of the algorithmic stability and generalization of stochastic gradient descent (SGD) has gained considerable attention recently. However, the existing stability analysis requires restrictive assumptions on bounded gradients, strong smoothness, and convexity of loss functions.", "key_idea": "The paper provides a fine-grained analysis of stability and generalization for SGD by significantly relaxing these assumptions. The key idea is the introduction of a new stability measure called 'on-average model stability', controlled by risks of SGD iterates.", "method": "The research exposes the relaxed stability measure with Holder continuous (sub)gradients and non-differentiable loss functions to obtain optimal bounds by balancing computation and stability. The study also examines learning problems with (strongly) convex objectives and non-convex loss functions.", "outcome": "The study offers generalization bounds based on the behavior of the best model and produces first-ever-known fast bounds in a low-noise setting using a stability approach. It also reveals the first-ever-known stability and generalization bounds for SGD with non-differentiable loss functions.", "future_impact": "The results could lead to improved understanding and utilization of SGD under less restrictive assumptions, potentially expanding its use in different learning problems.", "venue": "ICML", "year": 2020, "title": "Fine-Grained Analysis of Stability and Generalization for Stochastic Gradient Descent"}
{"pid": "60bdde338585e32c38af5259", "context": "The Dirichlet Belief Network (DirBN) is a deep generative model that learns interpretable deep latent distributions for objects. While promising, it is limited in its representation capability due to the similarity in latent distributions across different layers, reducing the flexibility of the overall distribution.", "key_idea": "To address these constraints, this study proposes a new model, the Poisson-randomised Dirichlet Belief Networks (Pois-DirBN), to enable large mutations for the latent distributions across each layer, enhancing representation capability.", "method": "Pois-DirBN first introduces a component-wise propagation mechanism. It then uses a layer-wise Gibbs sampling algorithm to infer the latent distributions, creating more effective layers compared to DirBN. Finally, the model applies to relational modeling and validates its effectiveness through improved link prediction performance and more interpretable latent distribution visualisations.", "outcome": "The study demonstrates that the Pois-DirBN model facilitates larger variations in latent distributions across different layers compared to DirBN. The proven effectiveness of the method is showcased through improved link prediction performance and more interpretable latent distribution visualisations.", "future_impact": "The improved representation capability provided by Pois-DirBN model has potential benefits for enhancing deep learning modeling methods and further development in generative models.", "venue": "ICML", "year": 2021, "title": "Poisson-Randomised Dirbn: Large Mutation Is Needed In Dirichlet Belief Networks"}
{"pid": "61fb47e15aee126c0f873a2c", "context": "Differentiable simulators propose faster computation time for reinforcement learning by replacing zeroth-order gradient estimates of a stochastic objective with first-order gradients. However, it remains unclear how the performance of these two estimators compares in complex landscapes involving long-horizon planning and control on physical systems.", "key_idea": "The authors propose an \u03b1-order gradient estimator that utilizes exact gradients to combine the efficiency of first-order estimates with the robustness of zero-order methods.", "method": "The authors analyze the efficacy of first-order estimators through the lens of bias and variance, considering characteristics of certain physical systems, such as stiffness or discontinuities. They also demonstrate the performance of the proposed \u03b1-order gradient estimator through numerical examples.", "outcome": "The authors show that characteristics of certain physical systems may compromise the efficacy of the first-order estimator. They further demonstrate the potential issues with traditional estimators and illustrate the benefits of the proposed \u03b1-order estimator.", "future_impact": "This work may influence the utility of differentiable simulators and how reinforcement learning is approached. The proposed \u03b1-order gradient estimator could provide a more effective method for reinforcement learning computation in certain contexts.", "venue": "ICML", "year": 2022, "title": "Do Differentiable Simulators Give Better Policy Gradients?"}
{"pid": "60bdde338585e32c38af51ca", "context": "While Transformers have been successful for many natural language processing tasks, their application to video domain tasks such as long-term video generation and scene understanding has been challenged by high computational complexity and the lack of natural tokenization.", "key_idea": "The authors propose an Object-Centric Video Transformer (OCVT) which uses an object-centric approach to decompose scenes into tokens suitable for a generative video transformer.", "method": "The proposed model, which is fully unsupervised, is used to learn complex spatio-temporal dynamics of multiple interacting objects and generate future video frames. The authors compare OCVT with previous RNN-based approaches and other possible video transformer baselines.", "outcome": "OCVT demonstrates good performance when compared with baselines in generating future frames and is significantly more memory-efficient than pixel-based models. It also achieves state-of-the-art performance on the CATER task.", "future_impact": "The proposal of OCVT opens up possibilities for developing efficient transformers for video processing tasks, potentially improving aspects like video generation, scene understanding and video reasoning.", "venue": "ICML", "year": 2021, "title": "Generative Video Transformer: Can Objects be the Words?"}
{"pid": "621d8ed25aee126c0f74692e", "context": "Recently, over-parameterized deep networks have demonstrated strong performances in modern machine learning. However, when training data is corrupted, these networks tend to overfit and do not generalize well.", "key_idea": "The authors propose a principled approach for robust training of over-parameterized deep networks where a proportion of training labels are corrupted. The main idea is to model the label noise via another sparse over-parameterization term and separate it from the data.", "method": "The authors perform experiments on real datasets to compare their proposed method against others under the presence of label noise. Theory on simplified linear models is also explored to back up the method.", "outcome": "They show that their method achieves state-of-the-art test accuracy against label noise on a variety of real datasets, and exact separation between sparse noise and low-rank data can be achieved under incoherent conditions.", "future_impact": "The work opens many interesting future research directions for improving over-parameterized models by using sparse over-parameterization and implicit regularization.", "venue": "ICML", "year": 2022, "title": "Robust Training under Label Noise by Over-parameterization."}
{"pid": "6233f88c5aee126c0f94b3d0", "context": "Online stochastic games with risk-averse agents have a unique challenge in that the distributions of the cost functions, which are based on the actions of all agents (generally unobservable), are unknown. This makes the Conditional Value at Risk (CVaR) values of the costs difficult to compute.", "key_idea": "The authors propose a new online risk-averse learning algorithm that uses one-point zeroth-order estimation of the CVaR gradients, computed using CVaR values that are estimated by appropriately sampling the cost functions.", "method": "The proposed algorithm and its two variants (one relying on a new sampling strategy to improve the estimation accuracy of the CVaR values, the other using CVaR values from the previous iteration to reduce the variance of the CVaR gradient estimates) are theoretically analyzed and tested on an online market problem modeled as a Cournot game.", "outcome": "The designed algorithm achieves sub-linear regret with a high probability. The analysis of the algorithm's variants reveal improved performance in estimating CVaR values.", "future_impact": "The learning algorithm and its variants hold potential for optimal decision-making in online stochastic games with risk-averse agents, potentially minimizing the risk of incurring significantly high costs.", "venue": "ICML", "year": 2022, "title": "Risk-Averse No-Regret Learning in Online Convex Games."}
{"pid": "60bdde338585e32c38af5191", "context": "Unrolled computation graphs are common in many scenarios including training of RNNs, tuning hyperparameters through unrolled optimization, and training learned optimizers. Existing methods for optimizing parameters in such graphs struggle with high variance gradients, bias, slow updates, or large memory use.", "key_idea": "The paper proposes a method called Persistent Evolution Strategies (PES), which divides the computation graph into a series of truncated unrolls. PES performs an evolution strategies-based update step after each unroll and eliminates bias from these truncations by accumulating correction terms over the entire sequence of unrolls.", "method": "PES is applied to synthetic tasks and its efficiency in training learned optimizers and tuning hyperparameters is tested.", "outcome": "The authors found that PES allows for rapid parameter updates, has low memory usage, is unbiased, and has reasonable variance characteristics. They also demonstrated the advantages of PES over several other methods for gradient estimation on synthetic tasks.", "future_impact": "PES, with its rapid parameter updates and low memory usage, could provide an unbiased and efficient method for gradient estimation, potentially improving training of learned optimizers and tuning of hyperparameters.", "venue": "ICML", "year": 2021, "title": "Unbiased Gradient Estimation in Unrolled Computation Graphs with Persistent Evolution Strategies"}
{"pid": "5f2934d691e011376d9c5e23", "context": "Actor-critic is one of the most popular families of reinforcement learning algorithms. However, existing works on actor-critic primarily focus on two-timescale updates where the actor and critic are updated in separate steps.", "key_idea": "The authors focus on the single-timescale setting where the actor and critic are updated simultaneously. In each iteration, the critic update is obtained by applying the Bellman evaluation operator once, and the actor is updated in the policy gradient direction computed using the critic.", "method": "The authors study the convergence and global optimality of their proposed approach under two function approximation settings where both the actor and critic are represented by either linear function approximation or deep neural networks.", "outcome": "The authors prove that the actor sequence in their proposed single-timescale actor-critic algorithm converges to a globally optimal policy at a sublinear O(K^-1/2) rate, where K is the number of iterations.", "future_impact": "This work provides a theoretical foundation for the convergence and global optimality of the single-timescale actor-critic approach, which can lead to further enhancements in the field of reinforcement learning.", "venue": "ICLR", "year": 2021, "title": "Single-Timescale Actor-Critic Provably Finds Globally Optimal Policy"}
{"pid": "ffda2b56-b201-4d3d-8e36-fefdd18d3513", "context": "The complexity of deep feed forward networks with linear pre-synaptic couplings and rectified linear activations is being explored, focusing on the growing body of work contrasting the representational power of deep and shallow network architectures.", "key_idea": "The authors offer a framework for comparing deep and shallow models that belong to the family of piecewise linear functions based on computational geometry. The paper also contrasts a deep rectifier multi-layer perceptron (MLP) with linear outputs units with its single layer version model.", "method": "The authors developed mathematical models to compare the number of linear regions that both deep and shallow models with linear pre-synaptic couplings and rectified linear activations can offer.", "outcome": "The results showed that in the asymptotic regime, the number of linear regions in a shallow model is $O(k^{n_0}n^{n_0})$. On the other hand, for a $k$ layer model with $n$ hidden units on each layer, it's $\\Omega(\\left( {n}/{n_0}\right)^{k-1}n^{n_0})$. It was observed that $\\left({n}/{n_0}\right)^{k-1}$ grows faster then $k^{n_0}$ when either $n$ goes to infinity or $k$ goes to infinity and $n u003e 2n_0$.", "future_impact": "This work is considered as a first step towards understanding the complexity of these models and providing suitable mathematical tools for future analysis.", "venue": "ICLR", "year": 2014, "title": "On the number of inference regions of deep feed forward networks with piece-wise linear activations"}
{"pid": "61d269325244ab9dcbc5ea42", "context": "The problem of learning a good set of policies to solve a variety of unseen reinforcement learning tasks without requiring a significant quantity of newer data is an open challenge. Most existing approaches do not fully facilitate efficient transfer to all possible downstream tasks.", "key_idea": "The authors propose the concept of a set of independent policies, which can attain high performance on all forms of possible downstream tasks. They introduce a simple algorithm that constructs this set of policies, based on the framework of generalized policy evaluation and improvement.", "method": "The proposed algorithm is validated through theoretical analysis and empirical experiments. The authors also compare their approach with other recently proposed methods for constructing diverse policy sets.", "outcome": "The experimental outcomes confirm the validity of the theoretical results. The proposed approach outperforms the existing methods, enabling instantaneous transfer to all possible downstream tasks. The set of independent policies were shown to have a beneficial effect on the learning process on downstream tasks.", "future_impact": "The constructed set of policies may find utility in various realistic lifelong reinforcement learning settings, thereby influencing future research and applications in reinforcement learning.", "venue": "ICLR", "year": 2022, "title": "Constructing a Good Behavior Basis for Transfer using Generalized Policy Updates"}
{"pid": "6164fcc15244ab9dcb24d265", "context": "Solving the Schr\u00f6dinger equation is key to many quantum mechanical properties, but it's only tractable for single-electron systems, and neural networks used to model wave functions of many-electron systems require significant computational resources. This is because one has to train a separate model for each molecular geometry, which can prove challenging.", "key_idea": "The authors propose a solution that combines a Graph Neural Network (GNN) with a neural wave function. This solution, named the Potential Energy Surface Network (PESNet), enables simultaneous solving of the Schr\u00f6dinger equation for multiple geometries via the variational Monte-Carlo (VMC) framework.", "method": "The authors experiment with their new network, PESNet, training it on multiple geometries simultaneously, and benchmark its performance in terms of training speed and accuracy against existing state-of-the-art networks.", "outcome": "PESNet is found to accelerate training for multiple geometries by up to 40 times, while maintaining or enhancing their accuracy relative to existing state-of-the-art networks.", "future_impact": "The proposed method can potentially lead to accurate and significantly cheaper quantum mechanical calculations, driving forward new advancements in this field.", "venue": "ICLR", "year": 2022, "title": "Ab-Initio Potential Energy Surfaces by Pairing GNNs with Neural Wave Functions"}
{"pid": "600833289e795ed227f5316f", "context": "The problem of how to improve generative modeling by better exploiting spatial regularities and coherence in images has not been successfully addressed in the literature. Current image generation models often use standard convolutional layers, but these may not fully account for the spatially distributed nature of image information.", "key_idea": "The paper introduces Spatial Dependency Networks (SDNs), a novel neural network architecture for image generators such as decoders. SDNs compute feature maps in a spatially coherent way using a sequential gating-based mechanism that distributes contextual information across 2-D space.", "method": "The authors apply the SDNs to variational autoencoders (VAEs), replacing the traditional decoder with spatial dependency layers. This method is tested on several benchmarks to evaluate its performance on density estimation, large image processing, and disentangled representation learning.", "outcome": "The study finds that using SDNs as decoders in VAEs significantly improves density estimation over baseline convolutional architectures and state-of-the-art models in the same class. They also show that SDNs can operate on large images, producing high-quality, coherent samples, and that a powerful SDN decoder also enhances learning of disentangled representations.", "future_impact": "The results suggest that spatial dependency layers might be favored over convolutional ones in various VAE settings, indicating potential future applications and studies using spatial dependency networks in image generation tasks.", "venue": "ICLR", "year": 2021, "title": "Spatial Dependency Networks: Neural Layers for Improved Generative Image Modeling"}
{"pid": "6006b33391e0111a1b6a22a2", "context": "Traditionally, the estimation of the informativeness of individual training samples for the training of neural models has been a difficult problem.", "key_idea": "The authors propose a new concept to measure the information an individual sample provides to the training of a neural network, specifically measuring both how much a sample informs the final weights and the function computed by the weights.", "method": "The authors provide efficient approximations of these measures using a linearized network. The approximations are empirically tested for accuracy using pre-trained ResNets.", "outcome": "The authors demonstrate that their approximation method works accurately for real-world architectures, such as pre-trained ResNets. This measure is successfully applied to several problems like dataset summarization, analysis of under-sampled classes, comparison of informativeness of different data sources, and detection of adversarial and corrupted examples.", "future_impact": "The authors' work helps generalize existing frameworks and exhibits improved computational properties for heavily over-parametrized models, potentially enabling better application to real-world networks.", "venue": "ICLR", "year": 2021, "title": "Estimating informativeness of samples with Smooth Unique Information"}
{"pid": "5e718f649e795e1c35c5f815", "context": "Transformer models have become widely used in natural language processing tasks. However, they require a substantial amount of computing resources to achieve high performance, which limits their applicability for mobile applications, which often have tight constraints on hardware resources and battery usage.", "key_idea": "The paper presents Lite Transformer, an efficient mobile NLP architecture that leverages the concept of Long-Short Range Attention (LSRA), where one group of heads in the model concentrates on local context modeling through convolution, while another group focuses on the modeling of long-distance relationships through attention.", "method": "The authors test Lite Transformer against the traditional transformer on three established language tasks: machine translation, abstractive summarization, and language modeling.", "outcome": "Under constrained resources, Lite Transformer outperforms the traditional transformer on the WMT'14 English-French translation task by 1.2/1.7 BLEU, respectively. Lite Transformer significantly reduces the computation of the transformer base model and even outperforms the AutoML-based Evolved Transformer in the mobile NLP setting.", "future_impact": "Deployment of the Lite Transformer methodology can facilitate deploying mobile NLP applications on edge devices due to its significantly reduced computational requirements.", "venue": "ICLR", "year": 2020, "title": "Lite Transformer with Long-Short Range Attention"}
{"pid": "81a0866d-a999-4b03-ba25-29d8bee1cee5", "context": "Prior research lacked efficient algorithms that could learn domain-invariant image representations and address domain mismatch issues in machine learning context.", "key_idea": "The paper presents a new algorithm that learns representations which compensate for domain mismatch and can be efficiently implemented as linear classifiers. The authors introduce a linear transformation which maps the test domain features to the training domain as part of training the classifier.", "method": "The transformation and classifier parameters are optimized collectively and the process includes an efficient cost function based on misclassification loss.", "outcome": "The algorithm was tested on several image datasets, demonstrating improved accuracy and computational benefits compared to previous solutions.", "future_impact": "The paper introduces an algorithm that has several features which haven't been available in a single algorithm before: multi-class adaptation through representation learning, ability to map between different feature spaces, and scalability to larger datasets.", "venue": "ICLR", "year": 2013, "title": "Efficient Learning of Domain-invariant Image Representations"}
{"pid": "5f63392691e011242e3f2c6b", "context": "Recurrent Neural Networks (RNNs) are often used to learn input-output relationships in temporal data. However, the specifics of how these networks handle memory, particularly over longer periods, are not fully understood.", "key_idea": "The authors look into the effects of memory on RNNs\u2019 ability to approximate and optimize linear functionals, identifying a problem they dub the 'curse of memory' where increasing memory exacerbates approximation difficulty and slows training.", "method": "The authors use continuous-time linear RNNs to learn from data generated by linear relationships, and perform a dynamical analysis of training linear RNNs by gradient methods.", "outcome": "The paper finds that when there is a long-term memory in the target, it requires a large number of neurons to approximate it, and the training process will suffer from slowdowns. These effects are termed the 'curse of memory' as they exponentially increase with more memory.", "future_impact": "These analyses represent a basic step towards a concrete mathematical understanding of new phenomena that may arise in learning temporal relationships using recurrent architectures.", "venue": "ICLR", "year": 2021, "title": "On the Curse of Memory in Recurrent Neural Networks: Approximation and  Optimization Analysis"}
{"pid": "5f8427d491e01129be18ff5c", "context": "In the field of multitask and continual training, a key challenge is avoiding catastrophic forgetting, whereby the solution found for a subsequent task does not perform well on the previously learned ones. The relationship between the different minima that the two training regimes arrive at is not well understood.", "key_idea": "The paper investigates whether multitask and continual solutions are connected through linear paths in the model's parameter space, inspired by previous work showing that different minima of the same task are often connected by very simple curves of low error.", "method": "The authors empirically investigated the connectivity between multitask and continual solutions, specifically focusing on whether a linear path connects these minima. Based on these findings, they proposed an algorithm that constrains the sequentially learned minima to behave as the multitask solution.", "outcome": "The authors' findings showed that multitask and continual solutions can be reliably connected by a linear path when the same initialization is used for both. The proposed algorithm outperforms several state-of-the-art continual learning algorithms on various vision benchmarks.", "future_impact": "The understanding of the connectivity between multitask and continual solutions could have significant impact on the continual learning process. The proposed algorithm might serve as a new way to mitigate catastrophic forgetting, potentially improving the way continual learning is handled in future research.", "venue": "ICLR", "year": 2021, "title": "Linear Mode Connectivity in Multitask and Continual Learning"}
{"pid": "600832469e795ed227f530f7", "context": "As large-scale graphs become increasingly more prevalent, it poses significant computational challenges to process, extract and analyze large graph data. Graph coarsening is a technique to reduce the size of a graph while maintaining essential properties. Despite rich graph coarsening literature, there is only limited exploration of data-driven methods in the field.", "key_idea": "The authors leverage the progress of deep learning on graphs for graph coarsening. The authors parametrize the weight assignment map with graph neural networks and train it to improve the coarsening quality in an unsupervised way.", "method": "The authors propose a framework for measuring the quality of coarsening algorithms. Through extensive experiments on both synthetic and real networks, the authors evaluate the performance of the proposed method.", "outcome": "The proposed method significantly improves common graph coarsening methods under various metrics, reduction ratios, graph sizes, and graph types. It generalizes to graphs of larger size (more than 25x of training graphs), adaptive to different losses (both differentiable and non-differentiable), and scales to much larger graphs than previous work.", "future_impact": "The methods and framework proposed in this paper can drive further explorations and advancements in the field of graph coarsening using neural network-based approaches.", "venue": "ICLR", "year": 2021, "title": "Graph Coarsening with Neural Networks"}
{"pid": "61ca80355244ab9dcba6950b", "context": "Importance weighting is a classic technique to handle distribution shifts. However, prior work has shown that importance weights can have little to no effect on overparameterized neural networks, leading to questions about the compatibility of importance weighting with such networks.", "key_idea": "The authors argue that the failure of importance weighting is not due to overparameterization, but due to the use of exponentially-tailed losses like the logistic or cross-entropy loss. They suggest that polynomially-tailed losses can restore the effects of importance reweighting in correcting distribution shift in overparameterized models.", "method": "The authors characterize the behavior of gradient descent on importance weighted polynomially-tailed losses with overparameterized linear models, and theoretically demonstrate the advantage of using such losses in a label shift setting. They validate their findings with neural network experiments on a subpopulation shift and a label shift dataset.", "outcome": "Through their theory and practical experiments, the authors demonstrate that their proposed loss function can outperform reweighted cross-entropy by as much as 9% in test accuracy, and yields results that are comparable to, or even exceeding, well-tuned state-of-the-art methods for correcting distribution shifts.", "future_impact": "The work provides valuable insights into the problem of distribution shifts in overparameterized models, and points to new directions in the use of importance weighting with different types of loss functions.", "venue": "ICLR", "year": 2022, "title": "Is Importance Weighting Incompatible with Interpolating Classifiers?"}
{"pid": "5fd0b5e191e01147f1d1e474", "context": "In the prediction setting, expensive annotations with the prediction targets are limited, but many inputs are cheaply annotated with auxiliary information. Current approaches struggle with effectively leveraging this auxiliary information.", "key_idea": "The authors introduce In-N-Out, a model that first trains with auxiliary inputs, pseudolabels all the in-distribution inputs, then pre-trains on OOD auxiliary outputs, and fine-tunes the model with pseudolabels.", "method": "The In-N-Out method was evaluated through empirical testing across three image and time-series datasets, and theoretically validated using multi-task linear regression setting.", "outcome": "The authors show that using auxiliary information as input features has mixed results, improving in-distribution error but potentially hurting out-of-distribution (OOD) error. However, using auxiliary information as outputs of auxiliary tasks to pre-train a model improves OOD error. The In-N-Out model outperforms auxiliary inputs or outputs alone on both in-distribution and OOD error.", "future_impact": "The proposed In-N-Out technique provides a new approach to leveraging both primary and auxiliary information in prediction settings, which has potential to significantly improve both in-distribution and out-of-distribution error rates.", "venue": "ICLR", "year": 2021, "title": "In-N-Out: Pre-Training and Self-Training using Auxiliary Information for  Out-of-Distribution Robustness"}
{"pid": "61a98afe5244ab9dcb955c6b", "context": "Recent advances have enabled analysis of large-scale dynamical sequential games with large numbers of agents. However, results have been largely limited to graphon mean field systems with continuous-time diffusive or jump dynamics, typically without control and with little focus on computational methods.", "key_idea": "The authors propose a novel discrete-time formulation for graphon mean field games as the limit of non-linear dense graph Markov games with weak interaction.", "method": "Theoretical proofs of existence and approximation properties of the graphon mean field solution in large systems are provided. General learning schemes for graphon mean field equilibria are developed by introducing agent equivalence classes or reformulating the graphon mean field system as a classical mean field system.", "outcome": "The authors have successfully obtained plausible approximate Nash equilibria in large dense graph games with many agents. Empirically, they demonstrate that the finite-agent behavior comes increasingly close to the mean field behavior for computed equilibria as the graph or system size grows.", "future_impact": "This approach can be extended and used in large scale multi-agent systems including the use of policy gradient reinforcement learning in conjunction with sequential Monte Carlo methods.", "venue": "ICLR", "year": 2022, "title": "Learning Graphon Mean Field Games and Approximate Nash Equilibria"}
{"pid": "5ee3526a91e011cb3bff746b", "context": "Few-sample fine-tuning of BERT contextual representations is a common practice in the field, but there are gaps in how this process is undertaken, potentially leading to sub-optimal results.", "key_idea": "The study identifies three areas of sub-optimal practices in BERT fine-tuning: omission of gradient bias correction, detrimental parts of the BERT network serving as starting points for fine-tuning, and insufficient allocation of training time.", "method": "The authors re-evaluate the effects of recently proposed methods for improving few-sample fine-tuning with BERT, modifying the fine-tuning process based on the identified problem areas.", "outcome": "The modifications based on the identified sub-optimal areas in the fine-tuning process resulted in a decrease in the relative impact of previously proposed solutions.", "future_impact": "Following these revised fine-tuning practices could yield improved performance for future studies fine-tuning the BERT model.", "venue": "ICLR", "year": 2021, "title": "Revisiting Few-sample BERT Fine-tuning"}
{"pid": "623964e9d18a2b6f530177c7", "context": "The ability of deep neural networks in automating the process of feature extraction still lacks a thorough mathematical understanding. While there has been significant recent effort on studying the generalization of neural networks, it typically focuses on regimes captured by the Neural Tangent Kernel.", "key_idea": "The authors analyze learning and generalization of a three-layer neural network with ReLU activations in a regime that goes beyond the linear approximation of the network, not captured by the Neural Tangent Kernel.", "method": "They employ a variant of Stochastic Gradient Descent (SGD) for convergence in polynomially many iterations towards a solution that generalizes well.", "outcome": "Despite the nonconvexity of the empirical loss, the authors demonstrated that the variant of SGD converges within polynomial iterations to a good solution that generalizes.", "future_impact": " Given the novel approach to analyzing learning and generalization of a three-layer neural network with ReLU activations, this work could spur more thorough mathematical understanding of feature extraction in deep neural networks.", "venue": "ICLR", "year": 2022, "title": "Optimization and Adaptive Generalization of Three layer Neural Networks"}
{"pid": "600834799e795ed227f53217", "context": "Most previous works focus on the quantization/pruning of weights and activations in neural networks to accelerate training, while often overlooking the propagation of neural gradients. Existing methods are often not applicable to neural gradients due to their unique statistical properties.", "key_idea": "The authors find that the distribution of neural gradients is approximately lognormal and propose two methods to reduce the computational and memory burdens of neural gradients. One method optimizes the floating-point format and scale of the gradients and the other accurately sets sparsity thresholds for gradient pruning.", "method": "The two proposed methods were validated by performing experiments on state-of-the-art results on ImageNet.", "outcome": "This paper presents the first known methods to quantize the gradients to 6-bit floating-point formats and achieve up to 85% gradient sparsity without accuracy degradation.", "future_impact": "The proposed methods for optimizing neural gradient propagation might pave the way for more efficient computational and memory usage in processing large neural networks, potentially allowing for faster training times and improved model performance.", "venue": "ICLR", "year": 2021, "title": "Neural gradients are near-lognormal: improved quantized  and sparse training"}
{"pid": "6201df4a5aee126c0f64dcef", "context": "Random pruning, a simple method to achieve sparsity in neural networks, has been considered less competitive than post-training pruning or sparse training methods.", "key_idea": "The authors propose that random pruning at initialization can be highly effective for the sparse training of modern neural networks, without requiring complex pruning criteria or meticulously designed sparsity structures.", "method": "The study investigates the performance benefits of random pruning in large networks and with different layer-wise sparsity ratios, applying it to the training of a randomly pruned subset of Wide ResNet-50 on ImageNet dataset. The authors further examine the performance of such pruned networks in out-of-distribution detection, uncertainty estimation, and adversarial robustness.", "outcome": "The randomly pruned network shows comparable performance to its dense equivalent. Crucially, a randomly pruned subset of Wide ResNet-50 outperforms the wholly dense Wide ResNet-50 on ImageNet when sparsely trained. Randomly pruned networks also outperform dense networks in out-of-distribution detection, uncertainty estimation, and adversarial robustness.", "future_impact": "These findings suggest that there is a larger than expected opportunity for sparse training to be highly effective, even when no intricate designs for pruning are implemented.", "venue": "ICLR", "year": 2022, "title": "The Unreasonable Effectiveness of Random Pruning: Return of the Most Naive Baseline for Sparse Training"}
{"pid": "6080416491e011772654fc98", "context": "Neural networks, despite their impressive data fitting capabilities, are believed to face difficulties when extrapolating beyond the training data distribution.", "key_idea": "The paper maintains that a model's inability to extrapolate is not tied to its capacity but is due to a learning hypothesis; it states that unobserved examples are underspecified in the learner's model. A learning framework is proposed to allow extrapolation over group transformations.", "method": "The authors introduce a learning framework that is counterfactually-guided by the hypothesis that any group invariance to (known) transformation groups is mandatory, with or without evidence, unless inconsistent with the training data. They also introduce sequence and image extrapolation tasks to validate the proposed framework.", "outcome": "The paper highlights the shortcomings of traditional methods by demonstrating how the proposed framework can perform extrapolations from a single environment.", "future_impact": "The introduced learning framework could potentially help neural networks extrapolate over group transformations, addressing a key challenge in machine learning.", "venue": "ICLR", "year": 2021, "title": "Neural Networks for Learning Counterfactual G-Invariances from Single  Environments"}
{"pid": "5e5e18dd93d709897ce371ff", "context": "The importance of obtaining high-quality uncertainty estimates for many applications of deep neural networks is well-recognized, however, current methods may not provide optimal solutions.", "key_idea": "The authors propose a theoretical scheme for estimating uncertainties in deep neural networks based on sampling from a prior distribution. This approach is formulated to never underestimate the posterior uncertainty obtained by a hypothetical Bayesian algorithm, making the uncertainty estimates conservative.", "method": "The proposed method is evaluated using typical computer vision tasks, for calibration and out-of-distribution detection, wherein the performance is compared to that of deep ensembles.", "outcome": "The proposed method of using random priors for uncertainty estimation was found to outperform deep ensembles in practice.", "future_impact": "The authors' approach to uncertainty estimation can be adapted to any deep neural network architecture and trained using standard supervised learning pipelines. This could potentially increase the robustness and reliability of deep learning models across a variety of applications.", "venue": "ICLR", "year": 2020, "title": "Conservative Uncertainty Estimation By Fitting Prior Networks"}
{"pid": "6008311f9e795ed227f53098", "context": "Knowing how the effects of directed actions generalize to new situations is key to rapid action generalization. Recent work has proposed that neural grid codes provide an efficient representation of the state space, as eigenvectors of a transition matrix reflecting diffusion across states, that allows efficient prediction of future state distributions.", "key_idea": "The authors propose to extend the eigenbasis prediction model to predict over arbitrary translation-invariant directed transition structures. They suggest that a single set of eigenvectors can support predictions over arbitrary directed actions.", "method": "The authors utilize tools from Fourier analysis to extend the eigenbasis prediction model and show the equivalence between the generalized prediction framework and traditional models of grid cells firing driven by self-motion to perform path integration using oscillatory interference models or continuous attractor networks.", "outcome": "The authors establish a unifying framework for the role of the grid system in predictive planning, sense of direction, and path integration. Their model allows a single grid-like representation to efficiently predict over directed transitions in both spatial and non-spatial tasks.", "future_impact": "The proposed model could support generalizable inference over directed actions across different tasks, which may lead to advancements in predictive planning and the understanding of grid cell functions.", "venue": "ICLR", "year": 2021, "title": "Prediction and generalisation over directed actions by grid cells"}
{"pid": "6257c5a75aee126c0f467808", "context": "In a continual or lifelong reinforcement learning (RL) setting, the ability to decompose knowledge into reusable components would enable agents to quickly learn new RL tasks, but approaches to do this effectively are lacking.", "key_idea": "The authors propose a form of composition based on neural modules and demonstrate that their proposed method can break down complex problems into reusable components to facilitate the learning of future tasks in reinforcement learning contexts.", "method": "The authors present a set of reinforcement learning problems that admit compositional solutions and propose a compositional lifelong RL method that leverages accumulated neural components and uses off-line RL over replayed experiences.", "outcome": "The study empirically demonstrates that neural composition captures the underlying structure of a set of reinforcement learning problems.", "future_impact": "The introduced method could accelerate the learning of future tasks while retaining performance on previous tasks in reinforcement learning, offering a promising direction for the development of more efficient and adaptable reinforcement learning models.", "venue": "ICLR", "year": 2022, "title": "Modular Lifelong Reinforcement Learning via Neural Composition"}
{"pid": "60efbb105244ab9dcbd4eb7d", "context": "Most existing Vision-and-Language (V&L) models rely on pre-trained visual encoders, using a small set of manually-annotated data to understand the visual world. Better generalization performance has been observed with large-scale pretraining models like CLIP, which are trained on a massive amount of image-caption pairs.", "key_idea": "The authors propose using CLIP as the visual encoder in various V&L models in two scenarios: 1) plugging CLIP into task-specific fine-tuning; 2) combining CLIP with V&L pre-training and transferring to downstream tasks.", "method": "The authors conduct an experimental study to demonstrate the advantage of using CLIP as the visual encoder in various V&L models under two typical scenarios. The performance of CLIP is compared with widely-used visual encoders that rely on in-domain annotated data.", "outcome": "CLIP is shown to significantly outperform the widely-used visual encoders trained with in-domain annotated data. It achieves competitive or better results on diverse V&L tasks, and establishes new state-of-the-art results on Visual Question Answering, Visual Entailment, and V&L Navigation tasks.", "future_impact": "The superior performance of the CLIP model on V&L tasks can promote further research in exploring its applications on different related tasks and will lead to improved models.", "venue": "ICLR", "year": 2022, "title": "How Much Can CLIP Benefit Vision-and-Language Tasks?"}
{"pid": "600830dc9e795ed227f53079", "context": "Although attention mechanism, especially self-attention, is a key component in modern deep learning for handling global correlation discovery, there are questions about its efficiency and irreplaceability when modeling the global context.", "key_idea": "Contrary to tradition, this paper finds that self-attention is not superior to the matrix decomposition (MD) model in performance and computational cost for encoding long-distance dependencies. The authors propose redefining the global context issue as a low-rank completion problem.", "method": "The paper presents Hamburgers: series of models using optimization algorithms for solving Matrix Decompositions to factorize input representations into sub-matrices, generating a low-rank embedding. These Hamburgers are tested in vision tasks like semantic segmentation and image generation.", "outcome": "The Hamburgers, with carefully managed gradients back-propagated through MDs, perform favorably against the popular global context module, self-attention. Demonstrable improvements are seen over self-attention and its variants in vision tasks.", "future_impact": "This study opens up new ways of thinking about global correlation modeling in deep learning, potentially moving away from self-attention towards more efficient methods like matrix decomposition.", "venue": "ICLR", "year": 2021, "title": "Is Attention Better Than Matrix Decomposition?"}
{"pid": "5d9b0cbe3a55acb039198fb5", "context": "Current generative models for text-to-speech translation are primarily unsupervised models and hence struggle to have consistent and interpretable variables. Moreover, control over aspects such as affect and speaking rate is limited in existing models.", "key_idea": "The authors propose a novel generative model that leverages semi-supervised learning with probabilistic latent variables. This approach enables partial supervision on some latent variables leading to forced consistent and interpretable purposes.", "method": "The model's ability to discover and control important but rarely labelled attributes of speech like affect and speaking rate, was tested with minimal supervision levels (1% or 30 minutes).", "outcome": "The proposed semi-supervised generative model was able to reliably discover and control speech attributes without degrading synthesis quality compared to a state-of-the-art baseline, even with minimal supervision.", "future_impact": "The authors plan to release audio samples demonstrating the effectiveness of their new model. This example of using semi-supervised learning models for controllable speech synthesis could inspire and facilitate further research in this field.", "venue": "ICLR", "year": 2020, "title": "Semi-Supervised Generative Modeling for Controllable Speech Synthesis"}
{"pid": "61552aed5244ab9dcb23eaae", "context": "Graph Convolution Networks (GCN) are used in numerous settings involving a large underlying graph as well as several layers. Standard SGD-based training scales poorly here since each descent step ends up updating node embeddings for a large portion of the graph. Recent methods attempt to remedy this by sub-sampling the graph which reduces the compute load, but at the cost of biased gradients which may offer suboptimal performance.", "key_idea": "The authors propose a new method, IGLU, that caches forward-pass embeddings for all nodes at various GCN layers, enabling it to perform lazy updates that do not require updating a large number of node embeddings during descent.", "method": "Under standard assumptions such as objective smoothness, IGLU's convergence is analyzed. The method is also validated extensively on a variety of benchmarks.", "outcome": "IGLU is shown to offer up to 1.2% better accuracy despite requiring up to 88% less wall-clock time.", "future_impact": "IGLU, with its lazy update mechanism and caching approach, could potentially improve the scalability and efficiency of GCN training, thus impacting its numerous applications.", "venue": "ICLR", "year": 2022, "title": "IGLU: Efficient GCN Training via Lazy Updates"}
{"pid": "5e5e18c893d709897ce30a9b", "context": "Graph convolutional networks (GCNs) have achieved remarkable performance in various network science learning tasks. However, their theoretical analysis is at its infancy. Graph scattering transforms (GSTs) are non-trainable deep GCN models that are amenable to generalization and stability analyses, but suffer from limitations including exponential complexity.", "key_idea": "The authors address the limitations of GSTs by proposing a novel pruned GST (pGST) approach. This approach uses a graph-spectrum-inspired criterion to retain informative scattering features on-the-fly, bypassing the high complexity associated with regular GSTs.", "method": "The authors apply the pGST approach to various domains through experiments. They evaluate the method's stability to perturbations of the input graph signals with bounded energy, and its performance compared to baseline GST and state-of-the-art GCNs.", "outcome": "The experiments show that pGST performs comparably to the GST that uses all scattering features, achieving significant computational savings. Furthermore, pGST achieves performance comparable to state-of-the-art GCNs. The method also reveals that graph data from different domains lead to different scattering patterns.", "future_impact": "The observed variations in scattering patterns suggest the future direction of developing domain-adaptive pGST network architectures.", "venue": "ICLR", "year": 2020, "title": "Pruned Graph Scattering Transforms"}
{"pid": "622eb2495aee126c0f62b24b", "context": "Vision Transformer (ViT) has shown promise in computer vision problems, but the performance of ViT quickly saturates with depth due to problems like attention collapse or patch uniformity. There are some empirical solutions, but a rigorous theory-based solution to this scalability issue is lacking.", "key_idea": "This study establishes a theory framework to analyze ViT features from the Fourier spectrum domain. It shows that self-attention in ViT acts like a low-pass filter, leading to excessive filtering when ViT scales up its depth. Two techniques, AttnScale and FeatScale, are proposed to overcome the low-pass limitation.", "method": "AttnScale decomposes a self-attention block into low-pass and high-pass components, then rescales and combines these filters to produce an all-pass self-attention matrix. FeatScale reweights feature maps on separate frequency bands to increase the high-frequency signals. These techniques are tested by integrating them into multiple ViT variants.", "outcome": "Both AttnScale and FeatScale techniques prove efficient and hyperparameter-free, and they effectively tackle ViT training issues such as attention collapse and patch uniformity. Their implementations provide up to 1.1% performance gains with minor parameter overhead in multiple ViT variants.", "future_impact": "The developed techniques and the publicly released code and pre-trained models could potentially be leveraged for better optimization of Vision Transformers and their applications in addressing a range of computer vision problems.", "venue": "ICLR", "year": 2022, "title": "Anti-Oversmoothing in Deep Vision Transformers via the Fourier Domain Analysis: From Theory to Practice"}
{"pid": "600832fd9e795ed227f53156", "context": "Humans can effortlessly adapt to new partners in collaborative tasks due to an inherent understanding of which skills transcend across partners. They can also adapt easily to similar tasks with the same partners by leveraging existing conventions. However, current AI approaches have not managed to distinguish between the complexities intrinsic to a task and the conventions used by a partner, with little emphasis on using conventions for adaptation to new settings.", "key_idea": "A new learning framework has been proposed that methodically separates rule-dependent representation from convention-dependent representation, enabling AI agents to adapt quickly to new partners and coordinate with old partners on new tasks without prior training.", "method": "The agents were tested on three collaborative tasks of varying complexity: a contextual multi-armed bandit, a block placing task, and the card game Hanabi. Under some assumptions, it was shown that the rule-dependent representation is a sufficient statistic of the distribution over best-response strategies across partners.", "outcome": "The agents, using the separation of representations, were able to quickly adapt to new partners and coordinate with old partners on new tasks in a zero-shot manner.", "future_impact": "The proposed learning framework that separates rule-dependent and convention-dependent representations could help in improving the adaptive capabilities of AI systems in collaborating with humans across varied tasks and partners.", "venue": "ICLR", "year": 2021, "title": "On the Critical Role of Conventions in Adaptive Human-AI Collaboration"}
{"pid": "621454535aee126c0f201356", "context": "Denoising Diffusion Probabilistic Models (DDPMs) are effective in generating high-quality samples such as image and audio samples, but their usage is limited due to requiring hundreds to thousands of iterations to produce final samples. Existing model acceleration methods, such as adjusting the variance schedule or the denoising equation, compromise the quality of samples, thereby limiting practicality.", "key_idea": "The authors propose treating DDPMs as a problem of solving differential equations on manifolds and introduce pseudo numerical methods for diffusion models (PNDMs) that potentially address the limitations in the inference speed and quality.", "method": "The authors experiment with several classical numerical methods, converting them into corresponding pseudo numerical methods. They then apply these methods to pre-trained models on Cifar10, CelebA, and LSUN datasets.", "outcome": "The proposed pseudo linear multi-step method outperforms Denoising Diffusion Implicit Models (DDIMs) with 250 steps in quality by around 0.4 in FID. Additionally, PNDMs can generate higher quality synthetic images with only 50 steps, as compared to 1000-step DDIMs, achieving a 20x speedup.", "future_impact": "This work effectively introduces a novel perspective and corresponding pseudo numerical methods that accelerate the inference process of DDPMs while preserving the sample quality, potentially promising substantial advancement in sample generation tasks.", "venue": "ICLR", "year": 2022, "title": "Pseudo Numerical Methods for Diffusion Models on Manifolds"}
{"pid": "6257c5aa5aee126c0f467d48", "context": "Current machine learning models that use aggregated performance metrics, such as loss and accuracy, may overlook higher errors on some training cases as compromises for lower errors on others. This can lead to models stagnating at local optima and poor generalization.", "key_idea": "The authors propose the integration of Lexicase Selection, a method from evolutionary computation, into the context of deep learning to enhance generalization. They specifically propose a new optimization framework named Gradient Lexicase Selection, which combines gradient descent and lexicase selection.", "method": "The proposed method is experimentally tested on various widely-used deep neural network architectures across three image classification benchmarks. Additionally, a qualitative analysis was performed to investigate the learning of diverse representations by the networks.", "outcome": "The experimental results demonstrate that the proposed method improves the generalization performance of various widely-used deep neural network architectures across three image classification benchmarks.", "future_impact": "Due to its ability to improve generalization performance and learning more diverse representations, the proposed Gradient Lexicase Selection method could be a valuable tool for optimizing neural networks in future research.", "venue": "ICLR", "year": 2023, "title": "Optimizing Neural Networks with Gradient Lexicase Selection"}
{"pid": "615fb6f25244ab9dcb9c3f5d", "context": "Creating labeled training sets in machine learning can be a major challenge. Current Weak Supervision frameworks attempt to solve this by synthesizing training labels from potentially noisy supervision sources, but they can only use sources that share the same output space as the target task.", "key_idea": "This study introduces a concept called Weak Indirect Supervision (WIS), which synthesizes training labels based on indirect supervision sources that have different output label spaces, and proposes a Probabilistic Label Relations Model (PLRM) to leverage these indirect supervision sources.", "method": "The study uses a probabilistic modeling approach, PLRM, which uses user-provided label relations to leverage indirect supervision sources. The authors test PLRM on unseen labels and provide a generalization bound. They test PLRM on image and text classification tasks as well as industrial advertising applications.", "outcome": "The probabilistic modeling approach (PLRM) outperformed the baselines by a margin of 2%-9% in image and text classification tasks as well as an industrial advertising application.", "future_impact": "The authors suggest that the new problem formulation, WIS, and their proposed modeling approach, PLRM, could expand the kinds of supervision sources that can be leveraged in creating labeled data sets, and thus might greatly benefit the field of machine learning.", "venue": "ICLR", "year": 2022, "title": "Creating Training Sets via Weak Indirect Supervision."}
{"pid": "5e5e18bf93d709897ce2d33b", "context": "The current methods for pruning neural networks do not simultaneously optimize network parameters and the network's sparseness.", "key_idea": "The authors introduce the Dynamic Sparse Training algorithm which jointly finds optimal network parameters and sparse network structure within a unified optimization process, using trainable pruning thresholds that have layer-wise adjustments dynamically via backpropagation.", "method": "The authors demonstrate the capabilities of their algorithm by training very sparse neural network models with little performance loss while using the same training epochs as dense models. They also make comparisons with other sparse training algorithms across various network architectures.", "outcome": "Dynamic Sparse Training achieves comparable performance with other sparse training algorithms across various network architectures, and it can be used to effectively train very sparse neural network models with minimal performance loss.", "future_impact": "The insights gained from observations made during testing reveal problems with traditional three-stage pruning algorithms, which could guide the design of even more compact network architectures in the future.", "venue": "ICLR", "year": 2020, "title": "Dynamic Sparse Training: Find Efficient Sparse Network From Scratch With Trainable Masked Layers"}
{"pid": "600834409e795ed227f531f2", "context": "Neural generative models typically generate outputs in a single pass, whereas human creativity often involves iterative building and refinement. Past work has proposed editing models for sequential data, but they usually focus on a single edit instead of an edit sequence.", "key_idea": "The authors propose a generic model for incremental editing of structured data, particularly focusing on tree-structured data like abstract syntax trees of computer programs. The editing process is formulated as consecutive, incremental tree transformations, with an emphasis on learning to represent edits.", "method": "The proposed model iteratively generates tree edits and applies these to the partially edited data. The authors further introduce a novel edit encoder and an imitation learning method. They evaluate the editor on two source code edit datasets.", "outcome": "The proposed editor, with its edit encoder, significantly improved accuracy over previous approaches that generated the edited program in one pass. Training the editor to imitate experts and correct its mistakes dynamically further improved performance.", "future_impact": "With the proposed editor that mimics the human process of iterative refinement, there may be advancements in the structural and incremental editing of computer programs and other structured data.", "venue": "ICLR", "year": 2021, "title": "Learning Structural Edits via Incremental Tree Transformations"}
{"pid": "600831759e795ed227f530b5", "context": "Several works have shown that the regularization mechanisms underlying deep neural networks' generalization performances are still poorly understood.", "key_idea": "The authors propose that intraclass clustering is an implicit form of regularization in deep neural networks that enables them to extract meaningful clusters among the samples of a class, without explicit training mechanisms or supervision.", "method": "To support their hypothesis, the authors design four different measures of intraclass clustering based on the neuron- and layer-level representations of the training data and test these measures across variations of a large set of hyperparameters.", "outcome": "The paper shows that the proposed measures of intraclass clustering serve as accurate predictors of generalization performance across various hyperparameters.", "future_impact": "This findings may lead to better understanding of regularization mechanisms in deep neural networks and potentially inspire new regularization methods specifically targeting intraclass clustering.", "venue": "ICLR", "year": 2021, "title": "Intraclass clustering: an implicit learning ability that regularizes DNNs"}
{"pid": "6257c63d5aee126c0f472a85", "context": "Deep neural networks are used for various regression problems but there is a significant accuracy gap between specialized models and generic, direct regression models where a network is trained to minimize the output label's squared or absolute error. Some work has improved accuracy by solving regression problems with a set of binary classifiers through well-studied binary classification algorithms.", "key_idea": "This paper proposes binary-encoded labels (BEL), which generalizes the application of binary classification to regression by providing a framework to consider arbitrary multi-bit values when encoding target values. The paper also suggests certain encoding and decoding functions with desirable properties identified through theory and empirical study.", "method": "The researchers combined BEL with off-the-shelf task-specific feature extractors and trained their model end-to-end, presenting a series of sample encoding, decoding, and training loss functions for BEL suitable for a variety of regression problems, network architectures, and evaluation metrics.", "outcome": "BEL achieves better results than both direct regression and specialized methods, showing lower error on a diverse set of regression problems. The method achieves state-of-the-art accuracies on several regression benchmarks.", "future_impact": "The introduction of the binary-encoded labels (BEL) offers a generalized approach to apply binary classification to regression, which can improve accuracy in a range of regression problems.", "venue": "ICLR", "year": 2022, "title": "Label Encoding for Regression Networks"}
{"pid": "5f02ecb291e011ee5e025840", "context": "Many domain generalization algorithms exist, aiming to predict well on distributions different from those seen during training. However, fair and realistic comparisons are rendered difficult due to inconsistencies in experimental conditions such as datasets, architectures, and model selection criteria.", "key_idea": "The authors argue that domain generalization algorithms without a model selection strategy should be regarded as incomplete, and propose DomainBed, a testbed for domain generalization that includes multi-domain datasets, baseline algorithms, and model selection criteria.", "method": "The authors conduct extensive experiments using DomainBed across seven multi-domain datasets, nine baseline algorithms, and three model selection criteria.", "outcome": "The authors find that when carefully implemented, empirical risk minimization shows state-of-the-art performance across all datasets.", "future_impact": "The release of DomainBed, along with future contributions from fellow researchers, is expected to streamline reproducible and rigorous research in domain generalization.", "venue": "ICLR", "year": 2021, "title": "In Search of Lost Domain Generalization"}
{"pid": "61ef6ad75244ab9dcb67dcfd", "context": "Model extraction attacks involve adversaries stealing machine learning models that are exposed via public APIs. Current defenses require detection of malicious queries and output distortion, introducing a tradeoff between robustness and model utility for legitimate users.", "key_idea": "The authors propose a method to prevent model extraction attacks by requiring users to complete a proof-of-work prior to accessing the model's predictions, which makes query-based extraction efforts more computationally demanding.", "method": "The proof-of-work method incorporates tools from differential privacy to measure the information revealed by a query and is calibrated according to each query. This doesn't necessitate any modifications to the model being safeguarded.", "outcome": "The proposed approach impedes model extraction by potentially increasing the required computational effort by up to100 times, while only causing up to a twofold overhead for regular users.", "future_impact": "This method could provide a more effective way for machine learning practitioners to protect their publicly available models from being stolen without compromising their utility for legitimate users.", "venue": "ICLR", "year": 2022, "title": "Increasing the Cost of Model Extraction with Calibrated Proof of Work"}
{"pid": "5e5e18e693d709897ce3a9c8", "context": "Previous formal verification techniques have yielded impressive results but most require knowledge of the architecture of the machine learning model and remain hard to scale to complex prediction pipelines. Although the method of randomized smoothing overcomes many of these obstacles, past work has focused on restricted classes of smoothing measures or perturbations.", "key_idea": "The authors introduce a novel framework that extends randomized smoothing procedures to handle arbitrary smoothing measures. It then proves the robustness properties of smoothed machine learning models in the black-box setting using f-divergences.", "method": "The authors apply their framework to several image classification tasks and an audio classification task with regard to several classes of adversarial perturbations.", "outcome": "The proposed methodology improves upon the state of the art in terms of computation time or certified robustness on several image classification tasks and an audio classification task.", "future_impact": "The generalized framework for proving robustness properties of smoothed machine learning models, even without internal knowledge of the network, could facilitate better scalability and performance of models against adversarial attacks or noise.", "venue": "ICLR", "year": 2020, "title": "A FRAMEWORK FOR ROBUSTNESS CERTIFICATION OF SMOOTHED CLASSIFIERS USING F-DIVERGENCES"}
{"pid": "6257c5c95aee126c0f46a9c8", "context": "In the set2vec problem, or the task of extracting vector representations from an input set of variable number of feature vectors, recent models like transformers have seen success. However, such models have high computational costs. Alternatives like inducing-point attention and optimal transport kernel embedding (OTKE) aim to reduce computational cost, but employ fixed learnable queries in attention, which may be limiting.", "key_idea": "The authors approach the set2vec problem from a new perspective, treating the elements of an input set as i.i.d. samples from a mixture distribution, and define the set embedding network as the maximum-a-posteriori estimate of the mixture, approximately computed by a few differentiable Expectation-Maximization (EM) steps.", "method": "The authors' methodology involves creating differentiable Maximum A Posteriori-Expectation Maximization (MAP-EM) steps in a feed-forward network. They also propose an unsupervised set representation learning framework that maximizes marginal likelihood, or empirical Bayes.", "outcome": "Their proposed method is shown to provide more flexible set embedding and model regularization compared to OTKE, and the authors demonstrate improved performance over state-of-the-art on various tasks.", "future_impact": "The novel perspective on set2vec problem and the proposed method allows for greater flexibility and improved performance in set embedding, demonstrating potential for further developments in this area of study.", "venue": "ICLR", "year": 2022, "title": "Differentiable Expectation-Maximization for Set Representation Learning"}
{"pid": "5f7c53f091e0117ac2a78bd5", "context": "The rise in generative modeling and adversarial learning has spurred interest in smooth games, but the absence of symmetry in the matrix of second derivatives presents challenges not present in classical minimization. Current understanding in the context of smooth games is limited due to the absence of a developed average-case analysis.", "key_idea": "The authors propose first-order methods to close this gap by providing average-case analysis for a subset of smooth games", "method": "This study develops three methods for zero-sum bilinear games, namely minimization of the Hamiltonian, providing an explicit expression for the optimal method corresponding to normal matrices, and specializing it to matrices with eigenvalues located in a disk.", "outcome": "The authors demonstrated a provable speed-up compared to worst-case optimal algorithms for matrices with eigenvalues located in a disk.", "future_impact": "The author's benchmarks suggest that these findings may influence future studies requiring average-case analysis for smooth games.", "venue": "ICLR", "year": 2021, "title": "Average-case Acceleration for Bilinear Games and Normal Matrices"}
{"pid": "600833be9e795ed227f531b9", "context": "Deep reinforcement learning training in visually complex 3D environments has historically been time-consuming and computationally expensive.", "key_idea": "The authors propose the concept of \u201cbatch simulation\u201d, where a 3D renderer and environment simulator are designed to execute large batches of simulation requests simultaneously, allowing for the amortization of storage, rendering, data loading, and synchronization costs across these requests.", "method": "The authors build a computationally efficient policy Deep Neural Network (DNN) that maintains high task performance, modify training algorithms to work efficiently with large mini-batches, and combine the batch simulation approach with DNN performance optimizations.", "outcome": "The proposed approach achieves training speeds of over 19,000 frames of experience per second on a single GPU, and up to 72,000 frames per second on an eight-GPU machine. In a test case, PointGoal navigation agents were trained in complex 3D environments on a single GPU in 1.5 days to 97% of the accuracy of agents trained on a prior state-of-the-art system using a 64-GPU cluster over three days.", "future_impact": "The authors provide open-source reference implementations of their batch 3D renderer and simulator, which can be incorporated into current and future reinforcement learning systems, potentially increasing their efficiency.", "venue": "ICLR", "year": 2021, "title": "Large Batch Simulation for Deep Reinforcement Learning"}
{"pid": "5f9aa10891e0114d7e781496", "context": "Recurrent Neural Networks (RNNs) are widely used in various applications, but how RNNs solve particular tasks is not well understood, especially in terms of the dynamical patterns they exhibit and how these patterns depend on the training data or task.", "key_idea": "In the context of text classification, this study proposes that text-classification networks use low-dimensional attractor manifolds to accumulate evidence for each class as they process the text, with the dimensionality and geometry of the attractor manifold determined by the structure of the training dataset.", "method": "The authors study RNNs dynamics in text-classification tasks beyond binary cases, using both natural and synthetic datasets. They analyse the dimensionality of the attractor manifolds in categorical classification and examine how correlations in the dataset influence these manifolds.", "outcome": "The study reveals that the dimensionality of the attractor manifold in categorical classification is one less than the number of classes and can be further reduced by correlations in the dataset, with this reduction predictable using simple word-count statistics computed on the training dataset.", "future_impact": "The findings may contribute to the ongoing efforts to use dynamical systems techniques to better understand the inner workings of RNNs, potentially leading to enhanced optimization and performance.", "venue": "ICLR", "year": 2021, "title": "The geometry of integration in text classification RNNs"}
{"pid": "619eff085244ab9dcbdda24d", "context": "Rate-distortion (R-D) function, a fundamental limit in information theory, helps researchers understand how much a data source can be compressed. However, previous works either relied on distributional assumptions on the data source or only applied to discrete data.", "key_idea": "This paper proposes a first-of-its-kind algorithm for sandwiching the R-D function of a general data source (not necessarily discrete) which requires only i.i.d. data samples.", "method": "To test the algorithm, the R-D sandwich bounds are estimated on Gaussian and high-dimension banana-shaped sources as well as GAN-generated images.", "outcome": "The R-D upper bound sandwiched on natural images shows there is room for improving the performance of state-of-the-art image compression methods by 1 dB in PSNR at various bitrates.", "future_impact": "The new method provides an opportunity for significant improvements in the performance of future image compression methods.", "venue": "ICLR", "year": 2021, "title": "Towards Empirical Sandwich Bounds on the Rate-Distortion Function"}
{"pid": "620dbcfa5aee126c0f5db47f", "context": "Graph Injection Attack (GIA) has emerged as a practical threat to Graph Neural Networks (GNNs), outperforming the traditional Graph Modification Attack (GMA) in its effectiveness due to its flexibility. However, little is known about why GIA is successful and whether there are any pitfalls.", "key_idea": "The researchers discovered that while GIA attacks are more effective due to their increased flexibility, they also distort the homophily distribution of the original graph. To counter this, they propose a novel constraint, termed homophily unnoticeability, to preserve the homophily during a GIA attack using the Harmonious Adversarial Objective (HAO).", "method": "They compared GIA and GMA to understand the power of GIA and proposed HAO to test if it preserves the homophily during a GIA attack. They conducted extensive experiments to verify the effectiveness of GIA with HAO against homophily-based defenses.", "outcome": "The experiments show that GIA attacks bolstered with HAO are able to evade homophily-based defenses and significantly outperform previous GIA attacks.", "future_impact": "The researchers' methods provide a more reliable evaluation of the robustness of GNNs and can assist in developing more effective defenses against sophisticated attacks like GIA in the future.", "venue": "ICLR", "year": 2022, "title": "Understanding and Improving Graph Injection Attack by Promoting Unnoticeability"}
{"pid": "626603225aee126c0f23394d", "context": "The existing research presents an absence of non-asymptotic global convergence guarantees for wide neural networks (NNs) undergoing optimization through gradient flow (GF). The feature-learning capabilities of these wide NNs also need to be explored.", "key_idea": "The authors address optimization of wide neural networks under the mean-field scaling and with a general class of activation functions. For both single-layer and multi-layer architectures, they ensure that the training loss converges to zero at a linear rate under GF.", "method": "The authors undertake optimization of wide shallow NNs and a model of wide multi-layer NNs whose second-to-last layer is trained via GF with the input dimension no less than the size of the training set. Additionally, empirical testing is conducted to compare the feature-learning and generalization performance of the multi-layer model with its Neural Tangent Kernel (NTK) counterpart.", "outcome": "It is confirmed that under GF, the training loss for both wide shallow NNs and the multi-layer model converges to zero at a linear rate. Comparative analysis shows that unlike NTK regime, the multi-layer model exhibits feature learning and has superior generalization performance.", "future_impact": "The study provides a foundation from which further exploration into feature learning capabilities in different neural network models with global convergence guarantees could be conducted.", "venue": "ICLR", "year": 2022, "title": "On feature learning in neural networks with global convergence guarantees"}
{"pid": "617771bd5244ab9dcbe795ce", "context": "Humans are known for their efficient exploration of new environments. However, the computational cognitive mechanisms supporting this efficiency have not been fully understood, posing a challenge to advancing the study of the human mind and developing more efficient exploration algorithms.", "key_idea": "The authors hypothesize that humans explore new environments efficiently by inferring the structure of unobserved spaces using spatial information collected from previously explored spaces. They propose a model based on program induction in a Hierarchical Bayesian framework, which explicitly reasons about uncertainty with strong spatial priors.", "method": "The authors use a new behavioral Map Induction Task to test their computational framework and compare it with non-inductive models and state-of-the-art planning algorithms applied to a realistic spatial navigation domain.", "outcome": "The results show that their computational framework explains human exploration behavior better than non-inductive models and outperforms state-of-the-art planning algorithms in a realistic spatial navigation domain.", "future_impact": "This study paves the way for advancing the understanding of human cognitive mechanism and enhancing algorithmic exploration efficiency, which could benefit various fields such as robotics and AI navigation.", "venue": "ICLR", "year": 2022, "title": "Map Induction: Compositional spatial submap learning for efficient exploration in novel environments"}
{"pid": "616ce5a15244ab9dcbacfcf3", "context": "Deep Generative Networks (DGNs) are used to approximate data manifolds and distributions. However, training samples often have biases due to factors like preference, cost, and convenience, which in turn generate artifacts that are reproduced in sampling from the trained DGN creating potential implications for fairness, data augmentation, anomaly detection, and domain adaptation.", "key_idea": "The paper proposes a differential geometry based sampler, MaGNET, which generates samples that are uniformly distributed on the learned manifold of a trained DGN, regardless of the training set distribution.", "method": "The authors conduct theoretical and empirical evaluations of the proposed technique. They perform a range of experiments on various datasets and DGNs, including one with the state-of-the-art StyleGAN2 trained on the FFHQ dataset.", "outcome": "The experiments show that uniform sampling via MaGNET increases distribution precision and recall by 4.1% & 3.0%, and decreases gender bias by 41.2%, without requiring labels or retraining.", "future_impact": "The proposed technique could improve fairness, data augmentation, anomaly detection, and domain adaptation by reducing biases in the sampling from trained DGNs.", "venue": "ICLR", "year": 2022, "title": "MaGNET: Uniform Sampling from Deep Generative Network Manifolds Without Retraining"}
{"pid": "6241273e5aee126c0f292b4a", "context": "Adversarial Training (AT) has been identified as an effective approach for enhancing the robustness of deep neural networks. Recently, it was observed that robust models created with AT can generate realistic images, but the reasons for this ability are not well understood.", "key_idea": "The authors propose a unified probabilistic framework, called Contrastive Energy-based Models (CEM), aiming to explain the generative abilities of models trained with Adversarial Training.", "method": "Robustness and generative ability are characterized probabilistically for AT within the unified framework. Additionally, the authors utilize this understanding to develop adversarial learning and sampling methods and evaluate them using experiments.", "outcome": "The adversarial learning and sampling methods derived from the framework improved sample quality in both supervised and unsupervised learning scenarios. Particularly, the unsupervised adversarial sampling method notched an Inception score of 9.61 on CIFAR-10, outperforming previous energy-based models and equalling top-tier generative models.", "future_impact": "The probabilistic understanding provided by the authors could play a crucial role in further developing adversarial training and sampling methodologies, leading to potential advancements in the quality of generated images.", "venue": "ICLR", "year": 2022, "title": "A Unified Contrastive Energy-based Model for Understanding the Generative Ability of Adversarial Training"}
{"pid": "6257c5af5aee126c0f468676", "context": "Traditional machine learning methods applied to imaging data for neurological and neuropsychiatric disease don't effectively model heterogeneity of disease effects or are often not interpretable. Also, semi-supervised clustering methods tend to overlook disease heterogeneity along spatial and temporal continuum and can mistakenly focus on nuisance factors rather than relevant pathological variance.", "key_idea": "Surreal-GAN, a novel method using cross-sectional imaging data, is proposed to dissect disease-related heterogeneity under semi-supervised clustering, providing a continuously dimensional representation and inferring the severity of the disease in individual patients along each dimension.", "method": "The model first learns a transformation function from normal control domain to the patient domain with latent variables controlling transformation directions. An inverse mapping function, along with function continuity, pattern orthogonality and monotonicity, is imposed to ensure significant clinical imaging patterns. The method was validated through semi-synthetic experiments and applied to Alzheimer's disease imaging patterns.", "outcome": "The model was shown to capture biologically plausible imaging patterns in patients with Alzheimer's disease, demonstrating its effectiveness in capturing disease-related heterogeneity.", "future_impact": "Surreal-GAN has potential for broad applications in understanding heterogeneous disease patterns in imaging data for various neurological and neuropsychiatric diseases, going forward.", "venue": "ICLR", "year": 2022, "title": "Surreal-GAN: Semi-Supervised Representation Learning via GAN for uncovering heterogeneous disease-related imaging patterns."}
{"pid": "600831219e795ed227f53099", "context": "Dynamic visual reasoning on raw videos is challenging due to the requirement for dense supervision on physical object properties and events from simulation, which is impractical in real-life scenarios.", "key_idea": "The authors introduce the Dynamic Concept Learner (DCL), a unified framework that grounds physical objects and events from video and language, sidestepping the need for dense supervision from simulations.", "method": "DCL uses a trajectory extractor to track objects over time, approximates dynamic interactions using graph networks, leverages a semantic parser to interpret questions, and a program executor to run parsed programs. DCL was trained and tested on CLEVRER, a video reasoning dataset, and a newly proposed video-retrieval and event localization dataset derived from CLEVRER.", "outcome": "DCL achieved state-of-the-art performance on the CLEVRER dataset without requiring ground-truth attributes and collision labels from simulations for training. Additionally, it demonstrated strong generalization capacity on a newly proposed video-retrieval and event localization dataset derived from CLEVRER.", "future_impact": "DCL's ability to detect and associate objects across frames, ground visual properties and physical events, understand the causal relationship between events, make future and counterfactual predictions, and answer queries could lead to advancements in the field of dynamic visual reasoning.", "venue": "ICLR", "year": 2021, "title": "Grounding Physical Object and Event Concepts Through Dynamic Visual Reasoning"}
{"pid": "613586d45244ab9dcbd3a2fa", "context": "The current language models struggle with zero-shot learning abilities, and the research gap lies in improving their proficiency in unseen tasks.", "key_idea": "The authors introduce instruction tuning, a method for finetuning language models on a collection of tasks explained via instructions, to enhance zero-shot performance on previously unseen tasks.", "method": "A 137B parameter pretrained language model was finetuned on over 60 NLP tasks using natural language instruction templates. This instruction-tuned model, FLAN, was then evaluated on unseen task types.", "outcome": "FLAN significantly improved its performance compared to its unmodified counterpart, surpassing zero-shot 175B GPT-3 on 19 out of 25 evaluated tasks. Moreover, FLAN outperformed few-shot GPT-3 considerably in tasks such as ANLI, RTE, BoolQ, AI2-ARC, OpenbookQA, and StoryCloze.", "future_impact": "The authors identified the number of tasks and model scale as key components for successful instruction tuning, which provides a direction for future research and model optimization.", "venue": "ICLR", "year": 2022, "title": "Finetuned Language Models are Zero-Shot Learners"}
{"pid": "5e5e18b993d709897ce2adaf", "context": "The effective use of deep neural networks in Multi-Task Reinforcement Learning has traditionally faced challenges due to individual task representation.", "key_idea": "The study leverages the assumption that learning from different tasks sharing common properties can help to generalize the knowledge of them, resulting in more effective feature extraction compared to learning a single task.", "method": "The authors extend the well-known finite-time bounds of Approximate Value-Iteration to the multi-task setting and propose multi-task extensions of three Reinforcement Learning algorithms. These models are then empirically evaluated on widely used Reinforcement Learning benchmarks.", "outcome": "The paper provides theoretical guarantees highlighting conditions for which sharing representations is convenient among tasks. The proposed multi-task extensions show significant improvements over the single-task counterparts in terms of sample efficiency and performance.", "future_impact": "The study suggests that sharing representations among tasks in Multi-Task Reinforcement Learning could lead to significant performance improvements, indicating potentially important implications for the design of future Reinforcement Learning algorithms.", "venue": "ICLR", "year": 2024, "title": "Sharing Knowledge in Multi-Task Deep Reinforcement Learning"}
{"pid": "600831e59e795ed227f530d2", "context": "While most research in the area of uncertainty estimation has focused on un-structured prediction tasks, limited work has been done on uncertainty estimation approaches for structured prediction tasks.", "key_idea": "This paper proposes to investigate uncertainty estimation for structured prediction tasks within a single unified and interpretable probabilistic ensemble-based framework.", "method": "The paper explores uncertainty estimation for token-level and complete sequence-level data, measuring and interpreting uncertainty, and addressing theoretical and practical challenges. Various baselines for token-level and sequence-level error detection, and sequence-level out-of-domain input detection were provided on the WMT\u201914 English-French and WMT\u201917 English-German translation and LibriSpeech speech recognition datasets.", "outcome": "The paper does not provide specific results in the abstract.", "future_impact": "The uncertainty estimation in structured prediction tasks could help in ensuring safety and robustness of AI systems.", "venue": "ICLR", "year": 2021, "title": "Uncertainty Estimation in Autoregressive Structured Prediction"}
{"pid": "5edb32399e795ec54fd81737", "context": "The design of deep graph models is a largely open area of research, with a key challenge being how to effectively explore and exploit the knowledge from different hops of neighbors.", "key_idea": "The paper introduces AdaGCN, an innovative RNN-like deep graph neural network architecture that incorporates AdaBoost into its computation, enabling the efficient extraction of knowledge from high-order neighbors of nodes and the integration of knowledge from different hops of neighbors in an AdaBoost manner.", "method": "AdaGCN's design and performance are evaluated and contrasted with existing approaches in extensive experiments on prediction tasks on graphs across different label rates.", "outcome": "The experiments show that AdaGCN outperforms existing methods in terms of prediction performance on graphs across different label rates, and the computational advantage of this approach is demonstrated.", "future_impact": "The theoretical establishment of the connection between AdaGCN and existing graph convolutional methods delineates the benefits of the proposed architecture and can provide new directions in the development of future deep graph models.", "venue": "ICLR", "year": 2021, "title": "AdaGCN - Adaboosting Graph Convolutional Networks into Deep Models."}
{"pid": "5f04608291e0114d4aaa4c1e", "context": "Many deep learning architectures are designed to be equivariant to certain transformations to improve generalization and conserve parameters. However, this approach requires prior knowledge of the task's symmetries and manual construction of an architecture with the corresponding equivariances.", "key_idea": "The authors propose a novel method for learning and encoding equivariances into networks by learning corresponding parameter sharing patterns from data, without the need for prior knowledge of a task's symmetries or custom task-specific architectures.", "method": "The method is designed to encode equivariance-inducing parameter sharing for any finite group of symmetry transformations, and its ability to automatically learn a variety of equivariances is evaluated using symmetries in data.", "outcome": "The experimental results demonstrate that the proposed method can automatically learn a variety of equivariances from symmetries found in the data.", "future_impact": "The proposed method for learning equivariances from data can be useful for tasks where symmetries are not known a priori, potentially simplifying the development of deep learning architectures.", "venue": "ICLR", "year": 2021, "title": "Meta-Learning Symmetries by Reparameterization"}
{"pid": "615fb6ef5244ab9dcb9c3c5c", "context": "Large Language Models (LMs) encode world knowledge through pretraining on vast amounts of web corpus. However, maintaining the knowledge up-to-date is challenging as it changes over time, and there are difficulties in reliably acquiring new knowledge while preserving invariant knowledge.", "key_idea": "The authors propose the concept of Continual Knowledge Learning (CKL), a continual learning approach designed to maintain up-to-date knowledge in language models without forgetting the invariant knowledge.", "method": "The authors constructed a new benchmark and metric to quantify the retention of time-invariant world knowledge, the update of outdated knowledge, and the acquisition of new knowledge. They also created several strong baselines using recent methods from literature.", "outcome": "Through extensive experiments, it was found that CKL presents unique challenges not addressed in previous continual learning setups, suggesting that parameter expansion is necessary to reliably retain and learn knowledge simultaneously.", "future_impact": "This work highlights the importance of addressing CKL, potentially leading to better understanding and training of ever-changing Language Models, contributing to more effective knowledge-dependent downstream tasks such as question answering, fact-checking, and open dialogue.", "venue": "ICLR", "year": 2022, "title": "Towards Continual Knowledge Learning of Language Models"}
{"pid": "6257c5b85aee126c0f4695a2", "context": "Stochastic Variational Inference is a dominant framework for learning large-scale probabilistic latent variable models, but typical assumptions on the factorization or independence of the latent variables may restrict its capacity for inference and generative modeling. The current trend is to build more expressive variational models by designing deep hierarchies of interdependent latent variables. However, these very deep models are facing diminishing returns in performance improvement and increased inference and training time.", "key_idea": "This paper proposes deep attentive variational autoencoder, which uses attention mechanisms to build more expressive variational distributions in deep probabilistic models, by explicitly modeling both local and global interactions in the latent space.", "method": "The deep attentive variational autoencoder is tested on a variety of established datasets to measure its performance and impact on training time.", "outcome": "The deep attentive variational autoencoder achieves state-of-the-art log-likelihoods while using fewer latent layers and requiring less training time than existing models.", "future_impact": "The proposed non-local inference mechanism could potentially reduce the computational footprint of future models by relieving the need for deep hierarchies.", "venue": "ICLR", "year": 2022, "title": "Deep Attentive Variational Inference"}
{"pid": "6257c5b45aee126c0f468e98", "context": "Existing deep generative memory models do not efficiently handle read and write operations and struggle with accurate retrieval of stored patterns, denoising of corrupted data, and generation of new samples.", "key_idea": "The authors propose Generative Pseudo-Inverse Memory (GPM), a class of deep generative memory models that leverages matrix pseudo-inverses for operation that are fast to read and write. The model can store a large dataset while maintaining key capabilities, and iteratively improves generating and denoising sample quality.", "method": "The authors empirically demonstrate the performance of the GPM model through a suite of experiments involving several datasets including binarized MNIST, binarized Omniglot, FashionMNIST, CIFAR10 & CIFAR100, and CelebA.", "outcome": "The results confirm that GPM can exactly retrieve what has been written to the memory under mild conditions and iteratively improve the quality of samples. It demonstrates efficiency and versatility on a comprehensive suite of different datasets.", "future_impact": "The GPM model may bring significant enhancements in accurate retrieving of stored patterns, denoising of corrupted data and generating novel samples for deep generative memory models.", "venue": "ICLR", "year": 2022, "title": "Generative Pseudo-Inverse Memory"}
{"pid": "5e5e18e793d709897ce3aff3", "context": "Recent continual learning methods largely alleviate the catastrophic forgetting problem on toy-sized datasets. However, they struggle with scalability, efficiency with a large number of tasks, and order-sensitivity, where task performance varies based on the order of task arrival.", "key_idea": "To overcome these challenges, the paper introduces a new continual learning approach called Additive Parameter Decomposition (APD), which represents each task's parameters as a sum of task-shared and sparse task-adaptive parameters.", "method": "The authors validate APD and its network variant, APD-Net, on multiple benchmark datasets and compare its performance against state-of-the-art continual learning methods.", "outcome": "The APD method and APD-Net outperformed state-of-the-art methods in terms of accuracy, scalability, and order-robustness in the experiments conducted on multiple benchmark datasets.", "future_impact": "The APD approach's computation and memory efficiency and its mitigation of catastrophic forgetting and order-sensitivity could inform and improve future continual learning implementations in real-world applications such as medical diagnoses.", "venue": "ICLR", "year": 2020, "title": "Scalable and Order-robust Continual Learning with Additive Parameter Decomposition"}
